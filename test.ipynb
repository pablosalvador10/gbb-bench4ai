{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory C:\\Users\\pablosal\\Desktop\\gbb-ai-upgrade does not exist.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the target directory (change yours)\n",
    "TARGET_DIRECTORY = r\"C:\\Users\\pablosal\\Desktop\\gbb-ai-upgrade\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(TARGET_DIRECTORY):\n",
    "    # Change the current working directory\n",
    "    os.chdir(TARGET_DIRECTORY)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {TARGET_DIRECTORY} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.performance.latencytest import AzureOpenAIBenchmarkStreaming, AzureOpenAIBenchmarkNonStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the environment variables using os.getenv\n",
    "OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_API_ENDPOINT\")\n",
    "DEPLOYMENT_ID = os.getenv(\"AZURE_AOAI_CHAT_MODEL_NAME_DEPLOYMENT_ID\")\n",
    "DEPLOYMENT_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_streaming = AzureOpenAIBenchmarkStreaming(api_key=OPENAI_API_KEY, \n",
    "                                                    azure_endpoint=AZURE_OPENAI_ENDPOINT, \n",
    "                                                    api_version=DEPLOYMENT_VERSION)\n",
    "\n",
    "benchmark_non_streaming = AzureOpenAIBenchmarkNonStreaming(api_key=OPENAI_API_KEY, \n",
    "                                                    azure_endpoint=AZURE_OPENAI_ENDPOINT, \n",
    "                                                    api_version=DEPLOYMENT_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 23:54:21,590 - micro - MainProcess - INFO     CPU usage: 13.7% (utils.py:log_system_info:233)\n",
      "2024-06-29 23:54:21,601 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "2024-06-29 23:54:21,620 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "2024-06-29 23:54:21,627 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "2024-06-29 23:54:22,117 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723262.1172395 snuck pathetic origin maintenance tugboat reader acquaintance decorous theme weather rubber wrapping property brown neck species democracy ark placid greatness supplier population weapon pacemaker mushroom hormone rustic vigorous barn cleric dude bush smash prospect primate service pie artist damp fencing step-grandfather icon oval aide rainstorm glider album suite veldt mud resistance balalaika in-joke temp transplantation terminal ambiguity freezer tutu do piece godfather grief bandanna self-esteem assorted yoyo lieutenant clipboard sightseeing authorisation pan parcel influx geometry cloud great-grandfather whispering herbs slap path inevitable contract precede treasury myth license switch compassion correlate unsuitable stalk distance borrow gale pamphlet gabby obsolete altar lid torte platter moai sandpaper boogeyman badger plea waterfront entertain fishery trolley terrible predict professor blogger harmonious apple yummy uncle debris hatchet normal ignore province faithful makeshift joint rabbi weight cotton towel drag win pause goldfish approval ashamed duel founder halt imperfect debtor divert jazz world octavo attendance hug grandfather urgency coral chronograph mambo convention die lackadaisical weave calcification departure moaning father tease algorithm toothpick adverb bachelor relation sunset accent bungalow hectare maple uniformity representation knock organize whine unit checkout karate discretion divan flatboat welcome evaluator coonskin gasp art office cravat dizzy outside shake faded gong engine candelabra clan appliance thankful renaissance ellipse give bagpipe crowd strive fleck cinnamon wampum independent jockey loving chalice altitude leading raft obscene poison soil futuristic goodie minute utensil outlook corridor playground bottom steamroller opossum hardboard laboratory capitalism algebra donor yang vulgar baker wedding rations wary casino long hunting workbench gaping mechanism solitaire news innervation jumper staff laparoscope grandmom live comedy improvise loophole silent clipboard radio misfit rate thyme tweezers spin blackboard mycoplasma glider statement status learn keyboarding nephew enter burglar acupuncture irony coffee poet systemize hubcap robe intervention decadence inspire rubric hiring frame small guitar fasten film appellation do specialist certainty invention puppet wraparound overflow dramatic agency adjoining innate fort foretell matrix bamboo chapel tuber feel snowboarding core clogs alb prize stacking bandolier penguin ground dibble mutt serval cappuccino squirrel foamy spoil achiever peak potty off-ramp quota remains bounce suitcase machinery stumbling sneaky preparation shoreline ashtray overjoyed normal likelihood patrimony gadget defense belligerent piglet extreme ozone albatross spend itchy kindness tooth institution tablet navigate kendo doc flour footstool rainy democracy grip alliance cobbler picture somersault special spiritual inspiration shield unpack duckling accord wanting congo hop cyclamen senior pepper hash luck leaf boudoir base rain trek look sell percentage shelf perfume withstand medal cover nougat comfortable favorite yawn step-daughter linkage mixture latitude push realign ferryboat authenticity machine greedy litter scanner new racism saint scraper recommendation packet gravel furnace overconfident thank acid marshmallow political stroke void pet teepee spicy actress disagreement measly tranquil gymnast hospice secretary open coupon secretariat prepare contribution republic spotless remote grid lady merchant downstairs rocket-ship host undesirable fat cacao agenda mineral gripper integrate fix society orchestra gender ectoderm creative listen remind leader temporariness sincere design authority deficit darkness ascertain operating whistle glen ascent outrun probation halloween self-confidence marshland gasp portion disillusioned top pollutant effacement threshold robot cartoon chance lining management consulate smash chandelier grandiose dull indication liquor appetizer hot detailed blister weasel moron large doorway human hedge truculent oasis endoderm teletype accommodation lambkin presence divert noodles proofread seizure slap omission facilitate melted commitment hunchback tusk waist creationism kettle brownie gander abdomen component captor starboard praised eyebrow secure sub suffocation tune-up vanity symptom rehospitalization platinum primary cope turning quickest center nibble maggot big swimming candle tandem maple grin block clam cutting regionalism debt shanty bewildered uniform vacuum criteria housework daybed strive sac chateau zip hygienic inversion complicity small booster bottom decadence minibus rugby gauge macro contagion airmail steam gravitas printing personality boysenberry communicate report gig restaurant fabulous longboat pine deliver aquatic drake step-sister fennel delay underclothes uniformity initiative arise passion procedure commerce ladle jeweller preside case fedelini stamp peasant beset vague blessing trunk solvency secretion macaroni aquifer quality meet biscuit voice raven sink inject progress grassland storage contract prose meadow import freezer apologize diesel criterion lashes toffee eyelids knowledgeable snatch snowplow liver project feng question prosecution jaguar front fixture classy beat solid foolish mesenchyme mariachi estuary glossy shower mailing trigonometry licence watchful notepad prize sycamore muscatel'}, {'role': 'user', 'content': '1719723262.1172395 write a long essay about machine learning in at least 100 tokens'}] and Context Tokens: 1007 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723262.1172395 snuck pathetic origin maintenance tugboat reader acquaintance decorous theme weather rubber wrapping property brown neck species democracy ark placid greatness supplier population weapon pacemaker mushroom hormone rustic vigorous barn cleric dude bush smash prospect primate service pie artist damp fencing step-grandfather icon oval aide rainstorm glider album suite veldt mud resistance balalaika in-joke temp transplantation terminal ambiguity freezer tutu do piece godfather grief bandanna self-esteem assorted yoyo lieutenant clipboard sightseeing authorisation pan parcel influx geometry cloud great-grandfather whispering herbs slap path inevitable contract precede treasury myth license switch compassion correlate unsuitable stalk distance borrow gale pamphlet gabby obsolete altar lid torte platter moai sandpaper boogeyman badger plea waterfront entertain fishery trolley terrible predict professor blogger harmonious apple yummy uncle debris hatchet normal ignore province faithful makeshift joint rabbi weight cotton towel drag win pause goldfish approval ashamed duel founder halt imperfect debtor divert jazz world octavo attendance hug grandfather urgency coral chronograph mambo convention die lackadaisical weave calcification departure moaning father tease algorithm toothpick adverb bachelor relation sunset accent bungalow hectare maple uniformity representation knock organize whine unit checkout karate discretion divan flatboat welcome evaluator coonskin gasp art office cravat dizzy outside shake faded gong engine candelabra clan appliance thankful renaissance ellipse give bagpipe crowd strive fleck cinnamon wampum independent jockey loving chalice altitude leading raft obscene poison soil futuristic goodie minute utensil outlook corridor playground bottom steamroller opossum hardboard laboratory capitalism algebra donor yang vulgar baker wedding rations wary casino long hunting workbench gaping mechanism solitaire news innervation jumper staff laparoscope grandmom live comedy improvise loophole silent clipboard radio misfit rate thyme tweezers spin blackboard mycoplasma glider statement status learn keyboarding nephew enter burglar acupuncture irony coffee poet systemize hubcap robe intervention decadence inspire rubric hiring frame small guitar fasten film appellation do specialist certainty invention puppet wraparound overflow dramatic agency adjoining innate fort foretell matrix bamboo chapel tuber feel snowboarding core clogs alb prize stacking bandolier penguin ground dibble mutt serval cappuccino squirrel foamy spoil achiever peak potty off-ramp quota remains bounce suitcase machinery stumbling sneaky preparation shoreline ashtray overjoyed normal likelihood patrimony gadget defense belligerent piglet extreme ozone albatross spend itchy kindness tooth institution tablet navigate kendo doc flour footstool rainy democracy grip alliance cobbler picture somersault special spiritual inspiration shield unpack duckling accord wanting congo hop cyclamen senior pepper hash luck leaf boudoir base rain trek look sell percentage shelf perfume withstand medal cover nougat comfortable favorite yawn step-daughter linkage mixture latitude push realign ferryboat authenticity machine greedy litter scanner new racism saint scraper recommendation packet gravel furnace overconfident thank acid marshmallow political stroke void pet teepee spicy actress disagreement measly tranquil gymnast hospice secretary open coupon secretariat prepare contribution republic spotless remote grid lady merchant downstairs rocket-ship host undesirable fat cacao agenda mineral gripper integrate fix society orchestra gender ectoderm creative listen remind leader temporariness sincere design authority deficit darkness ascertain operating whistle glen ascent outrun probation halloween self-confidence marshland gasp portion disillusioned top pollutant effacement threshold robot cartoon chance lining management consulate smash chandelier grandiose dull indication liquor appetizer hot detailed blister weasel moron large doorway human hedge truculent oasis endoderm teletype accommodation lambkin presence divert noodles proofread seizure slap omission facilitate melted commitment hunchback tusk waist creationism kettle brownie gander abdomen component captor starboard praised eyebrow secure sub suffocation tune-up vanity symptom rehospitalization platinum primary cope turning quickest center nibble maggot big swimming candle tandem maple grin block clam cutting regionalism debt shanty bewildered uniform vacuum criteria housework daybed strive sac chateau zip hygienic inversion complicity small booster bottom decadence minibus rugby gauge macro contagion airmail steam gravitas printing personality boysenberry communicate report gig restaurant fabulous longboat pine deliver aquatic drake step-sister fennel delay underclothes uniformity initiative arise passion procedure commerce ladle jeweller preside case fedelini stamp peasant beset vague blessing trunk solvency secretion macaroni aquifer quality meet biscuit voice raven sink inject progress grassland storage contract prose meadow import freezer apologize diesel criterion lashes toffee eyelids knowledgeable snatch snowplow liver project feng question prosecution jaguar front fixture classy beat solid foolish mesenchyme mariachi estuary glossy shower mailing trigonometry licence watchful notepad prize sycamore muscatel'}, {'role': 'user', 'content': '1719723262.1172395 write a long essay about machine learning in at least 100 tokens'}] and Context Tokens: 1007\n",
      "2024-06-29 23:54:22,120 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:22,122 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 100 at (Local time): 2024-06-29 23:54:22.122545, (GMT): 2024-06-30 04:54:22.122545+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 100 at (Local time): 2024-06-29 23:54:22.122545, (GMT): 2024-06-30 04:54:22.122545+00:00\n",
      "2024-06-29 23:54:22,577 - micro - MainProcess - INFO     CPU usage: 15.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.0%\n",
      "2024-06-29 23:54:22,588 - micro - MainProcess - INFO     RAM usage: 86.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.4%\n",
      "2024-06-29 23:54:22,626 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:54:22,632 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:22,786 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723262.786404 ethics curtain investigator childhood centurion providence residue pretend undesirable clogs gnat pan oats typeface node briefly water grid demur journey dirt spine shopper laryngitis doubling swear steward calf damp trooper develop glutamate spin intellect canon half sentiment gamma-ray tacky ceramics appliance golf ark enemy staircase boon headlight beating configuration chop amuse sweatshop colonial teenager zoologist delightful objective vacuous director analog lightning championship set story-telling cannon conversion mom print glory chamber pit horizon loud unable shine grant interloper jail prior motorcar easy endothelium grey salad care acceptance rutabaga embryo analogue settler bloom probation modify reserve extinction likeable sentencing table gigantism tambourine transparency constraint nebulous platform earth boom hardboard tasteful stamina angel arrest enterprise tamale exploration ant jaw chalet mapping hunter essay tomography consider pocket-watch composition proposal dickey catcher final barley ice suede joke textual spree nougat hysterical leek nurture metabolite cylinder clipboard tassel little scope used pawnshop riot thrush howitzer overwrought diner passenger anthropology lose waterwheel cloud nose weekend doubtful grin x-ray macaroni tailor irate roof quartz hotdog harmonise goggles make graft ziggurat cap jacket size minimalism seller impact slime scooter vampire high-pitched ephemeris forgetful lily navigation remote aluminum burlesque rowboat spatula workout tobacco dysfunctional squalid apathetic coonskin census manufacturer lonely execute grandmother earnings persimmon prosecution abiding boxspring investigation movement spike counselor legal lightscreen domination void hurricane trillion stamp lend deed form scrub sloth detainee bust lentil simplification age hover invincible interpret attention divan finish beck yang cocktail mare reader barley spectacle penitent exercise pun tournament endpoint nucleotide lighten beach gumshoe normalisation confusion scale shiny messy eviction asphalt relative vintner grid tranquil parent sailor opposite thunderhead lysine guarded gram callous washer loft pocketbook dory coherent trade piglet yak sneak accessible mammoth appetite mime panther courthouse limo reproduce fright farming rag cable advise pressroom obey righteous puncture colossal mixture recess encourage dredger shy sell formulate honey cause crown garment hound bored diction underweight nitrogen drive anchovy x-ray compulsion marshland satisfying thesis mushroom reclamation threshold syndrome retrospect expensive eclipse watery capable glasses annoying sycamore woodwind website desk pumpkinseed star extract small tissue buck menu device cucumber melted announcement aluminium document burro petticoat globe trolley bore decongestant eliminate childbirth story bronchitis mind runaway killer distribution regulate nebulous lipstick creep administer reduction gaze piety union advocate balalaika poverty temper bleed hypnotic poke versed shadow tuna forelimb observe enforce hysterical directive cappelletti curve silly rocker painful chairperson coin animated pinto vixen warlike graphic sense catalogue vague inversion bag parched pannier stiletto behaviour electrocardiogram dead bough widow oboe mama erosion porpoise value aback rye usual cloud clone grocery convention questionnaire meter manacle quilt minor everyone rations apology affair fallacy gate seed offence tom-tom neck step-sister forest grade self-esteem bookmark advertising bombing shirt cephalopod trumpet fetus pseudocode macaw orientation mailer equality snarl raisin sprinter ivory pruner silly doubling detection forgery wildlife civilization principle texture withdraw piety noisy father permission object consequence deadpan ritzy cottage title clover laboratory kneejerk speculation viscose bugle complication chair describe jealousy reserve adaptation fillet boon rudiment multiply hoof injunction tuba hire parade hatchling behavior deodorant scary launch result aloof referendum turn mirror trot maiden wail printer mean homeownership weep abacus sunshine acrid moron doll sparkle bitter minibus sash silo newsstand schooner stuff trombone action preface corporal larva consulate cappuccino trench futuristic witch careful cornerstone historical tasteless oatmeal enchanting naughty pear representative plumber talent game fish league membrane trance opponent lose sturgeon man prow citizen borrower thongs multimedia snakebite seaside exam inflammation squealing behold pecan cowbell fold semicolon perception river iron snuck blast select upper placement tenet pianist dangerous tributary grey lake concrete subject evocation yang devise brushing patriarch attendance dipstick blind inspect stick crabby digger detainee landmine beancurd dramatic crinoline stance duration bulb ford peek citizen marmalade cod valley forest broiler earthworm maestro sanctity reply sandwich hovel adapt mini vessel underpass heat fallacious thongs subroutine temptress observation damaging cartridge shirt tensor porcelain criticism quiche jumpsuit access percentage multimedia click begin waterwheel string abiding mist waist venison dig angstrom rich creation spray violation voice diner watcher homosexual peaceful primary butterfly laborer stole interferometer silkworm tritone sincere scrim nightlight postfix ambassador blazer immigrant carbon carol panda standardisation colon capable'}, {'role': 'user', 'content': '1719723262.786404 write a long essay about machine learning in at least 150 tokens'}] and Context Tokens: 1006 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723262.786404 ethics curtain investigator childhood centurion providence residue pretend undesirable clogs gnat pan oats typeface node briefly water grid demur journey dirt spine shopper laryngitis doubling swear steward calf damp trooper develop glutamate spin intellect canon half sentiment gamma-ray tacky ceramics appliance golf ark enemy staircase boon headlight beating configuration chop amuse sweatshop colonial teenager zoologist delightful objective vacuous director analog lightning championship set story-telling cannon conversion mom print glory chamber pit horizon loud unable shine grant interloper jail prior motorcar easy endothelium grey salad care acceptance rutabaga embryo analogue settler bloom probation modify reserve extinction likeable sentencing table gigantism tambourine transparency constraint nebulous platform earth boom hardboard tasteful stamina angel arrest enterprise tamale exploration ant jaw chalet mapping hunter essay tomography consider pocket-watch composition proposal dickey catcher final barley ice suede joke textual spree nougat hysterical leek nurture metabolite cylinder clipboard tassel little scope used pawnshop riot thrush howitzer overwrought diner passenger anthropology lose waterwheel cloud nose weekend doubtful grin x-ray macaroni tailor irate roof quartz hotdog harmonise goggles make graft ziggurat cap jacket size minimalism seller impact slime scooter vampire high-pitched ephemeris forgetful lily navigation remote aluminum burlesque rowboat spatula workout tobacco dysfunctional squalid apathetic coonskin census manufacturer lonely execute grandmother earnings persimmon prosecution abiding boxspring investigation movement spike counselor legal lightscreen domination void hurricane trillion stamp lend deed form scrub sloth detainee bust lentil simplification age hover invincible interpret attention divan finish beck yang cocktail mare reader barley spectacle penitent exercise pun tournament endpoint nucleotide lighten beach gumshoe normalisation confusion scale shiny messy eviction asphalt relative vintner grid tranquil parent sailor opposite thunderhead lysine guarded gram callous washer loft pocketbook dory coherent trade piglet yak sneak accessible mammoth appetite mime panther courthouse limo reproduce fright farming rag cable advise pressroom obey righteous puncture colossal mixture recess encourage dredger shy sell formulate honey cause crown garment hound bored diction underweight nitrogen drive anchovy x-ray compulsion marshland satisfying thesis mushroom reclamation threshold syndrome retrospect expensive eclipse watery capable glasses annoying sycamore woodwind website desk pumpkinseed star extract small tissue buck menu device cucumber melted announcement aluminium document burro petticoat globe trolley bore decongestant eliminate childbirth story bronchitis mind runaway killer distribution regulate nebulous lipstick creep administer reduction gaze piety union advocate balalaika poverty temper bleed hypnotic poke versed shadow tuna forelimb observe enforce hysterical directive cappelletti curve silly rocker painful chairperson coin animated pinto vixen warlike graphic sense catalogue vague inversion bag parched pannier stiletto behaviour electrocardiogram dead bough widow oboe mama erosion porpoise value aback rye usual cloud clone grocery convention questionnaire meter manacle quilt minor everyone rations apology affair fallacy gate seed offence tom-tom neck step-sister forest grade self-esteem bookmark advertising bombing shirt cephalopod trumpet fetus pseudocode macaw orientation mailer equality snarl raisin sprinter ivory pruner silly doubling detection forgery wildlife civilization principle texture withdraw piety noisy father permission object consequence deadpan ritzy cottage title clover laboratory kneejerk speculation viscose bugle complication chair describe jealousy reserve adaptation fillet boon rudiment multiply hoof injunction tuba hire parade hatchling behavior deodorant scary launch result aloof referendum turn mirror trot maiden wail printer mean homeownership weep abacus sunshine acrid moron doll sparkle bitter minibus sash silo newsstand schooner stuff trombone action preface corporal larva consulate cappuccino trench futuristic witch careful cornerstone historical tasteless oatmeal enchanting naughty pear representative plumber talent game fish league membrane trance opponent lose sturgeon man prow citizen borrower thongs multimedia snakebite seaside exam inflammation squealing behold pecan cowbell fold semicolon perception river iron snuck blast select upper placement tenet pianist dangerous tributary grey lake concrete subject evocation yang devise brushing patriarch attendance dipstick blind inspect stick crabby digger detainee landmine beancurd dramatic crinoline stance duration bulb ford peek citizen marmalade cod valley forest broiler earthworm maestro sanctity reply sandwich hovel adapt mini vessel underpass heat fallacious thongs subroutine temptress observation damaging cartridge shirt tensor porcelain criticism quiche jumpsuit access percentage multimedia click begin waterwheel string abiding mist waist venison dig angstrom rich creation spray violation voice diner watcher homosexual peaceful primary butterfly laborer stole interferometer silkworm tritone sincere scrim nightlight postfix ambassador blazer immigrant carbon carol panda standardisation colon capable'}, {'role': 'user', 'content': '1719723262.786404 write a long essay about machine learning in at least 150 tokens'}] and Context Tokens: 1006\n",
      "2024-06-29 23:54:22,790 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:22,793 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 150 at (Local time): 2024-06-29 23:54:22.793099, (GMT): 2024-06-30 04:54:22.793099+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 150 at (Local time): 2024-06-29 23:54:22.793099, (GMT): 2024-06-30 04:54:22.793099+00:00\n",
      "2024-06-29 23:54:22,796 - micro - MainProcess - INFO     CPU usage: 32.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 32.8%\n",
      "2024-06-29 23:54:22,804 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 23:54:22,819 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:54:22,824 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:23,020 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723263.0202134 modify broom shawl sloth businessman thug bruise opening variant solve beastie memory furtive ill think university specification watcher earthquake inauguration lens policy dream shine mountain swath pitcher history campaign quiche embassy wit signal flag pseudoscience disposer anger motionless invasion vitamin protection meatloaf swanling halibut dashboard tatami dud belong humor pannier teller vodka earsplitting bedroom caper conductor invoice parade broadcast entrance shack probation automation moron optimisation yolk orchid heaven hot passenger town data midnight childbirth actor pretzel bud fedelini exuberant sir parking pressroom spacing handsomely melted pantology lick fir motorboat brilliant scrutiny nobody replacement manacle pickaxe boon cloistered cilantro mortality rate tuba alluring hare verse ostrich rehospitalization operating coil fob carbon ruling ethereal peak barber heater galoshes waiver correspondent wisteria stopsign spring wont harmonise optimist asymmetry foam carotene waveform refreshments convertible rebel gynaecology number sandal outside astrologer underwear mankind founding pentagon conga decoration spit incubation ambiguous tray accelerate syrup washbasin service squash suggest creationist format therapist iceberg almond compassionate seafood trap inequality prefix patroller nit secrecy honeydew duck coconut funny catalog diagnose granola passion commodity admire practitioner location official stake playwright compose consumer beach quiet willing newsprint general festival maggot implementation mineshaft pain elbow empty mom talent endothelium approach attachment illustrate doorknob script synergy define industry camp chalice pumpernickel sanity soft squeegee seizure angiosperm obscene bay armrest hydrogen jewellery gather clearance psychiatrist toot toothsome winner cassock elk sill sesame attainment knowledgeable bathrobe chemical reconcile luxuriant buffer province weary countryside vague fugato poker ceramic curve location congress local barbeque rescue kaput caddy fashion alike high-pitched cartload tic premise originality concrete competition queen reflective grace pianist usage escort camp liability speedboat derivation panpipe ethics class directive catcher hops verbalize brain achiever reader undertaker manner residue iridescence cartel cabinet concern whole pulley itinerary stamen caper download flair weakness sell pinstripe cut source embossing stew walkway contributor grey spool safety diam legislature zip ellipse eve integrity toilet pomelo rapid dealer moonscape voter chubby war privilege spat talk parchment fighter people argue abundant poke gasp pudding glen mortal theory educate mansard match legend voyage context island category gasoline hug wiring lieutenant rowing bangle insurgence rinse heady differential polish fact kit flower moonshine frigate pathetic kohlrabi deed illness trout sundial tightfisted gender omelet wiseguy paper shark moccasins back gallery hypothesis book legitimacy makeup embassy coral fear randomization radiosonde simplify revolver gearshift queue aftermath modification conceptualize transformation assembly scrape cottage harp reign human luck community negotiate empire nutritious pike mom shelter fibrosis intent cupboard paddock spokesman reservation account bungalow downtown gaudy leather voyage interconnection count undesirable insomnia pass maternity inspiration withdrawal attempt habitual numerous cabbage meteor turtle spur banking foamy wrap maniacal boulder championship hassock raincoat particle cloistered patrolling periodical basket monasticism trick road glance navigation prayer plume bottom sushi lending monotheism complex aid scholar geometry purchase angora septicaemia custom soot counseling circumstance slit outlet pint eyeglasses agriculture collectivization imprisonment colonisation coordinator prefix clarity ethics bag wary barracks wedge friend gopher biopsy cocktail commerce conservative hike many mineral resolve catcher alder blinker quartet cleric wear oxford prove inexpensive subgroup radar pinpoint slippers alpha booty whole clergyman utopian wraparound oversight infiltration blessing wasting armadillo corner pasture afternoon destiny bargain steward aberrant burlesque dozen pulse chateau lot waterwheel soldier grieving nerve cashier kindhearted crown mark paper refrigerator nosy versed coaster humdrum shakedown decorate mature harmony carol decision editing piracy pinkie gradient eatable teach officiate forum thirsty pinafore word purchase smolt gaffe progression tension psychotic messenger ex-wife ownership cutover target shout silent disprove vivacious mozzarella sticker boxspring simplification instinctive sale lovely cereal classmate trowel noodle piety interchange shaker sphynx stacking type lung share till ironclad pledge raiment apology premium culvert egghead disconnection enforce soul xylophone gang dragster skating post doctor canon hose smite retrospective jealousy nutrient dynamite origin careful rose codling venue jazzy gander proprietor delight boiling kumquat steep grandfather statue haven parenting clogs abandoned judgment guinea used entirety cashier overtake oafish colonial macaw value relish ritual frightened ritzy complexity stepdaughter blast fava weave fish accurate grandparent birth deserted paragraph bind acoustic yellow marathon dock turnip millstone fanny-pack ferry illusion millet scooter masterpiece browsing colorlessness afterlife pilgrim negligee scalp expect'}, {'role': 'user', 'content': '1719723263.0202134 write a long essay about machine learning in at least 250 tokens'}] and Context Tokens: 1005 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723263.0202134 modify broom shawl sloth businessman thug bruise opening variant solve beastie memory furtive ill think university specification watcher earthquake inauguration lens policy dream shine mountain swath pitcher history campaign quiche embassy wit signal flag pseudoscience disposer anger motionless invasion vitamin protection meatloaf swanling halibut dashboard tatami dud belong humor pannier teller vodka earsplitting bedroom caper conductor invoice parade broadcast entrance shack probation automation moron optimisation yolk orchid heaven hot passenger town data midnight childbirth actor pretzel bud fedelini exuberant sir parking pressroom spacing handsomely melted pantology lick fir motorboat brilliant scrutiny nobody replacement manacle pickaxe boon cloistered cilantro mortality rate tuba alluring hare verse ostrich rehospitalization operating coil fob carbon ruling ethereal peak barber heater galoshes waiver correspondent wisteria stopsign spring wont harmonise optimist asymmetry foam carotene waveform refreshments convertible rebel gynaecology number sandal outside astrologer underwear mankind founding pentagon conga decoration spit incubation ambiguous tray accelerate syrup washbasin service squash suggest creationist format therapist iceberg almond compassionate seafood trap inequality prefix patroller nit secrecy honeydew duck coconut funny catalog diagnose granola passion commodity admire practitioner location official stake playwright compose consumer beach quiet willing newsprint general festival maggot implementation mineshaft pain elbow empty mom talent endothelium approach attachment illustrate doorknob script synergy define industry camp chalice pumpernickel sanity soft squeegee seizure angiosperm obscene bay armrest hydrogen jewellery gather clearance psychiatrist toot toothsome winner cassock elk sill sesame attainment knowledgeable bathrobe chemical reconcile luxuriant buffer province weary countryside vague fugato poker ceramic curve location congress local barbeque rescue kaput caddy fashion alike high-pitched cartload tic premise originality concrete competition queen reflective grace pianist usage escort camp liability speedboat derivation panpipe ethics class directive catcher hops verbalize brain achiever reader undertaker manner residue iridescence cartel cabinet concern whole pulley itinerary stamen caper download flair weakness sell pinstripe cut source embossing stew walkway contributor grey spool safety diam legislature zip ellipse eve integrity toilet pomelo rapid dealer moonscape voter chubby war privilege spat talk parchment fighter people argue abundant poke gasp pudding glen mortal theory educate mansard match legend voyage context island category gasoline hug wiring lieutenant rowing bangle insurgence rinse heady differential polish fact kit flower moonshine frigate pathetic kohlrabi deed illness trout sundial tightfisted gender omelet wiseguy paper shark moccasins back gallery hypothesis book legitimacy makeup embassy coral fear randomization radiosonde simplify revolver gearshift queue aftermath modification conceptualize transformation assembly scrape cottage harp reign human luck community negotiate empire nutritious pike mom shelter fibrosis intent cupboard paddock spokesman reservation account bungalow downtown gaudy leather voyage interconnection count undesirable insomnia pass maternity inspiration withdrawal attempt habitual numerous cabbage meteor turtle spur banking foamy wrap maniacal boulder championship hassock raincoat particle cloistered patrolling periodical basket monasticism trick road glance navigation prayer plume bottom sushi lending monotheism complex aid scholar geometry purchase angora septicaemia custom soot counseling circumstance slit outlet pint eyeglasses agriculture collectivization imprisonment colonisation coordinator prefix clarity ethics bag wary barracks wedge friend gopher biopsy cocktail commerce conservative hike many mineral resolve catcher alder blinker quartet cleric wear oxford prove inexpensive subgroup radar pinpoint slippers alpha booty whole clergyman utopian wraparound oversight infiltration blessing wasting armadillo corner pasture afternoon destiny bargain steward aberrant burlesque dozen pulse chateau lot waterwheel soldier grieving nerve cashier kindhearted crown mark paper refrigerator nosy versed coaster humdrum shakedown decorate mature harmony carol decision editing piracy pinkie gradient eatable teach officiate forum thirsty pinafore word purchase smolt gaffe progression tension psychotic messenger ex-wife ownership cutover target shout silent disprove vivacious mozzarella sticker boxspring simplification instinctive sale lovely cereal classmate trowel noodle piety interchange shaker sphynx stacking type lung share till ironclad pledge raiment apology premium culvert egghead disconnection enforce soul xylophone gang dragster skating post doctor canon hose smite retrospective jealousy nutrient dynamite origin careful rose codling venue jazzy gander proprietor delight boiling kumquat steep grandfather statue haven parenting clogs abandoned judgment guinea used entirety cashier overtake oafish colonial macaw value relish ritual frightened ritzy complexity stepdaughter blast fava weave fish accurate grandparent birth deserted paragraph bind acoustic yellow marathon dock turnip millstone fanny-pack ferry illusion millet scooter masterpiece browsing colorlessness afterlife pilgrim negligee scalp expect'}, {'role': 'user', 'content': '1719723263.0202134 write a long essay about machine learning in at least 250 tokens'}] and Context Tokens: 1005\n",
      "2024-06-29 23:54:23,026 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:23,028 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 23:54:23.028985, (GMT): 2024-06-30 04:54:23.028985+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 23:54:23.028985, (GMT): 2024-06-30 04:54:23.028985+00:00\n",
      "2024-06-29 23:54:24,862 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:24,905 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.3 seconds or 1300.48 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.3 seconds or 1300.48 milliseconds.\n",
      "2024-06-29 23:54:31,734 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:31,737 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:31,739 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.12 seconds or 8124.52 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.12 seconds or 8124.52 milliseconds.\n",
      "2024-06-29 23:54:31,742 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.21 seconds or 8206.7 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.21 seconds or 8206.7 milliseconds.\n",
      "2024-06-29 23:54:32,734 - micro - MainProcess - INFO     CPU usage: 12.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.6%\n",
      "2024-06-29 23:54:32,745 - micro - MainProcess - INFO     RAM usage: 86.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.0%\n",
      "2024-06-29 23:54:32,784 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:54:32,790 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:32,893 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723272.893549 bronco panel understatement blister bustle penguin retrospect peek woodchuck borrowing tricky make thrust roundabout bathe gold gravitas reversal confirmation grove jerk denim sunlight float chronometer approval uniformity carbohydrate meme recess game towering footstep wind creep decade gondola lunchmeat meringue buzzard ellipse storey ultra clutch vision duty epee entrance eel bloodflow haven loan raise declination bartender puggle evidence choke accessible legacy facsimile environment upper educated flatboat confuse radiator hippopotamus kick statistic scholarship highway gripper bark collateral seemly heavy crack union official lard pressure ambiguous beggar invitation reset bad rescue copy mirror knight removal intensity length methodology sordid grubby manufacturing caddy sink nit edge adaptable fava paste muscle daffy till myth epic issue banking locomotive graduate lunge scrambled tandem cleft timbale pattypan obsolete viability madam visa palm dynamic pince-nez badge courtroom meter sulky equation chainstay selling succinct sponge maintenance pecan pinpoint extend pomegranate side resale platform xylophone neon concern custard veldt glee lute endpoint alder crinoline settler disconnection want equinox chamber monument plantation licorice connection mandarin yang junker pyramid oasis sniffle fisherman wharf bungalow wastebasket floor health-care question spork deadpan gaffer thaw ring washtub jiffy airbag ivory honorable fanny-pack latitude boxspring interval concrete historical underwear something rust volleyball bizarre gemsbok precedence activity furtive refusal buffet gossip transformation contour ankle gateway aside analgesia ascend pajamas medium petite cyclamen appear jewellery talented godly scheme scorch calculator hallway grid tongue enterprise prepare consignment new dock architecture lord drip sprout competition intelligence plot pegboard nestmate directory goldfish nightingale become steer deer declaration contrast crusader chuck suppression aperitif samovar mineral sprout peck throne redesign recipient colonisation coincidence anthropology deathwatch sulky pin purity dramatic background float patty copying disappear editing link lapdog ephemera thank length investigation golf yard marsh hippopotamus tiresome uncle architect inflammation housework bowtie generator clarinet hapless murky observation jacket dealing successful twister camera sum donation meal clause anger traveler resistance saloon obeisant vanadyl accessory appreciate prefix eyestrain pheasant finalize vacuous head exhaustion new chairperson comradeship almanac juggle basin ranch malice vellum cascade profession suspend fill jar accountability mattress panic insurance goodwill rust purring loop mislead taco stacking hearth acrylic locust buckwheat arch-rival prosecution innovate plywood cello libido ocelot ability opposition blow mangle pardon extension belfry freelance vibe vet see influx woman cursor spill cupboard temporariness rail aberrant surprise kindness boost take-out calm borrowing archives afternoon t-shirt comestible antibody exultant pack ramen cravat event cleavage gaming slip photographer emergency aglet tasty attorney threatening step-aunt classroom tricky ischemia flap lynx memo accountability lover settler owe ruddy haze prosperity employ cub plover wrestler contest measure confidence wit patrol association sip thunderhead talk theism tritone existence haunt prostacyclin waste brisket phosphate calcification entity sausage rice jaw complex gaming armchair enactment population grandpa bench divergent rehabilitate moustache jackal official discharge clock parable bloody eyeball torso dressing alpha blizzard picture qualify liability determination piracy pizza psychology illusion clam jodhpurs analyze xylophone crumb fundraising sailboat shelf daffy cigarette interferometer citrus university recondite pregnancy hall grill patience blow midnight colony high-rise opera kennel radio efficient chorus porch strawman walrus fear animal router mallard operate linguist port cynical imported diver verse min alibi spreadsheet liberty jazzy propose brood villa hysterical mouton snake opportunity background kite knuckle horror well spice register softball calf underweight bay software corruption poker jealousy stench wingtip tadpole illustrious dispensable fish woolens police burlesque inflammation district dialect literate western coupon flour sniff junk warm-up beaver vintner prevention amazon dislike sidestream doing nutrient imprisonment intent population overthrow revolver caravan cloudburst institute laughable sunflower lemon metabolite chip haversack surplus pear appetite bifocals front main bend essence codling collard praised garrulous contour fingerling ashamed behalf bedrock radiate abbreviation exuberant zealous chub leptocephalus maintainer dirty spice dollop opposition architecture shirtdress ballet ear pudding whimsical publicize generate switchboard crewman disdain width piquant maniac epee cranberry collectivisation workout oregano satin pinpoint account pharmacopoeia opposite patrolling juvenile disdain cheddar apathetic image wonderful leap complain creator spectrograph inversion burly prick artifact silent bucket sexuality proctor dispensable age astrologer ectodermal acrylic achieve malice'}, {'role': 'user', 'content': '1719723272.893549 write a long essay about machine learning in at least 100 tokens'}] and Context Tokens: 1005 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723272.893549 bronco panel understatement blister bustle penguin retrospect peek woodchuck borrowing tricky make thrust roundabout bathe gold gravitas reversal confirmation grove jerk denim sunlight float chronometer approval uniformity carbohydrate meme recess game towering footstep wind creep decade gondola lunchmeat meringue buzzard ellipse storey ultra clutch vision duty epee entrance eel bloodflow haven loan raise declination bartender puggle evidence choke accessible legacy facsimile environment upper educated flatboat confuse radiator hippopotamus kick statistic scholarship highway gripper bark collateral seemly heavy crack union official lard pressure ambiguous beggar invitation reset bad rescue copy mirror knight removal intensity length methodology sordid grubby manufacturing caddy sink nit edge adaptable fava paste muscle daffy till myth epic issue banking locomotive graduate lunge scrambled tandem cleft timbale pattypan obsolete viability madam visa palm dynamic pince-nez badge courtroom meter sulky equation chainstay selling succinct sponge maintenance pecan pinpoint extend pomegranate side resale platform xylophone neon concern custard veldt glee lute endpoint alder crinoline settler disconnection want equinox chamber monument plantation licorice connection mandarin yang junker pyramid oasis sniffle fisherman wharf bungalow wastebasket floor health-care question spork deadpan gaffer thaw ring washtub jiffy airbag ivory honorable fanny-pack latitude boxspring interval concrete historical underwear something rust volleyball bizarre gemsbok precedence activity furtive refusal buffet gossip transformation contour ankle gateway aside analgesia ascend pajamas medium petite cyclamen appear jewellery talented godly scheme scorch calculator hallway grid tongue enterprise prepare consignment new dock architecture lord drip sprout competition intelligence plot pegboard nestmate directory goldfish nightingale become steer deer declaration contrast crusader chuck suppression aperitif samovar mineral sprout peck throne redesign recipient colonisation coincidence anthropology deathwatch sulky pin purity dramatic background float patty copying disappear editing link lapdog ephemera thank length investigation golf yard marsh hippopotamus tiresome uncle architect inflammation housework bowtie generator clarinet hapless murky observation jacket dealing successful twister camera sum donation meal clause anger traveler resistance saloon obeisant vanadyl accessory appreciate prefix eyestrain pheasant finalize vacuous head exhaustion new chairperson comradeship almanac juggle basin ranch malice vellum cascade profession suspend fill jar accountability mattress panic insurance goodwill rust purring loop mislead taco stacking hearth acrylic locust buckwheat arch-rival prosecution innovate plywood cello libido ocelot ability opposition blow mangle pardon extension belfry freelance vibe vet see influx woman cursor spill cupboard temporariness rail aberrant surprise kindness boost take-out calm borrowing archives afternoon t-shirt comestible antibody exultant pack ramen cravat event cleavage gaming slip photographer emergency aglet tasty attorney threatening step-aunt classroom tricky ischemia flap lynx memo accountability lover settler owe ruddy haze prosperity employ cub plover wrestler contest measure confidence wit patrol association sip thunderhead talk theism tritone existence haunt prostacyclin waste brisket phosphate calcification entity sausage rice jaw complex gaming armchair enactment population grandpa bench divergent rehabilitate moustache jackal official discharge clock parable bloody eyeball torso dressing alpha blizzard picture qualify liability determination piracy pizza psychology illusion clam jodhpurs analyze xylophone crumb fundraising sailboat shelf daffy cigarette interferometer citrus university recondite pregnancy hall grill patience blow midnight colony high-rise opera kennel radio efficient chorus porch strawman walrus fear animal router mallard operate linguist port cynical imported diver verse min alibi spreadsheet liberty jazzy propose brood villa hysterical mouton snake opportunity background kite knuckle horror well spice register softball calf underweight bay software corruption poker jealousy stench wingtip tadpole illustrious dispensable fish woolens police burlesque inflammation district dialect literate western coupon flour sniff junk warm-up beaver vintner prevention amazon dislike sidestream doing nutrient imprisonment intent population overthrow revolver caravan cloudburst institute laughable sunflower lemon metabolite chip haversack surplus pear appetite bifocals front main bend essence codling collard praised garrulous contour fingerling ashamed behalf bedrock radiate abbreviation exuberant zealous chub leptocephalus maintainer dirty spice dollop opposition architecture shirtdress ballet ear pudding whimsical publicize generate switchboard crewman disdain width piquant maniac epee cranberry collectivisation workout oregano satin pinpoint account pharmacopoeia opposite patrolling juvenile disdain cheddar apathetic image wonderful leap complain creator spectrograph inversion burly prick artifact silent bucket sexuality proctor dispensable age astrologer ectodermal acrylic achieve malice'}, {'role': 'user', 'content': '1719723272.893549 write a long essay about machine learning in at least 100 tokens'}] and Context Tokens: 1005\n",
      "2024-06-29 23:54:32,897 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:32,898 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 100 at (Local time): 2024-06-29 23:54:32.898060, (GMT): 2024-06-30 04:54:32.898060+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 100 at (Local time): 2024-06-29 23:54:32.898060, (GMT): 2024-06-30 04:54:32.898060+00:00\n",
      "2024-06-29 23:54:32,900 - micro - MainProcess - INFO     CPU usage: 13.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.8%\n",
      "2024-06-29 23:54:32,912 - micro - MainProcess - INFO     RAM usage: 86.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.2%\n",
      "2024-06-29 23:54:33,024 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:54:33,032 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:33,153 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': \"1719723273.1535988 please initial bacon eviction wolf wool laborer explode nasal consul trousers mysterious gall-bladder forgive loquat nutritious waggish vampire officiate clarity audit goodie habitual socks job telescreen astrakhan encyclopedia milepost cushion flash booty godmother elbow separation pence center front breastplate illustrious ritual spoon ash suitcase artery detainment consumer charger pastoralist supernatural photodiode clip meteor brainy junker grouse depression presidency ratio fratricide weather woodwind private unbiased jellybeans remind copywriter wingtip bird freon savings skullcap weep teriyaki bandolier worm latex dependency gallon carpenter intelligence parsley salsa inglenook silk overjoyed ill query century proud solve committee dust storm computer industrialization deduction decoration essay quizzical till be dragon offbeat rip bracelet tangy device nickel ordination journey aspect granola text crowded automation wrestler schizophrenic advancement verify data face port purring deeply threat analogue disarm judgment scorch gear agent arrogance pannier mouton confidence shortwave crystallography imminent cicada livestock comment sort copy abhorrent middle warrant compete barracks violin sunshine fetch pack sousaphone publication control quilt revenant initialize citizenship bustle stag step-grandfather anniversary pause feigned decryption calculus puppy boogeyman suite galoshes bomber oak medication sultan traditionalism niche pulse regionalism daybed function external hallowed grapefruit sofa pinot intentionality vision spank hygienic contrast salary wail heady credential hurry complaint target hood adjective addition bumpy advance prejudice razor diabetes reciprocity part ruby infancy mime touch cranberry tuxedo tam-o'-shanter daffy county circle redirect blowgun gate cytoplasm destiny size grandiose programme radish trunk maize cantaloupe puzzled seal cover cursor rotten mast yam resolute wisteria pantry turn realization acid fortune distribution damage going rudiment centre cheer retrospectivity apron correlate hanger subgroup erection perform framework symptom jet mill dioxide divorce ingredient envy commercial stencil remnant intent homely rainstorm oregano crate amnesty dinner soy disturbed galoshes derivation engagement understand confront cayenne wifi sale hydrolyze refund grape pancake dogwood treasure experiment frail cactus incarnation pin median bun romantic sweatshirt hardboard addicted disconnection clef nonchalant locality stacking laryngitis modeling tandem alarm contingency store bag picturesque boulder alibi hole creep assurance airship weather parable credibility pipe spoon telephone heating fulfillment spirituality driving luncheonette diesel broker proceedings vixen cockroach cascade cannon retailer add felony weekender waggish depot root analytics step-uncle arrival reconcile chivalry warm-up football ozone flood stimulating scimitar convection papa antling luggage addition algebra strobe terrorist dynasty rider magnitude porcupine revitalization pace prosecutor influence wonder sediment casualty basket symbol hapless yellow hypothesize seashore labor derivative sister-in-law grace null calorie whisker theme occupation speakerphone dynamic buying preoccupation veal cake memo sailing veneer middle bad champion bring domain publisher follower breast upbeat impress sanity modem moment instinctive genetics frustration sty lift content edition boutique horseradish psychedelic jellybeans groovy aftershave freak sturgeon catalogue hostel dune tramp parable overtake affiliate cirrus dust balloonist integrate voter honeybee raffle auspicious alibi mobility doorknob camp utilize impostor flap remnant diam devise step mouton flexibility corporal icy compliance tape smuggling viewer stab alpaca neighbor stucco developmental timetable strip vivacious leave entrepreneur optimist ham gelatin rod pegboard macaroon kennel almighty apse defective edited rabbit satisfaction grenade evaporation guest bugle shrimp lavish dragonfruit laryngitis branch accurate truth mailer compassionate vanity slink rainmaker proctor signature variety seizure madam trick blend melt wasting stability deputy climate month refusal lively soul capable cross-stitch linkage steward propane pipeline colorful proof brisket olive illusion physics warrant daily lieu clumsy cub instruct satisfy parable graph management dam advance marketplace description pard chocolate renaissance include vulgar defective practitioner alder peck bulk penitent highland chess quince establish prohibition agenda cheesecake cephalopod sling width abacus instrumentation clock heating passbook pagan defeat colony measles landscape classy lung diamond physical chassis airbus sniffle marketing papaya disgusted season communicant anterior sheath correspondence quotation sensibility melatonin vet antibody invite statistic ambiguity iron hole pharmacist appointment few orient head maddening cooking ambitious anxiety maniacal abrogation rim childlike match suffer hotel nutrition poisoning develop pat path hyacinth anthropology pantologist ability lacquerware relay overweight selection client undertaker frightened dilution erect blueberry lunge nestling bellows helium modernist godmother market veranda cascade client environment lobotomy rye receptor pamphlet classy brood meridian annual subexpression mower elver balance freeze pocket-watch nothing swivel movie cleft oil heel mare encyclopedia acoustic cirrus hassock\"}, {'role': 'user', 'content': '1719723273.1535988 write a long essay about machine learning in at least 250 tokens'}] and Context Tokens: 1005 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': \"1719723273.1535988 please initial bacon eviction wolf wool laborer explode nasal consul trousers mysterious gall-bladder forgive loquat nutritious waggish vampire officiate clarity audit goodie habitual socks job telescreen astrakhan encyclopedia milepost cushion flash booty godmother elbow separation pence center front breastplate illustrious ritual spoon ash suitcase artery detainment consumer charger pastoralist supernatural photodiode clip meteor brainy junker grouse depression presidency ratio fratricide weather woodwind private unbiased jellybeans remind copywriter wingtip bird freon savings skullcap weep teriyaki bandolier worm latex dependency gallon carpenter intelligence parsley salsa inglenook silk overjoyed ill query century proud solve committee dust storm computer industrialization deduction decoration essay quizzical till be dragon offbeat rip bracelet tangy device nickel ordination journey aspect granola text crowded automation wrestler schizophrenic advancement verify data face port purring deeply threat analogue disarm judgment scorch gear agent arrogance pannier mouton confidence shortwave crystallography imminent cicada livestock comment sort copy abhorrent middle warrant compete barracks violin sunshine fetch pack sousaphone publication control quilt revenant initialize citizenship bustle stag step-grandfather anniversary pause feigned decryption calculus puppy boogeyman suite galoshes bomber oak medication sultan traditionalism niche pulse regionalism daybed function external hallowed grapefruit sofa pinot intentionality vision spank hygienic contrast salary wail heady credential hurry complaint target hood adjective addition bumpy advance prejudice razor diabetes reciprocity part ruby infancy mime touch cranberry tuxedo tam-o'-shanter daffy county circle redirect blowgun gate cytoplasm destiny size grandiose programme radish trunk maize cantaloupe puzzled seal cover cursor rotten mast yam resolute wisteria pantry turn realization acid fortune distribution damage going rudiment centre cheer retrospectivity apron correlate hanger subgroup erection perform framework symptom jet mill dioxide divorce ingredient envy commercial stencil remnant intent homely rainstorm oregano crate amnesty dinner soy disturbed galoshes derivation engagement understand confront cayenne wifi sale hydrolyze refund grape pancake dogwood treasure experiment frail cactus incarnation pin median bun romantic sweatshirt hardboard addicted disconnection clef nonchalant locality stacking laryngitis modeling tandem alarm contingency store bag picturesque boulder alibi hole creep assurance airship weather parable credibility pipe spoon telephone heating fulfillment spirituality driving luncheonette diesel broker proceedings vixen cockroach cascade cannon retailer add felony weekender waggish depot root analytics step-uncle arrival reconcile chivalry warm-up football ozone flood stimulating scimitar convection papa antling luggage addition algebra strobe terrorist dynasty rider magnitude porcupine revitalization pace prosecutor influence wonder sediment casualty basket symbol hapless yellow hypothesize seashore labor derivative sister-in-law grace null calorie whisker theme occupation speakerphone dynamic buying preoccupation veal cake memo sailing veneer middle bad champion bring domain publisher follower breast upbeat impress sanity modem moment instinctive genetics frustration sty lift content edition boutique horseradish psychedelic jellybeans groovy aftershave freak sturgeon catalogue hostel dune tramp parable overtake affiliate cirrus dust balloonist integrate voter honeybee raffle auspicious alibi mobility doorknob camp utilize impostor flap remnant diam devise step mouton flexibility corporal icy compliance tape smuggling viewer stab alpaca neighbor stucco developmental timetable strip vivacious leave entrepreneur optimist ham gelatin rod pegboard macaroon kennel almighty apse defective edited rabbit satisfaction grenade evaporation guest bugle shrimp lavish dragonfruit laryngitis branch accurate truth mailer compassionate vanity slink rainmaker proctor signature variety seizure madam trick blend melt wasting stability deputy climate month refusal lively soul capable cross-stitch linkage steward propane pipeline colorful proof brisket olive illusion physics warrant daily lieu clumsy cub instruct satisfy parable graph management dam advance marketplace description pard chocolate renaissance include vulgar defective practitioner alder peck bulk penitent highland chess quince establish prohibition agenda cheesecake cephalopod sling width abacus instrumentation clock heating passbook pagan defeat colony measles landscape classy lung diamond physical chassis airbus sniffle marketing papaya disgusted season communicant anterior sheath correspondence quotation sensibility melatonin vet antibody invite statistic ambiguity iron hole pharmacist appointment few orient head maddening cooking ambitious anxiety maniacal abrogation rim childlike match suffer hotel nutrition poisoning develop pat path hyacinth anthropology pantologist ability lacquerware relay overweight selection client undertaker frightened dilution erect blueberry lunge nestling bellows helium modernist godmother market veranda cascade client environment lobotomy rye receptor pamphlet classy brood meridian annual subexpression mower elver balance freeze pocket-watch nothing swivel movie cleft oil heel mare encyclopedia acoustic cirrus hassock\"}, {'role': 'user', 'content': '1719723273.1535988 write a long essay about machine learning in at least 250 tokens'}] and Context Tokens: 1005\n",
      "2024-06-29 23:54:33,159 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:33,161 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 23:54:33.161126, (GMT): 2024-06-30 04:54:33.161126+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 23:54:33.161126, (GMT): 2024-06-30 04:54:33.161126+00:00\n",
      "2024-06-29 23:54:33,164 - micro - MainProcess - INFO     CPU usage: 39.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 39.4%\n",
      "2024-06-29 23:54:33,172 - micro - MainProcess - INFO     RAM usage: 86.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.3%\n",
      "2024-06-29 23:54:33,186 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:54:33,193 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:33,373 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723273.3736057 wok expensive dragonfly company strawberry chill tutu intentionality nifty dishwasher briefing viability tuba propaganda duster quaint in-laws internet discreet target railing banyan hamster pull reparation detention wastebasket rhinoceros vellum rider crucifixion ketchup dearest contention worshiper masterpiece abrupt database bandwidth force gaffer saddle strap disposition caboose forestry girl centurion primary disclaimer bud catastrophe disaster amusement stonework jelly squash chatter placebo referendum attractive coincidence high-pitched advantage homeless enactment shoes trick diversity percent atrium swanling tom-tom consistency collateral ideology farmland tranquil sedate banquette know procedure fraction plain analog tree merchant couple percentage pouch freon rim great-grandmother shampoo resemblance rectangle nickname tested elf bond lord thunderbolt pneumonia tuition policy critic backup travel gobbler null alfalfa diction aggressive poisoning mode tacky ritzy portfolio embellishment square chew limb neuron warning entertain advocacy turnover lining pepper midden uncovered jewel crate watch scripture pagoda bootee harsh deviance presidency evaluation timing sloth robe achiever synthesis tonight passive acceptance ridge blinker cricket feather mill dust co-producer beggar implement outrage pastoralist replace attitude curved recruit warmth leading wet gullible conformation thief rage accident tapioca whisker dictionary mousse kumquat monsoon health-care herring speaking responsibility silver lying sherry examine boulder bench steeple settler builder mailbox understatement used gastronomy astonishing emerald analogy riot wool polenta vex swell leaf fishnet murder contractor dolman vanish prelude upstairs dawn yielding decorate password conversation pyramid kit registration slate judgment fixture briefly bump utensil reproduce mistake sauerkraut domain anniversary tune-up section duckling refuse agent mammoth omnivore urgency note comic cushion illusion jacket unsuitable applaud sprinkles endorsement dolphin ensure audience coevolution mother-in-law male scarification window data browser query value scorn devilish fortress settle slate tide helpless dive soulmate reminiscent light angiosperm perceive quilt shower eliminate fritter cayenne timber poisoning jaguar umbrella wash render take-out waterspout steer jackal trial conformation enigma crook soliloquy petition atelier angle brainy particular determination cave make right visor thoughtful woozy champagne elicit porcelain humidity employee baobab progenitor craftsman cross-contamination design blazer extreme reach rosemary underpass volatility directory fencing guitar horizon declaration pianist manager lung threat streamline ptarmigan tabernacle dime chew institute strife acid bronze credible add swath copyright septicaemia pub angina presentation assure ephyra disconnection macho lace furniture dramatize hike lacking beanstalk west bullet eatable cohesion colony lark placement disposal tickle solidarity herbs field harvester person crunch baseline millimeter concert deep baggy thought poison cashier autumn wording volcano bout doe jade approach almighty tape marketer attempt fruit campaigning waitress molding horseradish gymnast worship parka fair panpipe polo realization carotene illusion sanity toaster facilitate proliferation godparent smith mutt quiet cover odyssey floor eyelash ant trove sack gearshift conduct retailer illegal gnu fleck wardrobe adapter slit majestic grab-bag retention heterosexual backbone dig foamy seizure join accusation rooster wick currant kale ultra misspell puffin drainage leather bat e-mail route faucet terminal departure bubble porter pants cashier incarnation depressed priesthood step-daughter tugboat complete carnation senior chub kinase account futuristic distinction rebellious farmland spree chiffonier cartridge soap loud onion authorisation tickle ring shed vote junk maker security sculptural involvement observe comparison hurried variability fasten reunion tawdry mineshaft arrest infusion expectation netsuke disdain copy yacht tendency reinforce turban communication cenotaph ancestor succinct eyeglasses quizzical recording skirt leaker hook fowl balance stage acre barbarous coin strength odometer frantic hurt fireplace gamebird king experience wasting houseboat arrangement reality avoid dogsled assist banquette anything tunic leverage e-reader installation nutrient workshop wannabe integrate hygienic snowstorm polish query appendix regionalism season cylinder reflect glossy turtle quadrant standard watchful wiseguy gauntlet dollop jalapeo rack grey chunky various key special lightning adopt finisher funeral bobcat joke pajamas stereo ark install famous interconnection leaker middleman amendment read nothing war leprosy poll sprinter fresco opera crocus scam battleship sentence dogwood outlaw selective utter hemp quit truck fortress airplane distribution frighten exhaustion clavier signet nougat uphold cannon seek carload optimist rough pup ceaseless stomach aquifer misplacement cattle tasteful cascade heavenly earsplitting behavior lucky adoption page idea conference neuropathologist penguin stot reinscription nick numeric member caravan poncho please anything great-grandfather officiate savage fan clover governor precedent spill judicious oleo periodical covariate soldier epic spool canopy chip primate unblinking haven distinction trust stack sweatshirt flat peel kitty seagull trailer'}, {'role': 'user', 'content': '1719723273.3736057 write a long essay about machine learning in at least 150 tokens'}] and Context Tokens: 1003 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723273.3736057 wok expensive dragonfly company strawberry chill tutu intentionality nifty dishwasher briefing viability tuba propaganda duster quaint in-laws internet discreet target railing banyan hamster pull reparation detention wastebasket rhinoceros vellum rider crucifixion ketchup dearest contention worshiper masterpiece abrupt database bandwidth force gaffer saddle strap disposition caboose forestry girl centurion primary disclaimer bud catastrophe disaster amusement stonework jelly squash chatter placebo referendum attractive coincidence high-pitched advantage homeless enactment shoes trick diversity percent atrium swanling tom-tom consistency collateral ideology farmland tranquil sedate banquette know procedure fraction plain analog tree merchant couple percentage pouch freon rim great-grandmother shampoo resemblance rectangle nickname tested elf bond lord thunderbolt pneumonia tuition policy critic backup travel gobbler null alfalfa diction aggressive poisoning mode tacky ritzy portfolio embellishment square chew limb neuron warning entertain advocacy turnover lining pepper midden uncovered jewel crate watch scripture pagoda bootee harsh deviance presidency evaluation timing sloth robe achiever synthesis tonight passive acceptance ridge blinker cricket feather mill dust co-producer beggar implement outrage pastoralist replace attitude curved recruit warmth leading wet gullible conformation thief rage accident tapioca whisker dictionary mousse kumquat monsoon health-care herring speaking responsibility silver lying sherry examine boulder bench steeple settler builder mailbox understatement used gastronomy astonishing emerald analogy riot wool polenta vex swell leaf fishnet murder contractor dolman vanish prelude upstairs dawn yielding decorate password conversation pyramid kit registration slate judgment fixture briefly bump utensil reproduce mistake sauerkraut domain anniversary tune-up section duckling refuse agent mammoth omnivore urgency note comic cushion illusion jacket unsuitable applaud sprinkles endorsement dolphin ensure audience coevolution mother-in-law male scarification window data browser query value scorn devilish fortress settle slate tide helpless dive soulmate reminiscent light angiosperm perceive quilt shower eliminate fritter cayenne timber poisoning jaguar umbrella wash render take-out waterspout steer jackal trial conformation enigma crook soliloquy petition atelier angle brainy particular determination cave make right visor thoughtful woozy champagne elicit porcelain humidity employee baobab progenitor craftsman cross-contamination design blazer extreme reach rosemary underpass volatility directory fencing guitar horizon declaration pianist manager lung threat streamline ptarmigan tabernacle dime chew institute strife acid bronze credible add swath copyright septicaemia pub angina presentation assure ephyra disconnection macho lace furniture dramatize hike lacking beanstalk west bullet eatable cohesion colony lark placement disposal tickle solidarity herbs field harvester person crunch baseline millimeter concert deep baggy thought poison cashier autumn wording volcano bout doe jade approach almighty tape marketer attempt fruit campaigning waitress molding horseradish gymnast worship parka fair panpipe polo realization carotene illusion sanity toaster facilitate proliferation godparent smith mutt quiet cover odyssey floor eyelash ant trove sack gearshift conduct retailer illegal gnu fleck wardrobe adapter slit majestic grab-bag retention heterosexual backbone dig foamy seizure join accusation rooster wick currant kale ultra misspell puffin drainage leather bat e-mail route faucet terminal departure bubble porter pants cashier incarnation depressed priesthood step-daughter tugboat complete carnation senior chub kinase account futuristic distinction rebellious farmland spree chiffonier cartridge soap loud onion authorisation tickle ring shed vote junk maker security sculptural involvement observe comparison hurried variability fasten reunion tawdry mineshaft arrest infusion expectation netsuke disdain copy yacht tendency reinforce turban communication cenotaph ancestor succinct eyeglasses quizzical recording skirt leaker hook fowl balance stage acre barbarous coin strength odometer frantic hurt fireplace gamebird king experience wasting houseboat arrangement reality avoid dogsled assist banquette anything tunic leverage e-reader installation nutrient workshop wannabe integrate hygienic snowstorm polish query appendix regionalism season cylinder reflect glossy turtle quadrant standard watchful wiseguy gauntlet dollop jalapeo rack grey chunky various key special lightning adopt finisher funeral bobcat joke pajamas stereo ark install famous interconnection leaker middleman amendment read nothing war leprosy poll sprinter fresco opera crocus scam battleship sentence dogwood outlaw selective utter hemp quit truck fortress airplane distribution frighten exhaustion clavier signet nougat uphold cannon seek carload optimist rough pup ceaseless stomach aquifer misplacement cattle tasteful cascade heavenly earsplitting behavior lucky adoption page idea conference neuropathologist penguin stot reinscription nick numeric member caravan poncho please anything great-grandfather officiate savage fan clover governor precedent spill judicious oleo periodical covariate soldier epic spool canopy chip primate unblinking haven distinction trust stack sweatshirt flat peel kitty seagull trailer'}, {'role': 'user', 'content': '1719723273.3736057 write a long essay about machine learning in at least 150 tokens'}] and Context Tokens: 1003\n",
      "2024-06-29 23:54:33,381 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:33,385 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 150 at (Local time): 2024-06-29 23:54:33.385846, (GMT): 2024-06-30 04:54:33.385846+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 150 at (Local time): 2024-06-29 23:54:33.385846, (GMT): 2024-06-30 04:54:33.385846+00:00\n",
      "2024-06-29 23:54:35,049 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:35,062 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.18 seconds or 1183.16 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.18 seconds or 1183.16 milliseconds.\n",
      "2024-06-29 23:54:35,554 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:35,591 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.81 seconds or 1813.22 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.81 seconds or 1813.22 milliseconds.\n",
      "2024-06-29 23:54:36,069 - micro - MainProcess - INFO     CPU usage: 23.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 23.4%\n",
      "2024-06-29 23:54:36,077 - micro - MainProcess - INFO     RAM usage: 86.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.6%\n",
      "2024-06-29 23:54:36,088 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:54:36,095 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:36,347 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723276.3470259 audited onerous ascent monkey ink unequaled microwave abounding homework petition arcade cope wealthy drive bosom judge provider sulfur tachometer daffodil segment cushion seeker manacle plausible reception certification leadership palace chicken guinea recorder aftermath melodic rowing round sunshine gigantism flagrant transportation asparagus accountability quotation revenue crystal republic savage rustic access marten pheromone sardine software discharge union blow heating modernist heirloom photodiode counselling notoriety syndrome authentication lacking neighbourhood variability refrigerator shipyard judgment meantime fairness timber standard lipstick stylus bomber precipitation jack resource outback obsequious troubled cargo valance bassoon competition quit inhibitor millet arithmetic leptocephalus terrarium self-esteem bankbook cinder imbalance artery scorn colorlessness erratic nuke molar cocoa cart mood innocence failure needless caption mug maddening itinerary apricot plight sting methodology evolution teepee saviour saving diving audience workable pillar effect utensil oak venue minute data corruption profile mission adviser colonialism transit peaceful grow electrocardiogram embassy piety zombie jailhouse syrup bunch sew mussel garden manage spotless brassiere offence agriculture circle trashy checkout race talented stepmother potty sneaky geek hawk bag tower alpenhorn convert convertible infinite kneel flesh gem cloud recreation tumble leeway winter bun bathroom likelihood sable analog harvest soliloquy builder coke poison mortise scaffold fallacy eagle dare thermometer evidence blossom classmate memory troop proceedings broker cartoon fourths obey symptom camp umbrella handgun slink trust cat excellent breath attainment subconscious art peony video kind gong freight wasteful tsunami facility creationism aluminium pipe security taxpayer fritter hurricane juvenile painter geometry discretion thyme rethinking length product bottling corporal kettle substitution shack buddy management possess recommend patriot crib equality selection splendor cliff inform skip accomplish parsley secretary pair percent polyester supernatural lentil execute sunlight theme greenhouse tuber load dependent spud eviction hummus makeshift seagull chopstick conformation misogyny baseline hammock bather banana watchful gavel mineshaft agenda hall wok shivering kaput opportunist technologist cocktail store web custom enforcement sermon browsing bladder brainy reactant steal side border tear counseling frighten gastropod bidet stupid faint invader proponent newsprint nonconformist anime dish clasp successful fur crumb hollow regard scatter secrecy till accuracy rag site hearsay interest analogy glance cholesterol dispatch wisteria protective kazoo restaurant nectarine compliance journalist pollution swine resort fascinated toot reorganization nonchalant route maniacal tree bone boiling brochure hint calculation threatening remark audience shackle dedication passbook petition alteration simplify butter rubber number bacon rowing meantime top-hat candy hassock octopus epee coal scraper remove safety change crime recapitulation aback lilac access slice violence grab-bag rim aberrant poppy dude pass reorganization turtle burn-out deeply jagged hydrofoil dictator market mushroom carboxyl dump truck drill classify morning wage sleep internet dramatic verdict drawbridge ashram innovate dune buggy confidentiality health-care doctor infarction consideration skyline vermicelli mantle responsibility lemonade pail phrasing concept channel cobweb handsaw match broom framework biplane wiretap clay resemblance flip-flops hurdle flavor assistant recognition prostrate nonchalant sunrise mastication expectation stone supplement dish retrospective debate pad affidavit selling knuckle chairlift replacement sweatshirt polarisation limit slippery overrated pickup proximity bagel apologize initialise flour noxious toast eternity git faded blanket presume murky knowledgeable damp lynx likeness copying click guy crocus humdrum poker star motionless bonding netsuke music cauliflower clarify infant regulate usher gravitas ticket tom-tom grow precipitation trot seizure helmet quart midwife gallery tributary mule tour undertake parched infancy glutamate parenthesis handsome vanadyl peek ligula progress flawless lox maiden ukulele acquaintance horst relate carving gasket probability skating dump truck veal lesson dragonfly x-ray live fragrance judge shopper cria president tumbler prosecution puffy gherkin riding outback quixotic gray airbag oat armour undertaker acoustics fraud impact software anise derby strawman hub comic verb envelope excited freezer elf babe capable atheist rose postage critique attachment brewer childlike borrow motivate conifer clamp sharp powerful wall nucleotide grandparent holistic conduct picket piracy pacemaker taboo panicky peace extend wilderness ruby selection spell anagram puffy gathering woodland creek fiber ruckus heartbeat zoologist neighbourhood conservative video cynical fall tornado underweight introduction iron cough arrangement scalp excellent fright vivo wide-eyed detective rightful think providence severity scaffold civilisation julienne info vinyl sari mentor luck excerpt orator excellent quartz colleague bath sultan applaud groovy stallion understanding lightning paddock priesthood chimpanzee scow venison coleslaw report send cable sidecar paw borrow offset ambassador disposer snowsuit reign garb utilization genie dude outlook alpenglow shut data mother-in-law tackle'}, {'role': 'user', 'content': '1719723276.3470259 write a long essay about machine learning in at least 100 tokens'}] and Context Tokens: 1005 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723276.3470259 audited onerous ascent monkey ink unequaled microwave abounding homework petition arcade cope wealthy drive bosom judge provider sulfur tachometer daffodil segment cushion seeker manacle plausible reception certification leadership palace chicken guinea recorder aftermath melodic rowing round sunshine gigantism flagrant transportation asparagus accountability quotation revenue crystal republic savage rustic access marten pheromone sardine software discharge union blow heating modernist heirloom photodiode counselling notoriety syndrome authentication lacking neighbourhood variability refrigerator shipyard judgment meantime fairness timber standard lipstick stylus bomber precipitation jack resource outback obsequious troubled cargo valance bassoon competition quit inhibitor millet arithmetic leptocephalus terrarium self-esteem bankbook cinder imbalance artery scorn colorlessness erratic nuke molar cocoa cart mood innocence failure needless caption mug maddening itinerary apricot plight sting methodology evolution teepee saviour saving diving audience workable pillar effect utensil oak venue minute data corruption profile mission adviser colonialism transit peaceful grow electrocardiogram embassy piety zombie jailhouse syrup bunch sew mussel garden manage spotless brassiere offence agriculture circle trashy checkout race talented stepmother potty sneaky geek hawk bag tower alpenhorn convert convertible infinite kneel flesh gem cloud recreation tumble leeway winter bun bathroom likelihood sable analog harvest soliloquy builder coke poison mortise scaffold fallacy eagle dare thermometer evidence blossom classmate memory troop proceedings broker cartoon fourths obey symptom camp umbrella handgun slink trust cat excellent breath attainment subconscious art peony video kind gong freight wasteful tsunami facility creationism aluminium pipe security taxpayer fritter hurricane juvenile painter geometry discretion thyme rethinking length product bottling corporal kettle substitution shack buddy management possess recommend patriot crib equality selection splendor cliff inform skip accomplish parsley secretary pair percent polyester supernatural lentil execute sunlight theme greenhouse tuber load dependent spud eviction hummus makeshift seagull chopstick conformation misogyny baseline hammock bather banana watchful gavel mineshaft agenda hall wok shivering kaput opportunist technologist cocktail store web custom enforcement sermon browsing bladder brainy reactant steal side border tear counseling frighten gastropod bidet stupid faint invader proponent newsprint nonconformist anime dish clasp successful fur crumb hollow regard scatter secrecy till accuracy rag site hearsay interest analogy glance cholesterol dispatch wisteria protective kazoo restaurant nectarine compliance journalist pollution swine resort fascinated toot reorganization nonchalant route maniacal tree bone boiling brochure hint calculation threatening remark audience shackle dedication passbook petition alteration simplify butter rubber number bacon rowing meantime top-hat candy hassock octopus epee coal scraper remove safety change crime recapitulation aback lilac access slice violence grab-bag rim aberrant poppy dude pass reorganization turtle burn-out deeply jagged hydrofoil dictator market mushroom carboxyl dump truck drill classify morning wage sleep internet dramatic verdict drawbridge ashram innovate dune buggy confidentiality health-care doctor infarction consideration skyline vermicelli mantle responsibility lemonade pail phrasing concept channel cobweb handsaw match broom framework biplane wiretap clay resemblance flip-flops hurdle flavor assistant recognition prostrate nonchalant sunrise mastication expectation stone supplement dish retrospective debate pad affidavit selling knuckle chairlift replacement sweatshirt polarisation limit slippery overrated pickup proximity bagel apologize initialise flour noxious toast eternity git faded blanket presume murky knowledgeable damp lynx likeness copying click guy crocus humdrum poker star motionless bonding netsuke music cauliflower clarify infant regulate usher gravitas ticket tom-tom grow precipitation trot seizure helmet quart midwife gallery tributary mule tour undertake parched infancy glutamate parenthesis handsome vanadyl peek ligula progress flawless lox maiden ukulele acquaintance horst relate carving gasket probability skating dump truck veal lesson dragonfly x-ray live fragrance judge shopper cria president tumbler prosecution puffy gherkin riding outback quixotic gray airbag oat armour undertaker acoustics fraud impact software anise derby strawman hub comic verb envelope excited freezer elf babe capable atheist rose postage critique attachment brewer childlike borrow motivate conifer clamp sharp powerful wall nucleotide grandparent holistic conduct picket piracy pacemaker taboo panicky peace extend wilderness ruby selection spell anagram puffy gathering woodland creek fiber ruckus heartbeat zoologist neighbourhood conservative video cynical fall tornado underweight introduction iron cough arrangement scalp excellent fright vivo wide-eyed detective rightful think providence severity scaffold civilisation julienne info vinyl sari mentor luck excerpt orator excellent quartz colleague bath sultan applaud groovy stallion understanding lightning paddock priesthood chimpanzee scow venison coleslaw report send cable sidecar paw borrow offset ambassador disposer snowsuit reign garb utilization genie dude outlook alpenglow shut data mother-in-law tackle'}, {'role': 'user', 'content': '1719723276.3470259 write a long essay about machine learning in at least 100 tokens'}] and Context Tokens: 1005\n",
      "2024-06-29 23:54:36,354 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:36,359 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 100 at (Local time): 2024-06-29 23:54:36.359856, (GMT): 2024-06-30 04:54:36.359856+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 100 at (Local time): 2024-06-29 23:54:36.359856, (GMT): 2024-06-30 04:54:36.359856+00:00\n",
      "2024-06-29 23:54:36,580 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:36,583 - micro - MainProcess - INFO     CPU usage: 29.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 29.7%\n",
      "2024-06-29 23:54:36,593 - micro - MainProcess - INFO     RAM usage: 86.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.1%\n",
      "2024-06-29 23:54:36,606 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:54:36,612 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:36,806 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723276.8063204 watchful discretion doing boast glow slimy manipulation tailbud reinscription thump pension soulmate clerk abbreviation evocation educate cirrus mRNA rock weave stereo remains contributor vivacious stucco herb collapse sneak ludicrous freon centimeter sulfur analyze panda bagpipe acquaintance picayune brochure chubby vibrissae shred demonic smelting brow thug lychee sovereignty publicize banjo knock humour rawhide goodie ability ape softball sour stink fitness rush margin attend demur expect peep eatable gather image anniversary cot youngster step-uncle trek instrumentation diadem hike door step-father efficacy advocate cue weak stud collection command brooch heterosexual passenger bond assignment lying lawn collision jacket uppity basket translate allowance buffalo peacock tributary spectacle purr weigh sort mycoplasma maple jeweller hypothesis unity clock slump manner sophomore flu bombing butcher injury pork effort nursing hake punishment mandate smile picket republican queen caterpillar withdraw geranium brandy thirst tepee operate mindless lord spectacular north medium abject earthworm sell variation cracker childbirth karate hierarchy wombat leprosy lyre catamaran webpage architecture fabric turf contractor riverbed polo insurgence defective outline disagree construction croup laborer crawl rot wander shopper bathe counselling leadership mom dirt eponym stab limit waitress sabre vista anesthesiology bankbook element data fortunate ruddy cornmeal burlesque freezer stockings bump puma buckle vaccine dude control cauliflower temporariness briefly seagull disposal leek mitten minimum moaning station-wagon profession great-grandfather cocktail dirty spray armrest horst going lowly seemly colonization scholar shrug chives edge undertaker astrology hay elbow disengagement utility govern spoil compose pepperoni aquarium equal deviation phosphate blocker orange absurd pail illustrate applause fling hearth homely nourishment blackness erosion drake living purse right booster honeydew news provide cria habit evaluate shark power examine engineering inscription measurement watercress barber tense laughter pastry inch pea bass meantime eaglet fallacy ladle supervisor blood antigen beet early see honor manufacture concept sunday corruption float sonar doc classy motion diner afternoon surprise nectar infix boring colonization employer fawn accomplishment night plaintiff voyage bustle abacus widow narrative nightingale distortion therapist photodiode interval dime catastrophe mesenchyme freeze wedge scrape happening reminder flag legacy silk care independence peony spider zampone rubber crate allegation misspell establish editing lantern desk physical march claim statistics emitter jade durian retrospect attainment ukulele shaky sphynx appreciation bake milkshake sailing bunghole dock pear hippopotamus muscatel horrible exhaustion bawdy hydrant comment relief labor mattock banana damaging region caddy robust adulthood airbus newsletter analog unfasten evening-wear beverage colorful heir paradise zucchini priest ripe stallion miniature tsunami rocker bow hellish anterior refrigerator cosset sleep bifocals return horror lollipop rest locomotive iris dry pickax thought unite restriction appetite porter tart ice-cream own shock birdcage symptom vet maniacal leisure humor abuse airmail action obey scooter self-confidence comment uniformity headquarters country copying dial kingfish businessman shark scrutiny bombing event diarist macrofauna communicate renaissance acoustic mapping socks camera flugelhorn chivalry breath soy overtake rice mixture print cone creature solitaire burst day sportsman slit spruce full save antennae bunghole eyelashes bank bookcase tulip originality gateway curio champagne relaxation peel rotten uneven programme meet exile turkey variability naive solid attendant meddle goose jelly encouraging leprosy adrenaline vermicelli link bulldozer ghost erect poet cash prisoner vagrant grandparent squealing location downfall other fun softball creator anime edge choke review acoustics effectiveness gifted proofread textbook version sociology fanny-pack brand construct incidence clipboard beret danger beanie gamma-ray baboon playwright witness district pastoral livestock promise consensus moonlight afoul tow freelance skating monasticism caboose spear jagged snuggle doe denim scrub metric lining quack bulk whisker controversy abhorrent poetry hyphenation humorous cloth executive people conference facet lyocell ascot waterfront mythology combat partridge needle bowling inverse pinafore aggression evaluation collect communicate album apologize laryngitis barber fault gale water worth capability pressure championship pimple trash placement teeny-tiny uncle crocodile pantsuit waist fascinated marathon divine graceful drawing fiction roomy spotlight octavo dryer tree homonym manservant enacted TV bell offset cathedral well employer eicosanoid compassion icy painting generation complaint barrier gaming macabre programming introduce marten irrigation port cultivar crow passing duck begin union escalator hurdle intervenor mattock expression jewellery tense alert beanstalk lowly cartoon federation helpful bonfire wound rub overhear policy ride profession townhouse send sensor trapezoid boring exaggeration alibi unique woodshed dress liquid deal vitality tearful curd instructor inverse section drab lion dirty bottom-line'}, {'role': 'user', 'content': '1719723276.8063204 write a long essay about machine learning in at least 150 tokens'}] and Context Tokens: 1004 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723276.8063204 watchful discretion doing boast glow slimy manipulation tailbud reinscription thump pension soulmate clerk abbreviation evocation educate cirrus mRNA rock weave stereo remains contributor vivacious stucco herb collapse sneak ludicrous freon centimeter sulfur analyze panda bagpipe acquaintance picayune brochure chubby vibrissae shred demonic smelting brow thug lychee sovereignty publicize banjo knock humour rawhide goodie ability ape softball sour stink fitness rush margin attend demur expect peep eatable gather image anniversary cot youngster step-uncle trek instrumentation diadem hike door step-father efficacy advocate cue weak stud collection command brooch heterosexual passenger bond assignment lying lawn collision jacket uppity basket translate allowance buffalo peacock tributary spectacle purr weigh sort mycoplasma maple jeweller hypothesis unity clock slump manner sophomore flu bombing butcher injury pork effort nursing hake punishment mandate smile picket republican queen caterpillar withdraw geranium brandy thirst tepee operate mindless lord spectacular north medium abject earthworm sell variation cracker childbirth karate hierarchy wombat leprosy lyre catamaran webpage architecture fabric turf contractor riverbed polo insurgence defective outline disagree construction croup laborer crawl rot wander shopper bathe counselling leadership mom dirt eponym stab limit waitress sabre vista anesthesiology bankbook element data fortunate ruddy cornmeal burlesque freezer stockings bump puma buckle vaccine dude control cauliflower temporariness briefly seagull disposal leek mitten minimum moaning station-wagon profession great-grandfather cocktail dirty spray armrest horst going lowly seemly colonization scholar shrug chives edge undertaker astrology hay elbow disengagement utility govern spoil compose pepperoni aquarium equal deviation phosphate blocker orange absurd pail illustrate applause fling hearth homely nourishment blackness erosion drake living purse right booster honeydew news provide cria habit evaluate shark power examine engineering inscription measurement watercress barber tense laughter pastry inch pea bass meantime eaglet fallacy ladle supervisor blood antigen beet early see honor manufacture concept sunday corruption float sonar doc classy motion diner afternoon surprise nectar infix boring colonization employer fawn accomplishment night plaintiff voyage bustle abacus widow narrative nightingale distortion therapist photodiode interval dime catastrophe mesenchyme freeze wedge scrape happening reminder flag legacy silk care independence peony spider zampone rubber crate allegation misspell establish editing lantern desk physical march claim statistics emitter jade durian retrospect attainment ukulele shaky sphynx appreciation bake milkshake sailing bunghole dock pear hippopotamus muscatel horrible exhaustion bawdy hydrant comment relief labor mattock banana damaging region caddy robust adulthood airbus newsletter analog unfasten evening-wear beverage colorful heir paradise zucchini priest ripe stallion miniature tsunami rocker bow hellish anterior refrigerator cosset sleep bifocals return horror lollipop rest locomotive iris dry pickax thought unite restriction appetite porter tart ice-cream own shock birdcage symptom vet maniacal leisure humor abuse airmail action obey scooter self-confidence comment uniformity headquarters country copying dial kingfish businessman shark scrutiny bombing event diarist macrofauna communicate renaissance acoustic mapping socks camera flugelhorn chivalry breath soy overtake rice mixture print cone creature solitaire burst day sportsman slit spruce full save antennae bunghole eyelashes bank bookcase tulip originality gateway curio champagne relaxation peel rotten uneven programme meet exile turkey variability naive solid attendant meddle goose jelly encouraging leprosy adrenaline vermicelli link bulldozer ghost erect poet cash prisoner vagrant grandparent squealing location downfall other fun softball creator anime edge choke review acoustics effectiveness gifted proofread textbook version sociology fanny-pack brand construct incidence clipboard beret danger beanie gamma-ray baboon playwright witness district pastoral livestock promise consensus moonlight afoul tow freelance skating monasticism caboose spear jagged snuggle doe denim scrub metric lining quack bulk whisker controversy abhorrent poetry hyphenation humorous cloth executive people conference facet lyocell ascot waterfront mythology combat partridge needle bowling inverse pinafore aggression evaluation collect communicate album apologize laryngitis barber fault gale water worth capability pressure championship pimple trash placement teeny-tiny uncle crocodile pantsuit waist fascinated marathon divine graceful drawing fiction roomy spotlight octavo dryer tree homonym manservant enacted TV bell offset cathedral well employer eicosanoid compassion icy painting generation complaint barrier gaming macabre programming introduce marten irrigation port cultivar crow passing duck begin union escalator hurdle intervenor mattock expression jewellery tense alert beanstalk lowly cartoon federation helpful bonfire wound rub overhear policy ride profession townhouse send sensor trapezoid boring exaggeration alibi unique woodshed dress liquid deal vitality tearful curd instructor inverse section drab lion dirty bottom-line'}, {'role': 'user', 'content': '1719723276.8063204 write a long essay about machine learning in at least 150 tokens'}] and Context Tokens: 1004\n",
      "2024-06-29 23:54:36,819 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:36,826 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 150 at (Local time): 2024-06-29 23:54:36.826124, (GMT): 2024-06-30 04:54:36.826124+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 150 at (Local time): 2024-06-29 23:54:36.826124, (GMT): 2024-06-30 04:54:36.826124+00:00\n",
      "2024-06-29 23:54:36,835 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.01 seconds or 3006.7 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.01 seconds or 3006.7 milliseconds.\n",
      "2024-06-29 23:54:37,820 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:37,842 - micro - MainProcess - INFO     CPU usage: 15.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.8%\n",
      "2024-06-29 23:54:37,854 - micro - MainProcess - INFO     RAM usage: 86.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.2%\n",
      "2024-06-29 23:54:37,886 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:54:37,890 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:38,122 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723278.1225512 challenge atheist coherent cloves somebody doctor reconcile cliff willow masterpiece slide nest scribble covariate marionberry solicitation chalet spider gumshoe sell minimum hoe executive nanoparticle tusk nit wetland compassionate aspic depression quartz rainy utilisation cloistered azimuth decisive casserole kid homogenate fav monkey way battery divide acid spray cinnamon scooter commotion priesthood repository cave degree house advertisement collectivization primate bourgeoisie merchandise wood enacted trillion nephew juggernaut feeding easel vacation jacket stumbling exterior gall-bladder quinoa brush likeness verve spacing dogsled bidding playwright chrome application circumstance envious carboxyl nose unpack assertion density drake servitude coonskin storyboard imitation inheritance rat limit storage stomach yeast puggle hearthside pillow reconsideration labour coordinate inside tutor satin headphones abiding hardware workout scary satellite encouragement pork con mistake half surround climb mathematics midden tenant gradient reflect smite trailpatrol deodorant evil normal networking breadcrumb passing regulate recipe caption ballpark afternoon waffle anywhere interest cymbal ride ruthless point tooth route apprehension reign late enhance uppity misrepresentation men mRNA productive tangerine traffic landscape accidental watchmaker federation vanity pyridine didactic basil necktie fetus shin suitcase voracious pitcher arrow ambition progression backdrop kohlrabi abrogation valuable teriyaki sprinter pot chaos scholar ladder abundance confess felony nitrogen otter crate uptight tickle digestive mere timeline kitchen border dimension trait maize hash chunky zealous blessing confectionery chainstay gruesome hound writing beanie bomber sweatsuit pass curler monument bill face achievement copyright deep pajamas unit lake elevator shampoo foolish artichoke happening game roasted beer meteor haze armpit excursion estrogen fool examine airport thoughtful armour bestseller wingtip downgrade clave balaclava reply venison clumsy reflection signify credenza blame postbox soda range headrest skyscraper drawer gaudy hatred till crest mukluk tuber cupola reason tawdry antennae veneer cutlet chub pan overcome assistant maintain deliver voracious initial dwarf killing slide receipt chorus colossal doctrine warlock semicircle altitude escort pinstripe expensive cephalopod injure moaning elver fair barber endure goat spatula quack solicitation regret wacky tinkle complement restored account tax step-grandmother diadem aid collateral treasury colony joke assessment print dam spot proximity physiology harvester reporting destiny champagne resonant rutabaga panpipe vertigo whole lesbian chestnut fibroblast pate elk press license cap reconcile dogwood dust vendor farm union resolve troubleshoot end sew saddle descent plasterboard cynical trustee goodnight alcoholic coherent daffy rosemary programming incandescent icicle tasteless classic smell worth backdrop blueberry retire childbirth accomplish corral collision simvastatin messy moan winter coat mathematics disparity correct tissue boorish chrysalis hum lip pail see vast gemsbok titanium tame architect museum plover option guarantee lily awake surgeon beautiful shoreline dinner dilution daughter clear aircraft hatchling aim prosecutor enlist mom enquiry ban oregano version underwriting outhouse crust sailing taxi disregard tracking metabolite pathology eyelashes hometown booty upper choose parenting galoshes explain grain sub synthesis grease acted radiator meantime spray gander concern sinuosity marathon belligerent mysterious instrument glance wharf apron satin scenery dizzy snob peak pilgrim farmer jog peony ownership stupid blowgun moat bull macrame promise trot wildebeest vacation president extreme little aquifer stove cofactor squalid marksman newsprint axis jellyfish profit due piece trophy step-son rite strange malnutrition dispute area suspect leading cofactor occurrence tattoo brownie measly clone tactics palate unify furry banyan omission refrigerator effector encouraging peaceful corsage judo warren pilgrim diaper humidity turmeric somber reveal notepad doubt boy egg muscatel enactment dashing catsup battleship maintainer flour tavern screenwriting newspaper ballpark serum parrot tadpole castle pancreas ash havoc samurai underweight venture intention floodplain doing revitalisation driveway interior footstep clever altered subway quota height loyalty interpret framework cousin bowl selfish picture fulfillment tough interpreter cheesecake handball salty reader sombrero drudgery bondsman crib thanks okra territory capon presidency volatile celebrity tract motorboat boom known disco vineyard aftershave goofy ethereal hen grandmom lackadaisical astrology sousaphone satisfaction recruit quaint concerned intentionality composition overload worker mission urge female chicory bunghole greed smoke schoolhouse comradeship summer glen glut sensibility nut lung veneer comestible brownie tights prisoner forager airmail mug salad anagram lonely lashes chance officiate affidavit crewmen roster curved map porch compliance test peer-to-peer talented sailing cicada pard settlement capability scraper pocket-watch windscreen proctor creationism tag darkness hormone copy elite teller switching cancer server fanatical stake cliff litmus mailing speakerphone extend'}, {'role': 'user', 'content': '1719723278.1225512 write a long essay about machine learning in at least 250 tokens'}] and Context Tokens: 1006 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723278.1225512 challenge atheist coherent cloves somebody doctor reconcile cliff willow masterpiece slide nest scribble covariate marionberry solicitation chalet spider gumshoe sell minimum hoe executive nanoparticle tusk nit wetland compassionate aspic depression quartz rainy utilisation cloistered azimuth decisive casserole kid homogenate fav monkey way battery divide acid spray cinnamon scooter commotion priesthood repository cave degree house advertisement collectivization primate bourgeoisie merchandise wood enacted trillion nephew juggernaut feeding easel vacation jacket stumbling exterior gall-bladder quinoa brush likeness verve spacing dogsled bidding playwright chrome application circumstance envious carboxyl nose unpack assertion density drake servitude coonskin storyboard imitation inheritance rat limit storage stomach yeast puggle hearthside pillow reconsideration labour coordinate inside tutor satin headphones abiding hardware workout scary satellite encouragement pork con mistake half surround climb mathematics midden tenant gradient reflect smite trailpatrol deodorant evil normal networking breadcrumb passing regulate recipe caption ballpark afternoon waffle anywhere interest cymbal ride ruthless point tooth route apprehension reign late enhance uppity misrepresentation men mRNA productive tangerine traffic landscape accidental watchmaker federation vanity pyridine didactic basil necktie fetus shin suitcase voracious pitcher arrow ambition progression backdrop kohlrabi abrogation valuable teriyaki sprinter pot chaos scholar ladder abundance confess felony nitrogen otter crate uptight tickle digestive mere timeline kitchen border dimension trait maize hash chunky zealous blessing confectionery chainstay gruesome hound writing beanie bomber sweatsuit pass curler monument bill face achievement copyright deep pajamas unit lake elevator shampoo foolish artichoke happening game roasted beer meteor haze armpit excursion estrogen fool examine airport thoughtful armour bestseller wingtip downgrade clave balaclava reply venison clumsy reflection signify credenza blame postbox soda range headrest skyscraper drawer gaudy hatred till crest mukluk tuber cupola reason tawdry antennae veneer cutlet chub pan overcome assistant maintain deliver voracious initial dwarf killing slide receipt chorus colossal doctrine warlock semicircle altitude escort pinstripe expensive cephalopod injure moaning elver fair barber endure goat spatula quack solicitation regret wacky tinkle complement restored account tax step-grandmother diadem aid collateral treasury colony joke assessment print dam spot proximity physiology harvester reporting destiny champagne resonant rutabaga panpipe vertigo whole lesbian chestnut fibroblast pate elk press license cap reconcile dogwood dust vendor farm union resolve troubleshoot end sew saddle descent plasterboard cynical trustee goodnight alcoholic coherent daffy rosemary programming incandescent icicle tasteless classic smell worth backdrop blueberry retire childbirth accomplish corral collision simvastatin messy moan winter coat mathematics disparity correct tissue boorish chrysalis hum lip pail see vast gemsbok titanium tame architect museum plover option guarantee lily awake surgeon beautiful shoreline dinner dilution daughter clear aircraft hatchling aim prosecutor enlist mom enquiry ban oregano version underwriting outhouse crust sailing taxi disregard tracking metabolite pathology eyelashes hometown booty upper choose parenting galoshes explain grain sub synthesis grease acted radiator meantime spray gander concern sinuosity marathon belligerent mysterious instrument glance wharf apron satin scenery dizzy snob peak pilgrim farmer jog peony ownership stupid blowgun moat bull macrame promise trot wildebeest vacation president extreme little aquifer stove cofactor squalid marksman newsprint axis jellyfish profit due piece trophy step-son rite strange malnutrition dispute area suspect leading cofactor occurrence tattoo brownie measly clone tactics palate unify furry banyan omission refrigerator effector encouraging peaceful corsage judo warren pilgrim diaper humidity turmeric somber reveal notepad doubt boy egg muscatel enactment dashing catsup battleship maintainer flour tavern screenwriting newspaper ballpark serum parrot tadpole castle pancreas ash havoc samurai underweight venture intention floodplain doing revitalisation driveway interior footstep clever altered subway quota height loyalty interpret framework cousin bowl selfish picture fulfillment tough interpreter cheesecake handball salty reader sombrero drudgery bondsman crib thanks okra territory capon presidency volatile celebrity tract motorboat boom known disco vineyard aftershave goofy ethereal hen grandmom lackadaisical astrology sousaphone satisfaction recruit quaint concerned intentionality composition overload worker mission urge female chicory bunghole greed smoke schoolhouse comradeship summer glen glut sensibility nut lung veneer comestible brownie tights prisoner forager airmail mug salad anagram lonely lashes chance officiate affidavit crewmen roster curved map porch compliance test peer-to-peer talented sailing cicada pard settlement capability scraper pocket-watch windscreen proctor creationism tag darkness hormone copy elite teller switching cancer server fanatical stake cliff litmus mailing speakerphone extend'}, {'role': 'user', 'content': '1719723278.1225512 write a long essay about machine learning in at least 250 tokens'}] and Context Tokens: 1006\n",
      "2024-06-29 23:54:38,128 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:38,133 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 23:54:38.131809, (GMT): 2024-06-30 04:54:38.133327+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 23:54:38.131809, (GMT): 2024-06-30 04:54:38.133327+00:00\n",
      "2024-06-29 23:54:38,140 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.31 seconds or 1305.76 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.31 seconds or 1305.76 milliseconds.\n",
      "2024-06-29 23:54:38,791 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:38,835 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.66 seconds or 1660.7 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.66 seconds or 1660.7 milliseconds.\n",
      "2024-06-29 23:54:39,157 - micro - MainProcess - INFO     CPU usage: 29.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 29.4%\n",
      "2024-06-29 23:54:39,168 - micro - MainProcess - INFO     RAM usage: 86.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.2%\n",
      "2024-06-29 23:54:39,191 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:54:39,198 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:39,287 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723279.2870934 essence interviewer deserve vast flash hydrolysis spacing solidity wander tart e-mail result practice compress cholesterol romance hollow radish spree runner quickest quill bugle downforce determined lean cold landing island painful haste opposite technology drainage robust ribbon ossified promenade high heart-throb clavier roadway chick doughnut animated feast ginger bless termite warmth fedelini claw sleepiness associate manner socialism inversion appear switchboard backdrop subsidy wine spell finish provision baseboard communion lip armchair flour globe headline morbidity teapot orator jellyfish fraudster nectar sphynx steward puma expense hellcat difficulty supper street dill southeast hose abounding chipmunk devastation overflow samovar rod newsprint coconut offer politics thaw ephemeris gaffe dip stir festive washer motion chamber clogs screenwriting pavement tractor compare painter rumor pail evaluation dilapidation mute offbeat trash tactics selection cria stumbling controversy med ripe great display bug regulation vintner collard humdrum loose psychedelic actor anything abnormal age roommate highland clam executor array haunt gullible dry zucchini rake sedate contributor stepson consist theism sonata half involvement diagnosis tiny walk citron beech justice irony cornet pince-nez scatter gnat gossip mandate guilt hate royal network angel peanut sparerib watch bank fusarium millimeter spectrum disillusioned bongo bronchitis lie lychee federation kit oxygen abdomen adult district tow-truck dimension boudoir daffodil side glib cloakroom prow sweltering nurse handsaw buzzard relaxation mechanism upgrade batting dish killer motorcar commitment pay condor counsellor berry tuxedo profit itch probability lyocell airplane delay launch pegboard hurdle pannier acceptance withdraw moron attitude arrogance geometry collect barbeque wraparound homeless conformation digging entertaining willow motorcar pen press work inquiry warlock gold philosopher sideburns rally evening-wear coast decoration bride shingle output howard ceremony fulfillment gutter income serum twist depend charter thermals tenement founding gray underpass colonisation integral aide verbalize adaptation weeder barrel humor defender ideal earthy canal greet absence attainment handicap effective coincidence examine subsidy extension park crewmate slapstick swanling troubled make tonic project driveway ATM wit someplace familiarity space incompetence legume dueling editorial phone wish strong bored steer ceramics abnormal bring wooden calico shoe-horn woodshed stage heifer tramp date deserve circumference comment spatula pattern security understanding shadowbox pruner pig working gynaecology stream noon venison mRNA covariate null terror form SUV ratepayer cheetah coin cereal total headache cheddar statuesque retention planter perpetual hiking damaged south trek heady incarnation impartial plume gang pseudocode mode charm daikon chair dude rescue evolution skullduggery duffel forum partner judicious explanation promenade part critic sweets position calorie teammate ziggurat progression dud owl jug stem hub dickey dad e-mail jockey bomber regard finger mincemeat corporation study sunshine snowflake arrest alligator experimentation mutt tentacle chivalry troubleshoot somebody screw-up evaporation loincloth sprag examine conflict institute blessing tone sleepiness siege kitchen cowbell wealth bankruptcy assembly issue license margarine sibling activation berry landscape draft broom vanish download haversack vintner vampire bright maximum grit tank-top mower grandma citizenship grab-bag presidency torte receptor proportion variation barn disaster decide beheading punctuation sundial octet incarnation booklet niece hectare weather hatred cynic fierce commandment liberty fundraising democrat open wifi neurobiologist afternoon crewman doubling excitement sensibility chairlift busy confusion maniac synod chub physiology stool artist intelligence bugle giggle endure reader borrow hypothesis vignette petticoat fish credible transmission operation guess hybridization loggia empowerment doorpost astronomy forsake brush expensive pun peace diamond hapless plead reinscription seabass combine solve direful validate contest sediment factor horn patience hyena hope jagged order moose underweight warfare soap sympathy prevalence massive quart liver agriculture dromedary gasp opportunity zonked supervisor stiletto norm shadow viola tornado guideline swing division zoom priest worm holistic save volatility stucco pipeline helpless laborer dignity terrify terrible ad yoyo strange examiner disclosure panic mangrove spume herb lysine petitioner sprat squalid weigh phenotype pillow caftan housewife wail fresh jellyfish pickup con grass tabernacle spawn monkey flow shirtdress isogloss forgive rowboat excess spool immense headline unadvised manacle simplify brassiere favor displacement dredger angry juvenile speak cloth peen complication dedication diagnosis copywriter destination arise soccer urge purchase cottage basil patience moth sexuality prelude cirrus harbour curious summer orientation discharge runner logic tangy senator wee courtroom self-esteem buckle enterprise attitude aftermath excited satisfy orientation assist van excite diversity debtor forbid marimba begonia insurgence cauliflower colony temporary loft ammunition minister vise pupa stepdaughter shirt'}, {'role': 'user', 'content': '1719723279.2870934 write a long essay about machine learning in at least 100 tokens'}] and Context Tokens: 1007 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723279.2870934 essence interviewer deserve vast flash hydrolysis spacing solidity wander tart e-mail result practice compress cholesterol romance hollow radish spree runner quickest quill bugle downforce determined lean cold landing island painful haste opposite technology drainage robust ribbon ossified promenade high heart-throb clavier roadway chick doughnut animated feast ginger bless termite warmth fedelini claw sleepiness associate manner socialism inversion appear switchboard backdrop subsidy wine spell finish provision baseboard communion lip armchair flour globe headline morbidity teapot orator jellyfish fraudster nectar sphynx steward puma expense hellcat difficulty supper street dill southeast hose abounding chipmunk devastation overflow samovar rod newsprint coconut offer politics thaw ephemeris gaffe dip stir festive washer motion chamber clogs screenwriting pavement tractor compare painter rumor pail evaluation dilapidation mute offbeat trash tactics selection cria stumbling controversy med ripe great display bug regulation vintner collard humdrum loose psychedelic actor anything abnormal age roommate highland clam executor array haunt gullible dry zucchini rake sedate contributor stepson consist theism sonata half involvement diagnosis tiny walk citron beech justice irony cornet pince-nez scatter gnat gossip mandate guilt hate royal network angel peanut sparerib watch bank fusarium millimeter spectrum disillusioned bongo bronchitis lie lychee federation kit oxygen abdomen adult district tow-truck dimension boudoir daffodil side glib cloakroom prow sweltering nurse handsaw buzzard relaxation mechanism upgrade batting dish killer motorcar commitment pay condor counsellor berry tuxedo profit itch probability lyocell airplane delay launch pegboard hurdle pannier acceptance withdraw moron attitude arrogance geometry collect barbeque wraparound homeless conformation digging entertaining willow motorcar pen press work inquiry warlock gold philosopher sideburns rally evening-wear coast decoration bride shingle output howard ceremony fulfillment gutter income serum twist depend charter thermals tenement founding gray underpass colonisation integral aide verbalize adaptation weeder barrel humor defender ideal earthy canal greet absence attainment handicap effective coincidence examine subsidy extension park crewmate slapstick swanling troubled make tonic project driveway ATM wit someplace familiarity space incompetence legume dueling editorial phone wish strong bored steer ceramics abnormal bring wooden calico shoe-horn woodshed stage heifer tramp date deserve circumference comment spatula pattern security understanding shadowbox pruner pig working gynaecology stream noon venison mRNA covariate null terror form SUV ratepayer cheetah coin cereal total headache cheddar statuesque retention planter perpetual hiking damaged south trek heady incarnation impartial plume gang pseudocode mode charm daikon chair dude rescue evolution skullduggery duffel forum partner judicious explanation promenade part critic sweets position calorie teammate ziggurat progression dud owl jug stem hub dickey dad e-mail jockey bomber regard finger mincemeat corporation study sunshine snowflake arrest alligator experimentation mutt tentacle chivalry troubleshoot somebody screw-up evaporation loincloth sprag examine conflict institute blessing tone sleepiness siege kitchen cowbell wealth bankruptcy assembly issue license margarine sibling activation berry landscape draft broom vanish download haversack vintner vampire bright maximum grit tank-top mower grandma citizenship grab-bag presidency torte receptor proportion variation barn disaster decide beheading punctuation sundial octet incarnation booklet niece hectare weather hatred cynic fierce commandment liberty fundraising democrat open wifi neurobiologist afternoon crewman doubling excitement sensibility chairlift busy confusion maniac synod chub physiology stool artist intelligence bugle giggle endure reader borrow hypothesis vignette petticoat fish credible transmission operation guess hybridization loggia empowerment doorpost astronomy forsake brush expensive pun peace diamond hapless plead reinscription seabass combine solve direful validate contest sediment factor horn patience hyena hope jagged order moose underweight warfare soap sympathy prevalence massive quart liver agriculture dromedary gasp opportunity zonked supervisor stiletto norm shadow viola tornado guideline swing division zoom priest worm holistic save volatility stucco pipeline helpless laborer dignity terrify terrible ad yoyo strange examiner disclosure panic mangrove spume herb lysine petitioner sprat squalid weigh phenotype pillow caftan housewife wail fresh jellyfish pickup con grass tabernacle spawn monkey flow shirtdress isogloss forgive rowboat excess spool immense headline unadvised manacle simplify brassiere favor displacement dredger angry juvenile speak cloth peen complication dedication diagnosis copywriter destination arise soccer urge purchase cottage basil patience moth sexuality prelude cirrus harbour curious summer orientation discharge runner logic tangy senator wee courtroom self-esteem buckle enterprise attitude aftermath excited satisfy orientation assist van excite diversity debtor forbid marimba begonia insurgence cauliflower colony temporary loft ammunition minister vise pupa stepdaughter shirt'}, {'role': 'user', 'content': '1719723279.2870934 write a long essay about machine learning in at least 100 tokens'}] and Context Tokens: 1007\n",
      "2024-06-29 23:54:39,291 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:39,293 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 100 at (Local time): 2024-06-29 23:54:39.293265, (GMT): 2024-06-30 04:54:39.293265+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 100 at (Local time): 2024-06-29 23:54:39.293265, (GMT): 2024-06-30 04:54:39.293265+00:00\n",
      "2024-06-29 23:54:39,842 - micro - MainProcess - INFO     CPU usage: 18.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 18.5%\n",
      "2024-06-29 23:54:39,853 - micro - MainProcess - INFO     RAM usage: 86.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.4%\n",
      "2024-06-29 23:54:39,875 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:54:39,882 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:39,985 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723279.9855795 greet source resistance atelier watchmaker checkbook polo tenet main tavern jar faithful vanilla causal transcript ton code pumpkin kitty highfalutin drawbridge representation asterisk reader metallurgist sculptural counter-force runner botany watery little gorilla rice grandparent caftan forehead cafe effector display ballet tawdry refund tangible dealer mine primate celeriac calf pig screen fishing comb decongestant forgery blush rage bruise wound birdbath weekend fallacy cilantro webinar statue dune chassis clef dragonfruit congregation stick wolf weight neighborly succeed charger pantologist swamp torte finding tandem shaw tick receiver neighbour sorbet dill glut shift tramp biplane disapprove software lobster lieutenant screamer carotene spur neurobiologist chug handsaw soulmate lumber youngster tradition heirloom actor nondescript macaroon inn consideration interfere pest lizard shackle cesspool harbor overthrow late draw chubby edge keyboard carpenter shadowbox zoom pass million bonding supplement testament point destroy seep premium pancreas macadamia imminent incident rest mycoplasma cousin allegation gas entity corridor adorable hospitalization supporter fright paw auction satellite faculty job porch picture flip-flops early headrest lilac damage preoccupation detection coral soak flu risk headphones thunder dungeon c-clamp slapstick carriage anxiety thong rhythm tub oasis subcontractor incompetent perpetual mean windscreen excerpt index enthusiastic barbeque jewellery spreadsheet embellishment riot vine jog garlic educated aim means earthworm extension disclosure cappuccino bamboo rain venom insurance destroyer liability dilution centurion rib compensation hysterical necktie driver puddle spleen issue attention hallway repulsive mainstream earthy concerned divorce debris marten intend river spotless antling alibi journal nick boon democracy twister fishbone calculation elderberry perfection takeover bunghole dysfunctional hiccups bootee skywalk shout analog cheddar bonus discrepancy eel tentacle shoat osprey plover poignance honorable lazy list bother fritter buck crepe dynamic score latter gruesome boorish plot riddle celery pleat hail imperfect shofar newspaper mature gorgeous vivacious booster harmonious stop behave politician sturgeon carriage cottage ad gymnastics swordfish sit load domain green mill jury division inn chalk tremble stereo background glee alliance nobody obnoxious actor nymph camp wheel second poetry solitaire castle bumpy exuberant millstone mambo mRNA decisive birdbath used cuisine sickness hatchling fig closing certainty precedence crawdad utilisation pour bonsai wake upbeat cartload obi rostrum breastplate crowded cacao steeple justification reservoir past museum prejudice bunkhouse notoriety dead plunger trinket soothsay interest commander hood ore gorilla prefix congressman shoehorn new junker comeback steal proceedings developing painful overrated starter wiretap functional racial pace antelope casement reproduce hurdler angle antling championship shawl boiling restored foresee blog apron alibi crime beet formation thought embryo eavesdropper top-hat bizarre frosting bun feel divert rape x-ray corruption elegant cold drizzle sequence furry swamp providence bean cyclamen venture coordinate macho accord wrecker whorl tough-guy reporting intend formulate wit belong cultivator pompom ghost machine variable walkway leeway half-brother repayment slate processing witty appetizer hungry drip revolution outfit enactment raisin crewmate innovation dad warm humdrum role partridge ubiquitous dude prostacyclin venison cheek acid trail valuable real berserk haze victorious bough refusal fisherman multiply extinction pad netball tension look youth excite riding bow product loss intention TV chance heritage badge invite substance inventor phase bloomer hunchback elixir street full TV cappuccino creationism fedelini compute wedding macaroon vector preside communication recliner addicted stamina cathedral seeker slink jobless hutch tonality alcohol tour mainstream caption quiet clever blood external dwelling fox bizarre embossing egg rabid aggression beginning ignorance copywriter awake magenta monastery door firm mere colloquy secretary drainage harbour still fledgling decision pricing tog petticoat wombat bugle turban chain ecology controller vol twister participation gather stumbling relay mislead hermit dungeon sender ascend ankle harbor trapezoid skunk code doctrine tatami airport melted loose checkroom buckle resident neon blade briefly fuzzy survival season tank shorts astronomy venture reciprocity favor hyphenation capitalism encyclopedia ambulance neighbourhood crude sausage toy festival contrary paramecium bed ruin smile plum sash imitation interior symmetry update campaign deserve fling anise parameter refusal crabby lean currency tax tributary childbirth adrenalin exhibition penicillin immense handle tinkle annoy boil discussion rage jet exploration hand drainage cashew skeleton stretch voice talking dream manufacturing feigned verve prevention eggnog screening hungry itch rescue spicy reamer claim still eddy lyocell inconvenience boil massage competitor cord length eatable watch screwdriver cellar attractive cloth soothsay'}, {'role': 'user', 'content': '1719723279.9855795 write a long essay about machine learning in at least 150 tokens'}] and Context Tokens: 1006 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723279.9855795 greet source resistance atelier watchmaker checkbook polo tenet main tavern jar faithful vanilla causal transcript ton code pumpkin kitty highfalutin drawbridge representation asterisk reader metallurgist sculptural counter-force runner botany watery little gorilla rice grandparent caftan forehead cafe effector display ballet tawdry refund tangible dealer mine primate celeriac calf pig screen fishing comb decongestant forgery blush rage bruise wound birdbath weekend fallacy cilantro webinar statue dune chassis clef dragonfruit congregation stick wolf weight neighborly succeed charger pantologist swamp torte finding tandem shaw tick receiver neighbour sorbet dill glut shift tramp biplane disapprove software lobster lieutenant screamer carotene spur neurobiologist chug handsaw soulmate lumber youngster tradition heirloom actor nondescript macaroon inn consideration interfere pest lizard shackle cesspool harbor overthrow late draw chubby edge keyboard carpenter shadowbox zoom pass million bonding supplement testament point destroy seep premium pancreas macadamia imminent incident rest mycoplasma cousin allegation gas entity corridor adorable hospitalization supporter fright paw auction satellite faculty job porch picture flip-flops early headrest lilac damage preoccupation detection coral soak flu risk headphones thunder dungeon c-clamp slapstick carriage anxiety thong rhythm tub oasis subcontractor incompetent perpetual mean windscreen excerpt index enthusiastic barbeque jewellery spreadsheet embellishment riot vine jog garlic educated aim means earthworm extension disclosure cappuccino bamboo rain venom insurance destroyer liability dilution centurion rib compensation hysterical necktie driver puddle spleen issue attention hallway repulsive mainstream earthy concerned divorce debris marten intend river spotless antling alibi journal nick boon democracy twister fishbone calculation elderberry perfection takeover bunghole dysfunctional hiccups bootee skywalk shout analog cheddar bonus discrepancy eel tentacle shoat osprey plover poignance honorable lazy list bother fritter buck crepe dynamic score latter gruesome boorish plot riddle celery pleat hail imperfect shofar newspaper mature gorgeous vivacious booster harmonious stop behave politician sturgeon carriage cottage ad gymnastics swordfish sit load domain green mill jury division inn chalk tremble stereo background glee alliance nobody obnoxious actor nymph camp wheel second poetry solitaire castle bumpy exuberant millstone mambo mRNA decisive birdbath used cuisine sickness hatchling fig closing certainty precedence crawdad utilisation pour bonsai wake upbeat cartload obi rostrum breastplate crowded cacao steeple justification reservoir past museum prejudice bunkhouse notoriety dead plunger trinket soothsay interest commander hood ore gorilla prefix congressman shoehorn new junker comeback steal proceedings developing painful overrated starter wiretap functional racial pace antelope casement reproduce hurdler angle antling championship shawl boiling restored foresee blog apron alibi crime beet formation thought embryo eavesdropper top-hat bizarre frosting bun feel divert rape x-ray corruption elegant cold drizzle sequence furry swamp providence bean cyclamen venture coordinate macho accord wrecker whorl tough-guy reporting intend formulate wit belong cultivator pompom ghost machine variable walkway leeway half-brother repayment slate processing witty appetizer hungry drip revolution outfit enactment raisin crewmate innovation dad warm humdrum role partridge ubiquitous dude prostacyclin venison cheek acid trail valuable real berserk haze victorious bough refusal fisherman multiply extinction pad netball tension look youth excite riding bow product loss intention TV chance heritage badge invite substance inventor phase bloomer hunchback elixir street full TV cappuccino creationism fedelini compute wedding macaroon vector preside communication recliner addicted stamina cathedral seeker slink jobless hutch tonality alcohol tour mainstream caption quiet clever blood external dwelling fox bizarre embossing egg rabid aggression beginning ignorance copywriter awake magenta monastery door firm mere colloquy secretary drainage harbour still fledgling decision pricing tog petticoat wombat bugle turban chain ecology controller vol twister participation gather stumbling relay mislead hermit dungeon sender ascend ankle harbor trapezoid skunk code doctrine tatami airport melted loose checkroom buckle resident neon blade briefly fuzzy survival season tank shorts astronomy venture reciprocity favor hyphenation capitalism encyclopedia ambulance neighbourhood crude sausage toy festival contrary paramecium bed ruin smile plum sash imitation interior symmetry update campaign deserve fling anise parameter refusal crabby lean currency tax tributary childbirth adrenalin exhibition penicillin immense handle tinkle annoy boil discussion rage jet exploration hand drainage cashew skeleton stretch voice talking dream manufacturing feigned verve prevention eggnog screening hungry itch rescue spicy reamer claim still eddy lyocell inconvenience boil massage competitor cord length eatable watch screwdriver cellar attractive cloth soothsay'}, {'role': 'user', 'content': '1719723279.9855795 write a long essay about machine learning in at least 150 tokens'}] and Context Tokens: 1006\n",
      "2024-06-29 23:54:39,990 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:39,992 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 150 at (Local time): 2024-06-29 23:54:39.992626, (GMT): 2024-06-30 04:54:39.992626+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 150 at (Local time): 2024-06-29 23:54:39.992626, (GMT): 2024-06-30 04:54:39.992626+00:00\n",
      "2024-06-29 23:54:40,808 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:40,835 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.1 seconds or 1097.08 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.1 seconds or 1097.08 milliseconds.\n",
      "2024-06-29 23:54:41,163 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:41,167 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 2.66 seconds or 2663.27 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 2.66 seconds or 2663.27 milliseconds.\n",
      "2024-06-29 23:54:41,843 - micro - MainProcess - INFO     CPU usage: 23.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 23.7%\n",
      "2024-06-29 23:54:41,855 - micro - MainProcess - INFO     RAM usage: 86.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.6%\n",
      "2024-06-29 23:54:41,881 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:54:41,886 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:42,021 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723282.0215626 appointment waffle cacao charity vessel scallion facilitate parchment hearth flu senate knit facelift poultry bankbook roster anime slimy gopher snug library virtue spectacular disgust normalization delightful ophthalmologist cribbage instructor evocation processor migrant oxygen colleague inglenook teller hometown step-mother minor fall brooch disruption relief setback spacing sun tribe extinction mourn total spank blow octave claw room lens confusion banquette masterpiece gleaming majestic knowing hilarious obscene dry secretion patio beetle gyro enquiry yoga integrity fry mailer crime shoot cable root hurried blackboard stealth violence reluctance grandmother continue godly rag smell belly squeal hellish moment grease interpreter racism terrace please distinct grapefruit folklore currant pancake latte sound sportsman governor gynaecology consignment intervenor bog intervention sofa jug emotion gesture withdrawal shearling inbox amnesty blossom care working wink chauffeur authorization cherry sunrise aside cushion gamy congress visor summarize foretell serval hobbit answer interfere crate bough faucet chilly track emu aboriginal niche thong meme armadillo arrogant spinach boost crisp pharmacopoeia region gnat melt fog paranoia savior chowder mortality record spaghetti crazy statistic sightseeing sunroom fibrosis lever antecedent stump secret scrim challenge cornerstone fight dinner wriggle rayon instant hockey better pumpkin burlesque bifocals crest domineering nosy transcript jam kiwi guerrilla hygienic visit computer zen torso tested repair yellowjacket assertion flugelhorn upper mere secretary musculature wriggler pigeon meteor thyme curve bricklaying aggressive bull dramatize decisive pattern ecology taro lode fund cactus checkout provision affair manatee knowledge spur glamorous aboard dial gemsbok magenta undergo safeguard sponsorship ligand crinoline nudge weekender laundry crooked complicity board premeditation handicap carpeting do consumption deliver curler diaper doubling tenement tickle wet-bar algorithm frown overnighter pair station jittery hops somewhere fatigues dish dilapidation staircase pawnshop baboon orator scrap heart-throb lunch remove expression insert issue big sore school infinite cap foundation decoder mortal exocrine syndrome hunting accidental courthouse debonair prickly aggradation snarl habitual sweet nationality surprise in-joke hosiery attend chin connect foray situation turmeric adult altered jazz eminent downforce processor compensation abject tin ape needle afternoon pastoral fire ecclesia zombie chauffeur ossified toy candidacy lobotomy minister summer instrumentation wildlife transom headline pleasure digit tutor mass heron lewd upgrade dragster codling tough-guy secretion annoy swamp permafrost unpack cohort nasal shoestring possess split laugh vivo palace adjoining persimmon paint pony soliloquy cockpit past SUV gasket eicosanoid walkway comic choke tech seashore intellect carport retention float formulate macaroni cartel implement solid interconnection applied sentence anise trade volume itch cause conserve teapot tear tomatillo circulation ceremony balalaika bootee loggia commodity ruckus freon saving archives privilege achieve lipoprotein mortal term rank monastery voice mountain zipper handrail typewriter walnut snotty difficult chair grotesque inquiry peach default baboon author coyote legitimacy curd agenda tiresome spectrum stallion prosecutor magenta cylinder catamaran eyelids behalf orator rotation marksman acrid troop zealous joke species gravy tortilla ecliptic incidence shopping marketing deadpan import jet boorish feel mirror reinforce yoga future argue tourism adulthood threatening permit freezer eicosanoid beef seashore program legislator chapel fedora dapper flint accelerant collision impudence lunch withhold trading industrialisation garden know basis choose college defiant tavern twig street feedback sunflower snore orange disregard innervation puny pumpernickel complement amused mythology print doctorate trapezium apparatus publication algorithm ruin workforce sofa spool crayfish dame cope tonight phosphate primary alluvium caramel amber beat disprove sinuosity longboat voice sorbet treatment faith accountability turtle clarinet oeuvre columnist pajamas broker graft front massive enthusiastic longing cormorant teriyaki wrathful moaning elongation lean sled fig carter detector pit lopsided critic distribute tip neuron stamen diver intent friendship couch miniature monsoon unadvised lush health-care rider efficacious lacquerware pistol publication comportment inspire training reputation build ravioli cheerful restriction complete curtain gazelle reflection mutt tournament gander independent notoriety reparation coaster wandering strange yesterday gigantism bonus settlement textual tow opium carabao palate total terminal efficiency sidestream blossom sun scarce reinscription marker hotel roller spatula compass hourglass licorice ketchup veil disco learning atrium airforce die reminiscent massive doing prescribe neighbourhood loneliness teacher waiter daddy represent regulate tale sweet parsnip steep bribery obtain baby stream vague observation curious swift imitation hostel connection syndicate playroom commander endpoint produce pub remark tease watchful solicitor shot methane step-aunt'}, {'role': 'user', 'content': '1719723282.0215626 write a long essay about machine learning in at least 100 tokens'}] and Context Tokens: 1006 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723282.0215626 appointment waffle cacao charity vessel scallion facilitate parchment hearth flu senate knit facelift poultry bankbook roster anime slimy gopher snug library virtue spectacular disgust normalization delightful ophthalmologist cribbage instructor evocation processor migrant oxygen colleague inglenook teller hometown step-mother minor fall brooch disruption relief setback spacing sun tribe extinction mourn total spank blow octave claw room lens confusion banquette masterpiece gleaming majestic knowing hilarious obscene dry secretion patio beetle gyro enquiry yoga integrity fry mailer crime shoot cable root hurried blackboard stealth violence reluctance grandmother continue godly rag smell belly squeal hellish moment grease interpreter racism terrace please distinct grapefruit folklore currant pancake latte sound sportsman governor gynaecology consignment intervenor bog intervention sofa jug emotion gesture withdrawal shearling inbox amnesty blossom care working wink chauffeur authorization cherry sunrise aside cushion gamy congress visor summarize foretell serval hobbit answer interfere crate bough faucet chilly track emu aboriginal niche thong meme armadillo arrogant spinach boost crisp pharmacopoeia region gnat melt fog paranoia savior chowder mortality record spaghetti crazy statistic sightseeing sunroom fibrosis lever antecedent stump secret scrim challenge cornerstone fight dinner wriggle rayon instant hockey better pumpkin burlesque bifocals crest domineering nosy transcript jam kiwi guerrilla hygienic visit computer zen torso tested repair yellowjacket assertion flugelhorn upper mere secretary musculature wriggler pigeon meteor thyme curve bricklaying aggressive bull dramatize decisive pattern ecology taro lode fund cactus checkout provision affair manatee knowledge spur glamorous aboard dial gemsbok magenta undergo safeguard sponsorship ligand crinoline nudge weekender laundry crooked complicity board premeditation handicap carpeting do consumption deliver curler diaper doubling tenement tickle wet-bar algorithm frown overnighter pair station jittery hops somewhere fatigues dish dilapidation staircase pawnshop baboon orator scrap heart-throb lunch remove expression insert issue big sore school infinite cap foundation decoder mortal exocrine syndrome hunting accidental courthouse debonair prickly aggradation snarl habitual sweet nationality surprise in-joke hosiery attend chin connect foray situation turmeric adult altered jazz eminent downforce processor compensation abject tin ape needle afternoon pastoral fire ecclesia zombie chauffeur ossified toy candidacy lobotomy minister summer instrumentation wildlife transom headline pleasure digit tutor mass heron lewd upgrade dragster codling tough-guy secretion annoy swamp permafrost unpack cohort nasal shoestring possess split laugh vivo palace adjoining persimmon paint pony soliloquy cockpit past SUV gasket eicosanoid walkway comic choke tech seashore intellect carport retention float formulate macaroni cartel implement solid interconnection applied sentence anise trade volume itch cause conserve teapot tear tomatillo circulation ceremony balalaika bootee loggia commodity ruckus freon saving archives privilege achieve lipoprotein mortal term rank monastery voice mountain zipper handrail typewriter walnut snotty difficult chair grotesque inquiry peach default baboon author coyote legitimacy curd agenda tiresome spectrum stallion prosecutor magenta cylinder catamaran eyelids behalf orator rotation marksman acrid troop zealous joke species gravy tortilla ecliptic incidence shopping marketing deadpan import jet boorish feel mirror reinforce yoga future argue tourism adulthood threatening permit freezer eicosanoid beef seashore program legislator chapel fedora dapper flint accelerant collision impudence lunch withhold trading industrialisation garden know basis choose college defiant tavern twig street feedback sunflower snore orange disregard innervation puny pumpernickel complement amused mythology print doctorate trapezium apparatus publication algorithm ruin workforce sofa spool crayfish dame cope tonight phosphate primary alluvium caramel amber beat disprove sinuosity longboat voice sorbet treatment faith accountability turtle clarinet oeuvre columnist pajamas broker graft front massive enthusiastic longing cormorant teriyaki wrathful moaning elongation lean sled fig carter detector pit lopsided critic distribute tip neuron stamen diver intent friendship couch miniature monsoon unadvised lush health-care rider efficacious lacquerware pistol publication comportment inspire training reputation build ravioli cheerful restriction complete curtain gazelle reflection mutt tournament gander independent notoriety reparation coaster wandering strange yesterday gigantism bonus settlement textual tow opium carabao palate total terminal efficiency sidestream blossom sun scarce reinscription marker hotel roller spatula compass hourglass licorice ketchup veil disco learning atrium airforce die reminiscent massive doing prescribe neighbourhood loneliness teacher waiter daddy represent regulate tale sweet parsnip steep bribery obtain baby stream vague observation curious swift imitation hostel connection syndicate playroom commander endpoint produce pub remark tease watchful solicitor shot methane step-aunt'}, {'role': 'user', 'content': '1719723282.0215626 write a long essay about machine learning in at least 100 tokens'}] and Context Tokens: 1006\n",
      "2024-06-29 23:54:42,064 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:42,072 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 100 at (Local time): 2024-06-29 23:54:42.072310, (GMT): 2024-06-30 04:54:42.072310+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 100 at (Local time): 2024-06-29 23:54:42.072310, (GMT): 2024-06-30 04:54:42.072310+00:00\n",
      "2024-06-29 23:54:42,079 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:42,083 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.74 seconds or 1736.53 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.74 seconds or 1736.53 milliseconds.\n",
      "2024-06-29 23:54:42,186 - micro - MainProcess - INFO     CPU usage: 40.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 40.1%\n",
      "2024-06-29 23:54:42,197 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-06-29 23:54:42,217 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:54:42,223 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:42,324 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723282.3242717 saffron pendulum pumpkinseed chocolate sousaphone pard toaster sociology hexagon coordination everything uppity sycamore reduction detainee okra floodplain singer harbor ludicrous badger accommodation locality cameo gong stance arrow marketing memory shock possibility acupuncture admission prince achieve nebulous mariachi battleship mule parent tote wear lewd scissors screw-up describe sidewalk tracking backbone fasten silica gaming sentence night section dreamer wardrobe gleaming cupola monitor experience corn slider organize pill cob infarction archaeology decisive plate rhubarb repair timer prick stereo veneer assist fantastic anywhere headline government glasses serve concentration dispense rotten legume chateau reamer horrible codling station-wagon own intuition swell graph bathhouse jelly value dignity gosling symptomatic wrong heating instrumentation phrasing polarisation accidental rebellious rib shivering jazzy observe self-esteem sense wholesale sympathy table winery secretion conformation sneakers interfere thread mow generation extend countryside submitter glut shallow overcome coast mochi wad alight nosy bug compulsion come sermon show-stopper broom fowl screening greedy wistful retention butterfly cartilage sandpaper encouragement husband elbow bench assistant baggie lord fragile cleric realize eve explode condor basil feast grieving creep effort backdrop figurine mushroom gastropod bijou youngster salmon fibrosis pin anticipation idea dinner stress thongs enterprise altitude crew poignance brow yoga financing jaw absorbing bureau parchment pleasure wetsuit ratty ocean wash trainer boundless buffalo ignorance divert calculus complexity step-uncle rally diffuse bosom scientific lute observation ship court fen syndicate shortage flippant hive abide debate emanate recommendation earthquake bawdy collar maize behold fertile fledgling elongation greasy noir bootie dimple stand toque trace redhead pitcher buckle subject diplomacy best-seller faded restored ring tower interconnection pupa gabby aquatic ship registry foot disconnection cocktail odd automaton macaw claim jagged rate charter official label subcomponent injure casserole popsicle nudge sour lift tiara curse withhold niece trash darkness auspicious peacoat gong puppy pigsty kilogram slow small barium center wistful irritate handsaw sensitivity stopwatch cushion nominate rhetorical sow wife meter depression giant uttermost diagnosis dinosaur fillet correspondent expression afford serval blackness flour rise percentage render linguist technique manhunt propose tepee agreement schizophrenic gene nuke bull initialise tonight grain scorpion crunch imperfect dolor arrow revascularisation monasticism passage cuisine bugle tabernacle occurrence wont imagine kayak airship flock developing program language quiver housing bonnet swell trigonometry swimsuit declination microphone drug scale godparent stench naturalisation tattoo wise acre mentor dude do memo belt commonsense motionless lowly memory jumbled boolean touch anyone refund reward boat badger imaginary tech credit homicide campus meatloaf submarine escort antling read jug itchy outlay afoul uncovered venti reparation risk voracious problem pea comfort surprise delay morbidity population pinstripe velocity dueling folklore criminal effect lashes hatbox exile masterpiece friendly typeface wedding sunlamp randomisation stove educated counseling thong condominium destiny decorate handgun endorsement poker colleague brook eclipse tent jeans utensil commotion octopus patentee touch consumption ruckus tissue vitamin ferryboat waggish catalyst caper wrathful hammer whey community albatross burrow leek pass rear t-shirt fridge tube oregano belfry optimist deserted collard admit factor primary toll pomelo floor tart gall-bladder anesthesiology macrame modem bull dead roadway cardigan ninja happy gaudy bankruptcy bolero ramen hypothesis complaint program ruddy band doubtful rot painstaking locate collectivisation misplacement adjustment chorus throne grin neuropathologist residence mallard dialogue feeding plasterboard calculus chandelier eatable brash licensing most elfin stalk misogyny twine applewood browser smelting tired relay abashed gymnastics overtake sweltering major cope hake thigh imported dash captor rag flower secretariat sundae advocate heron revenge relief processor wife parent grain film ritual pinafore discussion principal confused write tangible nod sing crabby visa wild sentiment ton scrub psychologist borrow theater easy misunderstand valentine caper lime ballpark hunting yummy fund mature plate defense impediment cyclooxygenase debt vegetable underwear rubric trowel tell colorlessness bed forearm jackal infant spill dynamic code protein penguin knot diagnose patrimony carabao movement horse painting beg flint stole ladybug gather veteran personal ranger willing communicate cheesecake surplus deviation lethal walking forecast yummy doctorate serval twilight enforcement shin glamorous mushy knuckle lighten splendid belly quail real adaptable fennel creepy fun regard credential disclosure trolley hamster town bounce loud lye sunrise harmonize strap pepperoni need princess panpipe cent big barbarous singer mandate bird-watcher succeed nightclub garter protein stimulating melt assist sir corner weave pump architecture geyser riverbed resolve'}, {'role': 'user', 'content': '1719723282.3242717 write a long essay about machine learning in at least 250 tokens'}] and Context Tokens: 1005 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723282.3242717 saffron pendulum pumpkinseed chocolate sousaphone pard toaster sociology hexagon coordination everything uppity sycamore reduction detainee okra floodplain singer harbor ludicrous badger accommodation locality cameo gong stance arrow marketing memory shock possibility acupuncture admission prince achieve nebulous mariachi battleship mule parent tote wear lewd scissors screw-up describe sidewalk tracking backbone fasten silica gaming sentence night section dreamer wardrobe gleaming cupola monitor experience corn slider organize pill cob infarction archaeology decisive plate rhubarb repair timer prick stereo veneer assist fantastic anywhere headline government glasses serve concentration dispense rotten legume chateau reamer horrible codling station-wagon own intuition swell graph bathhouse jelly value dignity gosling symptomatic wrong heating instrumentation phrasing polarisation accidental rebellious rib shivering jazzy observe self-esteem sense wholesale sympathy table winery secretion conformation sneakers interfere thread mow generation extend countryside submitter glut shallow overcome coast mochi wad alight nosy bug compulsion come sermon show-stopper broom fowl screening greedy wistful retention butterfly cartilage sandpaper encouragement husband elbow bench assistant baggie lord fragile cleric realize eve explode condor basil feast grieving creep effort backdrop figurine mushroom gastropod bijou youngster salmon fibrosis pin anticipation idea dinner stress thongs enterprise altitude crew poignance brow yoga financing jaw absorbing bureau parchment pleasure wetsuit ratty ocean wash trainer boundless buffalo ignorance divert calculus complexity step-uncle rally diffuse bosom scientific lute observation ship court fen syndicate shortage flippant hive abide debate emanate recommendation earthquake bawdy collar maize behold fertile fledgling elongation greasy noir bootie dimple stand toque trace redhead pitcher buckle subject diplomacy best-seller faded restored ring tower interconnection pupa gabby aquatic ship registry foot disconnection cocktail odd automaton macaw claim jagged rate charter official label subcomponent injure casserole popsicle nudge sour lift tiara curse withhold niece trash darkness auspicious peacoat gong puppy pigsty kilogram slow small barium center wistful irritate handsaw sensitivity stopwatch cushion nominate rhetorical sow wife meter depression giant uttermost diagnosis dinosaur fillet correspondent expression afford serval blackness flour rise percentage render linguist technique manhunt propose tepee agreement schizophrenic gene nuke bull initialise tonight grain scorpion crunch imperfect dolor arrow revascularisation monasticism passage cuisine bugle tabernacle occurrence wont imagine kayak airship flock developing program language quiver housing bonnet swell trigonometry swimsuit declination microphone drug scale godparent stench naturalisation tattoo wise acre mentor dude do memo belt commonsense motionless lowly memory jumbled boolean touch anyone refund reward boat badger imaginary tech credit homicide campus meatloaf submarine escort antling read jug itchy outlay afoul uncovered venti reparation risk voracious problem pea comfort surprise delay morbidity population pinstripe velocity dueling folklore criminal effect lashes hatbox exile masterpiece friendly typeface wedding sunlamp randomisation stove educated counseling thong condominium destiny decorate handgun endorsement poker colleague brook eclipse tent jeans utensil commotion octopus patentee touch consumption ruckus tissue vitamin ferryboat waggish catalyst caper wrathful hammer whey community albatross burrow leek pass rear t-shirt fridge tube oregano belfry optimist deserted collard admit factor primary toll pomelo floor tart gall-bladder anesthesiology macrame modem bull dead roadway cardigan ninja happy gaudy bankruptcy bolero ramen hypothesis complaint program ruddy band doubtful rot painstaking locate collectivisation misplacement adjustment chorus throne grin neuropathologist residence mallard dialogue feeding plasterboard calculus chandelier eatable brash licensing most elfin stalk misogyny twine applewood browser smelting tired relay abashed gymnastics overtake sweltering major cope hake thigh imported dash captor rag flower secretariat sundae advocate heron revenge relief processor wife parent grain film ritual pinafore discussion principal confused write tangible nod sing crabby visa wild sentiment ton scrub psychologist borrow theater easy misunderstand valentine caper lime ballpark hunting yummy fund mature plate defense impediment cyclooxygenase debt vegetable underwear rubric trowel tell colorlessness bed forearm jackal infant spill dynamic code protein penguin knot diagnose patrimony carabao movement horse painting beg flint stole ladybug gather veteran personal ranger willing communicate cheesecake surplus deviation lethal walking forecast yummy doctorate serval twilight enforcement shin glamorous mushy knuckle lighten splendid belly quail real adaptable fennel creepy fun regard credential disclosure trolley hamster town bounce loud lye sunrise harmonize strap pepperoni need princess panpipe cent big barbarous singer mandate bird-watcher succeed nightclub garter protein stimulating melt assist sir corner weave pump architecture geyser riverbed resolve'}, {'role': 'user', 'content': '1719723282.3242717 write a long essay about machine learning in at least 250 tokens'}] and Context Tokens: 1005\n",
      "2024-06-29 23:54:42,330 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:42,332 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 23:54:42.332283, (GMT): 2024-06-30 04:54:42.332283+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 23:54:42.332283, (GMT): 2024-06-30 04:54:42.332283+00:00\n",
      "2024-06-29 23:54:43,095 - micro - MainProcess - INFO     CPU usage: 30.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 30.4%\n",
      "2024-06-29 23:54:43,105 - micro - MainProcess - INFO     RAM usage: 86.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.1%\n",
      "2024-06-29 23:54:43,262 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:54:43,269 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:43,378 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723283.3780231 choir banner retreat marimba oxygen bang statement sustainment anarchist reamer fear economics hiking spokeswoman build corral split trombone stamen appearance slice chief aid owner warm saffron helium weigh hummus dibble locality instruct workbench fanatical wealthy dedication landform equality classroom flap costume sink habitual stake consumption cupola shock cage permafrost tube variation dangerous fruit bulk legume adrenaline bruise chimpanzee pigpen approve plausible slider win overheard pork boycott handsome barbeque semantics pita gauge pear village late multiply livestock need organising tapioca instruction doing poetry home thrust flour rejoice diplomacy statuesque boom first propaganda barrier back-up bottling yawl adjoining tenement anything center charlatan layout clergyman mud recipe sage data motionless press rosemary expedition switching family lace silica lag democracy throne wisdom tailbud protective release scream gunpowder pipeline fugato rinse anyone alder thunder be economic colorful housewife stereo defiant oatmeal narrow botany tavern octavo bonfire eliminate entrepreneur normal netbook modernist rod future base skate fringe sheath eaves ease checking led dory female place callous ludicrous moron robin characterization broken charge transparency journalism manatee heyday authority laptop chart participant grandmother samovar personality mosquito consulate interferometer fishing imagine libido pegboard spawn accelerant boatyard nut upgrade cold intent frantic croissant ice organic wording shop wiry ham wampum hull colonial gopher verb eyelids lambkin prestige someplace intensify stair reservation verse dromedary pathology cytoplasm bidding word populist climb tailor oriented diadem juggernaut descendant downgrade ad warlord brushfire underneath commerce evidence disruption portion flash weave edge blinker polarisation archer batting disguise online hosiery street nun evaluator discount balalaika doughnut weigh timing proof-reader cure scatter kumquat diligent offense hiring pile counselling final military candle reset dime licence heavy retreat member linguist butcher sombrero trial absence elm geek imported mid-course swift sentencing helo sequel clay whimsical heritage litigation chateau behold tussle alpenglow skyscraper fluke competitor mankind obedient dancing level calico beg humidity background optimist custom expert chrysalis north detail cribbage reconsideration combination establish sensitive vibration corporatism comparison angina flipped-out summer cycle understood implication flashy socialism celery sink worry wrapping mail workout scold kitty hut trapezium brandy anise colleague detector rhetoric owner delightful bronco coevolution soybean echidna child jackal display armament readiness squash pat harsh reception density drudgery attraction detailed nation debtor velodrome harpooner depressed ugly goal analyst seal powerful polarization arrange position breakthrough e-book hunchback fen tremble eyebrow seaweed secure spree duckling brink acrid unfasten trapdoor fahrenheit newsletter soggy manacle shoe hurdle overweight empowerment hammer cent sinuosity screw-up spooky age granny sin couple ape disruption isogloss homosexual petitioner punctuation crate dulcimer councilperson rod sandal refund pupa redhead plead billboard jeans disgusted deafening king bacon stot partnership gaffer fawn enchanting loneliness impartial earsplitting management tour facsimile dizzy tablet temptress appetiser vault opponent weep suspend fashion steel attack courthouse tobacco modification meat labour spume aftermath speed year buzzard scout yurt basics stupidity blink anise hunger wasteful rear colorlessness barometer mighty ambassador bizarre recommend briefly rally provision consumer robe romaine marathon goodie harm manipulation hissing gamma-ray diction gynaecology dusty zero necklace goal life transit campaign format scandalous retouching ruddy innocent waveform apparel lead meaning matrix wrench tone interpretation structure altered method lynx sad flaky affect insect surroundings blue-eyed aberrant congo affair productivity deep march veranda pence kidney cummerbund helium illiteracy source item harmonise sprag geranium resume burrito postfix recess burial thumb abortion greenhouse ritual tawdry attachment futon investigation spooky marketer soak primary chick ugly currant flood leisure pastor gun sportsman alfalfa thoughtless gaming milkshake wail wholesaler nightclub notion booty dashboard sublet patent compete cooperative chop bifocals humidity young essay dust hackwork define boogeyman itchy abuse hour confused floozie liquor marimba schnitzel employ gun omnivore prince nonsense cultivar dissect sigh tritone conversation stand granola handrail overthrow ray alto typical show discussion imbalance doing tremble swanling loophole transom choir beating whip ketch skip tunnel swimming gambling steward desk operate tectonics lathe horror signet screen illiteracy interface counsellor online merit addition dwell prickly omnivore continuity topic inspire arrow regime hedge precision ballot knife fifth pottery capable suspension buddy chimpanzee event sweater whine strike sampan remove soup reparation honoree turnover wok dragonfruit diner cursor lift right frog scrambled whip abounding stalk ragged incense subtract different reporter grasp formicarium petal seaside laryngitis chocolate exotic suspension roast obsolete tadpole'}, {'role': 'user', 'content': '1719723283.3780231 write a long essay about machine learning in at least 150 tokens'}] and Context Tokens: 1007 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719723283.3780231 choir banner retreat marimba oxygen bang statement sustainment anarchist reamer fear economics hiking spokeswoman build corral split trombone stamen appearance slice chief aid owner warm saffron helium weigh hummus dibble locality instruct workbench fanatical wealthy dedication landform equality classroom flap costume sink habitual stake consumption cupola shock cage permafrost tube variation dangerous fruit bulk legume adrenaline bruise chimpanzee pigpen approve plausible slider win overheard pork boycott handsome barbeque semantics pita gauge pear village late multiply livestock need organising tapioca instruction doing poetry home thrust flour rejoice diplomacy statuesque boom first propaganda barrier back-up bottling yawl adjoining tenement anything center charlatan layout clergyman mud recipe sage data motionless press rosemary expedition switching family lace silica lag democracy throne wisdom tailbud protective release scream gunpowder pipeline fugato rinse anyone alder thunder be economic colorful housewife stereo defiant oatmeal narrow botany tavern octavo bonfire eliminate entrepreneur normal netbook modernist rod future base skate fringe sheath eaves ease checking led dory female place callous ludicrous moron robin characterization broken charge transparency journalism manatee heyday authority laptop chart participant grandmother samovar personality mosquito consulate interferometer fishing imagine libido pegboard spawn accelerant boatyard nut upgrade cold intent frantic croissant ice organic wording shop wiry ham wampum hull colonial gopher verb eyelids lambkin prestige someplace intensify stair reservation verse dromedary pathology cytoplasm bidding word populist climb tailor oriented diadem juggernaut descendant downgrade ad warlord brushfire underneath commerce evidence disruption portion flash weave edge blinker polarisation archer batting disguise online hosiery street nun evaluator discount balalaika doughnut weigh timing proof-reader cure scatter kumquat diligent offense hiring pile counselling final military candle reset dime licence heavy retreat member linguist butcher sombrero trial absence elm geek imported mid-course swift sentencing helo sequel clay whimsical heritage litigation chateau behold tussle alpenglow skyscraper fluke competitor mankind obedient dancing level calico beg humidity background optimist custom expert chrysalis north detail cribbage reconsideration combination establish sensitive vibration corporatism comparison angina flipped-out summer cycle understood implication flashy socialism celery sink worry wrapping mail workout scold kitty hut trapezium brandy anise colleague detector rhetoric owner delightful bronco coevolution soybean echidna child jackal display armament readiness squash pat harsh reception density drudgery attraction detailed nation debtor velodrome harpooner depressed ugly goal analyst seal powerful polarization arrange position breakthrough e-book hunchback fen tremble eyebrow seaweed secure spree duckling brink acrid unfasten trapdoor fahrenheit newsletter soggy manacle shoe hurdle overweight empowerment hammer cent sinuosity screw-up spooky age granny sin couple ape disruption isogloss homosexual petitioner punctuation crate dulcimer councilperson rod sandal refund pupa redhead plead billboard jeans disgusted deafening king bacon stot partnership gaffer fawn enchanting loneliness impartial earsplitting management tour facsimile dizzy tablet temptress appetiser vault opponent weep suspend fashion steel attack courthouse tobacco modification meat labour spume aftermath speed year buzzard scout yurt basics stupidity blink anise hunger wasteful rear colorlessness barometer mighty ambassador bizarre recommend briefly rally provision consumer robe romaine marathon goodie harm manipulation hissing gamma-ray diction gynaecology dusty zero necklace goal life transit campaign format scandalous retouching ruddy innocent waveform apparel lead meaning matrix wrench tone interpretation structure altered method lynx sad flaky affect insect surroundings blue-eyed aberrant congo affair productivity deep march veranda pence kidney cummerbund helium illiteracy source item harmonise sprag geranium resume burrito postfix recess burial thumb abortion greenhouse ritual tawdry attachment futon investigation spooky marketer soak primary chick ugly currant flood leisure pastor gun sportsman alfalfa thoughtless gaming milkshake wail wholesaler nightclub notion booty dashboard sublet patent compete cooperative chop bifocals humidity young essay dust hackwork define boogeyman itchy abuse hour confused floozie liquor marimba schnitzel employ gun omnivore prince nonsense cultivar dissect sigh tritone conversation stand granola handrail overthrow ray alto typical show discussion imbalance doing tremble swanling loophole transom choir beating whip ketch skip tunnel swimming gambling steward desk operate tectonics lathe horror signet screen illiteracy interface counsellor online merit addition dwell prickly omnivore continuity topic inspire arrow regime hedge precision ballot knife fifth pottery capable suspension buddy chimpanzee event sweater whine strike sampan remove soup reparation honoree turnover wok dragonfruit diner cursor lift right frog scrambled whip abounding stalk ragged incense subtract different reporter grasp formicarium petal seaside laryngitis chocolate exotic suspension roast obsolete tadpole'}, {'role': 'user', 'content': '1719723283.3780231 write a long essay about machine learning in at least 150 tokens'}] and Context Tokens: 1007\n",
      "2024-06-29 23:54:43,383 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:43,386 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 150 at (Local time): 2024-06-29 23:54:43.386022, (GMT): 2024-06-30 04:54:43.386022+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 150 at (Local time): 2024-06-29 23:54:43.386022, (GMT): 2024-06-30 04:54:43.386022+00:00\n",
      "2024-06-29 23:54:43,699 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:43,742 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.19 seconds or 1187.53 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.19 seconds or 1187.53 milliseconds.\n",
      "2024-06-29 23:54:45,417 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:45,455 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 2.74 seconds or 2736.88 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 2.74 seconds or 2736.88 milliseconds.\n",
      "2024-06-29 23:54:45,503 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:45,550 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.63 seconds or 1625.61 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 1.63 seconds or 1625.61 milliseconds.\n",
      "2024-06-29 23:54:46,467 - micro - MainProcess - INFO     CPU usage: 21.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 21.6%\n",
      "2024-06-29 23:54:46,476 - micro - MainProcess - INFO     RAM usage: 86.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.2%\n",
      "2024-06-29 23:54:46,490 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:807)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:54:46,494 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:46,692 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': \"1719723286.692519 simple fascia copy rally weedkiller terrorist shortage tornado amuck wastebasket grasp churn incidence put membrane ordinary attention ease doubter empowerment judgment word unibody pass strife navigation conga charter c-clamp stag march thundering woozy backup brawny vehicle gaffe pocketbook longing earn caramel gaping cottage asymmetry course messy gunpowder puma waterfront cheese load ownership cooking crinoline ultimatum drummer heavenly login cria pub pinot advance buffer entree elm constellation team sleeping pamphlet boulder uniform existence parsnip marker nail temp first obscene vaulting channel led impact scraper lipoprotein destruction angry crawdad gusty early widget maintenance gas chastity hot thyme playroom swine cassock gastropod provision warden regionalism arrogant tour cupola jack leek octet mat hospitalization corps holistic melt ratepayer chateau bank journalism lava reminder momentous overwrought fir high bow profess dolman bumpy hound fibrosis terrorism flour conscience kimono lick capability dictaphone fundraising potty bassoon script press museum harpsichord short toga tangible filing foam distortion skin trot science pattern thug berry tacky disagreement volleyball clockwork loaf leaker duck manhunt slip reminiscent disadvantage loan elite crook habitat worry factory pike pilot sunbeam oat technologist nourishment professional hake paper fantasy captain commotion reinforce recession possess teaching query comestible spleen debate scandalous yellow manage pound landmine paragraph desire visual exploration peen poverty standard noiseless ink storm residence puny president cautious foretell hut send arthur hummus spread lament ruckus poignance daffy pledge legislature watchful expert amazement plucky offbeat postage creation register slump heartbreaking music-box mushy brass cytokine discourse objection wretched estrogen chutney passion gasket contention incompetent mud bench dark cut wheat catalog ambitious mama velocity encyclopedia diamond stitch armrest forum affiliate onset discrimination herb anesthesiology woebegone computer most aboard tongue heating guarantee whisper conflict controller sandal cameo sword compulsion consulting whistle oldie mighty blackberry meaning packet slink limit leptocephalus locust redhead breastplate grandpa union pocket remove compliment integrate founder freckle recruit operate duckling sandbar monument rich playroom chimpanzee scorn skywalk elegant sanctuary perfume macho hydrofoil impairment girl atom recipe wastebasket anagram diary gynaecology bottling gel motorboat symbolize crab preserves warren blue-eyed tough-guy chivalry sweat zucchini deathwatch bread secretive legislature curved bud dangerous jumpsuit volleyball beak regionalism relax readiness wit dozen behalf boar paperback refreshments uniformity violin console corn seat flipped-out custom stadium isolation ascend snobbish second culture work bandolier beginner competition birthday mayor isogloss polarisation imagination loving shopper rumor frame pattypan ban premeditation achievement expense hearsay cloudy organisation humorous wrestler speed kingdom shed teach giddy workhorse teaching codpiece inject surround hydrocarbon catch ridge campus workplace vice draft concern confront disregard kiosk meter vanish enacted feel robotics septicaemia surrounds apparel detainee airspace concerned tune history diadem royal recording distinct gas notice bloodflow deathwatch revival diesel integral efficiency briefly primate bike terrarium meat disarm claw cyclooxygenase eyelids pistol vinegar proposal backyard separation grasp aware gorgeous stepson substance tummy pea lyrical faculty end overjoyed labour gunpowder roster loafer tritone alcohol seller deal factor doing luxury yell milk stacking transportation elevation locust pregnancy chili depressed obsolete hound statue shear spear amnesty misplacement keyboard tam-o'-shanter retailer clarity scrub novel cougar dragonfruit marsh elated watchmaker measles keyboarding conclusion potty spade setback hermit pendant observation pasta diagnose height limestone structure conference breakfast moldy export grandmom sauce gambling fingerling finger bush disconnection diligent dredger crucifixion rainbow sustainment oats workbench skate celsius brief celebrity lack laboratory ranger anesthesiologist tourist backburn transparency charset plum philosopher corps tulip lining veterinarian automation mansard kendo icon asphalt succinct direct building accidental lawmaker guide milestone dibble alphabet proof-reader swift dock wife crystal literate lye staking supporter paddle lying pompom dump truck crunch bangle regulator woodland go rudiment cheddar runaway circle mosquito skill rabid dwarf ratty harmonica bestseller chairman back brassiere decoder catalogue server accountant coin slide adjective pressroom teen overdo ovary detainee ignorant meatball crackers dipstick debate progenitor field garbage soda slavery know-how birdbath strudel marsh success cyclamen armrest resist chicken neighbour presidency bawdy grit carriage bud embarrass beak canoe adventurous equation chronicle gator idiot analogue mud nurse pocketbook cheesecake decryption wonder license prefer caviar parable ringworm habit toothbrush pillbox hemisphere landmine quince laughter develop smog awful mailing sculpture utter retrospect trunk nasty stream aggradation waterfall slate director archeology cashier pronoun remains absorbing hallowed\"}, {'role': 'user', 'content': '1719723286.692519 write a long essay about machine learning in at least 250 tokens'}] and Context Tokens: 1007 (latencytest.py:make_call:816)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': \"1719723286.692519 simple fascia copy rally weedkiller terrorist shortage tornado amuck wastebasket grasp churn incidence put membrane ordinary attention ease doubter empowerment judgment word unibody pass strife navigation conga charter c-clamp stag march thundering woozy backup brawny vehicle gaffe pocketbook longing earn caramel gaping cottage asymmetry course messy gunpowder puma waterfront cheese load ownership cooking crinoline ultimatum drummer heavenly login cria pub pinot advance buffer entree elm constellation team sleeping pamphlet boulder uniform existence parsnip marker nail temp first obscene vaulting channel led impact scraper lipoprotein destruction angry crawdad gusty early widget maintenance gas chastity hot thyme playroom swine cassock gastropod provision warden regionalism arrogant tour cupola jack leek octet mat hospitalization corps holistic melt ratepayer chateau bank journalism lava reminder momentous overwrought fir high bow profess dolman bumpy hound fibrosis terrorism flour conscience kimono lick capability dictaphone fundraising potty bassoon script press museum harpsichord short toga tangible filing foam distortion skin trot science pattern thug berry tacky disagreement volleyball clockwork loaf leaker duck manhunt slip reminiscent disadvantage loan elite crook habitat worry factory pike pilot sunbeam oat technologist nourishment professional hake paper fantasy captain commotion reinforce recession possess teaching query comestible spleen debate scandalous yellow manage pound landmine paragraph desire visual exploration peen poverty standard noiseless ink storm residence puny president cautious foretell hut send arthur hummus spread lament ruckus poignance daffy pledge legislature watchful expert amazement plucky offbeat postage creation register slump heartbreaking music-box mushy brass cytokine discourse objection wretched estrogen chutney passion gasket contention incompetent mud bench dark cut wheat catalog ambitious mama velocity encyclopedia diamond stitch armrest forum affiliate onset discrimination herb anesthesiology woebegone computer most aboard tongue heating guarantee whisper conflict controller sandal cameo sword compulsion consulting whistle oldie mighty blackberry meaning packet slink limit leptocephalus locust redhead breastplate grandpa union pocket remove compliment integrate founder freckle recruit operate duckling sandbar monument rich playroom chimpanzee scorn skywalk elegant sanctuary perfume macho hydrofoil impairment girl atom recipe wastebasket anagram diary gynaecology bottling gel motorboat symbolize crab preserves warren blue-eyed tough-guy chivalry sweat zucchini deathwatch bread secretive legislature curved bud dangerous jumpsuit volleyball beak regionalism relax readiness wit dozen behalf boar paperback refreshments uniformity violin console corn seat flipped-out custom stadium isolation ascend snobbish second culture work bandolier beginner competition birthday mayor isogloss polarisation imagination loving shopper rumor frame pattypan ban premeditation achievement expense hearsay cloudy organisation humorous wrestler speed kingdom shed teach giddy workhorse teaching codpiece inject surround hydrocarbon catch ridge campus workplace vice draft concern confront disregard kiosk meter vanish enacted feel robotics septicaemia surrounds apparel detainee airspace concerned tune history diadem royal recording distinct gas notice bloodflow deathwatch revival diesel integral efficiency briefly primate bike terrarium meat disarm claw cyclooxygenase eyelids pistol vinegar proposal backyard separation grasp aware gorgeous stepson substance tummy pea lyrical faculty end overjoyed labour gunpowder roster loafer tritone alcohol seller deal factor doing luxury yell milk stacking transportation elevation locust pregnancy chili depressed obsolete hound statue shear spear amnesty misplacement keyboard tam-o'-shanter retailer clarity scrub novel cougar dragonfruit marsh elated watchmaker measles keyboarding conclusion potty spade setback hermit pendant observation pasta diagnose height limestone structure conference breakfast moldy export grandmom sauce gambling fingerling finger bush disconnection diligent dredger crucifixion rainbow sustainment oats workbench skate celsius brief celebrity lack laboratory ranger anesthesiologist tourist backburn transparency charset plum philosopher corps tulip lining veterinarian automation mansard kendo icon asphalt succinct direct building accidental lawmaker guide milestone dibble alphabet proof-reader swift dock wife crystal literate lye staking supporter paddle lying pompom dump truck crunch bangle regulator woodland go rudiment cheddar runaway circle mosquito skill rabid dwarf ratty harmonica bestseller chairman back brassiere decoder catalogue server accountant coin slide adjective pressroom teen overdo ovary detainee ignorant meatball crackers dipstick debate progenitor field garbage soda slavery know-how birdbath strudel marsh success cyclamen armrest resist chicken neighbour presidency bawdy grit carriage bud embarrass beak canoe adventurous equation chronicle gator idiot analogue mud nurse pocketbook cheesecake decryption wonder license prefer caviar parable ringworm habit toothbrush pillbox hemisphere landmine quince laughter develop smog awful mailing sculpture utter retrospect trunk nasty stream aggradation waterfall slate director archeology cashier pronoun remains absorbing hallowed\"}, {'role': 'user', 'content': '1719723286.692519 write a long essay about machine learning in at least 250 tokens'}] and Context Tokens: 1007\n",
      "2024-06-29 23:54:46,699 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:54:46,701 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 23:54:46.701736, (GMT): 2024-06-30 04:54:46.701736+00:00 (latencytest.py:make_call:838)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 23:54:46.701736, (GMT): 2024-06-30 04:54:46.701736+00:00\n",
      "2024-06-29 23:54:49,645 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:882)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 23:54:49,690 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 2.62 seconds or 2618.44 milliseconds. (latencytest.py:make_call:887)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 2.62 seconds or 2618.44 milliseconds.\n"
     ]
    }
   ],
   "source": [
    "await benchmark_streaming.run_latency_benchmark_bulk(deployment_names=[DEPLOYMENT_ID], max_tokens_list=[100, 150, 250], iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 23:55:29,416 - micro - MainProcess - INFO     CPU usage: 12.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.9%\n",
      "2024-06-29 23:55:29,430 - micro - MainProcess - INFO     RAM usage: 86.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.2%\n",
      "2024-06-29 23:55:29,451 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:29,456 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:29,554 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 100 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 100\n",
      "2024-06-29 23:55:29,559 - micro - MainProcess - INFO     CPU usage: 10.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 10.9%\n",
      "2024-06-29 23:55:29,571 - micro - MainProcess - INFO     RAM usage: 86.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.2%\n",
      "2024-06-29 23:55:29,589 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:29,592 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:29,784 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 150 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 150\n",
      "2024-06-29 23:55:29,789 - micro - MainProcess - INFO     CPU usage: 39.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 39.3%\n",
      "2024-06-29 23:55:29,800 - micro - MainProcess - INFO     RAM usage: 86.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.4%\n",
      "2024-06-29 23:55:29,820 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:29,823 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:29,983 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 23:55:31,607 - micro - MainProcess - INFO     Succesful Run - Time taken: 2.05 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 2.05 seconds.\n",
      "2024-06-29 23:55:32,213 - micro - MainProcess - INFO     Succesful Run - Time taken: 2.43 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 2.43 seconds.\n",
      "2024-06-29 23:55:32,617 - micro - MainProcess - INFO     CPU usage: 19.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.2%\n",
      "2024-06-29 23:55:32,633 - micro - MainProcess - INFO     RAM usage: 86.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.9%\n",
      "2024-06-29 23:55:32,661 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:32,665 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:32,768 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 100 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 100\n",
      "2024-06-29 23:55:33,216 - micro - MainProcess - INFO     CPU usage: 35.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 35.8%\n",
      "2024-06-29 23:55:33,230 - micro - MainProcess - INFO     RAM usage: 86.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.9%\n",
      "2024-06-29 23:55:33,253 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:33,257 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:33,374 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 150 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 150\n",
      "2024-06-29 23:55:34,339 - micro - MainProcess - INFO     Succesful Run - Time taken: 1.57 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 1.57 seconds.\n",
      "2024-06-29 23:55:34,983 - micro - MainProcess - INFO     Succesful Run - Time taken: 5.00 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 5.00 seconds.\n",
      "2024-06-29 23:55:35,362 - micro - MainProcess - INFO     CPU usage: 21.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 21.4%\n",
      "2024-06-29 23:55:35,373 - micro - MainProcess - INFO     RAM usage: 86.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.4%\n",
      "2024-06-29 23:55:35,391 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:35,394 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:35,483 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 100 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 100\n",
      "2024-06-29 23:55:35,994 - micro - MainProcess - INFO     CPU usage: 29.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 29.5%\n",
      "2024-06-29 23:55:36,008 - micro - MainProcess - INFO     RAM usage: 86.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.3%\n",
      "2024-06-29 23:55:36,036 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:36,040 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:36,139 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 23:55:36,840 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.46 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 3.46 seconds.\n",
      "2024-06-29 23:55:37,840 - micro - MainProcess - INFO     CPU usage: 24.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 24.4%\n",
      "2024-06-29 23:55:37,850 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 23:55:37,869 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:37,873 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:37,969 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 150 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 150\n",
      "2024-06-29 23:55:40,052 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.57 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 4.57 seconds.\n",
      "2024-06-29 23:55:40,123 - micro - MainProcess - INFO     Succesful Run - Time taken: 2.15 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 2.15 seconds.\n",
      "2024-06-29 23:55:41,075 - micro - MainProcess - INFO     CPU usage: 21.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 21.2%\n",
      "2024-06-29 23:55:41,085 - micro - MainProcess - INFO     RAM usage: 86.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.8%\n",
      "2024-06-29 23:55:41,104 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:41,108 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:41,206 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 100 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 100\n",
      "2024-06-29 23:55:41,210 - micro - MainProcess - INFO     CPU usage: 10.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 10.7%\n",
      "2024-06-29 23:55:41,219 - micro - MainProcess - INFO     RAM usage: 86.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.9%\n",
      "2024-06-29 23:55:41,239 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:41,243 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:41,509 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 150 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 150\n",
      "2024-06-29 23:55:42,053 - micro - MainProcess - INFO     Succesful Run - Time taken: 5.91 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 5.91 seconds.\n",
      "2024-06-29 23:55:42,997 - micro - MainProcess - INFO     Succesful Run - Time taken: 1.79 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 1.79 seconds.\n",
      "2024-06-29 23:55:43,057 - micro - MainProcess - INFO     CPU usage: 21.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 21.8%\n",
      "2024-06-29 23:55:43,067 - micro - MainProcess - INFO     RAM usage: 86.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.1%\n",
      "2024-06-29 23:55:43,082 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:43,083 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:43,299 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 23:55:43,544 - micro - MainProcess - INFO     Succesful Run - Time taken: 2.03 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 2.03 seconds.\n",
      "2024-06-29 23:55:44,018 - micro - MainProcess - INFO     CPU usage: 41.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 41.7%\n",
      "2024-06-29 23:55:44,029 - micro - MainProcess - INFO     RAM usage: 86.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.3%\n",
      "2024-06-29 23:55:44,052 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:44,056 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:44,168 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 100 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 100\n",
      "2024-06-29 23:55:44,545 - micro - MainProcess - INFO     CPU usage: 31.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 31.3%\n",
      "2024-06-29 23:55:44,555 - micro - MainProcess - INFO     RAM usage: 86.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.4%\n",
      "2024-06-29 23:55:44,582 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:44,584 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:44,699 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 150 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 150\n",
      "2024-06-29 23:55:45,739 - micro - MainProcess - INFO     Succesful Run - Time taken: 1.57 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 1.57 seconds.\n",
      "2024-06-29 23:55:46,442 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.14 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 3.14 seconds.\n",
      "2024-06-29 23:55:46,799 - micro - MainProcess - INFO     Succesful Run - Time taken: 2.10 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 2.10 seconds.\n",
      "2024-06-29 23:55:47,445 - micro - MainProcess - INFO     CPU usage: 27.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 27.7%\n",
      "2024-06-29 23:55:47,455 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 23:55:47,468 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:47,474 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:47,572 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 23:55:50,678 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.10 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 3.10 seconds.\n",
      "2024-06-29 23:55:51,685 - micro - MainProcess - INFO     CPU usage: 19.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.1%\n",
      "2024-06-29 23:55:51,698 - micro - MainProcess - INFO     RAM usage: 86.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.2%\n",
      "2024-06-29 23:55:51,720 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 23:55:51,723 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:649)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 23:55:51,814 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:740)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 23:55:55,368 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.55 seconds. (latencytest.py:make_call:769)\n",
      "INFO:micro:Succesful Run - Time taken: 3.55 seconds.\n"
     ]
    }
   ],
   "source": [
    "await benchmark_non_streaming.run_latency_benchmark_bulk(deployment_names=[DEPLOYMENT_ID], max_tokens_list=[100, 150, 250], iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.performance.latencyanalyzer import BenchmarkVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [benchmark_streaming.results, benchmark_non_streaming.results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2 = {}\n",
    "for result in results:\n",
    "    results_2.update(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_100': {'ttlt_successfull': [2.0491758999999945,\n",
       "   1.5677140000000094,\n",
       "   4.567109500000001,\n",
       "   1.7873945000000049,\n",
       "   1.5684222999999946],\n",
       "  'ttlt_unsucessfull': [],\n",
       "  'tbt': [0.02, 0.02, 0.05, 0.02, 0.02],\n",
       "  'ttft': [2.05, 1.57, 4.57, 1.79, 1.57],\n",
       "  'regions': ['East US 2', 'East US 2', 'East US 2', 'East US 2', 'East US 2'],\n",
       "  'number_of_iterations': 5,\n",
       "  'completion_tokens': [100, 100, 100, 100, 100],\n",
       "  'prompt_tokens': [981, 988, 971, 961, 974],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 1.57,\n",
       "   'completion_tokens': 100,\n",
       "   'prompt_tokens': 974,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-30 00:55:45 EDT'},\n",
       "  'worst_run': {'ttlt': 4.57,\n",
       "   'completion_tokens': 100,\n",
       "   'prompt_tokens': 971,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-30 00:55:40 EDT'}},\n",
       " 'gpt-4o-2024-05-13_250': {'ttlt_successfull': [4.997364700000006,\n",
       "   5.9118020999999885,\n",
       "   3.1401520000000005,\n",
       "   3.102061699999993,\n",
       "   3.5495413000000013],\n",
       "  'ttlt_unsucessfull': [],\n",
       "  'tbt': [0.02, 0.02, 0.01, 0.01, 0.01],\n",
       "  'ttft': [5.0, 5.91, 3.14, 3.1, 3.55],\n",
       "  'regions': ['East US 2', 'East US 2', 'East US 2', 'East US 2', 'East US 2'],\n",
       "  'number_of_iterations': 5,\n",
       "  'completion_tokens': [250, 250, 250, 250, 250],\n",
       "  'prompt_tokens': [959, 958, 976, 959, 971],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 3.1,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 959,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-30 00:55:50 EDT'},\n",
       "  'worst_run': {'ttlt': 5.91,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 958,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-30 00:55:42 EDT'}},\n",
       " 'gpt-4o-2024-05-13_150': {'ttlt_successfull': [2.425097099999988,\n",
       "   3.4628445000000028,\n",
       "   2.1502443000000113,\n",
       "   2.029444600000005,\n",
       "   2.0981093999999985],\n",
       "  'ttlt_unsucessfull': [],\n",
       "  'tbt': [0.02, 0.02, 0.01, 0.01, 0.01],\n",
       "  'ttft': [2.43, 3.46, 2.15, 2.03, 2.1],\n",
       "  'regions': ['East US 2', 'East US 2', 'East US 2', 'East US 2', 'East US 2'],\n",
       "  'number_of_iterations': 5,\n",
       "  'completion_tokens': [150, 150, 150, 150, 150],\n",
       "  'prompt_tokens': [968, 965, 965, 957, 963],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 2.03,\n",
       "   'completion_tokens': 150,\n",
       "   'prompt_tokens': 957,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-30 00:55:43 EDT'},\n",
       "  'worst_run': {'ttlt': 3.46,\n",
       "   'completion_tokens': 150,\n",
       "   'prompt_tokens': 965,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-30 00:55:36 EDT'}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_100': ['ttlt_successfull',\n",
       "  'ttlt_unsucessfull',\n",
       "  'tbt',\n",
       "  'ttft',\n",
       "  'regions',\n",
       "  'number_of_iterations',\n",
       "  'completion_tokens',\n",
       "  'prompt_tokens',\n",
       "  'errors',\n",
       "  'best_run',\n",
       "  'worst_run',\n",
       "  'ttlt_successfull',\n",
       "  'ttlt_unsucessfull',\n",
       "  'tbt',\n",
       "  'ttft',\n",
       "  'regions',\n",
       "  'number_of_iterations',\n",
       "  'completion_tokens',\n",
       "  'prompt_tokens',\n",
       "  'errors',\n",
       "  'best_run',\n",
       "  'worst_run'],\n",
       " 'gpt-4o-2024-05-13_250': ['ttlt_successfull',\n",
       "  'ttlt_unsucessfull',\n",
       "  'tbt',\n",
       "  'ttft',\n",
       "  'regions',\n",
       "  'number_of_iterations',\n",
       "  'completion_tokens',\n",
       "  'prompt_tokens',\n",
       "  'errors',\n",
       "  'best_run',\n",
       "  'worst_run',\n",
       "  'ttlt_successfull',\n",
       "  'ttlt_unsucessfull',\n",
       "  'tbt',\n",
       "  'ttft',\n",
       "  'regions',\n",
       "  'number_of_iterations',\n",
       "  'completion_tokens',\n",
       "  'prompt_tokens',\n",
       "  'errors',\n",
       "  'best_run',\n",
       "  'worst_run'],\n",
       " 'gpt-4o-2024-05-13_150': ['ttlt_successfull',\n",
       "  'ttlt_unsucessfull',\n",
       "  'tbt',\n",
       "  'ttft',\n",
       "  'regions',\n",
       "  'number_of_iterations',\n",
       "  'completion_tokens',\n",
       "  'prompt_tokens',\n",
       "  'errors',\n",
       "  'best_run',\n",
       "  'worst_run',\n",
       "  'ttlt_successfull',\n",
       "  'ttlt_unsucessfull',\n",
       "  'tbt',\n",
       "  'ttft',\n",
       "  'regions',\n",
       "  'number_of_iterations',\n",
       "  'completion_tokens',\n",
       "  'prompt_tokens',\n",
       "  'errors',\n",
       "  'best_run',\n",
       "  'worst_run']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 23:58:08,114 - micro - MainProcess - INFO     DataFrame created successfully (latencyanalyzer.py:_create_dataframe:50)\n",
      "INFO:micro:DataFrame created successfully\n",
      "2024-06-29 23:58:08,119 - micro - MainProcess - INFO     Model DataFrames created successfully (latencyanalyzer.py:_create_model_dfs:67)\n",
      "INFO:micro:Model DataFrames created successfully\n"
     ]
    }
   ],
   "source": [
    "visualizer = BenchmarkVisualizer(results_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gpt-4o-2024-05-13'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer.unique_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 23:58:13,964 - micro - MainProcess - INFO     Residuals calculated successfully (latencyanalyzer.py:_calculate_residuals:102)\n",
      "INFO:micro:Residuals calculated successfully\n",
      "2024-06-29 23:58:13,970 - micro - MainProcess - INFO     Top outliers identified successfully (latencyanalyzer.py:_identify_top_outliers:118)\n",
      "INFO:micro:Top outliers identified successfully\n",
      "2024-06-29 23:58:13,976 - micro - MainProcess - INFO     Correlation matrix calculated successfully (latencyanalyzer.py:_calculate_correlation_matrix:82)\n",
      "INFO:micro:Correlation matrix calculated successfully\n",
      "2024-06-29 23:58:14,213 - micro - MainProcess - INFO     Completion tokens plot created successfully for gpt-4o-2024-05-13 (latencyanalyzer.py:plot_completion_tokens:167)\n",
      "INFO:micro:Completion tokens plot created successfully for gpt-4o-2024-05-13\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "completion_tokens_plot = visualizer.plot_completion_tokens('gpt-4o-2024-05-13')\n",
    "completion_tokens_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 23:13:25,349 - micro - MainProcess - INFO     DataFrame created successfully (latencyanalyzer.py:_create_dataframe:45)\n",
      "INFO:micro:DataFrame created successfully\n",
      "2024-06-29 23:13:25,353 - micro - MainProcess - INFO     Model DataFrames created successfully (latencyanalyzer.py:_create_model_dfs:61)\n",
      "INFO:micro:Model DataFrames created successfully\n",
      "2024-06-29 23:13:25,359 - micro - MainProcess - INFO     Correlation matrix calculated successfully (latencyanalyzer.py:_calculate_correlation_matrix:75)\n",
      "INFO:micro:Correlation matrix calculated successfully\n",
      "2024-06-29 23:13:25,370 - micro - MainProcess - INFO     Residuals calculated successfully (latencyanalyzer.py:_calculate_residuals:92)\n",
      "INFO:micro:Residuals calculated successfully\n",
      "2024-06-29 23:13:25,373 - micro - MainProcess - INFO     Top outliers identified successfully (latencyanalyzer.py:_identify_top_outliers:106)\n",
      "INFO:micro:Top outliers identified successfully\n",
      "2024-06-29 23:13:25,517 - micro - MainProcess - INFO     Correlation matrix plot created successfully (latencyanalyzer.py:plot_correlation_matrix:122)\n",
      "INFO:micro:Correlation matrix plot created successfully\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 23:13:25,901 - micro - MainProcess - INFO     Completion tokens plot created successfully (latencyanalyzer.py:plot_completion_tokens:146)\n",
      "INFO:micro:Completion tokens plot created successfully\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 23:13:26,289 - micro - MainProcess - INFO     Prompt tokens plot created successfully (latencyanalyzer.py:plot_prompt_tokens:170)\n",
      "INFO:micro:Prompt tokens plot created successfully\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizer = BenchmarkVisualizer(benchmark_streaming.results)\n",
    "correlation_matrix_plot = visualizer.plot_correlation_matrix()\n",
    "correlation_matrix_plot.show()\n",
    "\n",
    "completion_tokens_plot = visualizer.plot_completion_tokens()\n",
    "completion_tokens_plot.show()\n",
    "\n",
    "prompt_tokens_plot = visualizer.plot_prompt_tokens()\n",
    "prompt_tokens_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage Example\n",
    "# benchmark_results = {...}  # Your dictionary here\n",
    "# visualizer = BenchmarkVisualizer(benchmark_results)\n",
    "# correlation_matrix_plot = visualizer.plot_correlation_matrix()\n",
    "# correlation_matrix_plot.show()\n",
    "\n",
    "# completion_tokens_plot = visualizer.plot_completion_tokens()\n",
    "# completion_tokens_plot.show()\n",
    "\n",
    "# prompt_tokens_plot = visualizer.plot_prompt_tokens()\n",
    "# prompt_tokens_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top outliers for 'completion_tokens':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ttlt_successfull</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>Residuals Completion Tokens</th>\n",
       "      <th>Residuals Prompt Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>150</td>\n",
       "      <td>2.19</td>\n",
       "      <td>150</td>\n",
       "      <td>1006</td>\n",
       "      <td>-0.181816</td>\n",
       "      <td>0.495833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>150</td>\n",
       "      <td>2.16</td>\n",
       "      <td>150</td>\n",
       "      <td>1006</td>\n",
       "      <td>-0.211816</td>\n",
       "      <td>0.465833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>150</td>\n",
       "      <td>2.05</td>\n",
       "      <td>150</td>\n",
       "      <td>1007</td>\n",
       "      <td>-0.321816</td>\n",
       "      <td>-0.056250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>150</td>\n",
       "      <td>2.01</td>\n",
       "      <td>150</td>\n",
       "      <td>1007</td>\n",
       "      <td>-0.361816</td>\n",
       "      <td>-0.096250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>150</td>\n",
       "      <td>3.45</td>\n",
       "      <td>151</td>\n",
       "      <td>1009</td>\n",
       "      <td>1.057338</td>\n",
       "      <td>0.519583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name  tokens  ttlt_successfull  completion_tokens  \\\n",
       "9  gpt-4o-2024-05-13     150              2.19                150   \n",
       "6  gpt-4o-2024-05-13     150              2.16                150   \n",
       "8  gpt-4o-2024-05-13     150              2.05                150   \n",
       "7  gpt-4o-2024-05-13     150              2.01                150   \n",
       "5  gpt-4o-2024-05-13     150              3.45                151   \n",
       "\n",
       "   prompt_tokens  Residuals Completion Tokens  Residuals Prompt Tokens  \n",
       "9           1006                    -0.181816                 0.495833  \n",
       "6           1006                    -0.211816                 0.465833  \n",
       "8           1007                    -0.321816                -0.056250  \n",
       "7           1007                    -0.361816                -0.096250  \n",
       "5           1009                     1.057338                 0.519583  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top outliers for 'prompt_tokens':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ttlt_successfull</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>Residuals Completion Tokens</th>\n",
       "      <th>Residuals Prompt Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>100</td>\n",
       "      <td>1.36</td>\n",
       "      <td>100</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.030493</td>\n",
       "      <td>-0.334167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>150</td>\n",
       "      <td>2.16</td>\n",
       "      <td>150</td>\n",
       "      <td>1006</td>\n",
       "      <td>-0.211816</td>\n",
       "      <td>0.465833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>150</td>\n",
       "      <td>2.19</td>\n",
       "      <td>150</td>\n",
       "      <td>1006</td>\n",
       "      <td>-0.181816</td>\n",
       "      <td>0.495833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>150</td>\n",
       "      <td>3.45</td>\n",
       "      <td>151</td>\n",
       "      <td>1009</td>\n",
       "      <td>1.057338</td>\n",
       "      <td>0.519583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>100</td>\n",
       "      <td>1.34</td>\n",
       "      <td>101</td>\n",
       "      <td>1007</td>\n",
       "      <td>-0.010353</td>\n",
       "      <td>-0.766250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name  tokens  ttlt_successfull  completion_tokens  \\\n",
       "0  gpt-4o-2024-05-13     100              1.36                100   \n",
       "6  gpt-4o-2024-05-13     150              2.16                150   \n",
       "9  gpt-4o-2024-05-13     150              2.19                150   \n",
       "5  gpt-4o-2024-05-13     150              3.45                151   \n",
       "1  gpt-4o-2024-05-13     100              1.34                101   \n",
       "\n",
       "   prompt_tokens  Residuals Completion Tokens  Residuals Prompt Tokens  \n",
       "0           1006                     0.030493                -0.334167  \n",
       "6           1006                    -0.211816                 0.465833  \n",
       "9           1006                    -0.181816                 0.495833  \n",
       "5           1009                     1.057338                 0.519583  \n",
       "1           1007                    -0.010353                -0.766250  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to hold all data\n",
    "all_data = []\n",
    "\n",
    "# Extract model names and tokens, then populate the list with data\n",
    "for key, value in benchmark_streaming.results.items():\n",
    "    model_name, tokens = key.rsplit('_', 1)\n",
    "    for i in range(len(next(iter(value.values())))):\n",
    "        all_data.append({\n",
    "            'model_name': model_name,\n",
    "            'tokens': int(tokens),\n",
    "            'ttlt_successfull': value['ttlt_successfull'][i],\n",
    "            'completion_tokens': value['completion_tokens'][i],\n",
    "            'prompt_tokens': value['prompt_tokens'][i]\n",
    "        })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Create a dictionary to hold each model's DataFrame\n",
    "model_dfs = {}\n",
    "\n",
    "# Iterate over each unique model name\n",
    "for model_name in df['model_name'].unique():\n",
    "    # Filter the main DataFrame for the current model and assign it to the dictionary\n",
    "    model_dfs[model_name] = df[df['model_name'] == model_name]\n",
    "\n",
    "\n",
    "# Perform analyses and visualizations\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = df[['ttlt_successfull', 'completion_tokens', 'prompt_tokens']].corr()\n",
    "\n",
    "# Linear regression and residuals calculation for 'completion_tokens'\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['completion_tokens'], df['ttlt_successfull'])\n",
    "df['Residuals Completion Tokens'] = df['ttlt_successfull'] - (slope * df['completion_tokens'] + intercept)\n",
    "\n",
    "# Linear regression and residuals calculation for 'prompt_tokens'\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['prompt_tokens'], df['ttlt_successfull'])\n",
    "df['Residuals Prompt Tokens'] = df['ttlt_successfull'] - (slope * df['prompt_tokens'] + intercept)\n",
    "\n",
    "# Identify top outliers for both residuals\n",
    "top_outliers_completion = df.iloc[np.abs(df['Residuals Completion Tokens']).argsort()[-5:]]\n",
    "top_outliers_prompt = df.iloc[np.abs(df['Residuals Prompt Tokens']).argsort()[-5:]]\n",
    "\n",
    "# Display top outliers\n",
    "print(\"Top outliers for 'completion_tokens':\")\n",
    "display(top_outliers_completion)\n",
    "\n",
    "print(\"Top outliers for 'prompt_tokens':\")\n",
    "display(top_outliers_prompt)\n",
    "\n",
    "# Correlation matrix heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Visualization for 'completion_tokens'\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.regplot(x='completion_tokens', \n",
    "            y='ttlt_successfull', \n",
    "            data=df, color='blue', label='Completion Tokens vs TTLT')\n",
    "for i in range(top_outliers_completion.shape[0]):\n",
    "    plt.annotate(f\"{top_outliers_completion.iloc[i]['completion_tokens']:.2f}, {top_outliers_completion.iloc[i]['ttlt_successfull']:.2f}\", \n",
    "                 (top_outliers_completion.iloc[i]['completion_tokens'], top_outliers_completion.iloc[i]['ttlt_successfull']))\n",
    "plt.xlabel('Completion Tokens')\n",
    "plt.ylabel('TTLT Successful')\n",
    "plt.title('TTLT Successful vs Completion Tokens')\n",
    "plt.legend()\n",
    "plt.text(0.2, 0.8, f\"Correlation: {correlation_matrix.loc['completion_tokens', 'ttlt_successfull']:.2f}\", transform=plt.gca().transAxes)\n",
    "plt.text(0.2, 0.7, f\"Note: Data from {df['model_name'][0]}\", transform=plt.gca().transAxes)\n",
    "plt.show()\n",
    "\n",
    "# Visualization for 'prompt_tokens'\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.regplot(x='prompt_tokens', \n",
    "            y='ttlt_successfull', \n",
    "            data=df, color='red', label='Prompt Tokens vs TTLT')\n",
    "for i in range(top_outliers_prompt.shape[0]):\n",
    "    plt.annotate(f\"{top_outliers_prompt.iloc[i]['prompt_tokens']:.2f}, {top_outliers_prompt.iloc[i]['ttlt_successfull']:.2f}\", \n",
    "                 (top_outliers_prompt.iloc[i]['prompt_tokens'], top_outliers_prompt.iloc[i]['ttlt_successfull']))\n",
    "plt.xlabel('Prompt Tokens')\n",
    "plt.ylabel('TTLT Successful')\n",
    "plt.title('TTLT Successful vs Prompt Tokens')\n",
    "plt.legend()\n",
    "plt.text(0.2, 0.8, f\"Correlation: {correlation_matrix.loc['prompt_tokens', 'ttlt_successfull']:.2f}\", transform=plt.gca().transAxes)\n",
    "plt.text(0.2, 0.7, f\"Note: Data from {df['model_name'][0]}\", transform=plt.gca().transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df[['Average TTLT (s)', 'Median Completion Tokens', 'Median Prompt Tokens']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot calculate a linear regression if all x values are identical",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResiduals Completion Tokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage TTLT (s)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m (slope \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedian Completion Tokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m intercept)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Linear regression and residuals calculation for 'Median Prompt Tokens'\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m slope, intercept, r_value, p_value, std_err \u001b[38;5;241m=\u001b[39m \u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinregress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMedian Prompt Tokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAverage TTLT (s)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResiduals Prompt Tokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage TTLT (s)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m (slope \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedian Prompt Tokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m intercept)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Identify top outliers for both residuals\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\upgrade-llm\\lib\\site-packages\\scipy\\stats\\_stats_mstats_common.py:157\u001b[0m, in \u001b[0;36mlinregress\u001b[1;34m(x, y, alternative)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs must not be empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mamax(x) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mamin(x) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot calculate a linear regression \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif all x values are identical\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    160\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[0;32m    161\u001b[0m xmean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(x, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot calculate a linear regression if all x values are identical"
     ]
    }
   ],
   "source": [
    "# Perform analyses and visualizations\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = df[['Average TTLT (s)', 'Median Completion Tokens', 'Median Prompt Tokens']].corr()\n",
    "\n",
    "# Assuming 'time' column exists in df for min and max time calculation\n",
    "min_time = df['time'].min() if 'time' in df.columns else \"N/A\"\n",
    "max_time = df['time'].max() if 'time' in df.columns else \"N/A\"\n",
    "\n",
    "# Linear regression and residuals calculation for 'Median Completion Tokens'\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['Median Completion Tokens'], df['Average TTLT (s)'])\n",
    "df['Residuals Completion Tokens'] = df['Average TTLT (s)'] - (slope * df['Median Completion Tokens'] + intercept)\n",
    "\n",
    "# Linear regression and residuals calculation for 'Median Prompt Tokens'\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['Median Prompt Tokens'], df['Average TTLT (s)'])\n",
    "df['Residuals Prompt Tokens'] = df['Average TTLT (s)'] - (slope * df['Median Prompt Tokens'] + intercept)\n",
    "\n",
    "# Identify top outliers for both residuals\n",
    "top_outliers_completion = df.iloc[np.abs(df['Residuals Completion Tokens']).argsort()[-5:]]\n",
    "top_outliers_prompt = df.iloc[np.abs(df['Residuals Prompt Tokens']).argsort()[-5:]]\n",
    "\n",
    "# Display top outliers\n",
    "print(\"Top outliers for 'Median Completion Tokens':\")\n",
    "display(top_outliers_completion)\n",
    "\n",
    "print(\"Top outliers for 'Median Prompt Tokens':\")\n",
    "display(top_outliers_prompt)\n",
    "\n",
    "# Correlation matrix heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Visualization for 'Median Completion Tokens'\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.regplot(x='Median Completion Tokens', \n",
    "            y='Average TTLT (s)', \n",
    "            data=df, color='blue', label='Completion Tokens vs TTLT')\n",
    "for i in range(top_outliers_completion.shape[0]):\n",
    "    plt.annotate(f\"{top_outliers_completion.iloc[i]['Median Completion Tokens']:.2f}, {top_outliers_completion.iloc[i]['Average TTLT (s)']:.2f}\", \n",
    "                 (top_outliers_completion.iloc[i]['Median Completion Tokens'], top_outliers_completion.iloc[i]['Average TTLT (s)']))\n",
    "plt.xlabel('Median Completion Tokens')\n",
    "plt.ylabel('Average TTLT (s)')\n",
    "plt.title('Average TTLT vs Median Completion Tokens')\n",
    "plt.legend()\n",
    "plt.text(0.2, 0.8, f\"Correlation: {correlation_matrix.loc['Median Completion Tokens', 'Average TTLT (s)']:.2f}\", transform=plt.gca().transAxes)\n",
    "plt.text(0.2, 0.7, f\"Note: Data from {min_time} to {max_time}\", transform=plt.gca().transAxes)\n",
    "plt.show()\n",
    "\n",
    "# Visualization for 'Median Prompt Tokens'\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.regplot(x='Median Prompt Tokens', \n",
    "            y='Average TTLT (s)', \n",
    "            data=df, color='red', label='Prompt Tokens vs TTLT')\n",
    "for i in range(top_outliers_prompt.shape[0]):\n",
    "    plt.annotate(f\"{top_outliers_prompt.iloc[i]['Median Prompt Tokens']:.2f}, {top_outliers_prompt.iloc[i]['Average TTLT (s)']:.2f}\", \n",
    "                 (top_outliers_prompt.iloc[i]['Median Prompt Tokens'], top_outliers_prompt.iloc[i]['Average TTLT (s)']))\n",
    "plt.xlabel('Median Prompt Tokens')\n",
    "plt.ylabel('Average TTLT (s)')\n",
    "plt.title('Average TTLT vs Median Prompt Tokens')\n",
    "plt.legend()\n",
    "plt.text(0.2, 0.8, f\"Correlation: {correlation_matrix.loc['Median Prompt Tokens', 'Average TTLT (s)']:.2f}\", transform=plt.gca().transAxes)\n",
    "plt.text(0.2, 0.7, f\"Note: Data from {min_time} to {max_time}\", transform=plt.gca().transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.performance.utils import read_prompts_from_csv_with_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = read_prompts_from_csv_with_pandas(r\"C:\\Users\\pablosal\\Desktop\\gbb-ai-upgrade-llm\\utils\\data\\contextual_prompts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 13:56:33,978 - micro - MainProcess - INFO     Split list into 4 parts. (utils.py:split_list_into_variable_parts:165)\n",
      "2024-06-29 13:56:33,981 - micro - MainProcess - INFO     CPU usage: 11.9% (utils.py:log_system_info:233)\n",
      "2024-06-29 13:56:33,993 - micro - MainProcess - INFO     RAM usage: 88.1% (utils.py:log_system_info:235)\n",
      "2024-06-29 13:56:34,004 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "2024-06-29 13:56:34,009 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "2024-06-29 13:56:34,458 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687394.4587574 Quantum computing is a new frontier in technology, promising to solve problems that are currently intractable for classical computers. Can you explain the concept of quantum computing and its potential impact on technology? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 77 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687394.4587574 Quantum computing is a new frontier in technology, promising to solve problems that are currently intractable for classical computers. Can you explain the concept of quantum computing and its potential impact on technology? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 77\n",
      "2024-06-29 13:56:34,464 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:34,467 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:34.467470, (GMT): 2024-06-29 18:56:34.467470+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:34.467470, (GMT): 2024-06-29 18:56:34.467470+00:00\n",
      "2024-06-29 13:56:34,972 - micro - MainProcess - INFO     CPU usage: 19.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.4%\n",
      "2024-06-29 13:56:34,982 - micro - MainProcess - INFO     RAM usage: 88.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.4%\n",
      "2024-06-29 13:56:35,011 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:35,019 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:35,024 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687395.0242708 Virtual reality (VR) creates immersive environments that can be used for entertainment, education, and therapy. How is virtual reality being used in therapeutic settings to treat mental health conditions? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687395.0242708 Virtual reality (VR) creates immersive environments that can be used for entertainment, education, and therapy. How is virtual reality being used in therapeutic settings to treat mental health conditions? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:56:35,031 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:35,036 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:35.036024, (GMT): 2024-06-29 18:56:35.036024+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:35.036024, (GMT): 2024-06-29 18:56:35.036024+00:00\n",
      "2024-06-29 13:56:35,039 - micro - MainProcess - INFO     CPU usage: 22.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 22.6%\n",
      "2024-06-29 13:56:35,051 - micro - MainProcess - INFO     RAM usage: 88.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.4%\n",
      "2024-06-29 13:56:35,072 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:35,078 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:35,083 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687395.0834787 Wearable technologies, such as fitness trackers and smartwatches, monitor various health metrics. How are wearable technologies transforming personal health and fitness monitoring? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687395.0834787 Wearable technologies, such as fitness trackers and smartwatches, monitor various health metrics. How are wearable technologies transforming personal health and fitness monitoring? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:56:35,089 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:35,092 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:35.092627, (GMT): 2024-06-29 18:56:35.092627+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:35.092627, (GMT): 2024-06-29 18:56:35.092627+00:00\n",
      "2024-06-29 13:56:35,095 - micro - MainProcess - INFO     CPU usage: 8.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 8.3%\n",
      "2024-06-29 13:56:35,111 - micro - MainProcess - INFO     RAM usage: 88.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.4%\n",
      "2024-06-29 13:56:35,132 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:35,141 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:35,145 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687395.1440096 Biotechnology raises ethical questions, especially when it comes to modifying human genes. What are some ethical considerations in the use of biotechnology in humans? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687395.1440096 Biotechnology raises ethical questions, especially when it comes to modifying human genes. What are some ethical considerations in the use of biotechnology in humans? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:56:35,149 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:35,152 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:35.152619, (GMT): 2024-06-29 18:56:35.152619+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:35.152619, (GMT): 2024-06-29 18:56:35.152619+00:00\n",
      "2024-06-29 13:56:35,156 - micro - MainProcess - INFO     CPU usage: 21.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 21.3%\n",
      "2024-06-29 13:56:35,170 - micro - MainProcess - INFO     RAM usage: 88.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.5%\n",
      "2024-06-29 13:56:35,192 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:35,199 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:35,208 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687395.2087638 Quantum computing is a new frontier in technology, promising to solve problems that are currently intractable for classical computers. Can you explain the concept of quantum computing and its potential impact on technology? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 77 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687395.2087638 Quantum computing is a new frontier in technology, promising to solve problems that are currently intractable for classical computers. Can you explain the concept of quantum computing and its potential impact on technology? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 77\n",
      "2024-06-29 13:56:35,223 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:35,235 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:35.235308, (GMT): 2024-06-29 18:56:35.235308+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:35.235308, (GMT): 2024-06-29 18:56:35.235308+00:00\n",
      "2024-06-29 13:56:35,275 - micro - MainProcess - INFO     CPU usage: 45.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 45.7%\n",
      "2024-06-29 13:56:35,289 - micro - MainProcess - INFO     RAM usage: 88.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.6%\n",
      "2024-06-29 13:56:35,335 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:35,342 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:35,347 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687395.3462417 Virtual reality (VR) creates immersive environments that can be used for entertainment, education, and therapy. How is virtual reality being used in therapeutic settings to treat mental health conditions? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687395.3462417 Virtual reality (VR) creates immersive environments that can be used for entertainment, education, and therapy. How is virtual reality being used in therapeutic settings to treat mental health conditions? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:56:35,353 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:35,357 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:35.356065, (GMT): 2024-06-29 18:56:35.356065+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:35.356065, (GMT): 2024-06-29 18:56:35.356065+00:00\n",
      "2024-06-29 13:56:35,361 - micro - MainProcess - INFO     CPU usage: 40.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 40.2%\n",
      "2024-06-29 13:56:35,375 - micro - MainProcess - INFO     RAM usage: 88.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.5%\n",
      "2024-06-29 13:56:35,394 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:35,399 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:35,406 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687395.4050272 Wearable technologies, such as fitness trackers and smartwatches, monitor various health metrics. How are wearable technologies transforming personal health and fitness monitoring? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687395.4050272 Wearable technologies, such as fitness trackers and smartwatches, monitor various health metrics. How are wearable technologies transforming personal health and fitness monitoring? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:56:35,412 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:35,414 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:35.414369, (GMT): 2024-06-29 18:56:35.414369+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:35.414369, (GMT): 2024-06-29 18:56:35.414369+00:00\n",
      "2024-06-29 13:56:35,418 - micro - MainProcess - INFO     CPU usage: 2.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 2.5%\n",
      "2024-06-29 13:56:35,429 - micro - MainProcess - INFO     RAM usage: 88.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.4%\n",
      "2024-06-29 13:56:35,451 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:35,456 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:35,461 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687395.460812 Biotechnology raises ethical questions, especially when it comes to modifying human genes. What are some ethical considerations in the use of biotechnology in humans? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687395.460812 Biotechnology raises ethical questions, especially when it comes to modifying human genes. What are some ethical considerations in the use of biotechnology in humans? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:56:35,466 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:35,469 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:35.469475, (GMT): 2024-06-29 18:56:35.469475+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:35.469475, (GMT): 2024-06-29 18:56:35.469475+00:00\n",
      "2024-06-29 13:56:42,239 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:42,253 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:42,257 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:42,268 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.91 seconds or 6908.55 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.91 seconds or 6908.55 milliseconds.\n",
      "2024-06-29 13:56:42,979 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:42,986 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:42,990 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.75 seconds or 7751.27 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.75 seconds or 7751.27 milliseconds.\n",
      "2024-06-29 13:56:43,035 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:43,038 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.57 seconds or 7566.77 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.57 seconds or 7566.77 milliseconds.\n",
      "2024-06-29 13:56:43,088 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:43,092 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.67 seconds or 7674.16 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.67 seconds or 7674.16 milliseconds.\n",
      "2024-06-29 13:56:43,141 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:43,985 - micro - MainProcess - INFO     CPU usage: 8.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 8.4%\n",
      "2024-06-29 13:56:43,996 - micro - MainProcess - INFO     RAM usage: 88.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.3%\n",
      "2024-06-29 13:56:44,048 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:44,055 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:44,058 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687404.0580375 E-commerce has grown rapidly, especially during the COVID-19 pandemic, changing the way we shop. What are the key factors driving the growth of e-commerce, and how is it changing retail? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 78 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687404.0580375 E-commerce has grown rapidly, especially during the COVID-19 pandemic, changing the way we shop. What are the key factors driving the growth of e-commerce, and how is it changing retail? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 78\n",
      "2024-06-29 13:56:44,064 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:44,067 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:44.067847, (GMT): 2024-06-29 18:56:44.067847+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:44.067847, (GMT): 2024-06-29 18:56:44.067847+00:00\n",
      "2024-06-29 13:56:44,073 - micro - MainProcess - INFO     CPU usage: 25.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 25.4%\n",
      "2024-06-29 13:56:44,087 - micro - MainProcess - INFO     RAM usage: 88.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.3%\n",
      "2024-06-29 13:56:44,105 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:44,112 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:44,119 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687404.119585 Blockchain technology, initially popularized by cryptocurrencies like Bitcoin, has far-reaching applications beyond digital currencies. How does blockchain technology work, and what are its main applications beyond cryptocurrencies? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687404.119585 Blockchain technology, initially popularized by cryptocurrencies like Bitcoin, has far-reaching applications beyond digital currencies. How does blockchain technology work, and what are its main applications beyond cryptocurrencies? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:56:44,126 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:44,129 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:44.129595, (GMT): 2024-06-29 18:56:44.129595+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:44.129595, (GMT): 2024-06-29 18:56:44.129595+00:00\n",
      "2024-06-29 13:56:44,137 - micro - MainProcess - INFO     CPU usage: 18.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 18.4%\n",
      "2024-06-29 13:56:44,150 - micro - MainProcess - INFO     RAM usage: 88.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.3%\n",
      "2024-06-29 13:56:44,167 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:44,173 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:44,178 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687404.178543 Artificial intelligence (AI) is becoming increasingly important in cybersecurity to detect and prevent threats. How is artificial intelligence being used to enhance cybersecurity measures? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 66 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687404.178543 Artificial intelligence (AI) is becoming increasingly important in cybersecurity to detect and prevent threats. How is artificial intelligence being used to enhance cybersecurity measures? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 66\n",
      "2024-06-29 13:56:44,183 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:44,186 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:44.186667, (GMT): 2024-06-29 18:56:44.186667+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:44.186667, (GMT): 2024-06-29 18:56:44.186667+00:00\n",
      "2024-06-29 13:56:44,192 - micro - MainProcess - INFO     CPU usage: 12.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.5%\n",
      "2024-06-29 13:56:44,203 - micro - MainProcess - INFO     RAM usage: 88.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.3%\n",
      "2024-06-29 13:56:44,270 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:44,280 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:44,283 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687404.2836838 Virtual reality (VR) and augmented reality (AR) offer different ways to enhance our perception of the world. What are the main differences between virtual reality and augmented reality? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687404.2836838 Virtual reality (VR) and augmented reality (AR) offer different ways to enhance our perception of the world. What are the main differences between virtual reality and augmented reality? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:56:44,292 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:44,297 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:44.297972, (GMT): 2024-06-29 18:56:44.297972+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:44.297972, (GMT): 2024-06-29 18:56:44.297972+00:00\n",
      "2024-06-29 13:56:45,129 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:45,156 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:45,162 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 10.69 seconds or 10691.58 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 10.69 seconds or 10691.58 milliseconds.\n",
      "2024-06-29 13:56:45,242 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:45,248 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:45,253 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:45,260 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 10.1 seconds or 10102.4 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 10.1 seconds or 10102.4 milliseconds.\n",
      "2024-06-29 13:56:45,326 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:45,331 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 10.24 seconds or 10235.16 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 10.24 seconds or 10235.16 milliseconds.\n",
      "2024-06-29 13:56:45,452 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:45,459 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 10.42 seconds or 10417.49 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 10.42 seconds or 10417.49 milliseconds.\n",
      "2024-06-29 13:56:45,508 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:46,236 - micro - MainProcess - INFO     CPU usage: 21.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 21.0%\n",
      "2024-06-29 13:56:46,248 - micro - MainProcess - INFO     RAM usage: 87.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.6%\n",
      "2024-06-29 13:56:46,278 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:46,295 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:46,302 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687406.3028412 Blockchain technology, initially popularized by cryptocurrencies like Bitcoin, has far-reaching applications beyond digital currencies. How does blockchain technology work, and what are its main applications beyond cryptocurrencies? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687406.3028412 Blockchain technology, initially popularized by cryptocurrencies like Bitcoin, has far-reaching applications beyond digital currencies. How does blockchain technology work, and what are its main applications beyond cryptocurrencies? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:56:46,311 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:46,315 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:46.315142, (GMT): 2024-06-29 18:56:46.315142+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:46.315142, (GMT): 2024-06-29 18:56:46.315142+00:00\n",
      "2024-06-29 13:56:46,328 - micro - MainProcess - INFO     CPU usage: 45.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 45.8%\n",
      "2024-06-29 13:56:46,342 - micro - MainProcess - INFO     RAM usage: 87.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.4%\n",
      "2024-06-29 13:56:46,368 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:46,376 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:46,381 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687406.3808894 Artificial intelligence (AI) is becoming increasingly important in cybersecurity to detect and prevent threats. How is artificial intelligence being used to enhance cybersecurity measures? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687406.3808894 Artificial intelligence (AI) is becoming increasingly important in cybersecurity to detect and prevent threats. How is artificial intelligence being used to enhance cybersecurity measures? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:56:46,391 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:46,395 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:46.395170, (GMT): 2024-06-29 18:56:46.395170+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:46.395170, (GMT): 2024-06-29 18:56:46.395170+00:00\n",
      "2024-06-29 13:56:46,466 - micro - MainProcess - INFO     CPU usage: 36.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 36.6%\n",
      "2024-06-29 13:56:46,491 - micro - MainProcess - INFO     RAM usage: 87.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.5%\n",
      "2024-06-29 13:56:46,568 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:46,574 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:46,579 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687406.5794444 Virtual reality (VR) and augmented reality (AR) offer different ways to enhance our perception of the world. What are the main differences between virtual reality and augmented reality? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687406.5794444 Virtual reality (VR) and augmented reality (AR) offer different ways to enhance our perception of the world. What are the main differences between virtual reality and augmented reality? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:56:46,584 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:46,588 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:46.588974, (GMT): 2024-06-29 18:56:46.588974+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:46.588974, (GMT): 2024-06-29 18:56:46.588974+00:00\n",
      "2024-06-29 13:56:46,606 - micro - MainProcess - INFO     CPU usage: 79.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 79.5%\n",
      "2024-06-29 13:56:46,626 - micro - MainProcess - INFO     RAM usage: 87.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.5%\n",
      "2024-06-29 13:56:46,659 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:46,666 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:46,672 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687406.6709077 E-commerce has grown rapidly, especially during the COVID-19 pandemic, changing the way we shop. What are the key factors driving the growth of e-commerce, and how is it changing retail? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 78 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687406.6709077 E-commerce has grown rapidly, especially during the COVID-19 pandemic, changing the way we shop. What are the key factors driving the growth of e-commerce, and how is it changing retail? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 78\n",
      "2024-06-29 13:56:46,678 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:46,683 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:46.683342, (GMT): 2024-06-29 18:56:46.683342+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:46.683342, (GMT): 2024-06-29 18:56:46.683342+00:00\n",
      "2024-06-29 13:56:47,266 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:47,297 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.23 seconds or 3225.28 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.23 seconds or 3225.28 milliseconds.\n",
      "2024-06-29 13:56:47,365 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:47,645 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:47,656 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:47,666 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:47,674 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.54 seconds or 3541.68 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.54 seconds or 3541.68 milliseconds.\n",
      "2024-06-29 13:56:47,734 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:47,743 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.44 seconds or 3438.53 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.44 seconds or 3438.53 milliseconds.\n",
      "2024-06-29 13:56:47,792 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:47,796 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.6 seconds or 3604.73 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.6 seconds or 3604.73 milliseconds.\n",
      "2024-06-29 13:56:47,860 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:48,366 - micro - MainProcess - INFO     CPU usage: 27.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 27.2%\n",
      "2024-06-29 13:56:48,377 - micro - MainProcess - INFO     RAM usage: 86.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.9%\n",
      "2024-06-29 13:56:48,397 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:48,404 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:48,409 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687408.4086394 Big data analytics involves examining large datasets to uncover hidden patterns and insights. How do big data analytics help businesses make better decisions? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 64 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687408.4086394 Big data analytics involves examining large datasets to uncover hidden patterns and insights. How do big data analytics help businesses make better decisions? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 64\n",
      "2024-06-29 13:56:48,417 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:48,422 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:48.421184, (GMT): 2024-06-29 18:56:48.422179+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:48.421184, (GMT): 2024-06-29 18:56:48.422179+00:00\n",
      "2024-06-29 13:56:48,732 - micro - MainProcess - INFO     CPU usage: 15.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.7%\n",
      "2024-06-29 13:56:48,745 - micro - MainProcess - INFO     RAM usage: 87.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.2%\n",
      "2024-06-29 13:56:48,771 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:48,788 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:48,794 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687408.794077 Climate change is one of the most pressing issues of our time, affecting ecosystems, weather patterns, and sea levels. What are the major challenges in combating climate change, and what can individuals do to help? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 79 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687408.794077 Climate change is one of the most pressing issues of our time, affecting ecosystems, weather patterns, and sea levels. What are the major challenges in combating climate change, and what can individuals do to help? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 79\n",
      "2024-06-29 13:56:48,805 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:48,808 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:48.808641, (GMT): 2024-06-29 18:56:48.808641+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:48.808641, (GMT): 2024-06-29 18:56:48.808641+00:00\n",
      "2024-06-29 13:56:48,818 - micro - MainProcess - INFO     CPU usage: 46.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 46.5%\n",
      "2024-06-29 13:56:48,836 - micro - MainProcess - INFO     RAM usage: 87.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.2%\n",
      "2024-06-29 13:56:48,905 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:48,911 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:48,924 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687408.9238877 Data privacy is a growing concern as more personal information is collected and stored online. Can you discuss the importance of data privacy and how individuals can protect their information? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687408.9238877 Data privacy is a growing concern as more personal information is collected and stored online. Can you discuss the importance of data privacy and how individuals can protect their information? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:56:48,931 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:48,940 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:48.940685, (GMT): 2024-06-29 18:56:48.940685+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:48.940685, (GMT): 2024-06-29 18:56:48.940685+00:00\n",
      "2024-06-29 13:56:48,988 - micro - MainProcess - INFO     CPU usage: 93.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 93.7%\n",
      "2024-06-29 13:56:49,112 - micro - MainProcess - INFO     RAM usage: 87.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.3%\n",
      "2024-06-29 13:56:49,134 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:49,141 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:49,147 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687409.1468697 Smart contracts are self-executing contracts with the terms of the agreement directly written into code. Can you explain the concept of smart contracts and their use in blockchain technology? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687409.1468697 Smart contracts are self-executing contracts with the terms of the agreement directly written into code. Can you explain the concept of smart contracts and their use in blockchain technology? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:56:49,155 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:49,158 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:49.158063, (GMT): 2024-06-29 18:56:49.158063+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:49.158063, (GMT): 2024-06-29 18:56:49.158063+00:00\n",
      "2024-06-29 13:56:52,940 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:52,979 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.55 seconds or 4552.87 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.55 seconds or 4552.87 milliseconds.\n",
      "2024-06-29 13:56:53,048 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:53,054 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:53,060 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.74 seconds or 6740.06 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.74 seconds or 6740.06 milliseconds.\n",
      "2024-06-29 13:56:53,118 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:53,731 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:53,755 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:53,766 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.37 seconds or 7365.3 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.37 seconds or 7365.3 milliseconds.\n",
      "2024-06-29 13:56:53,821 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:53,828 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:53,834 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:53,840 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.89 seconds or 4894.73 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.89 seconds or 4894.73 milliseconds.\n",
      "2024-06-29 13:56:53,888 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:53,892 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.73 seconds or 4730.68 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.73 seconds or 4730.68 milliseconds.\n",
      "2024-06-29 13:56:53,939 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:53,944 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.13 seconds or 5130.67 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.13 seconds or 5130.67 milliseconds.\n",
      "2024-06-29 13:56:53,990 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:54,064 - micro - MainProcess - INFO     CPU usage: 13.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.3%\n",
      "2024-06-29 13:56:54,076 - micro - MainProcess - INFO     RAM usage: 87.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.5%\n",
      "2024-06-29 13:56:54,127 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:54,136 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:54,142 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687414.1426969 Precision medicine tailors medical treatment to the individual characteristics of each patient. Can you explain the concept of precision medicine and its advantages in treating diseases? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687414.1426969 Precision medicine tailors medical treatment to the individual characteristics of each patient. Can you explain the concept of precision medicine and its advantages in treating diseases? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:56:54,149 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:54,159 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:54.159288, (GMT): 2024-06-29 18:56:54.159288+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:54.159288, (GMT): 2024-06-29 18:56:54.159288+00:00\n",
      "2024-06-29 13:56:54,166 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:54,176 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.58 seconds or 7580.21 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.58 seconds or 7580.21 milliseconds.\n",
      "2024-06-29 13:56:54,246 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:54,249 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:54,254 - micro - MainProcess - INFO     CPU usage: 68.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 68.1%\n",
      "2024-06-29 13:56:54,267 - micro - MainProcess - INFO     RAM usage: 87.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.5%\n",
      "2024-06-29 13:56:54,285 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:54,292 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:54,299 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687414.2978377 Climate change is one of the most pressing issues of our time, affecting ecosystems, weather patterns, and sea levels. What are the major challenges in combating climate change, and what can individuals do to help? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 80 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687414.2978377 Climate change is one of the most pressing issues of our time, affecting ecosystems, weather patterns, and sea levels. What are the major challenges in combating climate change, and what can individuals do to help? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 80\n",
      "2024-06-29 13:56:54,306 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:54,310 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:54.310463, (GMT): 2024-06-29 18:56:54.310463+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:54.310463, (GMT): 2024-06-29 18:56:54.310463+00:00\n",
      "2024-06-29 13:56:54,315 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.63 seconds or 7626.81 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.63 seconds or 7626.81 milliseconds.\n",
      "2024-06-29 13:56:54,366 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:54,835 - micro - MainProcess - INFO     CPU usage: 15.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.6%\n",
      "2024-06-29 13:56:54,851 - micro - MainProcess - INFO     RAM usage: 87.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.6%\n",
      "2024-06-29 13:56:54,893 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:54,903 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:54,909 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687414.909834 Smart contracts are self-executing contracts with the terms of the agreement directly written into code. Can you explain the concept of smart contracts and their use in blockchain technology? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687414.909834 Smart contracts are self-executing contracts with the terms of the agreement directly written into code. Can you explain the concept of smart contracts and their use in blockchain technology? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:56:54,917 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:54,919 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:54.919416, (GMT): 2024-06-29 18:56:54.919416+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:54.919416, (GMT): 2024-06-29 18:56:54.919416+00:00\n",
      "2024-06-29 13:56:54,927 - micro - MainProcess - INFO     CPU usage: 13.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.5%\n",
      "2024-06-29 13:56:54,941 - micro - MainProcess - INFO     RAM usage: 87.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.6%\n",
      "2024-06-29 13:56:54,971 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:54,978 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:54,984 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687414.9830167 Quantum cryptography uses the principles of quantum mechanics to secure communication. How is quantum cryptography enhancing the security of digital communications? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 62 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687414.9830167 Quantum cryptography uses the principles of quantum mechanics to secure communication. How is quantum cryptography enhancing the security of digital communications? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 62\n",
      "2024-06-29 13:56:54,990 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:54,992 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:54.992903, (GMT): 2024-06-29 18:56:54.992903+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:54.992903, (GMT): 2024-06-29 18:56:54.992903+00:00\n",
      "2024-06-29 13:56:54,995 - micro - MainProcess - INFO     CPU usage: 23.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 23.1%\n",
      "2024-06-29 13:56:55,009 - micro - MainProcess - INFO     RAM usage: 87.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.7%\n",
      "2024-06-29 13:56:55,028 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:55,035 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:55,040 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687415.0403376 3D printing, also known as additive manufacturing, creates objects layer by layer from digital models. What are some innovative uses of 3D printing in manufacturing and healthcare? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687415.0403376 3D printing, also known as additive manufacturing, creates objects layer by layer from digital models. What are some innovative uses of 3D printing in manufacturing and healthcare? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:56:55,049 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:55,053 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:55.053778, (GMT): 2024-06-29 18:56:55.053778+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:55.053778, (GMT): 2024-06-29 18:56:55.053778+00:00\n",
      "2024-06-29 13:56:55,127 - micro - MainProcess - INFO     CPU usage: 42.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 42.6%\n",
      "2024-06-29 13:56:55,143 - micro - MainProcess - INFO     RAM usage: 87.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.6%\n",
      "2024-06-29 13:56:55,163 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:55,173 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:55,180 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687415.1789982 Machine learning is a subset of artificial intelligence where algorithms learn from data to make predictions or decisions. How do machine learning algorithms improve over time, and what are some common applications? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687415.1789982 Machine learning is a subset of artificial intelligence where algorithms learn from data to make predictions or decisions. How do machine learning algorithms improve over time, and what are some common applications? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:56:55,186 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:55,190 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:55.189775, (GMT): 2024-06-29 18:56:55.189775+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:55.189775, (GMT): 2024-06-29 18:56:55.189775+00:00\n",
      "2024-06-29 13:56:55,222 - micro - MainProcess - INFO     CPU usage: 53.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 53.2%\n",
      "2024-06-29 13:56:55,236 - micro - MainProcess - INFO     RAM usage: 87.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.6%\n",
      "2024-06-29 13:56:55,253 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:55,258 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:55,262 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687415.262393 Data privacy is a growing concern as more personal information is collected and stored online. Can you discuss the importance of data privacy and how individuals can protect their information? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687415.262393 Data privacy is a growing concern as more personal information is collected and stored online. Can you discuss the importance of data privacy and how individuals can protect their information? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:56:55,268 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:55,270 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:55.270515, (GMT): 2024-06-29 18:56:55.270515+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:55.270515, (GMT): 2024-06-29 18:56:55.270515+00:00\n",
      "2024-06-29 13:56:55,353 - micro - MainProcess - INFO     CPU usage: 9.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 9.4%\n",
      "2024-06-29 13:56:55,363 - micro - MainProcess - INFO     RAM usage: 87.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.8%\n",
      "2024-06-29 13:56:55,392 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:55,397 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:55,402 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687415.4028604 Big data analytics involves examining large datasets to uncover hidden patterns and insights. How do big data analytics help businesses make better decisions? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 64 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687415.4028604 Big data analytics involves examining large datasets to uncover hidden patterns and insights. How do big data analytics help businesses make better decisions? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 64\n",
      "2024-06-29 13:56:55,409 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:55,411 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:55.411333, (GMT): 2024-06-29 18:56:55.411333+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:56:55.411333, (GMT): 2024-06-29 18:56:55.411333+00:00\n",
      "2024-06-29 13:56:57,409 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:57,439 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.28 seconds or 3276.35 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.28 seconds or 3276.35 milliseconds.\n",
      "2024-06-29 13:56:57,491 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:58,437 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:58,469 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.27 seconds or 3272.84 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.27 seconds or 3272.84 milliseconds.\n",
      "2024-06-29 13:56:58,546 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:58,552 - micro - MainProcess - INFO     CPU usage: 15.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.4%\n",
      "2024-06-29 13:56:58,563 - micro - MainProcess - INFO     RAM usage: 87.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.6%\n",
      "2024-06-29 13:56:58,697 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:58,704 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:58,708 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687418.7075555 Smart cities use technology to improve urban living conditions, making cities more efficient and sustainable. What are some examples of how smart cities are improving urban living conditions? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687418.7075555 Smart cities use technology to improve urban living conditions, making cities more efficient and sustainable. What are some examples of how smart cities are improving urban living conditions? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:56:58,714 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:58,721 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:58.721330, (GMT): 2024-06-29 18:56:58.721330+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:58.721330, (GMT): 2024-06-29 18:56:58.721330+00:00\n",
      "2024-06-29 13:56:58,726 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:58,732 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.67 seconds or 3673.4 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.67 seconds or 3673.4 milliseconds.\n",
      "2024-06-29 13:56:58,829 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:59,383 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:56:59,415 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.42 seconds or 4418.92 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.42 seconds or 4418.92 milliseconds.\n",
      "2024-06-29 13:56:59,472 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:56:59,561 - micro - MainProcess - INFO     CPU usage: 37.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 37.1%\n",
      "2024-06-29 13:56:59,574 - micro - MainProcess - INFO     RAM usage: 87.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.5%\n",
      "2024-06-29 13:56:59,601 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:59,613 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:59,620 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687419.6192904 As artificial intelligence becomes more integrated into our daily lives, ethical considerations become increasingly important. Can you discuss the ethical considerations surrounding artificial intelligence? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 66 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687419.6192904 As artificial intelligence becomes more integrated into our daily lives, ethical considerations become increasingly important. Can you discuss the ethical considerations surrounding artificial intelligence? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 66\n",
      "2024-06-29 13:56:59,629 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:59,652 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:59.652568, (GMT): 2024-06-29 18:56:59.652568+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:59.652568, (GMT): 2024-06-29 18:56:59.652568+00:00\n",
      "2024-06-29 13:56:59,835 - micro - MainProcess - INFO     CPU usage: 50.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 50.5%\n",
      "2024-06-29 13:56:59,849 - micro - MainProcess - INFO     RAM usage: 87.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.4%\n",
      "2024-06-29 13:56:59,871 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:56:59,878 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:59,886 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687419.8862855 Augmented reality (AR) is being used in retail to create interactive shopping experiences for customers. How is augmented reality being integrated into retail experiences to enhance customer engagement? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687419.8862855 Augmented reality (AR) is being used in retail to create interactive shopping experiences for customers. How is augmented reality being integrated into retail experiences to enhance customer engagement? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:56:59,892 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:56:59,897 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:59.897316, (GMT): 2024-06-29 18:56:59.897316+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:56:59.897316, (GMT): 2024-06-29 18:56:59.897316+00:00\n",
      "2024-06-29 13:57:00,217 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:00,223 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.91 seconds or 5908.24 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.91 seconds or 5908.24 milliseconds.\n",
      "2024-06-29 13:57:00,274 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:00,483 - micro - MainProcess - INFO     CPU usage: 37.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 37.8%\n",
      "2024-06-29 13:57:00,494 - micro - MainProcess - INFO     RAM usage: 87.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.5%\n",
      "2024-06-29 13:57:00,546 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:00,554 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:00,567 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687420.5672305 Artificial general intelligence (AGI) aims to create machines that can perform any intellectual task that a human can. What are some current challenges in the development of artificial general intelligence? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687420.5672305 Artificial general intelligence (AGI) aims to create machines that can perform any intellectual task that a human can. What are some current challenges in the development of artificial general intelligence? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:57:00,575 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:00,579 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:00.579777, (GMT): 2024-06-29 18:57:00.579777+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:00.579777, (GMT): 2024-06-29 18:57:00.579777+00:00\n",
      "2024-06-29 13:57:01,004 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:01,010 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.6 seconds or 5595.09 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.6 seconds or 5595.09 milliseconds.\n",
      "2024-06-29 13:57:01,059 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:01,063 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:01,091 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.82 seconds or 5816.3 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.82 seconds or 5816.3 milliseconds.\n",
      "2024-06-29 13:57:01,143 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:01,276 - micro - MainProcess - INFO     CPU usage: 35.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 35.8%\n",
      "2024-06-29 13:57:01,289 - micro - MainProcess - INFO     RAM usage: 87.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.6%\n",
      "2024-06-29 13:57:01,309 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:01,317 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:01,325 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687421.3246195 Machine learning is a subset of artificial intelligence where algorithms learn from data to make predictions or decisions. How do machine learning algorithms improve over time, and what are some common applications? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687421.3246195 Machine learning is a subset of artificial intelligence where algorithms learn from data to make predictions or decisions. How do machine learning algorithms improve over time, and what are some common applications? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:57:01,331 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:01,335 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:01.335174, (GMT): 2024-06-29 18:57:01.335174+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:01.335174, (GMT): 2024-06-29 18:57:01.335174+00:00\n",
      "2024-06-29 13:57:01,407 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:01,442 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.52 seconds or 6517.55 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.52 seconds or 6517.55 milliseconds.\n",
      "2024-06-29 13:57:01,499 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:02,020 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:02,049 - micro - MainProcess - INFO     CPU usage: 19.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.6%\n",
      "2024-06-29 13:57:02,068 - micro - MainProcess - INFO     RAM usage: 87.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.4%\n",
      "2024-06-29 13:57:02,094 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:02,101 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:02,107 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687422.1070077 Precision medicine tailors medical treatment to the individual characteristics of each patient. Can you explain the concept of precision medicine and its advantages in treating diseases? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687422.1070077 Precision medicine tailors medical treatment to the individual characteristics of each patient. Can you explain the concept of precision medicine and its advantages in treating diseases? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:57:02,114 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:02,118 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:02.117208, (GMT): 2024-06-29 18:57:02.117208+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:02.117208, (GMT): 2024-06-29 18:57:02.117208+00:00\n",
      "2024-06-29 13:57:02,125 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.4 seconds or 3400.13 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.4 seconds or 3400.13 milliseconds.\n",
      "2024-06-29 13:57:02,172 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:02,179 - micro - MainProcess - INFO     CPU usage: 40.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 40.9%\n",
      "2024-06-29 13:57:02,281 - micro - MainProcess - INFO     RAM usage: 87.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.5%\n",
      "2024-06-29 13:57:02,326 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:02,332 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:02,339 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687422.3382893 Quantum cryptography uses the principles of quantum mechanics to secure communication. How is quantum cryptography enhancing the security of digital communications? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 62 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687422.3382893 Quantum cryptography uses the principles of quantum mechanics to secure communication. How is quantum cryptography enhancing the security of digital communications? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 62\n",
      "2024-06-29 13:57:02,346 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:02,350 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:02.350096, (GMT): 2024-06-29 18:57:02.350096+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:02.350096, (GMT): 2024-06-29 18:57:02.350096+00:00\n",
      "2024-06-29 13:57:02,518 - micro - MainProcess - INFO     CPU usage: 75.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 75.1%\n",
      "2024-06-29 13:57:02,531 - micro - MainProcess - INFO     RAM usage: 87.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.7%\n",
      "2024-06-29 13:57:02,551 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:02,560 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:02,565 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687422.5641804 3D printing, also known as additive manufacturing, creates objects layer by layer from digital models. What are some innovative uses of 3D printing in manufacturing and healthcare? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687422.5641804 3D printing, also known as additive manufacturing, creates objects layer by layer from digital models. What are some innovative uses of 3D printing in manufacturing and healthcare? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:57:02,573 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:02,576 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:02.576503, (GMT): 2024-06-29 18:57:02.576503+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:02.576503, (GMT): 2024-06-29 18:57:02.576503+00:00\n",
      "2024-06-29 13:57:03,074 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:03,103 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.2 seconds or 3197.26 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.2 seconds or 3197.26 milliseconds.\n",
      "2024-06-29 13:57:03,191 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:03,198 - micro - MainProcess - INFO     CPU usage: 27.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 27.3%\n",
      "2024-06-29 13:57:03,210 - micro - MainProcess - INFO     RAM usage: 87.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.7%\n",
      "2024-06-29 13:57:03,238 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:03,244 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:03,251 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687423.251478 Fintech innovations are transforming the financial industry, making services more accessible and efficient. How is fintech innovation changing the banking and finance industry? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687423.251478 Fintech innovations are transforming the financial industry, making services more accessible and efficient. How is fintech innovation changing the banking and finance industry? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:57:03,259 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:03,263 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:03.263698, (GMT): 2024-06-29 18:57:03.263698+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:03.263698, (GMT): 2024-06-29 18:57:03.263698+00:00\n",
      "2024-06-29 13:57:03,762 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:03,790 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.21 seconds or 3206.24 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.21 seconds or 3206.24 milliseconds.\n",
      "2024-06-29 13:57:03,845 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:04,202 - micro - MainProcess - INFO     CPU usage: 20.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 20.1%\n",
      "2024-06-29 13:57:04,217 - micro - MainProcess - INFO     RAM usage: 87.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.6%\n",
      "2024-06-29 13:57:04,239 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:04,246 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:04,251 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687424.250013 Electric vehicles (EVs) offer a cleaner alternative to traditional gasoline-powered cars, but their widespread adoption poses challenges. What are the potential environmental impacts of widespread adoption of electric vehicles? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687424.250013 Electric vehicles (EVs) offer a cleaner alternative to traditional gasoline-powered cars, but their widespread adoption poses challenges. What are the potential environmental impacts of widespread adoption of electric vehicles? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:57:04,260 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:04,263 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:04.263368, (GMT): 2024-06-29 18:57:04.263368+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:04.263368, (GMT): 2024-06-29 18:57:04.263368+00:00\n",
      "2024-06-29 13:57:04,855 - micro - MainProcess - INFO     CPU usage: 23.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 23.1%\n",
      "2024-06-29 13:57:04,866 - micro - MainProcess - INFO     RAM usage: 87.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.7%\n",
      "2024-06-29 13:57:04,938 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:04,951 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:04,959 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687424.9596643 Nanotechnology involves manipulating matter at the atomic and molecular scale for various applications. How is nanotechnology being used in medical treatments and drug delivery systems? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687424.9596643 Nanotechnology involves manipulating matter at the atomic and molecular scale for various applications. How is nanotechnology being used in medical treatments and drug delivery systems? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:57:04,968 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:04,972 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:04.972373, (GMT): 2024-06-29 18:57:04.972373+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:04.972373, (GMT): 2024-06-29 18:57:04.972373+00:00\n",
      "2024-06-29 13:57:04,979 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:04,985 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.29 seconds or 5290.66 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.29 seconds or 5290.66 milliseconds.\n",
      "2024-06-29 13:57:05,039 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:06,038 - micro - MainProcess - INFO     CPU usage: 13.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.5%\n",
      "2024-06-29 13:57:06,049 - micro - MainProcess - INFO     RAM usage: 87.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.6%\n",
      "2024-06-29 13:57:06,102 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:06,109 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:06,114 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687426.114157 Autonomous vehicles, or self-driving cars, have the potential to revolutionize transportation, but they also pose significant challenges. What are the benefits and risks of autonomous vehicles on our roads? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687426.114157 Autonomous vehicles, or self-driving cars, have the potential to revolutionize transportation, but they also pose significant challenges. What are the benefits and risks of autonomous vehicles on our roads? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:57:06,119 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:06,122 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:06.122811, (GMT): 2024-06-29 18:57:06.122811+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:06.122811, (GMT): 2024-06-29 18:57:06.122811+00:00\n",
      "2024-06-29 13:57:06,971 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:07,003 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.73 seconds or 3734.94 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.73 seconds or 3734.94 milliseconds.\n",
      "2024-06-29 13:57:07,050 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:07,859 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:07,889 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.55 seconds or 6551.13 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.55 seconds or 6551.13 milliseconds.\n",
      "2024-06-29 13:57:07,941 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:08,014 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:08,047 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.78 seconds or 3779.15 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.78 seconds or 3779.15 milliseconds.\n",
      "2024-06-29 13:57:08,101 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:08,110 - micro - MainProcess - INFO     CPU usage: 15.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.4%\n",
      "2024-06-29 13:57:08,124 - micro - MainProcess - INFO     RAM usage: 87.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.7%\n",
      "2024-06-29 13:57:08,266 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:08,275 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:08,294 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687428.2940314 Telemedicine allows healthcare providers to consult with patients remotely, increasing access to care. What are the benefits and challenges of telemedicine for both patients and healthcare providers? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687428.2940314 Telemedicine allows healthcare providers to consult with patients remotely, increasing access to care. What are the benefits and challenges of telemedicine for both patients and healthcare providers? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:57:08,301 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:08,305 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:08.305583, (GMT): 2024-06-29 18:57:08.305583+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:08.305583, (GMT): 2024-06-29 18:57:08.305583+00:00\n",
      "2024-06-29 13:57:08,706 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:08,734 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.76 seconds or 3757.18 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.76 seconds or 3757.18 milliseconds.\n",
      "2024-06-29 13:57:08,786 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:08,808 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:08,847 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.72 seconds or 6723.88 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.72 seconds or 6723.88 milliseconds.\n",
      "2024-06-29 13:57:08,931 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:08,940 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:08,946 - micro - MainProcess - INFO     CPU usage: 50.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 50.4%\n",
      "2024-06-29 13:57:08,958 - micro - MainProcess - INFO     RAM usage: 87.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.8%\n",
      "2024-06-29 13:57:08,987 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:08,998 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:09,006 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687429.0060015 As artificial intelligence becomes more integrated into our daily lives, ethical considerations become increasingly important. Can you discuss the ethical considerations surrounding artificial intelligence? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 66 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687429.0060015 As artificial intelligence becomes more integrated into our daily lives, ethical considerations become increasingly important. Can you discuss the ethical considerations surrounding artificial intelligence? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 66\n",
      "2024-06-29 13:57:09,015 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:09,019 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:09.019036, (GMT): 2024-06-29 18:57:09.019036+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:09.019036, (GMT): 2024-06-29 18:57:09.019036+00:00\n",
      "2024-06-29 13:57:09,027 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.65 seconds or 6654.95 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.65 seconds or 6654.95 milliseconds.\n",
      "2024-06-29 13:57:09,116 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:09,123 - micro - MainProcess - INFO     CPU usage: 88.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 88.4%\n",
      "2024-06-29 13:57:09,145 - micro - MainProcess - INFO     RAM usage: 88.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.0%\n",
      "2024-06-29 13:57:09,176 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:09,190 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:09,196 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687429.19681 Robots are being programmed to perform increasingly complex tasks in various industries, from manufacturing to healthcare. How do robots learn to perform complex tasks, and what are some examples of their use in industry? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 76 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687429.19681 Robots are being programmed to perform increasingly complex tasks in various industries, from manufacturing to healthcare. How do robots learn to perform complex tasks, and what are some examples of their use in industry? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 76\n",
      "2024-06-29 13:57:09,212 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:09,231 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:09.231922, (GMT): 2024-06-29 18:57:09.231922+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:09.231922, (GMT): 2024-06-29 18:57:09.231922+00:00\n",
      "2024-06-29 13:57:09,266 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:09,292 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.71 seconds or 6710.98 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.71 seconds or 6710.98 milliseconds.\n",
      "2024-06-29 13:57:09,383 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:09,480 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:09,514 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.39 seconds or 3388.63 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.39 seconds or 3388.63 milliseconds.\n",
      "2024-06-29 13:57:09,577 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:09,810 - micro - MainProcess - INFO     CPU usage: 91.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 91.9%\n",
      "2024-06-29 13:57:09,822 - micro - MainProcess - INFO     RAM usage: 88.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.2%\n",
      "2024-06-29 13:57:09,854 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:09,864 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:09,874 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687429.873202 Smart homes use connected devices to automate and control household systems, improving convenience and efficiency. What are the key components of a smart home, and how do they work together? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687429.873202 Smart homes use connected devices to automate and control household systems, improving convenience and efficiency. What are the key components of a smart home, and how do they work together? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:57:09,884 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:09,889 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:09.889318, (GMT): 2024-06-29 18:57:09.889318+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:09.889318, (GMT): 2024-06-29 18:57:09.889318+00:00\n",
      "2024-06-29 13:57:09,933 - micro - MainProcess - INFO     CPU usage: 75.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 75.5%\n",
      "2024-06-29 13:57:09,949 - micro - MainProcess - INFO     RAM usage: 88.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.3%\n",
      "2024-06-29 13:57:09,978 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:09,991 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:09,997 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687429.9979382 Smart cities use technology to improve urban living conditions, making cities more efficient and sustainable. What are some examples of how smart cities are improving urban living conditions? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687429.9979382 Smart cities use technology to improve urban living conditions, making cities more efficient and sustainable. What are some examples of how smart cities are improving urban living conditions? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:57:10,008 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:10,012 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:10.012310, (GMT): 2024-06-29 18:57:10.012310+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:10.012310, (GMT): 2024-06-29 18:57:10.012310+00:00\n",
      "2024-06-29 13:57:10,135 - micro - MainProcess - INFO     CPU usage: 79.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 79.8%\n",
      "2024-06-29 13:57:10,148 - micro - MainProcess - INFO     RAM usage: 88.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.5%\n",
      "2024-06-29 13:57:10,181 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:10,192 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:10,199 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687430.198551 Artificial general intelligence (AGI) aims to create machines that can perform any intellectual task that a human can. What are some current challenges in the development of artificial general intelligence? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687430.198551 Artificial general intelligence (AGI) aims to create machines that can perform any intellectual task that a human can. What are some current challenges in the development of artificial general intelligence? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:57:10,207 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:10,214 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:10.214899, (GMT): 2024-06-29 18:57:10.214899+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:10.214899, (GMT): 2024-06-29 18:57:10.214899+00:00\n",
      "2024-06-29 13:57:10,393 - micro - MainProcess - INFO     CPU usage: 72.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 72.4%\n",
      "2024-06-29 13:57:10,409 - micro - MainProcess - INFO     RAM usage: 88.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.6%\n",
      "2024-06-29 13:57:10,444 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:10,461 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:10,467 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687430.465001 Augmented reality (AR) is being used in retail to create interactive shopping experiences for customers. How is augmented reality being integrated into retail experiences to enhance customer engagement? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687430.465001 Augmented reality (AR) is being used in retail to create interactive shopping experiences for customers. How is augmented reality being integrated into retail experiences to enhance customer engagement? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:57:10,474 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:10,479 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:10.479469, (GMT): 2024-06-29 18:57:10.479469+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:10.479469, (GMT): 2024-06-29 18:57:10.479469+00:00\n",
      "2024-06-29 13:57:10,580 - micro - MainProcess - INFO     CPU usage: 63.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 63.5%\n",
      "2024-06-29 13:57:10,597 - micro - MainProcess - INFO     RAM usage: 88.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.7%\n",
      "2024-06-29 13:57:10,628 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:10,639 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:10,645 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687430.645015 Augmented reality (AR) overlays digital information onto the real world, providing new ways to interact with our environment. How is augmented reality being used in education and training programs? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687430.645015 Augmented reality (AR) overlays digital information onto the real world, providing new ways to interact with our environment. How is augmented reality being used in education and training programs? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:57:10,654 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:10,662 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:10.662111, (GMT): 2024-06-29 18:57:10.662111+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:10.662111, (GMT): 2024-06-29 18:57:10.662111+00:00\n",
      "2024-06-29 13:57:11,589 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:11,630 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.32 seconds or 3320.79 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.32 seconds or 3320.79 milliseconds.\n",
      "2024-06-29 13:57:11,676 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:12,687 - micro - MainProcess - INFO     CPU usage: 17.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 17.2%\n",
      "2024-06-29 13:57:12,698 - micro - MainProcess - INFO     RAM usage: 88.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.6%\n",
      "2024-06-29 13:57:12,721 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:12,726 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:12,730 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687432.7309084 Bioinformatics combines biology, computer science, and information technology to analyze biological data. Can you discuss the role of bioinformatics in modern biology and medical research? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687432.7309084 Bioinformatics combines biology, computer science, and information technology to analyze biological data. Can you discuss the role of bioinformatics in modern biology and medical research? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:57:12,740 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:12,743 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:12.743963, (GMT): 2024-06-29 18:57:12.743963+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:12.743963, (GMT): 2024-06-29 18:57:12.743963+00:00\n",
      "2024-06-29 13:57:12,933 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:12,964 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.7 seconds or 3702.55 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.7 seconds or 3702.55 milliseconds.\n",
      "2024-06-29 13:57:13,041 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:13,734 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:13,766 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.87 seconds or 3870.32 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.87 seconds or 3870.32 milliseconds.\n",
      "2024-06-29 13:57:13,822 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:14,042 - micro - MainProcess - INFO     CPU usage: 18.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 18.2%\n",
      "2024-06-29 13:57:14,054 - micro - MainProcess - INFO     RAM usage: 88.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.6%\n",
      "2024-06-29 13:57:14,078 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:14,085 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:14,090 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687434.0902743 Sustainable development seeks to meet the needs of the present without compromising the ability of future generations to meet their own needs. What are some challenges and solutions in implementing sustainable development practices? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687434.0902743 Sustainable development seeks to meet the needs of the present without compromising the ability of future generations to meet their own needs. What are some challenges and solutions in implementing sustainable development practices? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:57:14,096 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:14,098 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:14.098269, (GMT): 2024-06-29 18:57:14.098269+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:14.098269, (GMT): 2024-06-29 18:57:14.098269+00:00\n",
      "2024-06-29 13:57:14,833 - micro - MainProcess - INFO     CPU usage: 13.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.9%\n",
      "2024-06-29 13:57:14,842 - micro - MainProcess - INFO     RAM usage: 88.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.5%\n",
      "2024-06-29 13:57:14,868 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:14,871 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:14,877 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687434.877217 Advancements in neuroscience are providing new insights into how the brain functions and how we can treat neurological disorders. Can you describe the advancements in neuroscience that are helping us understand the brain? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687434.877217 Advancements in neuroscience are providing new insights into how the brain functions and how we can treat neurological disorders. Can you describe the advancements in neuroscience that are helping us understand the brain? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:57:14,883 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:14,887 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:14.887879, (GMT): 2024-06-29 18:57:14.887879+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:14.887879, (GMT): 2024-06-29 18:57:14.887879+00:00\n",
      "2024-06-29 13:57:16,360 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:16,407 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.74 seconds or 5741.04 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.74 seconds or 5741.04 milliseconds.\n",
      "2024-06-29 13:57:16,481 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:16,489 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:16,497 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.47 seconds or 7471.94 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.47 seconds or 7471.94 milliseconds.\n",
      "2024-06-29 13:57:16,548 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:16,591 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:16,620 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.87 seconds or 3873.88 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.87 seconds or 3873.88 milliseconds.\n",
      "2024-06-29 13:57:16,689 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:16,695 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:16,740 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.52 seconds or 6518.9 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.52 seconds or 6518.9 milliseconds.\n",
      "2024-06-29 13:57:16,800 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:17,482 - micro - MainProcess - INFO     CPU usage: 9.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 9.9%\n",
      "2024-06-29 13:57:17,491 - micro - MainProcess - INFO     RAM usage: 87.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.9%\n",
      "2024-06-29 13:57:17,514 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:17,522 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:17,526 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687437.5266864 Genetic engineering allows scientists to modify the DNA of organisms, leading to advancements in medicine and agriculture. What are the latest advancements in genetic engineering, and how might they affect healthcare? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687437.5266864 Genetic engineering allows scientists to modify the DNA of organisms, leading to advancements in medicine and agriculture. What are the latest advancements in genetic engineering, and how might they affect healthcare? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:57:17,535 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:17,538 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:17.538599, (GMT): 2024-06-29 18:57:17.538599+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:17.538599, (GMT): 2024-06-29 18:57:17.538599+00:00\n",
      "2024-06-29 13:57:17,543 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:17,548 - micro - MainProcess - INFO     CPU usage: 21.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 21.4%\n",
      "2024-06-29 13:57:17,561 - micro - MainProcess - INFO     RAM usage: 87.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.9%\n",
      "2024-06-29 13:57:17,581 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:17,594 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:17,600 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687437.6009803 Autonomous vehicles, or self-driving cars, have the potential to revolutionize transportation, but they also pose significant challenges. What are the benefits and risks of autonomous vehicles on our roads? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 75 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687437.6009803 Autonomous vehicles, or self-driving cars, have the potential to revolutionize transportation, but they also pose significant challenges. What are the benefits and risks of autonomous vehicles on our roads? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 75\n",
      "2024-06-29 13:57:17,617 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:17,619 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:17.619267, (GMT): 2024-06-29 18:57:17.619267+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:17.619267, (GMT): 2024-06-29 18:57:17.619267+00:00\n",
      "2024-06-29 13:57:17,626 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.6 seconds or 7601.47 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.6 seconds or 7601.47 milliseconds.\n",
      "2024-06-29 13:57:17,695 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:17,701 - micro - MainProcess - INFO     CPU usage: 33.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 33.1%\n",
      "2024-06-29 13:57:17,715 - micro - MainProcess - INFO     RAM usage: 88.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.0%\n",
      "2024-06-29 13:57:17,755 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:17,761 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:17,778 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687437.7785141 Natural language processing (NLP) enables computers to understand and generate human language. How does natural language processing enable computers to understand human language? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687437.7785141 Natural language processing (NLP) enables computers to understand and generate human language. How does natural language processing enable computers to understand human language? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:57:17,786 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:17,791 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:17.791587, (GMT): 2024-06-29 18:57:17.791587+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:17.791587, (GMT): 2024-06-29 18:57:17.791587+00:00\n",
      "2024-06-29 13:57:17,808 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:17,823 - micro - MainProcess - INFO     CPU usage: 79.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 79.8%\n",
      "2024-06-29 13:57:17,839 - micro - MainProcess - INFO     RAM usage: 88.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.1%\n",
      "2024-06-29 13:57:17,859 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:17,864 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:17,870 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687437.870125 Nanotechnology involves manipulating matter at the atomic and molecular scale for various applications. How is nanotechnology being used in medical treatments and drug delivery systems? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687437.870125 Nanotechnology involves manipulating matter at the atomic and molecular scale for various applications. How is nanotechnology being used in medical treatments and drug delivery systems? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:57:17,877 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:17,880 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:17.880352, (GMT): 2024-06-29 18:57:17.880352+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:17.880352, (GMT): 2024-06-29 18:57:17.880352+00:00\n",
      "2024-06-29 13:57:17,890 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.0 seconds or 2999.75 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.0 seconds or 2999.75 milliseconds.\n",
      "2024-06-29 13:57:17,942 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:17,950 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:17,957 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.47 seconds or 7468.61 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.47 seconds or 7468.61 milliseconds.\n",
      "2024-06-29 13:57:18,018 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:18,026 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:18,046 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.94 seconds or 3942.86 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.94 seconds or 3942.86 milliseconds.\n",
      "2024-06-29 13:57:18,155 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:18,701 - micro - MainProcess - INFO     CPU usage: 31.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 31.9%\n",
      "2024-06-29 13:57:18,712 - micro - MainProcess - INFO     RAM usage: 87.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.8%\n",
      "2024-06-29 13:57:18,738 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:18,776 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:18,781 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687438.7812877 Fintech innovations are transforming the financial industry, making services more accessible and efficient. How is fintech innovation changing the banking and finance industry? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687438.7812877 Fintech innovations are transforming the financial industry, making services more accessible and efficient. How is fintech innovation changing the banking and finance industry? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:57:18,790 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:18,796 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:18.796434, (GMT): 2024-06-29 18:57:18.796434+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:18.796434, (GMT): 2024-06-29 18:57:18.796434+00:00\n",
      "2024-06-29 13:57:18,939 - micro - MainProcess - INFO     CPU usage: 51.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 51.9%\n",
      "2024-06-29 13:57:18,952 - micro - MainProcess - INFO     RAM usage: 88.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.0%\n",
      "2024-06-29 13:57:18,972 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:18,979 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:18,987 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687438.986335 The circular economy aims to minimize waste and make the most of resources by creating closed-loop systems. What are the benefits of a circular economy, and how does it promote sustainability? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687438.986335 The circular economy aims to minimize waste and make the most of resources by creating closed-loop systems. What are the benefits of a circular economy, and how does it promote sustainability? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:57:18,994 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:18,997 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:18.997783, (GMT): 2024-06-29 18:57:18.997783+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:18.997783, (GMT): 2024-06-29 18:57:18.997783+00:00\n",
      "2024-06-29 13:57:19,005 - micro - MainProcess - INFO     CPU usage: 51.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 51.8%\n",
      "2024-06-29 13:57:19,018 - micro - MainProcess - INFO     RAM usage: 87.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.9%\n",
      "2024-06-29 13:57:19,036 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:19,044 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:19,053 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687439.052966 Electric vehicles (EVs) offer a cleaner alternative to traditional gasoline-powered cars, but their widespread adoption poses challenges. What are the potential environmental impacts of widespread adoption of electric vehicles? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687439.052966 Electric vehicles (EVs) offer a cleaner alternative to traditional gasoline-powered cars, but their widespread adoption poses challenges. What are the potential environmental impacts of widespread adoption of electric vehicles? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:57:19,060 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:19,064 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:19.064983, (GMT): 2024-06-29 18:57:19.064983+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:19.064983, (GMT): 2024-06-29 18:57:19.064983+00:00\n",
      "2024-06-29 13:57:19,164 - micro - MainProcess - INFO     CPU usage: 15.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.1%\n",
      "2024-06-29 13:57:19,175 - micro - MainProcess - INFO     RAM usage: 87.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.9%\n",
      "2024-06-29 13:57:19,198 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:19,205 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:19,210 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687439.2106853 Social media trends influence consumer behavior and marketing strategies, shaping how brands interact with their audiences. Can you discuss the impact of social media trends on consumer behavior and marketing? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687439.2106853 Social media trends influence consumer behavior and marketing strategies, shaping how brands interact with their audiences. Can you discuss the impact of social media trends on consumer behavior and marketing? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:57:19,218 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:19,221 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:19.221231, (GMT): 2024-06-29 18:57:19.221231+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:19.221231, (GMT): 2024-06-29 18:57:19.221231+00:00\n",
      "2024-06-29 13:57:22,215 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:22,246 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.7 seconds or 4704.4 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.7 seconds or 4704.4 milliseconds.\n",
      "2024-06-29 13:57:22,298 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:22,306 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:22,318 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.52 seconds or 4518.59 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.52 seconds or 4518.59 milliseconds.\n",
      "2024-06-29 13:57:22,371 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:23,320 - micro - MainProcess - INFO     CPU usage: 13.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.2%\n",
      "2024-06-29 13:57:23,339 - micro - MainProcess - INFO     RAM usage: 88.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.1%\n",
      "2024-06-29 13:57:23,363 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:23,375 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:23,381 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687443.3816466 The Internet of Things (IoT) refers to a network of interconnected devices that communicate and share data. Can you explain the concept of the Internet of Things and provide some real-world examples? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 77 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687443.3816466 The Internet of Things (IoT) refers to a network of interconnected devices that communicate and share data. Can you explain the concept of the Internet of Things and provide some real-world examples? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 77\n",
      "2024-06-29 13:57:23,408 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:23,411 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:23.411946, (GMT): 2024-06-29 18:57:23.411946+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:23.411946, (GMT): 2024-06-29 18:57:23.411946+00:00\n",
      "2024-06-29 13:57:23,420 - micro - MainProcess - INFO     CPU usage: 32.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 32.9%\n",
      "2024-06-29 13:57:23,433 - micro - MainProcess - INFO     RAM usage: 88.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.0%\n",
      "2024-06-29 13:57:23,457 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:23,464 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:23,471 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687443.4718094 Drones are being used in various industries, from agriculture to logistics, due to their versatility. What are the potential uses of drones in agriculture and other industries? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687443.4718094 Drones are being used in various industries, from agriculture to logistics, due to their versatility. What are the potential uses of drones in agriculture and other industries? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:57:23,479 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:23,485 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:23.485521, (GMT): 2024-06-29 18:57:23.485521+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:23.485521, (GMT): 2024-06-29 18:57:23.485521+00:00\n",
      "2024-06-29 13:57:23,554 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:23,562 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.56 seconds or 4560.16 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.56 seconds or 4560.16 milliseconds.\n",
      "2024-06-29 13:57:23,621 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:23,688 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:23,726 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.5 seconds or 4501.46 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.5 seconds or 4501.46 milliseconds.\n",
      "2024-06-29 13:57:23,774 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:24,624 - micro - MainProcess - INFO     CPU usage: 29.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 29.5%\n",
      "2024-06-29 13:57:24,683 - micro - MainProcess - INFO     RAM usage: 88.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.2%\n",
      "2024-06-29 13:57:24,707 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:24,713 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:24,719 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687444.7172976 Agritech innovations are improving agricultural productivity and sustainability through the use of technology. How are advancements in agritech improving food production and sustainability? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 66 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687444.7172976 Agritech innovations are improving agricultural productivity and sustainability through the use of technology. How are advancements in agritech improving food production and sustainability? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 66\n",
      "2024-06-29 13:57:24,727 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:24,730 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:24.730137, (GMT): 2024-06-29 18:57:24.730137+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:24.730137, (GMT): 2024-06-29 18:57:24.730137+00:00\n",
      "2024-06-29 13:57:24,781 - micro - MainProcess - INFO     CPU usage: 30.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 30.6%\n",
      "2024-06-29 13:57:24,795 - micro - MainProcess - INFO     RAM usage: 88.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.1%\n",
      "2024-06-29 13:57:24,808 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:24,815 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:24,823 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687444.8201725 Artificial intelligence (AI) is being used to improve the accuracy and efficiency of medical diagnoses. How is artificial intelligence being used to improve the accuracy of medical diagnoses? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687444.8201725 Artificial intelligence (AI) is being used to improve the accuracy and efficiency of medical diagnoses. How is artificial intelligence being used to improve the accuracy of medical diagnoses? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:57:24,829 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:24,832 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:24.832744, (GMT): 2024-06-29 18:57:24.832744+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:24.832744, (GMT): 2024-06-29 18:57:24.832744+00:00\n",
      "2024-06-29 13:57:26,412 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:26,440 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.82 seconds or 8818.0 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.82 seconds or 8818.0 milliseconds.\n",
      "2024-06-29 13:57:26,496 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:26,504 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:26,509 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.62 seconds or 8624.54 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.62 seconds or 8624.54 milliseconds.\n",
      "2024-06-29 13:57:26,591 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:27,210 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:27,243 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.44 seconds or 8441.8 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.44 seconds or 8441.8 milliseconds.\n",
      "2024-06-29 13:57:27,305 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:27,504 - micro - MainProcess - INFO     CPU usage: 18.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 18.9%\n",
      "2024-06-29 13:57:27,515 - micro - MainProcess - INFO     RAM usage: 88.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.3%\n",
      "2024-06-29 13:57:27,537 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:27,545 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:27,551 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687447.5509071 Augmented reality (AR) overlays digital information onto the real world, providing new ways to interact with our environment. How is augmented reality being used in education and training programs? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687447.5509071 Augmented reality (AR) overlays digital information onto the real world, providing new ways to interact with our environment. How is augmented reality being used in education and training programs? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:57:27,558 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:27,562 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:27.562933, (GMT): 2024-06-29 18:57:27.562933+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:27.562933, (GMT): 2024-06-29 18:57:27.562933+00:00\n",
      "2024-06-29 13:57:27,591 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:27,596 - micro - MainProcess - INFO     CPU usage: 26.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 26.2%\n",
      "2024-06-29 13:57:27,610 - micro - MainProcess - INFO     RAM usage: 88.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.3%\n",
      "2024-06-29 13:57:27,634 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:27,640 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:27,647 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687447.6454334 Smart homes use connected devices to automate and control household systems, improving convenience and efficiency. What are the key components of a smart home, and how do they work together? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687447.6454334 Smart homes use connected devices to automate and control household systems, improving convenience and efficiency. What are the key components of a smart home, and how do they work together? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:57:27,652 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:27,655 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:27.655758, (GMT): 2024-06-29 18:57:27.655758+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:27.655758, (GMT): 2024-06-29 18:57:27.655758+00:00\n",
      "2024-06-29 13:57:27,665 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.59 seconds or 8594.4 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.59 seconds or 8594.4 milliseconds.\n",
      "2024-06-29 13:57:27,728 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:27,785 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:27,810 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.32 seconds or 4320.12 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.32 seconds or 4320.12 milliseconds.\n",
      "2024-06-29 13:57:27,862 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:27,945 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:27,994 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.58 seconds or 4579.06 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.58 seconds or 4579.06 milliseconds.\n",
      "2024-06-29 13:57:28,048 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:28,317 - micro - MainProcess - INFO     CPU usage: 42.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 42.0%\n",
      "2024-06-29 13:57:28,335 - micro - MainProcess - INFO     RAM usage: 88.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.4%\n",
      "2024-06-29 13:57:28,359 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:28,365 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:28,373 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687448.3724744 Telemedicine allows healthcare providers to consult with patients remotely, increasing access to care. What are the benefits and challenges of telemedicine for both patients and healthcare providers? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687448.3724744 Telemedicine allows healthcare providers to consult with patients remotely, increasing access to care. What are the benefits and challenges of telemedicine for both patients and healthcare providers? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:57:28,378 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:28,383 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:28.381699, (GMT): 2024-06-29 18:57:28.383214+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:28.381699, (GMT): 2024-06-29 18:57:28.383214+00:00\n",
      "2024-06-29 13:57:28,733 - micro - MainProcess - INFO     CPU usage: 14.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.6%\n",
      "2024-06-29 13:57:28,747 - micro - MainProcess - INFO     RAM usage: 88.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.4%\n",
      "2024-06-29 13:57:28,770 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:28,840 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:28,848 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687448.8478615 Robots are being programmed to perform increasingly complex tasks in various industries, from manufacturing to healthcare. How do robots learn to perform complex tasks, and what are some examples of their use in industry? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 77 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687448.8478615 Robots are being programmed to perform increasingly complex tasks in various industries, from manufacturing to healthcare. How do robots learn to perform complex tasks, and what are some examples of their use in industry? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 77\n",
      "2024-06-29 13:57:28,855 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:28,859 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:28.859898, (GMT): 2024-06-29 18:57:28.859898+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:28.859898, (GMT): 2024-06-29 18:57:28.859898+00:00\n",
      "2024-06-29 13:57:28,866 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:28,877 - micro - MainProcess - INFO     CPU usage: 77.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 77.4%\n",
      "2024-06-29 13:57:28,896 - micro - MainProcess - INFO     RAM usage: 88.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.4%\n",
      "2024-06-29 13:57:28,942 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:28,950 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:28,958 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687448.9587448 Cloud computing provides on-demand access to computing resources over the internet. How does cloud computing enhance business operations and data management? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 63 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687448.9587448 Cloud computing provides on-demand access to computing resources over the internet. How does cloud computing enhance business operations and data management? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 63\n",
      "2024-06-29 13:57:28,970 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:28,974 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:28.974179, (GMT): 2024-06-29 18:57:28.974179+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:28.974179, (GMT): 2024-06-29 18:57:28.974179+00:00\n",
      "2024-06-29 13:57:28,984 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:29,019 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.28 seconds or 4278.05 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.28 seconds or 4278.05 milliseconds.\n",
      "2024-06-29 13:57:29,102 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:29,107 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.27 seconds or 4268.19 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.27 seconds or 4268.19 milliseconds.\n",
      "2024-06-29 13:57:29,192 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:29,208 - micro - MainProcess - INFO     CPU usage: 80.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 80.3%\n",
      "2024-06-29 13:57:29,230 - micro - MainProcess - INFO     RAM usage: 88.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 88.7%\n",
      "2024-06-29 13:57:29,256 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:29,264 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:29,270 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687449.27079 Cybersecurity is crucial in protecting our personal and professional data from malicious attacks. How does cybersecurity protect our personal data, and what measures can individuals take? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687449.27079 Cybersecurity is crucial in protecting our personal and professional data from malicious attacks. How does cybersecurity protect our personal data, and what measures can individuals take? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:57:29,279 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:29,297 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:29.297305, (GMT): 2024-06-29 18:57:29.297305+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:29.297305, (GMT): 2024-06-29 18:57:29.297305+00:00\n",
      "2024-06-29 13:57:30,103 - micro - MainProcess - INFO     CPU usage: 36.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 36.2%\n",
      "2024-06-29 13:57:30,114 - micro - MainProcess - INFO     RAM usage: 87.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.6%\n",
      "2024-06-29 13:57:30,139 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:30,147 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:30,151 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687450.1519327 Urban planning involves designing and organizing urban spaces to improve the quality of life for residents. What is the role of urban planning in creating more livable and sustainable cities? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687450.1519327 Urban planning involves designing and organizing urban spaces to improve the quality of life for residents. What is the role of urban planning in creating more livable and sustainable cities? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:57:30,160 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:30,163 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:30.163343, (GMT): 2024-06-29 18:57:30.163343+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:30.163343, (GMT): 2024-06-29 18:57:30.163343+00:00\n",
      "2024-06-29 13:57:30,195 - micro - MainProcess - INFO     CPU usage: 25.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 25.4%\n",
      "2024-06-29 13:57:30,207 - micro - MainProcess - INFO     RAM usage: 87.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.8%\n",
      "2024-06-29 13:57:30,231 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:30,241 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:30,245 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687450.245661 Blockchain technology offers transparent and secure ways to track products through the supply chain. What are the key benefits of using blockchain for supply chain management? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 66 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687450.245661 Blockchain technology offers transparent and secure ways to track products through the supply chain. What are the key benefits of using blockchain for supply chain management? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 66\n",
      "2024-06-29 13:57:30,253 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:30,256 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:30.256431, (GMT): 2024-06-29 18:57:30.256431+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:30.256431, (GMT): 2024-06-29 18:57:30.256431+00:00\n",
      "2024-06-29 13:57:32,740 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:32,772 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.79 seconds or 3791.33 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.79 seconds or 3791.33 milliseconds.\n",
      "2024-06-29 13:57:32,839 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:33,830 - micro - MainProcess - INFO     CPU usage: 10.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 10.6%\n",
      "2024-06-29 13:57:33,843 - micro - MainProcess - INFO     RAM usage: 87.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.0%\n",
      "2024-06-29 13:57:33,867 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:33,872 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:33,875 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687453.8758519 Digital marketing is evolving with new trends and technologies that help businesses reach their audiences. What are some emerging trends in digital marketing that businesses should be aware of? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687453.8758519 Digital marketing is evolving with new trends and technologies that help businesses reach their audiences. What are some emerging trends in digital marketing that businesses should be aware of? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:57:33,881 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:33,886 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:33.886822, (GMT): 2024-06-29 18:57:33.886822+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:33.886822, (GMT): 2024-06-29 18:57:33.886822+00:00\n",
      "2024-06-29 13:57:33,909 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:33,950 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.69 seconds or 3689.33 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.69 seconds or 3689.33 milliseconds.\n",
      "2024-06-29 13:57:34,003 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:34,842 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:34,872 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.21 seconds or 7212.32 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.21 seconds or 7212.32 milliseconds.\n",
      "2024-06-29 13:57:34,924 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:35,014 - micro - MainProcess - INFO     CPU usage: 22.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 22.4%\n",
      "2024-06-29 13:57:35,027 - micro - MainProcess - INFO     RAM usage: 87.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.2%\n",
      "2024-06-29 13:57:35,066 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:35,091 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:35,097 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687455.0974312 Smart grids use digital technology to manage the production and distribution of electricity more efficiently. How is the development of smart grids contributing to more efficient energy distribution? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 69 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687455.0974312 Smart grids use digital technology to manage the production and distribution of electricity more efficiently. How is the development of smart grids contributing to more efficient energy distribution? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 69\n",
      "2024-06-29 13:57:35,110 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:35,115 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:35.115246, (GMT): 2024-06-29 18:57:35.115246+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:35.115246, (GMT): 2024-06-29 18:57:35.115246+00:00\n",
      "2024-06-29 13:57:35,833 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:35,863 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.47 seconds or 7474.74 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.47 seconds or 7474.74 milliseconds.\n",
      "2024-06-29 13:57:35,908 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:35,921 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:35,925 - micro - MainProcess - INFO     CPU usage: 14.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.2%\n",
      "2024-06-29 13:57:35,938 - micro - MainProcess - INFO     RAM usage: 87.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.0%\n",
      "2024-06-29 13:57:35,960 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:35,969 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:35,977 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687455.9754593 Advancements in neuroscience are providing new insights into how the brain functions and how we can treat neurological disorders. Can you describe the advancements in neuroscience that are helping us understand the brain? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 75 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687455.9754593 Advancements in neuroscience are providing new insights into how the brain functions and how we can treat neurological disorders. Can you describe the advancements in neuroscience that are helping us understand the brain? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 75\n",
      "2024-06-29 13:57:35,985 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:35,992 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:35.992499, (GMT): 2024-06-29 18:57:35.992499+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:35.992499, (GMT): 2024-06-29 18:57:35.992499+00:00\n",
      "2024-06-29 13:57:36,005 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.68 seconds or 6681.87 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.68 seconds or 6681.87 milliseconds.\n",
      "2024-06-29 13:57:36,075 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:36,924 - micro - MainProcess - INFO     CPU usage: 31.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 31.8%\n",
      "2024-06-29 13:57:36,936 - micro - MainProcess - INFO     RAM usage: 87.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.1%\n",
      "2024-06-29 13:57:36,950 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:36,958 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:36,962 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687456.9628851 Bioinformatics combines biology, computer science, and information technology to analyze biological data. Can you discuss the role of bioinformatics in modern biology and medical research? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687456.9628851 Bioinformatics combines biology, computer science, and information technology to analyze biological data. Can you discuss the role of bioinformatics in modern biology and medical research? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:57:36,971 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:36,982 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:36.982148, (GMT): 2024-06-29 18:57:36.982148+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:36.982148, (GMT): 2024-06-29 18:57:36.982148+00:00\n",
      "2024-06-29 13:57:37,089 - micro - MainProcess - INFO     CPU usage: 25.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 25.2%\n",
      "2024-06-29 13:57:37,100 - micro - MainProcess - INFO     RAM usage: 87.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.1%\n",
      "2024-06-29 13:57:37,133 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:37,141 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:37,148 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687457.14809 Renewable energy sources, such as solar and wind power, are essential in reducing our reliance on fossil fuels. What are the environmental benefits of renewable energy sources compared to fossil fuels? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687457.14809 Renewable energy sources, such as solar and wind power, are essential in reducing our reliance on fossil fuels. What are the environmental benefits of renewable energy sources compared to fossil fuels? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:57:37,152 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:37,156 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:37.156352, (GMT): 2024-06-29 18:57:37.156352+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:37.156352, (GMT): 2024-06-29 18:57:37.156352+00:00\n",
      "2024-06-29 13:57:37,281 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:37,321 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.15 seconds or 7153.55 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.15 seconds or 7153.55 milliseconds.\n",
      "2024-06-29 13:57:37,376 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:38,388 - micro - MainProcess - INFO     CPU usage: 23.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 23.4%\n",
      "2024-06-29 13:57:38,400 - micro - MainProcess - INFO     RAM usage: 87.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.4%\n",
      "2024-06-29 13:57:38,424 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:38,431 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:38,439 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687458.4399142 Autonomous drones can operate without human intervention, offering various applications in different industries. How do autonomous drones operate, and what are their potential applications? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687458.4399142 Autonomous drones can operate without human intervention, offering various applications in different industries. How do autonomous drones operate, and what are their potential applications? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:57:38,445 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:38,447 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:38.447959, (GMT): 2024-06-29 18:57:38.447959+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:38.447959, (GMT): 2024-06-29 18:57:38.447959+00:00\n",
      "2024-06-29 13:57:39,177 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:39,209 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.64 seconds or 11639.49 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.64 seconds or 11639.49 milliseconds.\n",
      "2024-06-29 13:57:39,257 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:39,262 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:39,277 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.16 seconds or 4156.42 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.16 seconds or 4156.42 milliseconds.\n",
      "2024-06-29 13:57:39,342 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:40,190 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:40,220 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.33 seconds or 6328.29 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.33 seconds or 6328.29 milliseconds.\n",
      "2024-06-29 13:57:40,267 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:40,275 - micro - MainProcess - INFO     CPU usage: 25.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 25.5%\n",
      "2024-06-29 13:57:40,288 - micro - MainProcess - INFO     RAM usage: 87.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.3%\n",
      "2024-06-29 13:57:40,309 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:40,314 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:40,320 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687460.3195121 Genetic engineering allows scientists to modify the DNA of organisms, leading to advancements in medicine and agriculture. What are the latest advancements in genetic engineering, and how might they affect healthcare? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687460.3195121 Genetic engineering allows scientists to modify the DNA of organisms, leading to advancements in medicine and agriculture. What are the latest advancements in genetic engineering, and how might they affect healthcare? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:57:40,328 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:40,331 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:40.331658, (GMT): 2024-06-29 18:57:40.331658+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:40.331658, (GMT): 2024-06-29 18:57:40.331658+00:00\n",
      "2024-06-29 13:57:40,932 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:40,959 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.8 seconds or 3798.53 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.8 seconds or 3798.53 milliseconds.\n",
      "2024-06-29 13:57:41,015 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:41,270 - micro - MainProcess - INFO     CPU usage: 21.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 21.0%\n",
      "2024-06-29 13:57:41,282 - micro - MainProcess - INFO     RAM usage: 87.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.4%\n",
      "2024-06-29 13:57:41,307 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:41,315 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:41,322 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687461.3218503 Genetic modification in crops aims to improve yield, resistance to pests, and nutritional value. Can you explain the principles of genetic modification in crops and its impact on agriculture? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687461.3218503 Genetic modification in crops aims to improve yield, resistance to pests, and nutritional value. Can you explain the principles of genetic modification in crops and its impact on agriculture? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:57:41,330 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:41,333 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:41.333588, (GMT): 2024-06-29 18:57:41.333588+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:41.333588, (GMT): 2024-06-29 18:57:41.333588+00:00\n",
      "2024-06-29 13:57:41,873 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:41,902 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 13.04 seconds or 13037.34 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 13.04 seconds or 13037.34 milliseconds.\n",
      "2024-06-29 13:57:42,452 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:42,460 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:42,470 - micro - MainProcess - INFO     CPU usage: 26.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 26.5%\n",
      "2024-06-29 13:57:42,481 - micro - MainProcess - INFO     RAM usage: 87.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.4%\n",
      "2024-06-29 13:57:42,499 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:42,508 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:42,515 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687462.5140944 Deep learning, a subset of machine learning, uses neural networks with many layers to analyze complex data. Can you describe the process of deep learning and how it differs from traditional machine learning? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 76 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687462.5140944 Deep learning, a subset of machine learning, uses neural networks with many layers to analyze complex data. Can you describe the process of deep learning and how it differs from traditional machine learning? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 76\n",
      "2024-06-29 13:57:42,537 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:42,542 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:42.542478, (GMT): 2024-06-29 18:57:42.542478+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:42.542478, (GMT): 2024-06-29 18:57:42.542478+00:00\n",
      "2024-06-29 13:57:42,548 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.55 seconds or 6549.76 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.55 seconds or 6549.76 milliseconds.\n",
      "2024-06-29 13:57:42,613 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:42,845 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:42,873 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.42 seconds or 4422.56 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.42 seconds or 4422.56 milliseconds.\n",
      "2024-06-29 13:57:42,925 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:42,990 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:43,022 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.03 seconds or 6025.29 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.03 seconds or 6025.29 milliseconds.\n",
      "2024-06-29 13:57:43,134 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:43,463 - micro - MainProcess - INFO     CPU usage: 30.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 30.3%\n",
      "2024-06-29 13:57:43,477 - micro - MainProcess - INFO     RAM usage: 87.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.3%\n",
      "2024-06-29 13:57:43,500 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:43,510 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:43,514 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687463.5148735 Sustainable development seeks to meet the needs of the present without compromising the ability of future generations to meet their own needs. What are some challenges and solutions in implementing sustainable development practices? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687463.5148735 Sustainable development seeks to meet the needs of the present without compromising the ability of future generations to meet their own needs. What are some challenges and solutions in implementing sustainable development practices? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:57:43,522 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:43,526 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:43.526510, (GMT): 2024-06-29 18:57:43.526510+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:43.526510, (GMT): 2024-06-29 18:57:43.526510+00:00\n",
      "2024-06-29 13:57:43,621 - micro - MainProcess - INFO     CPU usage: 22.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 22.3%\n",
      "2024-06-29 13:57:43,633 - micro - MainProcess - INFO     RAM usage: 87.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.4%\n",
      "2024-06-29 13:57:43,679 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:43,689 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:43,696 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687463.696268 The circular economy aims to minimize waste and make the most of resources by creating closed-loop systems. What are the benefits of a circular economy, and how does it promote sustainability? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687463.696268 The circular economy aims to minimize waste and make the most of resources by creating closed-loop systems. What are the benefits of a circular economy, and how does it promote sustainability? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:57:43,708 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:43,712 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:43.712803, (GMT): 2024-06-29 18:57:43.712803+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:43.712803, (GMT): 2024-06-29 18:57:43.712803+00:00\n",
      "2024-06-29 13:57:44,139 - micro - MainProcess - INFO     CPU usage: 27.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 27.3%\n",
      "2024-06-29 13:57:44,150 - micro - MainProcess - INFO     RAM usage: 87.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.2%\n",
      "2024-06-29 13:57:44,175 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:44,182 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:44,190 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687464.189514 Natural language processing (NLP) enables computers to understand and generate human language. How does natural language processing enable computers to understand human language? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 66 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687464.189514 Natural language processing (NLP) enables computers to understand and generate human language. How does natural language processing enable computers to understand human language? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 66\n",
      "2024-06-29 13:57:44,196 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:44,198 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:44.198582, (GMT): 2024-06-29 18:57:44.198582+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:44.198582, (GMT): 2024-06-29 18:57:44.198582+00:00\n",
      "2024-06-29 13:57:45,728 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:45,764 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.43 seconds or 4426.08 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.43 seconds or 4426.08 milliseconds.\n",
      "2024-06-29 13:57:45,819 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:45,825 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:45,852 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.51 seconds or 5512.3 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.51 seconds or 5512.3 milliseconds.\n",
      "2024-06-29 13:57:45,900 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:46,908 - micro - MainProcess - INFO     CPU usage: 14.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.7%\n",
      "2024-06-29 13:57:46,921 - micro - MainProcess - INFO     RAM usage: 87.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.1%\n",
      "2024-06-29 13:57:46,946 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:46,956 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:46,960 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687466.9603143 The Internet of Things (IoT) refers to a network of interconnected devices that communicate and share data. Can you explain the concept of the Internet of Things and provide some real-world examples? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 77 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687466.9603143 The Internet of Things (IoT) refers to a network of interconnected devices that communicate and share data. Can you explain the concept of the Internet of Things and provide some real-world examples? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 77\n",
      "2024-06-29 13:57:46,964 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:46,967 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:46.967490, (GMT): 2024-06-29 18:57:46.967490+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:46.967490, (GMT): 2024-06-29 18:57:46.967490+00:00\n",
      "2024-06-29 13:57:46,973 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:46,988 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.44 seconds or 4442.09 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.44 seconds or 4442.09 milliseconds.\n",
      "2024-06-29 13:57:47,036 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:48,047 - micro - MainProcess - INFO     CPU usage: 17.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 17.9%\n",
      "2024-06-29 13:57:48,058 - micro - MainProcess - INFO     RAM usage: 87.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.3%\n",
      "2024-06-29 13:57:48,074 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:48,080 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:48,087 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687468.0869527 The rollout of 5G technology promises faster internet speeds and more reliable connections. What are some potential applications of 5G technology in everyday life? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 69 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687468.0869527 The rollout of 5G technology promises faster internet speeds and more reliable connections. What are some potential applications of 5G technology in everyday life? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 69\n",
      "2024-06-29 13:57:48,093 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:48,097 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:48.097473, (GMT): 2024-06-29 18:57:48.097473+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:57:48.097473, (GMT): 2024-06-29 18:57:48.097473+00:00\n",
      "2024-06-29 13:57:54,150 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:54,181 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.08 seconds or 6078.04 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.08 seconds or 6078.04 milliseconds.\n",
      "2024-06-29 13:57:54,230 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:54,797 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:54,830 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.86 seconds or 7858.74 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.86 seconds or 7858.74 milliseconds.\n",
      "2024-06-29 13:57:54,885 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:55,612 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:55,648 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 12.12 seconds or 12115.81 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 12.12 seconds or 12115.81 milliseconds.\n",
      "2024-06-29 13:57:55,703 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:55,740 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:55,772 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 12.04 seconds or 12044.09 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 12.04 seconds or 12044.09 milliseconds.\n",
      "2024-06-29 13:57:55,823 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:55,901 - micro - MainProcess - INFO     CPU usage: 19.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.3%\n",
      "2024-06-29 13:57:55,914 - micro - MainProcess - INFO     RAM usage: 87.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 87.0%\n",
      "2024-06-29 13:57:55,949 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:55,957 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:55,964 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687475.9638386 Cybersecurity is crucial in protecting our personal and professional data from malicious attacks. How does cybersecurity protect our personal data, and what measures can individuals take? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 69 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687475.9638386 Cybersecurity is crucial in protecting our personal and professional data from malicious attacks. How does cybersecurity protect our personal data, and what measures can individuals take? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 69\n",
      "2024-06-29 13:57:55,972 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:55,976 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:55.976167, (GMT): 2024-06-29 18:57:55.976167+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:55.976167, (GMT): 2024-06-29 18:57:55.976167+00:00\n",
      "2024-06-29 13:57:56,210 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:57:56,243 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 12.04 seconds or 12039.3 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 12.04 seconds or 12039.3 milliseconds.\n",
      "2024-06-29 13:57:56,356 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:57:56,717 - micro - MainProcess - INFO     CPU usage: 57.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 57.2%\n",
      "2024-06-29 13:57:56,735 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-06-29 13:57:56,757 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:56,762 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:56,768 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687476.7688947 Social media trends influence consumer behavior and marketing strategies, shaping how brands interact with their audiences. Can you discuss the impact of social media trends on consumer behavior and marketing? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687476.7688947 Social media trends influence consumer behavior and marketing strategies, shaping how brands interact with their audiences. Can you discuss the impact of social media trends on consumer behavior and marketing? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:57:56,775 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:56,779 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:56.779440, (GMT): 2024-06-29 18:57:56.779440+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:56.779440, (GMT): 2024-06-29 18:57:56.779440+00:00\n",
      "2024-06-29 13:57:56,825 - micro - MainProcess - INFO     CPU usage: 21.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 21.2%\n",
      "2024-06-29 13:57:56,839 - micro - MainProcess - INFO     RAM usage: 86.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.8%\n",
      "2024-06-29 13:57:56,860 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:56,867 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:56,873 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687476.8734229 Agritech innovations are improving agricultural productivity and sustainability through the use of technology. How are advancements in agritech improving food production and sustainability? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 66 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687476.8734229 Agritech innovations are improving agricultural productivity and sustainability through the use of technology. How are advancements in agritech improving food production and sustainability? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 66\n",
      "2024-06-29 13:57:56,878 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:56,884 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:56.882994, (GMT): 2024-06-29 18:57:56.884021+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:56.882994, (GMT): 2024-06-29 18:57:56.884021+00:00\n",
      "2024-06-29 13:57:57,378 - micro - MainProcess - INFO     CPU usage: 25.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 25.5%\n",
      "2024-06-29 13:57:57,389 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-06-29 13:57:57,412 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:57:57,419 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:57,423 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687477.423755 Drones are being used in various industries, from agriculture to logistics, due to their versatility. What are the potential uses of drones in agriculture and other industries? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687477.423755 Drones are being used in various industries, from agriculture to logistics, due to their versatility. What are the potential uses of drones in agriculture and other industries? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:57:57,429 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:57:57,436 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:57.436921, (GMT): 2024-06-29 18:57:57.436921+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:57:57.436921, (GMT): 2024-06-29 18:57:57.436921+00:00\n",
      "2024-06-29 13:58:07,556 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:07,583 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.6 seconds or 11602.13 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.6 seconds or 11602.13 milliseconds.\n",
      "2024-06-29 13:58:07,640 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:58:08,245 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:08,272 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.49 seconds or 11490.57 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.49 seconds or 11490.57 milliseconds.\n",
      "2024-06-29 13:58:08,336 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:58:08,341 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:08,346 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.46 seconds or 11456.32 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.46 seconds or 11456.32 milliseconds.\n",
      "2024-06-29 13:58:08,465 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:58:08,645 - micro - MainProcess - INFO     CPU usage: 11.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 11.3%\n",
      "2024-06-29 13:58:08,656 - micro - MainProcess - INFO     RAM usage: 86.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.8%\n",
      "2024-06-29 13:58:08,673 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:58:08,679 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:08,685 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687488.6852221 Renewable energy sources, such as solar and wind power, are essential in reducing our reliance on fossil fuels. What are the environmental benefits of renewable energy sources compared to fossil fuels? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687488.6852221 Renewable energy sources, such as solar and wind power, are essential in reducing our reliance on fossil fuels. What are the environmental benefits of renewable energy sources compared to fossil fuels? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:58:08,690 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:08,695 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:08.695077, (GMT): 2024-06-29 18:58:08.695077+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:08.695077, (GMT): 2024-06-29 18:58:08.695077+00:00\n",
      "2024-06-29 13:58:08,803 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:08,849 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.4 seconds or 11404.52 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.4 seconds or 11404.52 milliseconds.\n",
      "2024-06-29 13:58:08,912 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:58:09,338 - micro - MainProcess - INFO     CPU usage: 31.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 31.0%\n",
      "2024-06-29 13:58:09,347 - micro - MainProcess - INFO     RAM usage: 86.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.8%\n",
      "2024-06-29 13:58:09,366 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:58:09,375 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:09,379 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687489.3794446 Artificial intelligence (AI) is being used to improve the accuracy and efficiency of medical diagnoses. How is artificial intelligence being used to improve the accuracy of medical diagnoses? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687489.3794446 Artificial intelligence (AI) is being used to improve the accuracy and efficiency of medical diagnoses. How is artificial intelligence being used to improve the accuracy of medical diagnoses? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:58:09,385 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:09,390 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:09.390712, (GMT): 2024-06-29 18:58:09.390712+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:09.390712, (GMT): 2024-06-29 18:58:09.390712+00:00\n",
      "2024-06-29 13:58:09,461 - micro - MainProcess - INFO     CPU usage: 17.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 17.7%\n",
      "2024-06-29 13:58:09,474 - micro - MainProcess - INFO     RAM usage: 86.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.9%\n",
      "2024-06-29 13:58:09,510 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:58:09,561 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:09,570 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687489.5703564 Urban planning involves designing and organizing urban spaces to improve the quality of life for residents. What is the role of urban planning in creating more livable and sustainable cities? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687489.5703564 Urban planning involves designing and organizing urban spaces to improve the quality of life for residents. What is the role of urban planning in creating more livable and sustainable cities? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:58:09,580 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:09,596 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:09.596868, (GMT): 2024-06-29 18:58:09.596868+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:09.596868, (GMT): 2024-06-29 18:58:09.596868+00:00\n",
      "2024-06-29 13:58:09,910 - micro - MainProcess - INFO     CPU usage: 40.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 40.1%\n",
      "2024-06-29 13:58:09,921 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-06-29 13:58:09,943 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:58:09,953 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:09,958 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687489.9575243 Cloud computing provides on-demand access to computing resources over the internet. How does cloud computing enhance business operations and data management? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 63 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687489.9575243 Cloud computing provides on-demand access to computing resources over the internet. How does cloud computing enhance business operations and data management? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 63\n",
      "2024-06-29 13:58:09,964 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:09,971 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:09.971243, (GMT): 2024-06-29 18:58:09.971243+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:09.971243, (GMT): 2024-06-29 18:58:09.971243+00:00\n",
      "2024-06-29 13:58:22,039 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:22,072 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 13.37 seconds or 13374.22 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 13.37 seconds or 13374.22 milliseconds.\n",
      "2024-06-29 13:58:22,144 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:58:22,916 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:22,953 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 13.56 seconds or 13559.14 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 13.56 seconds or 13559.14 milliseconds.\n",
      "2024-06-29 13:58:23,013 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:58:23,018 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:23,022 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 13.42 seconds or 13418.47 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 13.42 seconds or 13418.47 milliseconds.\n",
      "2024-06-29 13:58:23,071 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:58:23,160 - micro - MainProcess - INFO     CPU usage: 9.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 9.9%\n",
      "2024-06-29 13:58:23,172 - micro - MainProcess - INFO     RAM usage: 86.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.9%\n",
      "2024-06-29 13:58:23,296 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:58:23,303 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:23,309 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687503.3095202 Deep learning, a subset of machine learning, uses neural networks with many layers to analyze complex data. Can you describe the process of deep learning and how it differs from traditional machine learning? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 76 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687503.3095202 Deep learning, a subset of machine learning, uses neural networks with many layers to analyze complex data. Can you describe the process of deep learning and how it differs from traditional machine learning? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 76\n",
      "2024-06-29 13:58:23,316 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:23,319 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:23.319830, (GMT): 2024-06-29 18:58:23.319830+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:23.319830, (GMT): 2024-06-29 18:58:23.319830+00:00\n",
      "2024-06-29 13:58:23,362 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:23,385 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 13.41 seconds or 13408.74 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 13.41 seconds or 13408.74 milliseconds.\n",
      "2024-06-29 13:58:23,434 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:58:24,026 - micro - MainProcess - INFO     CPU usage: 28.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 28.9%\n",
      "2024-06-29 13:58:24,037 - micro - MainProcess - INFO     RAM usage: 86.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.8%\n",
      "2024-06-29 13:58:24,059 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:58:24,068 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:24,072 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687504.072978 Blockchain technology offers transparent and secure ways to track products through the supply chain. What are the key benefits of using blockchain for supply chain management? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 66 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687504.072978 Blockchain technology offers transparent and secure ways to track products through the supply chain. What are the key benefits of using blockchain for supply chain management? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 66\n",
      "2024-06-29 13:58:24,080 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:24,083 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:24.082023, (GMT): 2024-06-29 18:58:24.082023+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:24.082023, (GMT): 2024-06-29 18:58:24.082023+00:00\n",
      "2024-06-29 13:58:24,089 - micro - MainProcess - INFO     CPU usage: 14.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.0%\n",
      "2024-06-29 13:58:24,099 - micro - MainProcess - INFO     RAM usage: 86.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.9%\n",
      "2024-06-29 13:58:24,206 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:58:24,215 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:24,220 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687504.2206545 Autonomous drones can operate without human intervention, offering various applications in different industries. How do autonomous drones operate, and what are their potential applications? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687504.2206545 Autonomous drones can operate without human intervention, offering various applications in different industries. How do autonomous drones operate, and what are their potential applications? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:58:24,229 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:24,237 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:24.237005, (GMT): 2024-06-29 18:58:24.237005+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:24.237005, (GMT): 2024-06-29 18:58:24.237005+00:00\n",
      "2024-06-29 13:58:24,427 - micro - MainProcess - INFO     CPU usage: 43.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 43.4%\n",
      "2024-06-29 13:58:24,439 - micro - MainProcess - INFO     RAM usage: 86.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.9%\n",
      "2024-06-29 13:58:24,459 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:58:24,467 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:24,472 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687504.4727566 Digital marketing is evolving with new trends and technologies that help businesses reach their audiences. What are some emerging trends in digital marketing that businesses should be aware of? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687504.4727566 Digital marketing is evolving with new trends and technologies that help businesses reach their audiences. What are some emerging trends in digital marketing that businesses should be aware of? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:58:24,478 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:24,480 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:24.480079, (GMT): 2024-06-29 18:58:24.480079+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:24.480079, (GMT): 2024-06-29 18:58:24.480079+00:00\n",
      "2024-06-29 13:58:33,478 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:33,513 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.27 seconds or 9270.91 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.27 seconds or 9270.91 milliseconds.\n",
      "2024-06-29 13:58:33,581 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:58:35,236 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:35,241 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.92 seconds or 11916.78 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.92 seconds or 11916.78 milliseconds.\n",
      "2024-06-29 13:58:35,289 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:58:36,091 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:36,123 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 12.03 seconds or 12034.42 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 12.03 seconds or 12034.42 milliseconds.\n",
      "2024-06-29 13:58:36,172 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:58:36,293 - micro - MainProcess - INFO     CPU usage: 11.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 11.0%\n",
      "2024-06-29 13:58:36,303 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 13:58:36,398 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:58:36,403 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:36,410 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687516.4088373 The rollout of 5G technology promises faster internet speeds and more reliable connections. What are some potential applications of 5G technology in everyday life? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 69 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687516.4088373 The rollout of 5G technology promises faster internet speeds and more reliable connections. What are some potential applications of 5G technology in everyday life? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 69\n",
      "2024-06-29 13:58:36,418 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:36,423 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:36.423471, (GMT): 2024-06-29 18:58:36.423471+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:36.423471, (GMT): 2024-06-29 18:58:36.423471+00:00\n",
      "2024-06-29 13:58:36,430 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:36,438 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.95 seconds or 11951.1 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.95 seconds or 11951.1 milliseconds.\n",
      "2024-06-29 13:58:36,679 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:58:37,188 - micro - MainProcess - INFO     CPU usage: 29.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 29.4%\n",
      "2024-06-29 13:58:37,198 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-06-29 13:58:37,280 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:58:37,286 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:37,292 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687517.2909925 Smart grids use digital technology to manage the production and distribution of electricity more efficiently. How is the development of smart grids contributing to more efficient energy distribution? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 69 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687517.2909925 Smart grids use digital technology to manage the production and distribution of electricity more efficiently. How is the development of smart grids contributing to more efficient energy distribution? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 69\n",
      "2024-06-29 13:58:37,365 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:37,380 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:37.380232, (GMT): 2024-06-29 18:58:37.380232+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:37.380232, (GMT): 2024-06-29 18:58:37.380232+00:00\n",
      "2024-06-29 13:58:37,681 - micro - MainProcess - INFO     CPU usage: 30.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 30.1%\n",
      "2024-06-29 13:58:37,691 - micro - MainProcess - INFO     RAM usage: 86.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.6%\n",
      "2024-06-29 13:58:37,713 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:58:37,719 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:37,724 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687517.7241652 Genetic modification in crops aims to improve yield, resistance to pests, and nutritional value. Can you explain the principles of genetic modification in crops and its impact on agriculture? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719687517.7241652 Genetic modification in crops aims to improve yield, resistance to pests, and nutritional value. Can you explain the principles of genetic modification in crops and its impact on agriculture? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:58:37,729 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:76)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:58:37,732 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:37.732166, (GMT): 2024-06-29 18:58:37.732166+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:58:37.732166, (GMT): 2024-06-29 18:58:37.732166+00:00\n",
      "2024-06-29 13:58:43,236 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:43,264 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.53 seconds or 5525.55 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.53 seconds or 5525.55 milliseconds.\n",
      "2024-06-29 13:58:43,348 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:58:46,806 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:46,839 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 10.41 seconds or 10410.86 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 10.41 seconds or 10410.86 milliseconds.\n",
      "2024-06-29 13:58:46,892 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:58:47,317 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:58:47,350 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.96 seconds or 9957.48 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.96 seconds or 9957.48 milliseconds.\n",
      "2024-06-29 13:58:47,415 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n"
     ]
    }
   ],
   "source": [
    "await benchmark_streaming.run_latency_benchmark_bulk(deployment_names=[DEPLOYMENT_ID], max_tokens_list=[500,250], byop=prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_region_from_endpoint(endpoint):\n",
    "    \"\"\"\n",
    "    Extracts the region from an OpenAI endpoint URL, where the region is the part immediately preceding '.openai'.\n",
    "\n",
    "    :param endpoint: The OpenAI endpoint URL as a string.\n",
    "    :return: The region as a string. Returns 'Invalid endpoint format.' if the region cannot be extracted.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Split the endpoint by '.openai' to isolate the part containing the region\n",
    "        before_openai, _ = endpoint.split('.openai', 1)\n",
    "        # Extract the region by taking the last segment after splitting by '.' or '/'\n",
    "        region = before_openai.split('.')[-1] if '.' in before_openai else before_openai.split('/')[-1]\n",
    "        return region\n",
    "    except ValueError:\n",
    "        # If '.openai' is not found in the endpoint, or other parsing errors occur\n",
    "        return \"Invalid endpoint format.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev-aoai-aoai2-eastus2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "endpoint = \"https://dev-aoai-aoai2-eastus2.openai.azure.com/\"\n",
    "print(extract_region_from_endpoint(endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 14:00:12,139 - micro - MainProcess - INFO     Calculating statistics for data: [6.91, 7.75, 7.57, 7.67, 3.23, 3.54, 3.44, 3.6, 4.55, 4.89, 4.73, 5.13, 3.28, 3.27, 3.67, 4.42, 3.4, 3.2, 3.21, 5.29, 3.73, 3.78, 3.76, 3.39, 3.32, 3.7, 3.87, 5.74, 3.87, 3.0, 3.94, 4.7, 4.52, 4.56, 4.5, 4.32, 4.58, 4.28, 4.27, 3.79, 3.69, 6.68, 7.15, 4.16, 6.33, 3.8, 4.42, 4.43, 4.44, 6.08] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [6.91, 7.75, 7.57, 7.67, 3.23, 3.54, 3.44, 3.6, 4.55, 4.89, 4.73, 5.13, 3.28, 3.27, 3.67, 4.42, 3.4, 3.2, 3.21, 5.29, 3.73, 3.78, 3.76, 3.39, 3.32, 3.7, 3.87, 5.74, 3.87, 3.0, 3.94, 4.7, 4.52, 4.56, 4.5, 4.32, 4.58, 4.28, 4.27, 3.79, 3.69, 6.68, 7.15, 4.16, 6.33, 3.8, 4.42, 4.43, 4.44, 6.08]\n",
      "2024-06-29 14:00:12,144 - micro - MainProcess - INFO     Data converted to numpy array: [6.91 7.75 7.57 7.67 3.23 3.54 3.44 3.6  4.55 4.89 4.73 5.13 3.28 3.27\n",
      " 3.67 4.42 3.4  3.2  3.21 5.29 3.73 3.78 3.76 3.39 3.32 3.7  3.87 5.74\n",
      " 3.87 3.   3.94 4.7  4.52 4.56 4.5  4.32 4.58 4.28 4.27 3.79 3.69 6.68\n",
      " 7.15 4.16 6.33 3.8  4.42 4.43 4.44 6.08] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [6.91 7.75 7.57 7.67 3.23 3.54 3.44 3.6  4.55 4.89 4.73 5.13 3.28 3.27\n",
      " 3.67 4.42 3.4  3.2  3.21 5.29 3.73 3.78 3.76 3.39 3.32 3.7  3.87 5.74\n",
      " 3.87 3.   3.94 4.7  4.52 4.56 4.5  4.32 4.58 4.28 4.27 3.79 3.69 6.68\n",
      " 7.15 4.16 6.33 3.8  4.42 4.43 4.44 6.08]\n",
      "2024-06-29 14:00:12,147 - micro - MainProcess - INFO     Calculated median: 4.28 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 4.28\n",
      "2024-06-29 14:00:12,153 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 1.05 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 1.05\n",
      "2024-06-29 14:00:12,156 - micro - MainProcess - INFO     Calculated 95th percentile: 7.38 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 7.38\n",
      "2024-06-29 14:00:12,159 - micro - MainProcess - INFO     Calculated 99th percentile: 7.71 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 7.71\n",
      "2024-06-29 14:00:12,165 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.28 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.28\n",
      "2024-06-29 14:00:12,168 - micro - MainProcess - INFO     Result: (4.28, 1.05, 7.38, 7.71, 0.28) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (4.28, 1.05, 7.38, 7.71, 0.28)\n",
      "2024-06-29 14:00:12,170 - micro - MainProcess - INFO     Calculating statistics for data: [251, 250, 255, 251, 252, 249, 252, 251, 250, 254, 249, 251, 253, 245, 250, 249, 247, 252, 252, 250, 254, 253, 253, 250, 250, 250, 248, 251, 252, 252, 250, 255, 253, 250, 252, 253, 248, 253, 253, 255, 249, 254, 254, 256, 251, 254, 254, 247, 247, 248] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [251, 250, 255, 251, 252, 249, 252, 251, 250, 254, 249, 251, 253, 245, 250, 249, 247, 252, 252, 250, 254, 253, 253, 250, 250, 250, 248, 251, 252, 252, 250, 255, 253, 250, 252, 253, 248, 253, 253, 255, 249, 254, 254, 256, 251, 254, 254, 247, 247, 248]\n",
      "2024-06-29 14:00:12,173 - micro - MainProcess - INFO     Data converted to numpy array: [251 250 255 251 252 249 252 251 250 254 249 251 253 245 250 249 247 252\n",
      " 252 250 254 253 253 250 250 250 248 251 252 252 250 255 253 250 252 253\n",
      " 248 253 253 255 249 254 254 256 251 254 254 247 247 248] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [251 250 255 251 252 249 252 251 250 254 249 251 253 245 250 249 247 252\n",
      " 252 250 254 253 253 250 250 250 248 251 252 252 250 255 253 250 252 253\n",
      " 248 253 253 255 249 254 254 256 251 254 254 247 247 248]\n",
      "2024-06-29 14:00:12,177 - micro - MainProcess - INFO     Calculated median: 251.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 251.0\n",
      "2024-06-29 14:00:12,180 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 3.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 3.0\n",
      "2024-06-29 14:00:12,183 - micro - MainProcess - INFO     Calculated 95th percentile: 255.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 255.0\n",
      "2024-06-29 14:00:12,186 - micro - MainProcess - INFO     Calculated 99th percentile: 255.51 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 255.51\n",
      "2024-06-29 14:00:12,189 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.01 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.01\n",
      "2024-06-29 14:00:12,192 - micro - MainProcess - INFO     Result: (251.0, 3.0, 255.0, 255.51, 0.01) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (251.0, 3.0, 255.0, 255.51, 0.01)\n",
      "2024-06-29 14:00:12,195 - micro - MainProcess - INFO     Calculating statistics for data: [74, 77, 67, 68, 78, 72, 73, 66, 64, 71, 72, 79, 68, 74, 74, 62, 70, 72, 74, 66, 67, 74, 68, 74, 71, 76, 72, 73, 70, 74, 74, 74, 67, 73, 72, 71, 77, 66, 71, 63, 66, 68, 72, 69, 70, 73, 67, 72, 76, 69] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [74, 77, 67, 68, 78, 72, 73, 66, 64, 71, 72, 79, 68, 74, 74, 62, 70, 72, 74, 66, 67, 74, 68, 74, 71, 76, 72, 73, 70, 74, 74, 74, 67, 73, 72, 71, 77, 66, 71, 63, 66, 68, 72, 69, 70, 73, 67, 72, 76, 69]\n",
      "2024-06-29 14:00:12,198 - micro - MainProcess - INFO     Data converted to numpy array: [74 77 67 68 78 72 73 66 64 71 72 79 68 74 74 62 70 72 74 66 67 74 68 74\n",
      " 71 76 72 73 70 74 74 74 67 73 72 71 77 66 71 63 66 68 72 69 70 73 67 72\n",
      " 76 69] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [74 77 67 68 78 72 73 66 64 71 72 79 68 74 74 62 70 72 74 66 67 74 68 74\n",
      " 71 76 72 73 70 74 74 74 67 73 72 71 77 66 71 63 66 68 72 69 70 73 67 72\n",
      " 76 69]\n",
      "2024-06-29 14:00:12,202 - micro - MainProcess - INFO     Calculated median: 72.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 72.0\n",
      "2024-06-29 14:00:12,205 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 6.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 6.0\n",
      "2024-06-29 14:00:12,208 - micro - MainProcess - INFO     Calculated 95th percentile: 77.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 77.0\n",
      "2024-06-29 14:00:12,213 - micro - MainProcess - INFO     Calculated 99th percentile: 78.51 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 78.51\n",
      "2024-06-29 14:00:12,222 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.05 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.05\n",
      "2024-06-29 14:00:12,225 - micro - MainProcess - INFO     Result: (72.0, 6.0, 77.0, 78.51, 0.05) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (72.0, 6.0, 77.0, 78.51, 0.05)\n",
      "2024-06-29 14:00:12,228 - micro - MainProcess - INFO     Calculating statistics for data: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.43, 1, 1, 1, 1, 1, 1, 1, 1, 45.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 289.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 208.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 410.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 455.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 65.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 386.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 864.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 203.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 188.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 278.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 366.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 187.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 198.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 215.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 170.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 197.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 484.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 117.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 63.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 514.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 27.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 229.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 452.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 204.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 156.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 145.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1185.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 145.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 441.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 119.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 414.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 244.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 192.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 245.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 197.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.86, 1, 1, 1, 1, 1, 1, 1, 1, 242.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 557.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 79.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 208.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 272.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 224.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 727.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.1, 1, 1, 1, 1, 1, 1, 1, 432.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.24, 1, 1, 1, 1, 1, 380.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 515.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 36.07, 1, 1, 1, 1, 1, 264.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 289.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 300.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 203.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 300.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 54.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 244.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 206.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 160.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.04, 1, 1, 1, 1, 238.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 254.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 231.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 459.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 525.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 549.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 492.99, 2.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 700.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 550.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 423.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 393.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 380.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 198.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 428.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 516.01, 1, 1, 1, 31.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 425.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 69.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 386.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 393.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 164.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 221.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 274.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 158.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 55.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 182.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 213.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 454.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.39, 1, 1, 1, 1, 279.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 196.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 412.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 184.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 459.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 489.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 512.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 814.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 722.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 587.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 472.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 533.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 448.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 37.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 232.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 218.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 201.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 157.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 107.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 474.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 366.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 407.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 70.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 428.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 452.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.06, 1, 1, 1, 1, 1, 1, 318.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.21, 1, 1, 1, 1, 1, 1, 349.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 226.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 413.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 400.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 444.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 453.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 465.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 412.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 457.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.45, 1, 1, 1, 1, 1, 1, 372.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 429.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 436.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 455.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 418.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 462.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 595.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 418.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 410.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 458.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 203.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 441.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 414.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 454.62, 1, 1.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 452.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 562.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 411.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 449.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 220.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 539.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 87.38, 1, 235.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 479.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 21.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 468.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 110.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 274.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 258.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 70.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 481.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 196.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1658.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 584.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 537.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 507.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 623.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 583.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 602.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 939.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 601.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 607.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 594.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 539.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 635.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 622.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 546.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 525.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 97.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 242.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 473.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 550.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 456.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 87.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 634.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 528.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.56, 586.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 596.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 656.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 611.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 624.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 54.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 528.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 524.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 400.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 380.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 190.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 677.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 923.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 186.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 146.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 437.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 436.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 458.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 595.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 471.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 35.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 55.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 457.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 658.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 692.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 605.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 749.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 429.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 499.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 488.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.43, 1, 1, 1, 1, 1, 1, 1, 1, 45.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 289.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 208.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 410.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 455.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 65.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 386.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 864.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 203.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 188.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 278.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 366.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 187.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 198.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 215.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 170.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 197.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 484.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 117.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 63.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 514.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 27.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 229.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 452.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 204.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 156.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 145.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1185.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 145.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 441.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 119.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 414.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 244.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 192.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 245.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 197.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.86, 1, 1, 1, 1, 1, 1, 1, 1, 242.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 557.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 79.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 208.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 272.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 224.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 727.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.1, 1, 1, 1, 1, 1, 1, 1, 432.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.24, 1, 1, 1, 1, 1, 380.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 515.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 36.07, 1, 1, 1, 1, 1, 264.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 289.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 300.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 203.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 300.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 54.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 244.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 206.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 160.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.04, 1, 1, 1, 1, 238.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 254.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 231.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 459.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 525.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 549.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 492.99, 2.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 700.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 550.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 423.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 393.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 380.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 198.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 428.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 516.01, 1, 1, 1, 31.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 425.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 69.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 386.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 393.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 164.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 221.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 274.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 158.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 55.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 182.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 213.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 454.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.39, 1, 1, 1, 1, 279.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 196.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 412.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 184.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 459.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 489.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 512.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 814.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 722.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 587.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 472.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 533.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 448.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 37.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 232.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 218.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 201.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 157.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 107.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 474.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 366.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 407.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 70.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 428.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 452.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.06, 1, 1, 1, 1, 1, 1, 318.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.21, 1, 1, 1, 1, 1, 1, 349.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 226.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 413.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 400.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 444.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 453.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 465.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 412.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 457.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.45, 1, 1, 1, 1, 1, 1, 372.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 429.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 436.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 455.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 418.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 462.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 595.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 418.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 410.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 458.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 203.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 441.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 414.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 454.62, 1, 1.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 452.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 562.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 411.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 449.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 220.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 539.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 87.38, 1, 235.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 479.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 21.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 468.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 110.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 274.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 258.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 70.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 481.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 196.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1658.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 584.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 537.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 507.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 623.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 583.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 602.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 939.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 601.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 607.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 594.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 539.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 635.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 622.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 546.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 525.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 97.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 242.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 473.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 550.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 456.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 87.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 634.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 528.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.56, 586.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 596.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 656.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 611.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 624.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 54.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 528.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 524.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 400.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 380.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 190.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 677.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 923.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 186.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 146.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 437.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 436.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 458.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 595.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 471.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 35.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 55.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 457.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 658.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 692.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 605.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 749.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 429.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 499.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 488.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "2024-06-29 14:00:12,237 - micro - MainProcess - INFO     Data converted to numpy array: [1. 1. 1. ... 1. 1. 1.] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [1. 1. 1. ... 1. 1. 1.]\n",
      "2024-06-29 14:00:12,240 - micro - MainProcess - INFO     Calculated median: 1.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 1.0\n",
      "2024-06-29 14:00:12,245 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-29 14:00:12,249 - micro - MainProcess - INFO     Calculated 95th percentile: 1.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 1.0\n",
      "2024-06-29 14:00:12,253 - micro - MainProcess - INFO     Calculated 99th percentile: 403.5 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 403.5\n",
      "2024-06-29 14:00:12,258 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 5.16 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 5.16\n",
      "2024-06-29 14:00:12,260 - micro - MainProcess - INFO     Result: (1.0, 0.0, 1.0, 403.5, 5.16) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (1.0, 0.0, 1.0, 403.5, 5.16)\n",
      "2024-06-29 14:00:12,263 - micro - MainProcess - INFO     Calculating statistics for data: [3.98, 4.08, 3.89, 3.96, 0.84, 0.78, 0.73, 0.81, 0.74, 1.78, 1.53, 1.89, 0.76, 0.86, 0.94, 0.98, 0.75, 0.58, 0.64, 0.89, 0.58, 0.72, 0.79, 0.64, 0.63, 0.77, 0.83, 0.82, 0.66, 0.56, 0.65, 1.3, 1.1, 0.87, 0.73, 0.93, 1.04, 0.77, 0.71, 0.99, 0.68, 0.85, 1.4, 0.63, 0.94, 0.68, 1.0, 1.96, 0.92, 1.03] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [3.98, 4.08, 3.89, 3.96, 0.84, 0.78, 0.73, 0.81, 0.74, 1.78, 1.53, 1.89, 0.76, 0.86, 0.94, 0.98, 0.75, 0.58, 0.64, 0.89, 0.58, 0.72, 0.79, 0.64, 0.63, 0.77, 0.83, 0.82, 0.66, 0.56, 0.65, 1.3, 1.1, 0.87, 0.73, 0.93, 1.04, 0.77, 0.71, 0.99, 0.68, 0.85, 1.4, 0.63, 0.94, 0.68, 1.0, 1.96, 0.92, 1.03]\n",
      "2024-06-29 14:00:12,268 - micro - MainProcess - INFO     Data converted to numpy array: [3.98 4.08 3.89 3.96 0.84 0.78 0.73 0.81 0.74 1.78 1.53 1.89 0.76 0.86\n",
      " 0.94 0.98 0.75 0.58 0.64 0.89 0.58 0.72 0.79 0.64 0.63 0.77 0.83 0.82\n",
      " 0.66 0.56 0.65 1.3  1.1  0.87 0.73 0.93 1.04 0.77 0.71 0.99 0.68 0.85\n",
      " 1.4  0.63 0.94 0.68 1.   1.96 0.92 1.03] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [3.98 4.08 3.89 3.96 0.84 0.78 0.73 0.81 0.74 1.78 1.53 1.89 0.76 0.86\n",
      " 0.94 0.98 0.75 0.58 0.64 0.89 0.58 0.72 0.79 0.64 0.63 0.77 0.83 0.82\n",
      " 0.66 0.56 0.65 1.3  1.1  0.87 0.73 0.93 1.04 0.77 0.71 0.99 0.68 0.85\n",
      " 1.4  0.63 0.94 0.68 1.   1.96 0.92 1.03]\n",
      "2024-06-29 14:00:12,273 - micro - MainProcess - INFO     Calculated median: 0.84 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.84\n",
      "2024-06-29 14:00:12,276 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.3 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.3\n",
      "2024-06-29 14:00:12,280 - micro - MainProcess - INFO     Calculated 95th percentile: 3.93 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 3.93\n",
      "2024-06-29 14:00:12,284 - micro - MainProcess - INFO     Calculated 99th percentile: 4.03 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 4.03\n",
      "2024-06-29 14:00:12,288 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.77 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.77\n",
      "2024-06-29 14:00:12,291 - micro - MainProcess - INFO     Result: (0.84, 0.3, 3.93, 4.03, 0.77) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.84, 0.3, 3.93, 4.03, 0.77)\n",
      "2024-06-29 14:00:12,295 - micro - MainProcess - INFO     Calculating statistics for data: [10.69, 10.1, 10.24, 10.42, 6.74, 7.37, 7.58, 7.63, 5.91, 5.6, 5.82, 6.52, 6.55, 6.72, 6.65, 6.71, 7.47, 6.52, 7.6, 7.47, 8.82, 8.62, 8.44, 8.59, 7.21, 7.47, 11.64, 13.04, 6.55, 6.03, 5.51, 7.86, 12.12, 12.04, 12.04, 11.6, 11.49, 11.46, 11.4, 13.37, 13.56, 13.42, 13.41, 9.27, 11.92, 12.03, 11.95, 5.53, 10.41, 9.96] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [10.69, 10.1, 10.24, 10.42, 6.74, 7.37, 7.58, 7.63, 5.91, 5.6, 5.82, 6.52, 6.55, 6.72, 6.65, 6.71, 7.47, 6.52, 7.6, 7.47, 8.82, 8.62, 8.44, 8.59, 7.21, 7.47, 11.64, 13.04, 6.55, 6.03, 5.51, 7.86, 12.12, 12.04, 12.04, 11.6, 11.49, 11.46, 11.4, 13.37, 13.56, 13.42, 13.41, 9.27, 11.92, 12.03, 11.95, 5.53, 10.41, 9.96]\n",
      "2024-06-29 14:00:12,299 - micro - MainProcess - INFO     Data converted to numpy array: [10.69 10.1  10.24 10.42  6.74  7.37  7.58  7.63  5.91  5.6   5.82  6.52\n",
      "  6.55  6.72  6.65  6.71  7.47  6.52  7.6   7.47  8.82  8.62  8.44  8.59\n",
      "  7.21  7.47 11.64 13.04  6.55  6.03  5.51  7.86 12.12 12.04 12.04 11.6\n",
      " 11.49 11.46 11.4  13.37 13.56 13.42 13.41  9.27 11.92 12.03 11.95  5.53\n",
      " 10.41  9.96] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [10.69 10.1  10.24 10.42  6.74  7.37  7.58  7.63  5.91  5.6   5.82  6.52\n",
      "  6.55  6.72  6.65  6.71  7.47  6.52  7.6   7.47  8.82  8.62  8.44  8.59\n",
      "  7.21  7.47 11.64 13.04  6.55  6.03  5.51  7.86 12.12 12.04 12.04 11.6\n",
      " 11.49 11.46 11.4  13.37 13.56 13.42 13.41  9.27 11.92 12.03 11.95  5.53\n",
      " 10.41  9.96]\n",
      "2024-06-29 14:00:12,302 - micro - MainProcess - INFO     Calculated median: 8.6 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 8.6\n",
      "2024-06-29 14:00:12,306 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 4.85 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 4.85\n",
      "2024-06-29 14:00:12,309 - micro - MainProcess - INFO     Calculated 95th percentile: 13.39 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 13.39\n",
      "2024-06-29 14:00:12,313 - micro - MainProcess - INFO     Calculated 99th percentile: 13.49 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 13.49\n",
      "2024-06-29 14:00:12,317 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.28 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.28\n",
      "2024-06-29 14:00:12,320 - micro - MainProcess - INFO     Result: (8.6, 4.85, 13.39, 13.49, 0.28) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (8.6, 4.85, 13.39, 13.49, 0.28)\n",
      "2024-06-29 14:00:12,322 - micro - MainProcess - INFO     Calculating statistics for data: [496, 501, 505, 501, 498, 503, 500, 497, 499, 501, 500, 493, 496, 506, 495, 506, 502, 497, 504, 503, 497, 504, 515, 506, 506, 493, 504, 499, 503, 504, 508, 489, 498, 499, 506, 498, 498, 506, 505, 504, 503, 503, 502, 492, 495, 499, 504, 493, 503, 503] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [496, 501, 505, 501, 498, 503, 500, 497, 499, 501, 500, 493, 496, 506, 495, 506, 502, 497, 504, 503, 497, 504, 515, 506, 506, 493, 504, 499, 503, 504, 508, 489, 498, 499, 506, 498, 498, 506, 505, 504, 503, 503, 502, 492, 495, 499, 504, 493, 503, 503]\n",
      "2024-06-29 14:00:12,325 - micro - MainProcess - INFO     Data converted to numpy array: [496 501 505 501 498 503 500 497 499 501 500 493 496 506 495 506 502 497\n",
      " 504 503 497 504 515 506 506 493 504 499 503 504 508 489 498 499 506 498\n",
      " 498 506 505 504 503 503 502 492 495 499 504 493 503 503] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [496 501 505 501 498 503 500 497 499 501 500 493 496 506 495 506 502 497\n",
      " 504 503 497 504 515 506 506 493 504 499 503 504 508 489 498 499 506 498\n",
      " 498 506 505 504 503 503 502 492 495 499 504 493 503 503]\n",
      "2024-06-29 14:00:12,328 - micro - MainProcess - INFO     Calculated median: 501.5 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 501.5\n",
      "2024-06-29 14:00:12,333 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 6.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 6.0\n",
      "2024-06-29 14:00:12,337 - micro - MainProcess - INFO     Calculated 95th percentile: 506.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 506.0\n",
      "2024-06-29 14:00:12,340 - micro - MainProcess - INFO     Calculated 99th percentile: 511.57 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 511.57\n",
      "2024-06-29 14:00:12,344 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.01 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.01\n",
      "2024-06-29 14:00:12,347 - micro - MainProcess - INFO     Result: (501.5, 6.0, 506.0, 511.57, 0.01) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (501.5, 6.0, 506.0, 511.57, 0.01)\n",
      "2024-06-29 14:00:12,350 - micro - MainProcess - INFO     Calculating statistics for data: [77, 68, 68, 74, 73, 67, 73, 78, 80, 64, 70, 71, 74, 68, 62, 74, 66, 73, 70, 71, 75, 67, 68, 74, 73, 71, 74, 77, 75, 70, 74, 77, 74, 73, 66, 69, 72, 66, 70, 74, 71, 72, 63, 67, 76, 66, 70, 72, 69, 69] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [77, 68, 68, 74, 73, 67, 73, 78, 80, 64, 70, 71, 74, 68, 62, 74, 66, 73, 70, 71, 75, 67, 68, 74, 73, 71, 74, 77, 75, 70, 74, 77, 74, 73, 66, 69, 72, 66, 70, 74, 71, 72, 63, 67, 76, 66, 70, 72, 69, 69]\n",
      "2024-06-29 14:00:12,361 - micro - MainProcess - INFO     Data converted to numpy array: [77 68 68 74 73 67 73 78 80 64 70 71 74 68 62 74 66 73 70 71 75 67 68 74\n",
      " 73 71 74 77 75 70 74 77 74 73 66 69 72 66 70 74 71 72 63 67 76 66 70 72\n",
      " 69 69] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [77 68 68 74 73 67 73 78 80 64 70 71 74 68 62 74 66 73 70 71 75 67 68 74\n",
      " 73 71 74 77 75 70 74 77 74 73 66 69 72 66 70 74 71 72 63 67 76 66 70 72\n",
      " 69 69]\n",
      "2024-06-29 14:00:12,393 - micro - MainProcess - INFO     Calculated median: 71.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 71.0\n",
      "2024-06-29 14:00:12,401 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 6.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 6.0\n",
      "2024-06-29 14:00:12,410 - micro - MainProcess - INFO     Calculated 95th percentile: 77.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 77.0\n",
      "2024-06-29 14:00:12,414 - micro - MainProcess - INFO     Calculated 99th percentile: 79.02 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 79.02\n",
      "2024-06-29 14:00:12,430 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.06 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.06\n",
      "2024-06-29 14:00:12,434 - micro - MainProcess - INFO     Result: (71.0, 6.0, 77.0, 79.02, 0.06) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (71.0, 6.0, 77.0, 79.02, 0.06)\n",
      "2024-06-29 14:00:12,448 - micro - MainProcess - INFO     Calculating statistics for data: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 416.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.99, 1, 1, 1, 44.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.85, 1, 1, 1, 1, 1, 1, 325.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 428.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.53, 1, 1, 1, 1, 1, 1, 330.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 920.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 156.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 132.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 285.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 414.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 963.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 238.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 278.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 40.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 272.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 447.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 208.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 765.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 156.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 208.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 174.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 15.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 405.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 56.41, 1, 1, 1, 1, 1, 320.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 816.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 160.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 228.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 376.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 419.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 244.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 455.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 534.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 246.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 262.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 483.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 426.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 444.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 220.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 481.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 125.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 110.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.92, 2.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 28.09, 1, 1, 1, 256.46, 1, 1, 1, 1, 1, 53.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1304.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 35.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 495.04, 1, 1, 1, 1, 1, 1, 1, 49.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 439.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 512.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 498.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 125.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 407.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 182.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1264.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 315.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 422.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 82.79, 205.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 215.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 94.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 153.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 396.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 209.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 175.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 187.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 178.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 216.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 227.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 232.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 220.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 225.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 234.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 262.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 247.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 243.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 285.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 220.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 223.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 78.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 272.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 235.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 938.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 134.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 285.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 200.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 417.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 263.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 65.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 206.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 31.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 206.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.89, 1, 48.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 643.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 464.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.82, 1, 1, 1, 1, 1, 1, 405.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 410.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 106.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 16.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 67.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 226.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 451.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 132.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 147.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 229.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 520.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 517.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 196.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3.36, 354.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3.49, 1, 1, 1, 1, 397.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 405.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 352.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.06, 1, 1, 1, 1, 1, 1, 1, 1, 49.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 515.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 422.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 51.19, 1, 1, 1, 1, 1, 1, 418.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 206.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 411.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 398.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 389.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 300.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 518.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 37.76, 1, 1, 1, 1, 1, 1, 282.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 483.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 454.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 564.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 405.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 458.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 438.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 467.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 573.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 471.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 448.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 418.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 159.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 451.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 463.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 681.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 456.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 442.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 439.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 40.78, 1, 1, 1, 1, 1, 1, 411.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 607.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 409.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 423.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 386.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 422.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 416.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 453.14, 1, 1, 1, 48.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 513.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 607.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 410.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 179.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 482.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 479.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 102.75, 1, 1, 1, 1, 331.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 469.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 479.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 485.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 154.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 124.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.47, 1, 1, 1.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 55.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 453.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 396.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 467.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 62.97, 1, 1, 1, 1, 1, 1, 1, 404.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 453.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 541.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 622.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.92, 1, 1, 1, 1, 1, 1, 1, 1, 3.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 603.14, 1, 1, 1, 1, 1, 1, 1, 1, 2.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1404.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 555.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 490.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 633.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 623.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 562.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 634.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 653.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 577.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 554.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 559.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 576.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 246.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1585.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 556.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 683.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 549.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 611.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 682.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 622.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 617.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 685.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 660.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 51.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 537.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 682.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 619.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 578.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 667.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 623.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 164.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 220.2, 1, 1, 1, 1, 1, 1, 1, 13.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 272.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 791.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 226.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 241.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 848.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 231.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 948.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 156.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 9.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 199.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 218.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 178.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 215.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 258.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 228.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 249.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 278.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 497.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 444.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 449.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 470.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 418.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 443.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 447.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 83.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 213.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 572.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 604.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 527.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 571.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 462.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 584.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 764.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 538.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 638.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 526.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 700.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 579.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 523.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 577.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 556.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 559.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 656.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 594.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 537.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 792.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 496.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 715.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 605.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 545.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 788.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 579.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 630.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 601.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 567.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 599.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 584.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 537.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 625.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 613.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 554.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 800.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 697.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.86, 1, 1, 1, 580.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 715.01, 1, 1, 1, 1, 1, 1, 1, 1, 43.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 619.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 684.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 709.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 797.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 40.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 783.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 627.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1051.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 493.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 615.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 764.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 590.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 776.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 216.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 553.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 478.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 629.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 625.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 896.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 522.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 740.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 34.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 681.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 570.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 694.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.35, 1, 1, 1, 1, 658.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 610.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 488.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 535.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 608.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 642.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.87, 1, 1, 1, 1, 1, 1, 1, 417.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 37.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 646.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 589.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 725.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 592.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 585.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 673.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 666.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 595.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 539.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 587.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 523.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 633.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 670.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 484.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 588.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 489.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 107.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 657.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 575.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 825.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 51.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 683.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 630.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 626.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 640.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 629.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 655.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 543.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 572.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 670.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 54.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 522.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 613.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 519.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 411.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 547.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 619.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 800.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 539.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 580.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 634.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 566.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 648.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 584.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 664.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 584.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 546.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 746.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.72, 1, 1, 1, 1, 1, 1, 1, 1, 460.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 438.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.28, 1, 1, 1, 1, 1, 1, 371.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 516.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 475.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 622.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 574.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 681.59, 1, 1, 1, 45.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 571.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 524.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 766.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 650.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 569.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 664.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 688.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 581.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2099.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 560.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 708.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 662.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 664.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 172.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 525.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 678.53, 1, 1, 1, 1, 44.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 673.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 513.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 684.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 590.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 761.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 517.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 603.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 723.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.0, 1, 1, 1, 1, 2117.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 543.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 568.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 633.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 632.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 599.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 509.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 418.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 547.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 526.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 644.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 634.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 466.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 575.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 583.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 613.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 589.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 548.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 488.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2112.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 601.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 515.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 691.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 605.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 576.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 541.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 580.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 92.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 540.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 509.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 675.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 422.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 743.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 518.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 550.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 593.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 606.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 476.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 579.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2170.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 586.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 663.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 585.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 691.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.28, 1, 1, 1, 1, 1, 1, 1, 505.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 486.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 23.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 36.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 452.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 485.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 495.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 579.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 40.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 473.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 533.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 39.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 419.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 503.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 535.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 516.11, 1, 16.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 452.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 507.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 510.83, 1, 1, 1, 1, 1, 1, 42.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 400.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 160.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 593.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 507.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 666.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 730.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 618.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 592.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 737.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 645.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 561.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 582.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 791.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 36.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 610.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 787.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 699.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 707.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 55.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 687.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 557.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 553.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 494.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 566.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 557.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 635.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 638.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 535.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 566.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 541.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 512.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 539.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 559.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 692.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 481.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 655.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 843.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 622.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 639.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 556.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 590.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 565.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 503.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 598.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 583.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 647.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 647.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 558.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 581.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 604.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 700.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 608.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 591.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 722.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 764.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 562.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 234.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 55.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 238.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 272.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 202.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 555.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 696.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 619.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 56.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 809.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 754.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 54.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 631.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 587.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 620.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 566.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 36.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 490.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 430.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 120.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 603.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 599.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 522.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 594.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 590.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 570.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 632.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 680.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 529.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 405.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 410.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 416.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.99, 1, 1, 1, 44.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.85, 1, 1, 1, 1, 1, 1, 325.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 428.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.53, 1, 1, 1, 1, 1, 1, 330.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 920.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 156.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 132.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 285.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 414.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 963.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 238.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 278.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 40.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 272.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 447.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 208.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 765.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 156.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 208.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 174.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 15.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 405.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 56.41, 1, 1, 1, 1, 1, 320.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 816.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 160.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 228.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 376.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 419.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 244.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 455.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 534.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 246.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 262.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 483.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 426.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 444.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 220.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 481.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 125.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 110.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.92, 2.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 28.09, 1, 1, 1, 256.46, 1, 1, 1, 1, 1, 53.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1304.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 35.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 495.04, 1, 1, 1, 1, 1, 1, 1, 49.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 439.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 512.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 498.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 125.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 407.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 182.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1264.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 315.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 422.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 82.79, 205.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 215.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 94.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 153.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 396.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 209.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 175.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 187.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 178.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 216.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 227.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 232.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 220.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 225.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 234.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 262.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 247.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 243.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 285.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 220.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 223.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 78.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 272.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 235.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 938.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 134.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 285.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 200.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 417.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 263.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 65.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 206.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 31.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 206.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.89, 1, 48.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 643.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 464.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.82, 1, 1, 1, 1, 1, 1, 405.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 410.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 106.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 16.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 67.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 226.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 451.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 132.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 147.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 229.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 520.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 517.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 196.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3.36, 354.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3.49, 1, 1, 1, 1, 397.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 405.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 352.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.06, 1, 1, 1, 1, 1, 1, 1, 1, 49.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 515.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 422.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 51.19, 1, 1, 1, 1, 1, 1, 418.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 206.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 411.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 398.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 389.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 300.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 518.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 37.76, 1, 1, 1, 1, 1, 1, 282.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 483.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 454.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 564.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 405.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 458.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 438.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 467.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 573.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 471.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 448.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 418.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 159.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 451.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 463.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 681.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 456.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 442.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 439.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 40.78, 1, 1, 1, 1, 1, 1, 411.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 607.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 409.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 423.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 386.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 422.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 416.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 453.14, 1, 1, 1, 48.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 513.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 607.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 410.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 179.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 482.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 479.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 102.75, 1, 1, 1, 1, 331.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 469.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 479.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 485.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 154.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 124.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.47, 1, 1, 1.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 55.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 453.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 396.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 467.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 62.97, 1, 1, 1, 1, 1, 1, 1, 404.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 453.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 541.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 622.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.92, 1, 1, 1, 1, 1, 1, 1, 1, 3.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 603.14, 1, 1, 1, 1, 1, 1, 1, 1, 2.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1404.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 555.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 490.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 633.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 623.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 562.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 634.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 653.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 577.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 554.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 559.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 576.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 246.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1585.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 556.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 683.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 549.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 611.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 682.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 622.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 617.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 685.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 660.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 51.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 537.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 682.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 619.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 578.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 667.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 623.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 164.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 220.2, 1, 1, 1, 1, 1, 1, 1, 13.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 272.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 791.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 226.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 241.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 848.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 231.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 948.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 156.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 9.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 199.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 218.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 178.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 215.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 258.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 228.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 249.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 278.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 497.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 444.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 449.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 470.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 418.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 443.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 447.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 83.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 213.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 572.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 604.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 527.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 571.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 462.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 584.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 764.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 538.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 638.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 526.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 700.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 579.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 523.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 577.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 556.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 559.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 656.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 594.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 537.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 792.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 496.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 715.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 605.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 545.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 788.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 579.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 630.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 601.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 567.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 599.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 584.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 537.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 625.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 613.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 554.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 800.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 697.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.86, 1, 1, 1, 580.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 715.01, 1, 1, 1, 1, 1, 1, 1, 1, 43.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 619.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 684.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 709.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 797.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 40.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 783.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 627.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1051.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 493.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 615.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 764.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 590.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 776.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 216.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 553.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 478.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 629.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 625.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 896.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 522.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 740.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 34.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 681.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 570.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 694.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.35, 1, 1, 1, 1, 658.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 610.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 488.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 535.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 608.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 642.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.87, 1, 1, 1, 1, 1, 1, 1, 417.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 37.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 646.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 589.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 725.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 592.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 585.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 673.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 666.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 595.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 539.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 587.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 523.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 633.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 670.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 484.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 588.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 489.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 107.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 657.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 575.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 825.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 51.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 683.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 630.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 626.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 640.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 629.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 655.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 543.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 572.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 670.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 54.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 522.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 613.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 519.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 411.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 547.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 619.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 800.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 539.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 580.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 634.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 566.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 648.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 584.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 664.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 584.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 546.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 746.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.72, 1, 1, 1, 1, 1, 1, 1, 1, 460.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 438.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.28, 1, 1, 1, 1, 1, 1, 371.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 516.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 475.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 622.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 574.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 681.59, 1, 1, 1, 45.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 571.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 524.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 766.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 650.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 569.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 664.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 688.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 581.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2099.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 560.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 708.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 662.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 664.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 172.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 525.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 678.53, 1, 1, 1, 1, 44.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 673.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 513.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 684.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 590.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 761.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 517.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 603.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 723.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.0, 1, 1, 1, 1, 2117.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 543.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 568.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 633.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 632.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 599.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 509.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 418.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 547.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 526.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 644.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 634.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 466.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 575.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 583.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 613.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 589.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 548.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 488.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2112.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 601.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 515.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 691.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 605.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 576.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 541.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 580.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 92.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 540.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 509.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 675.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 422.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 743.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 518.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 550.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 593.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 606.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 476.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 579.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2170.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 586.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 663.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 585.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 691.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.28, 1, 1, 1, 1, 1, 1, 1, 505.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 486.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 23.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 36.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 452.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 485.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 495.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 579.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 40.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 473.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 533.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 39.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 419.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 503.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 535.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 516.11, 1, 16.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 452.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 507.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 510.83, 1, 1, 1, 1, 1, 1, 42.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 400.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 160.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 593.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 507.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 666.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 730.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 618.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 592.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 737.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 645.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 561.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 582.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 791.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 36.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 610.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 787.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 699.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 707.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 55.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 687.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 557.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 553.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 494.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 566.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 557.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 635.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 638.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 535.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 566.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 541.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 512.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 539.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 559.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 692.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 481.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 655.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 843.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 622.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 639.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 556.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 590.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 565.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 503.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 598.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 583.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 647.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 647.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 558.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 581.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 604.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 700.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 608.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 591.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 722.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 764.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 562.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 234.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 55.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 238.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 272.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 202.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 555.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 696.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 619.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 56.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 809.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 754.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 54.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 631.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 587.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 620.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 566.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 36.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 490.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 430.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 120.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 603.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 599.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 522.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 594.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 590.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 570.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 632.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 680.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 529.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 405.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 410.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "2024-06-29 14:00:12,493 - micro - MainProcess - INFO     Data converted to numpy array: [1. 1. 1. ... 1. 1. 1.] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [1. 1. 1. ... 1. 1. 1.]\n",
      "2024-06-29 14:00:12,497 - micro - MainProcess - INFO     Calculated median: 1.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 1.0\n",
      "2024-06-29 14:00:12,502 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-29 14:00:12,507 - micro - MainProcess - INFO     Calculated 95th percentile: 1.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 1.0\n",
      "2024-06-29 14:00:12,513 - micro - MainProcess - INFO     Calculated 99th percentile: 541.62 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 541.62\n",
      "2024-06-29 14:00:12,520 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 5.35 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 5.35\n",
      "2024-06-29 14:00:12,524 - micro - MainProcess - INFO     Result: (1.0, 0.0, 1.0, 541.62, 5.35) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (1.0, 0.0, 1.0, 541.62, 5.35)\n",
      "2024-06-29 14:00:12,527 - micro - MainProcess - INFO     Calculating statistics for data: [4.85, 4.17, 4.24, 4.34, 0.83, 0.86, 0.78, 0.68, 0.81, 0.84, 0.79, 1.11, 0.69, 0.92, 0.65, 0.69, 1.0, 0.57, 0.75, 0.71, 1.18, 0.95, 0.74, 0.95, 0.73, 0.81, 0.82, 1.18, 0.68, 0.59, 0.57, 0.85, 0.99, 0.89, 1.01, 0.91, 0.95, 0.82, 0.98, 0.91, 0.99, 0.87, 0.87, 0.84, 0.98, 0.98, 0.86, 0.67, 1.31, 0.83] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [4.85, 4.17, 4.24, 4.34, 0.83, 0.86, 0.78, 0.68, 0.81, 0.84, 0.79, 1.11, 0.69, 0.92, 0.65, 0.69, 1.0, 0.57, 0.75, 0.71, 1.18, 0.95, 0.74, 0.95, 0.73, 0.81, 0.82, 1.18, 0.68, 0.59, 0.57, 0.85, 0.99, 0.89, 1.01, 0.91, 0.95, 0.82, 0.98, 0.91, 0.99, 0.87, 0.87, 0.84, 0.98, 0.98, 0.86, 0.67, 1.31, 0.83]\n",
      "2024-06-29 14:00:12,530 - micro - MainProcess - INFO     Data converted to numpy array: [4.85 4.17 4.24 4.34 0.83 0.86 0.78 0.68 0.81 0.84 0.79 1.11 0.69 0.92\n",
      " 0.65 0.69 1.   0.57 0.75 0.71 1.18 0.95 0.74 0.95 0.73 0.81 0.82 1.18\n",
      " 0.68 0.59 0.57 0.85 0.99 0.89 1.01 0.91 0.95 0.82 0.98 0.91 0.99 0.87\n",
      " 0.87 0.84 0.98 0.98 0.86 0.67 1.31 0.83] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [4.85 4.17 4.24 4.34 0.83 0.86 0.78 0.68 0.81 0.84 0.79 1.11 0.69 0.92\n",
      " 0.65 0.69 1.   0.57 0.75 0.71 1.18 0.95 0.74 0.95 0.73 0.81 0.82 1.18\n",
      " 0.68 0.59 0.57 0.85 0.99 0.89 1.01 0.91 0.95 0.82 0.98 0.91 0.99 0.87\n",
      " 0.87 0.84 0.98 0.98 0.86 0.67 1.31 0.83]\n",
      "2024-06-29 14:00:12,535 - micro - MainProcess - INFO     Calculated median: 0.86 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.86\n",
      "2024-06-29 14:00:12,539 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.22 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.22\n",
      "2024-06-29 14:00:12,543 - micro - MainProcess - INFO     Calculated 95th percentile: 4.21 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 4.21\n",
      "2024-06-29 14:00:12,548 - micro - MainProcess - INFO     Calculated 99th percentile: 4.6 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 4.6\n",
      "2024-06-29 14:00:12,555 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.86 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.86\n",
      "2024-06-29 14:00:12,558 - micro - MainProcess - INFO     Result: (0.86, 0.22, 4.21, 4.6, 0.86) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.86, 0.22, 4.21, 4.6, 0.86)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------+------------+---------+--------------+-------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+---------+---------------------+---------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|    Model_MaxTokens    | is_Streaming | Iterations | Regions | Average TTLT | Median TTLT | IQR TTLT | 95th Percentile TTLT | 99th Percentile TTLT | CV TTLT | Median Prompt Tokens | IQR Prompt Tokens | Median Completion Tokens | IQR Completion Tokens | 95th Percentile Completion Tokens | 99th Percentile Completion Tokens | CV Completion Tokens | Average TBT | Median TBT | IQR TBT | 95th Percentile TBT | 99th Percentile TBT | Average TTFT | Median TTFT | IQR TTFT | 95th Percentile TTFT | 99th Percentile TTFT | Error Rate | Error Types | Successful Runs | Unsuccessful Runs | Throttle Count | Throttle Rate |                                                                  Best Run                                                                  |                                                                  Worst Run                                                                  |\n",
      "+-----------------------+--------------+------------+---------+--------------+-------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+---------+---------------------+---------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| gpt-4o-2024-05-13_250 |     True     |     50     |   N/A   |     4.51     |    4.28     |   1.05   |         7.38         |         7.71         |  0.28   |         72.0         |        6.0        |          251.0           |          3.0          |               255.0               |              255.51               |         0.01         |    14.13    |    1.0     |   0.0   |         1.0         |        403.5        |     1.15     |    0.84     |   0.3    |         3.93         |         4.03         |    0.0     |     []      |       50        |         0         |       0        |      0.0      | {\"ttlt\": 3.0, \"completion_tokens\": 252, \"prompt_tokens\": 74, \"region\": \"N/A\", \"utilization\": \"N/A\", \"local_time\": \"2024-06-29 13:57:17 \"}  | {\"ttlt\": 7.75, \"completion_tokens\": 250, \"prompt_tokens\": 77, \"region\": \"N/A\", \"utilization\": \"N/A\", \"local_time\": \"2024-06-29 13:56:43 \"}  |\n",
      "| gpt-4o-2024-05-13_500 |     True     |     50     |   N/A   |     9.14     |     8.6     |   4.85   |        13.39         |        13.49         |  0.28   |         71.0         |        6.0        |          501.5           |          6.0          |               506.0               |              511.57               |         0.01         |    16.89    |    1.0     |   0.0   |         1.0         |       541.62        |     1.14     |    0.86     |   0.22   |         4.21         |         4.6          |    0.0     |     []      |       50        |         0         |       0        |      0.0      | {\"ttlt\": 5.51, \"completion_tokens\": 508, \"prompt_tokens\": 74, \"region\": \"N/A\", \"utilization\": \"N/A\", \"local_time\": \"2024-06-29 13:57:45 \"} | {\"ttlt\": 13.56, \"completion_tokens\": 503, \"prompt_tokens\": 71, \"region\": \"N/A\", \"utilization\": \"N/A\", \"local_time\": \"2024-06-29 13:58:23 \"} |\n",
      "+-----------------------+--------------+------------+---------+--------------+-------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+---------+---------------------+---------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_250': {'median_ttlt': 4.28,\n",
       "  'is_Streaming': True,\n",
       "  'regions': ['N/A'],\n",
       "  'iqr_ttlt': 1.05,\n",
       "  'percentile_95_ttlt': 7.38,\n",
       "  'percentile_99_ttlt': 7.71,\n",
       "  'cv_ttlt': 0.28,\n",
       "  'median_completion_tokens': 251.0,\n",
       "  'iqr_completion_tokens': 3.0,\n",
       "  'percentile_95_completion_tokens': 255.0,\n",
       "  'percentile_99_completion_tokens': 255.51,\n",
       "  'cv_completion_tokens': 0.01,\n",
       "  'median_prompt_tokens': 72.0,\n",
       "  'iqr_prompt_tokens': 6.0,\n",
       "  'percentile_95_prompt_tokens': 77.0,\n",
       "  'percentile_99_prompt_tokens': 78.51,\n",
       "  'cv_prompt_tokens': 0.05,\n",
       "  'average_ttlt': 4.51,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 50,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 50,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 1.0,\n",
       "  'iqr_tbt': 0.0,\n",
       "  'percentile_95_tbt': 1.0,\n",
       "  'percentile_99_tbt': 403.5,\n",
       "  'cv_tbt': 5.16,\n",
       "  'average_tbt': 14.13,\n",
       "  'median_ttft': 0.84,\n",
       "  'iqr_ttft': 0.3,\n",
       "  'percentile_95_ttft': 3.93,\n",
       "  'percentile_99_ttft': 4.03,\n",
       "  'cv_ttft': 0.77,\n",
       "  'average_ttft': 1.15,\n",
       "  'best_run': {'ttlt': 3.0,\n",
       "   'completion_tokens': 252,\n",
       "   'prompt_tokens': 74,\n",
       "   'region': 'N/A',\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-29 13:57:17 '},\n",
       "  'worst_run': {'ttlt': 7.75,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 77,\n",
       "   'region': 'N/A',\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-29 13:56:43 '}},\n",
       " 'gpt-4o-2024-05-13_500': {'median_ttlt': 8.6,\n",
       "  'is_Streaming': True,\n",
       "  'regions': ['N/A'],\n",
       "  'iqr_ttlt': 4.85,\n",
       "  'percentile_95_ttlt': 13.39,\n",
       "  'percentile_99_ttlt': 13.49,\n",
       "  'cv_ttlt': 0.28,\n",
       "  'median_completion_tokens': 501.5,\n",
       "  'iqr_completion_tokens': 6.0,\n",
       "  'percentile_95_completion_tokens': 506.0,\n",
       "  'percentile_99_completion_tokens': 511.57,\n",
       "  'cv_completion_tokens': 0.01,\n",
       "  'median_prompt_tokens': 71.0,\n",
       "  'iqr_prompt_tokens': 6.0,\n",
       "  'percentile_95_prompt_tokens': 77.0,\n",
       "  'percentile_99_prompt_tokens': 79.02,\n",
       "  'cv_prompt_tokens': 0.06,\n",
       "  'average_ttlt': 9.14,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 50,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 50,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 1.0,\n",
       "  'iqr_tbt': 0.0,\n",
       "  'percentile_95_tbt': 1.0,\n",
       "  'percentile_99_tbt': 541.62,\n",
       "  'cv_tbt': 5.35,\n",
       "  'average_tbt': 16.89,\n",
       "  'median_ttft': 0.86,\n",
       "  'iqr_ttft': 0.22,\n",
       "  'percentile_95_ttft': 4.21,\n",
       "  'percentile_99_ttft': 4.6,\n",
       "  'cv_ttft': 0.86,\n",
       "  'average_ttft': 1.14,\n",
       "  'best_run': {'ttlt': 5.51,\n",
       "   'completion_tokens': 508,\n",
       "   'prompt_tokens': 74,\n",
       "   'region': 'N/A',\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-29 13:57:45 '},\n",
       "  'worst_run': {'ttlt': 13.56,\n",
       "   'completion_tokens': 503,\n",
       "   'prompt_tokens': 71,\n",
       "   'region': 'N/A',\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-29 13:58:23 '}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_streaming.calculate_and_show_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 13:26:24,285 - micro - MainProcess - INFO     Split list into 4 parts. (utils.py:split_list_into_variable_parts:174)\n",
      "INFO:micro:Split list into 4 parts.\n",
      "2024-06-29 13:26:24,290 - micro - MainProcess - INFO     CPU usage: 10.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 10.3%\n",
      "2024-06-29 13:26:24,301 - micro - MainProcess - INFO     RAM usage: 85.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.1%\n",
      "2024-06-29 13:26:24,323 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:24,328 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,332 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.3317206 Quantum computing is a new frontier in technology, promising to solve problems that are currently intractable for classical computers. Can you explain the concept of quantum computing and its potential impact on technology? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 77 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.3317206 Quantum computing is a new frontier in technology, promising to solve problems that are currently intractable for classical computers. Can you explain the concept of quantum computing and its potential impact on technology? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 77\n",
      "2024-06-29 13:26:24,341 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,345 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:24.345031, (GMT): 2024-06-29 18:26:24.345031+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:24.345031, (GMT): 2024-06-29 18:26:24.345031+00:00\n",
      "2024-06-29 13:26:24,349 - micro - MainProcess - INFO     CPU usage: 5.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 5.0%\n",
      "2024-06-29 13:26:24,363 - micro - MainProcess - INFO     RAM usage: 85.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.1%\n",
      "2024-06-29 13:26:24,381 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:24,388 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,392 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.39125 Virtual reality (VR) creates immersive environments that can be used for entertainment, education, and therapy. How is virtual reality being used in therapeutic settings to treat mental health conditions? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.39125 Virtual reality (VR) creates immersive environments that can be used for entertainment, education, and therapy. How is virtual reality being used in therapeutic settings to treat mental health conditions? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:26:24,399 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,403 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:24.403603, (GMT): 2024-06-29 18:26:24.403603+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:24.403603, (GMT): 2024-06-29 18:26:24.403603+00:00\n",
      "2024-06-29 13:26:24,407 - micro - MainProcess - INFO     CPU usage: 4.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 4.4%\n",
      "2024-06-29 13:26:24,422 - micro - MainProcess - INFO     RAM usage: 85.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.1%\n",
      "2024-06-29 13:26:24,440 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:24,445 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,450 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.4491832 Wearable technologies, such as fitness trackers and smartwatches, monitor various health metrics. How are wearable technologies transforming personal health and fitness monitoring? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.4491832 Wearable technologies, such as fitness trackers and smartwatches, monitor various health metrics. How are wearable technologies transforming personal health and fitness monitoring? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:26:24,456 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,459 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:24.458406, (GMT): 2024-06-29 18:26:24.458406+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:24.458406, (GMT): 2024-06-29 18:26:24.458406+00:00\n",
      "2024-06-29 13:26:24,461 - micro - MainProcess - INFO     CPU usage: 2.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 2.6%\n",
      "2024-06-29 13:26:24,472 - micro - MainProcess - INFO     RAM usage: 85.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.1%\n",
      "2024-06-29 13:26:24,495 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:24,506 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,510 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.5097642 Biotechnology raises ethical questions, especially when it comes to modifying human genes. What are some ethical considerations in the use of biotechnology in humans? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.5097642 Biotechnology raises ethical questions, especially when it comes to modifying human genes. What are some ethical considerations in the use of biotechnology in humans? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:26:24,520 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,525 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:24.525404, (GMT): 2024-06-29 18:26:24.525404+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:24.525404, (GMT): 2024-06-29 18:26:24.525404+00:00\n",
      "2024-06-29 13:26:24,530 - micro - MainProcess - INFO     CPU usage: 23.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 23.1%\n",
      "2024-06-29 13:26:24,548 - micro - MainProcess - INFO     RAM usage: 85.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.3%\n",
      "2024-06-29 13:26:24,587 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:24,594 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,598 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.5981498 Quantum computing is a new frontier in technology, promising to solve problems that are currently intractable for classical computers. Can you explain the concept of quantum computing and its potential impact on technology? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 77 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.5981498 Quantum computing is a new frontier in technology, promising to solve problems that are currently intractable for classical computers. Can you explain the concept of quantum computing and its potential impact on technology? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 77\n",
      "2024-06-29 13:26:24,608 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,611 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:24.611850, (GMT): 2024-06-29 18:26:24.611850+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:24.611850, (GMT): 2024-06-29 18:26:24.611850+00:00\n",
      "2024-06-29 13:26:24,661 - micro - MainProcess - INFO     CPU usage: 29.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 29.8%\n",
      "2024-06-29 13:26:24,679 - micro - MainProcess - INFO     RAM usage: 85.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.3%\n",
      "2024-06-29 13:26:24,721 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:24,730 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,735 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.735036 Virtual reality (VR) creates immersive environments that can be used for entertainment, education, and therapy. How is virtual reality being used in therapeutic settings to treat mental health conditions? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.735036 Virtual reality (VR) creates immersive environments that can be used for entertainment, education, and therapy. How is virtual reality being used in therapeutic settings to treat mental health conditions? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:26:24,743 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,747 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:24.747631, (GMT): 2024-06-29 18:26:24.747631+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:24.747631, (GMT): 2024-06-29 18:26:24.747631+00:00\n",
      "2024-06-29 13:26:24,756 - micro - MainProcess - INFO     CPU usage: 73.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 73.7%\n",
      "2024-06-29 13:26:24,768 - micro - MainProcess - INFO     RAM usage: 85.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.3%\n",
      "2024-06-29 13:26:24,787 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:24,794 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,800 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.7987113 Wearable technologies, such as fitness trackers and smartwatches, monitor various health metrics. How are wearable technologies transforming personal health and fitness monitoring? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.7987113 Wearable technologies, such as fitness trackers and smartwatches, monitor various health metrics. How are wearable technologies transforming personal health and fitness monitoring? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:26:24,805 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,808 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:24.808942, (GMT): 2024-06-29 18:26:24.808942+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:24.808942, (GMT): 2024-06-29 18:26:24.808942+00:00\n",
      "2024-06-29 13:26:24,813 - micro - MainProcess - INFO     CPU usage: 5.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 5.9%\n",
      "2024-06-29 13:26:24,825 - micro - MainProcess - INFO     RAM usage: 85.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.3%\n",
      "2024-06-29 13:26:24,846 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:24,853 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,858 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.8583302 Biotechnology raises ethical questions, especially when it comes to modifying human genes. What are some ethical considerations in the use of biotechnology in humans? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685584.8583302 Biotechnology raises ethical questions, especially when it comes to modifying human genes. What are some ethical considerations in the use of biotechnology in humans? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:26:24,866 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:24,869 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:24.869887, (GMT): 2024-06-29 18:26:24.869887+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:24.869887, (GMT): 2024-06-29 18:26:24.869887+00:00\n",
      "2024-06-29 13:26:27,729 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:27,762 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.14 seconds or 3138.05 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.14 seconds or 3138.05 milliseconds.\n",
      "2024-06-29 13:26:27,905 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:28,922 - micro - MainProcess - INFO     CPU usage: 12.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.2%\n",
      "2024-06-29 13:26:28,937 - micro - MainProcess - INFO     RAM usage: 85.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.3%\n",
      "2024-06-29 13:26:28,982 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:28,992 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:28,996 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685588.99647 Blockchain technology, initially popularized by cryptocurrencies like Bitcoin, has far-reaching applications beyond digital currencies. How does blockchain technology work, and what are its main applications beyond cryptocurrencies? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685588.99647 Blockchain technology, initially popularized by cryptocurrencies like Bitcoin, has far-reaching applications beyond digital currencies. How does blockchain technology work, and what are its main applications beyond cryptocurrencies? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:26:29,003 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:29,009 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:29.009141, (GMT): 2024-06-29 18:26:29.009141+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:29.009141, (GMT): 2024-06-29 18:26:29.009141+00:00\n",
      "2024-06-29 13:26:29,016 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:29,021 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:29,028 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.15 seconds or 4151.9 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.15 seconds or 4151.9 milliseconds.\n",
      "2024-06-29 13:26:29,077 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:29,081 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.27 seconds or 4268.45 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.27 seconds or 4268.45 milliseconds.\n",
      "2024-06-29 13:26:29,140 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:29,225 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:29,258 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.5 seconds or 4504.36 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.5 seconds or 4504.36 milliseconds.\n",
      "2024-06-29 13:26:29,303 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:30,097 - micro - MainProcess - INFO     CPU usage: 31.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 31.1%\n",
      "2024-06-29 13:26:30,117 - micro - MainProcess - INFO     RAM usage: 85.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.3%\n",
      "2024-06-29 13:26:30,150 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:30,161 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:30,170 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685590.1709027 Artificial intelligence (AI) is becoming increasingly important in cybersecurity to detect and prevent threats. How is artificial intelligence being used to enhance cybersecurity measures? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685590.1709027 Artificial intelligence (AI) is becoming increasingly important in cybersecurity to detect and prevent threats. How is artificial intelligence being used to enhance cybersecurity measures? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:26:30,178 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:30,186 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:30.186770, (GMT): 2024-06-29 18:26:30.186770+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:30.186770, (GMT): 2024-06-29 18:26:30.186770+00:00\n",
      "2024-06-29 13:26:30,203 - micro - MainProcess - INFO     CPU usage: 13.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.8%\n",
      "2024-06-29 13:26:30,232 - micro - MainProcess - INFO     RAM usage: 85.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.3%\n",
      "2024-06-29 13:26:30,261 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:30,277 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:30,290 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685590.2903528 Virtual reality (VR) and augmented reality (AR) offer different ways to enhance our perception of the world. What are the main differences between virtual reality and augmented reality? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685590.2903528 Virtual reality (VR) and augmented reality (AR) offer different ways to enhance our perception of the world. What are the main differences between virtual reality and augmented reality? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:26:30,301 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:30,314 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:30.314551, (GMT): 2024-06-29 18:26:30.314551+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:30.314551, (GMT): 2024-06-29 18:26:30.314551+00:00\n",
      "2024-06-29 13:26:30,326 - micro - MainProcess - INFO     CPU usage: 55.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 55.8%\n",
      "2024-06-29 13:26:30,345 - micro - MainProcess - INFO     RAM usage: 85.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.4%\n",
      "2024-06-29 13:26:30,433 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:30,445 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:30,450 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685590.4509313 E-commerce has grown rapidly, especially during the COVID-19 pandemic, changing the way we shop. What are the key factors driving the growth of e-commerce, and how is it changing retail? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 78 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685590.4509313 E-commerce has grown rapidly, especially during the COVID-19 pandemic, changing the way we shop. What are the key factors driving the growth of e-commerce, and how is it changing retail? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 78\n",
      "2024-06-29 13:26:30,458 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:30,474 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:30.474675, (GMT): 2024-06-29 18:26:30.474675+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:30.474675, (GMT): 2024-06-29 18:26:30.474675+00:00\n",
      "2024-06-29 13:26:32,039 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:32,045 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:32,052 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:32,083 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.62 seconds or 7618.87 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.62 seconds or 7618.87 milliseconds.\n",
      "2024-06-29 13:26:32,130 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:32,140 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.79 seconds or 7788.39 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.79 seconds or 7788.39 milliseconds.\n",
      "2024-06-29 13:26:32,186 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:32,195 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.66 seconds or 7661.89 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.66 seconds or 7661.89 milliseconds.\n",
      "2024-06-29 13:26:32,244 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:32,542 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:32,575 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.56 seconds or 3559.75 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.56 seconds or 3559.75 milliseconds.\n",
      "2024-06-29 13:26:32,626 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:33,129 - micro - MainProcess - INFO     CPU usage: 47.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 47.6%\n",
      "2024-06-29 13:26:33,140 - micro - MainProcess - INFO     RAM usage: 86.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.0%\n",
      "2024-06-29 13:26:33,159 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:33,169 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:33,177 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685593.1762571 Virtual reality (VR) and augmented reality (AR) offer different ways to enhance our perception of the world. What are the main differences between virtual reality and augmented reality? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685593.1762571 Virtual reality (VR) and augmented reality (AR) offer different ways to enhance our perception of the world. What are the main differences between virtual reality and augmented reality? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:26:33,185 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:33,189 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:33.189280, (GMT): 2024-06-29 18:26:33.189280+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:33.189280, (GMT): 2024-06-29 18:26:33.189280+00:00\n",
      "2024-06-29 13:26:33,197 - micro - MainProcess - INFO     CPU usage: 20.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 20.8%\n",
      "2024-06-29 13:26:33,210 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:26:33,229 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:33,236 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:33,243 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685593.2412727 Blockchain technology, initially popularized by cryptocurrencies like Bitcoin, has far-reaching applications beyond digital currencies. How does blockchain technology work, and what are its main applications beyond cryptocurrencies? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685593.2412727 Blockchain technology, initially popularized by cryptocurrencies like Bitcoin, has far-reaching applications beyond digital currencies. How does blockchain technology work, and what are its main applications beyond cryptocurrencies? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:26:33,247 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:33,250 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:33.250941, (GMT): 2024-06-29 18:26:33.250941+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:33.250941, (GMT): 2024-06-29 18:26:33.250941+00:00\n",
      "2024-06-29 13:26:33,258 - micro - MainProcess - INFO     CPU usage: 12.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.5%\n",
      "2024-06-29 13:26:33,281 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:26:33,336 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:33,345 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:33,352 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685593.3514612 Artificial intelligence (AI) is becoming increasingly important in cybersecurity to detect and prevent threats. How is artificial intelligence being used to enhance cybersecurity measures? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685593.3514612 Artificial intelligence (AI) is becoming increasingly important in cybersecurity to detect and prevent threats. How is artificial intelligence being used to enhance cybersecurity measures? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:26:33,361 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:33,365 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:33.365877, (GMT): 2024-06-29 18:26:33.365877+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:33.365877, (GMT): 2024-06-29 18:26:33.365877+00:00\n",
      "2024-06-29 13:26:33,637 - micro - MainProcess - INFO     CPU usage: 31.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 31.2%\n",
      "2024-06-29 13:26:33,647 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:26:33,667 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:33,674 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:33,678 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685593.6784482 Climate change is one of the most pressing issues of our time, affecting ecosystems, weather patterns, and sea levels. What are the major challenges in combating climate change, and what can individuals do to help? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 80 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685593.6784482 Climate change is one of the most pressing issues of our time, affecting ecosystems, weather patterns, and sea levels. What are the major challenges in combating climate change, and what can individuals do to help? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 80\n",
      "2024-06-29 13:26:33,683 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:33,686 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:33.686981, (GMT): 2024-06-29 18:26:33.686981+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:33.686981, (GMT): 2024-06-29 18:26:33.686981+00:00\n",
      "2024-06-29 13:26:33,783 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:33,813 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.62 seconds or 3618.71 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.62 seconds or 3618.71 milliseconds.\n",
      "2024-06-29 13:26:33,860 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:33,871 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:33,895 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.41 seconds or 3408.66 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.41 seconds or 3408.66 milliseconds.\n",
      "2024-06-29 13:26:33,941 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:34,021 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:34,052 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.64 seconds or 9644.94 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.64 seconds or 9644.94 milliseconds.\n",
      "2024-06-29 13:26:34,108 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:34,337 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:34,370 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.05 seconds or 4049.77 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.05 seconds or 4049.77 milliseconds.\n",
      "2024-06-29 13:26:34,417 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:34,875 - micro - MainProcess - INFO     CPU usage: 19.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.5%\n",
      "2024-06-29 13:26:34,885 - micro - MainProcess - INFO     RAM usage: 86.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.0%\n",
      "2024-06-29 13:26:34,906 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:34,912 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:34,915 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685594.9159925 Smart contracts are self-executing contracts with the terms of the agreement directly written into code. Can you explain the concept of smart contracts and their use in blockchain technology? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685594.9159925 Smart contracts are self-executing contracts with the terms of the agreement directly written into code. Can you explain the concept of smart contracts and their use in blockchain technology? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:26:34,928 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:34,931 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:34.931549, (GMT): 2024-06-29 18:26:34.931549+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:34.931549, (GMT): 2024-06-29 18:26:34.931549+00:00\n",
      "2024-06-29 13:26:34,939 - micro - MainProcess - INFO     CPU usage: 27.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 27.3%\n",
      "2024-06-29 13:26:34,949 - micro - MainProcess - INFO     RAM usage: 86.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.0%\n",
      "2024-06-29 13:26:34,974 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:34,980 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:34,985 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685594.9844363 Big data analytics involves examining large datasets to uncover hidden patterns and insights. How do big data analytics help businesses make better decisions? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 64 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685594.9844363 Big data analytics involves examining large datasets to uncover hidden patterns and insights. How do big data analytics help businesses make better decisions? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 64\n",
      "2024-06-29 13:26:34,994 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:34,997 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:34.997792, (GMT): 2024-06-29 18:26:34.997792+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:34.997792, (GMT): 2024-06-29 18:26:34.997792+00:00\n",
      "2024-06-29 13:26:35,122 - micro - MainProcess - INFO     CPU usage: 60.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 60.1%\n",
      "2024-06-29 13:26:35,136 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:26:35,153 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:35,160 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:35,164 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685595.1643531 E-commerce has grown rapidly, especially during the COVID-19 pandemic, changing the way we shop. What are the key factors driving the growth of e-commerce, and how is it changing retail? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 78 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685595.1643531 E-commerce has grown rapidly, especially during the COVID-19 pandemic, changing the way we shop. What are the key factors driving the growth of e-commerce, and how is it changing retail? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 78\n",
      "2024-06-29 13:26:35,171 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:35,174 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:35.174126, (GMT): 2024-06-29 18:26:35.174126+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:35.174126, (GMT): 2024-06-29 18:26:35.174126+00:00\n",
      "2024-06-29 13:26:35,423 - micro - MainProcess - INFO     CPU usage: 11.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 11.4%\n",
      "2024-06-29 13:26:35,435 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:26:35,452 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:35,460 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:35,464 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685595.4640648 Data privacy is a growing concern as more personal information is collected and stored online. Can you discuss the importance of data privacy and how individuals can protect their information? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685595.4640648 Data privacy is a growing concern as more personal information is collected and stored online. Can you discuss the importance of data privacy and how individuals can protect their information? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:26:35,472 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:35,475 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:35.475607, (GMT): 2024-06-29 18:26:35.475607+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:35.475607, (GMT): 2024-06-29 18:26:35.475607+00:00\n",
      "2024-06-29 13:26:37,176 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:37,208 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.52 seconds or 3518.32 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.52 seconds or 3518.32 milliseconds.\n",
      "2024-06-29 13:26:37,263 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:38,280 - micro - MainProcess - INFO     CPU usage: 12.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.0%\n",
      "2024-06-29 13:26:38,291 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:26:38,316 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:38,325 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:38,332 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685598.3289857 Machine learning is a subset of artificial intelligence where algorithms learn from data to make predictions or decisions. How do machine learning algorithms improve over time, and what are some common applications? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685598.3289857 Machine learning is a subset of artificial intelligence where algorithms learn from data to make predictions or decisions. How do machine learning algorithms improve over time, and what are some common applications? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:26:38,340 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:38,344 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:38.344655, (GMT): 2024-06-29 18:26:38.344655+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:38.344655, (GMT): 2024-06-29 18:26:38.344655+00:00\n",
      "2024-06-29 13:26:38,824 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:38,852 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.85 seconds or 3849.65 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.85 seconds or 3849.65 milliseconds.\n",
      "2024-06-29 13:26:38,930 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:39,310 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:39,344 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.87 seconds or 3866.48 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.87 seconds or 3866.48 milliseconds.\n",
      "2024-06-29 13:26:39,393 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:39,925 - micro - MainProcess - INFO     CPU usage: 25.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 25.2%\n",
      "2024-06-29 13:26:39,937 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:26:39,963 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:39,972 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:39,975 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685599.9758494 Precision medicine tailors medical treatment to the individual characteristics of each patient. Can you explain the concept of precision medicine and its advantages in treating diseases? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685599.9758494 Precision medicine tailors medical treatment to the individual characteristics of each patient. Can you explain the concept of precision medicine and its advantages in treating diseases? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:26:39,981 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:39,986 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:39.986385, (GMT): 2024-06-29 18:26:39.986385+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:39.986385, (GMT): 2024-06-29 18:26:39.986385+00:00\n",
      "2024-06-29 13:26:40,203 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:40,237 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.04 seconds or 7043.02 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.04 seconds or 7043.02 milliseconds.\n",
      "2024-06-29 13:26:40,284 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:40,289 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:40,292 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:40,301 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:40,306 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.94 seconds or 6935.93 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.94 seconds or 6935.93 milliseconds.\n",
      "2024-06-29 13:26:40,357 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:40,364 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.11 seconds or 7107.95 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.11 seconds or 7107.95 milliseconds.\n",
      "2024-06-29 13:26:40,412 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:40,419 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.48 seconds or 5483.08 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.48 seconds or 5483.08 milliseconds.\n",
      "2024-06-29 13:26:40,473 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:40,477 - micro - MainProcess - INFO     CPU usage: 29.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 29.1%\n",
      "2024-06-29 13:26:40,489 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:26:40,511 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:40,516 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:40,521 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685600.519687 Quantum cryptography uses the principles of quantum mechanics to secure communication. How is quantum cryptography enhancing the security of digital communications? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 61 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685600.519687 Quantum cryptography uses the principles of quantum mechanics to secure communication. How is quantum cryptography enhancing the security of digital communications? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 61\n",
      "2024-06-29 13:26:40,527 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:40,530 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:40.530983, (GMT): 2024-06-29 18:26:40.530983+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:40.530983, (GMT): 2024-06-29 18:26:40.530983+00:00\n",
      "2024-06-29 13:26:41,303 - micro - MainProcess - INFO     CPU usage: 19.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.6%\n",
      "2024-06-29 13:26:41,314 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:41,366 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:41,373 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:41,377 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685601.3775523 Data privacy is a growing concern as more personal information is collected and stored online. Can you discuss the importance of data privacy and how individuals can protect their information? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685601.3775523 Data privacy is a growing concern as more personal information is collected and stored online. Can you discuss the importance of data privacy and how individuals can protect their information? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:26:41,384 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:41,389 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:41.389078, (GMT): 2024-06-29 18:26:41.389078+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:41.389078, (GMT): 2024-06-29 18:26:41.389078+00:00\n",
      "2024-06-29 13:26:41,395 - micro - MainProcess - INFO     CPU usage: 30.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 30.3%\n",
      "2024-06-29 13:26:41,407 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:41,441 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:41,448 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:41,453 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685601.4533148 Smart contracts are self-executing contracts with the terms of the agreement directly written into code. Can you explain the concept of smart contracts and their use in blockchain technology? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685601.4533148 Smart contracts are self-executing contracts with the terms of the agreement directly written into code. Can you explain the concept of smart contracts and their use in blockchain technology? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:26:41,460 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:41,463 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:41.463852, (GMT): 2024-06-29 18:26:41.463852+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:41.463852, (GMT): 2024-06-29 18:26:41.463852+00:00\n",
      "2024-06-29 13:26:41,474 - micro - MainProcess - INFO     CPU usage: 16.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.4%\n",
      "2024-06-29 13:26:41,488 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:41,515 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:41,523 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:41,530 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685601.5291536 Climate change is one of the most pressing issues of our time, affecting ecosystems, weather patterns, and sea levels. What are the major challenges in combating climate change, and what can individuals do to help? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 80 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685601.5291536 Climate change is one of the most pressing issues of our time, affecting ecosystems, weather patterns, and sea levels. What are the major challenges in combating climate change, and what can individuals do to help? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 80\n",
      "2024-06-29 13:26:41,537 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:41,555 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:41.555436, (GMT): 2024-06-29 18:26:41.555436+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:41.555436, (GMT): 2024-06-29 18:26:41.555436+00:00\n",
      "2024-06-29 13:26:41,563 - micro - MainProcess - INFO     CPU usage: 19.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.4%\n",
      "2024-06-29 13:26:41,576 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:41,596 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:41,603 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:41,609 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685601.6083193 3D printing, also known as additive manufacturing, creates objects layer by layer from digital models. What are some innovative uses of 3D printing in manufacturing and healthcare? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685601.6083193 3D printing, also known as additive manufacturing, creates objects layer by layer from digital models. What are some innovative uses of 3D printing in manufacturing and healthcare? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:26:41,615 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:41,618 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:41.618553, (GMT): 2024-06-29 18:26:41.618553+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:41.618553, (GMT): 2024-06-29 18:26:41.618553+00:00\n",
      "2024-06-29 13:26:42,106 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:42,147 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.8 seconds or 3799.51 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.8 seconds or 3799.51 milliseconds.\n",
      "2024-06-29 13:26:42,197 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:42,303 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:42,332 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.15 seconds or 7154.46 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.15 seconds or 7154.46 milliseconds.\n",
      "2024-06-29 13:26:42,475 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:43,195 - micro - MainProcess - INFO     CPU usage: 21.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 21.6%\n",
      "2024-06-29 13:26:43,207 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:26:43,225 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:43,232 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:43,236 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685603.236134 As artificial intelligence becomes more integrated into our daily lives, ethical considerations become increasingly important. Can you discuss the ethical considerations surrounding artificial intelligence? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 65 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685603.236134 As artificial intelligence becomes more integrated into our daily lives, ethical considerations become increasingly important. Can you discuss the ethical considerations surrounding artificial intelligence? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 65\n",
      "2024-06-29 13:26:43,249 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:43,251 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:43.251915, (GMT): 2024-06-29 18:26:43.251915+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:43.251915, (GMT): 2024-06-29 18:26:43.251915+00:00\n",
      "2024-06-29 13:26:43,473 - micro - MainProcess - INFO     CPU usage: 11.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 11.8%\n",
      "2024-06-29 13:26:43,484 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:43,506 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:43,514 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:43,518 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685603.5184133 Big data analytics involves examining large datasets to uncover hidden patterns and insights. How do big data analytics help businesses make better decisions? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 64 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685603.5184133 Big data analytics involves examining large datasets to uncover hidden patterns and insights. How do big data analytics help businesses make better decisions? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 64\n",
      "2024-06-29 13:26:43,525 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:43,528 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:43.528638, (GMT): 2024-06-29 18:26:43.528638+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:43.528638, (GMT): 2024-06-29 18:26:43.528638+00:00\n",
      "2024-06-29 13:26:43,696 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:43,727 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.74 seconds or 3735.42 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.74 seconds or 3735.42 milliseconds.\n",
      "2024-06-29 13:26:43,781 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:44,322 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:44,351 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.81 seconds or 3809.84 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.81 seconds or 3809.84 milliseconds.\n",
      "2024-06-29 13:26:44,449 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:44,785 - micro - MainProcess - INFO     CPU usage: 27.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 27.9%\n",
      "2024-06-29 13:26:44,810 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:44,852 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:44,861 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:44,866 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685604.8663273 Smart cities use technology to improve urban living conditions, making cities more efficient and sustainable. What are some examples of how smart cities are improving urban living conditions? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685604.8663273 Smart cities use technology to improve urban living conditions, making cities more efficient and sustainable. What are some examples of how smart cities are improving urban living conditions? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:26:44,872 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:44,876 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:44.875762, (GMT): 2024-06-29 18:26:44.875762+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:44.875762, (GMT): 2024-06-29 18:26:44.875762+00:00\n",
      "2024-06-29 13:26:45,188 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:45,218 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.6 seconds or 3595.87 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.6 seconds or 3595.87 milliseconds.\n",
      "2024-06-29 13:26:45,352 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:45,452 - micro - MainProcess - INFO     CPU usage: 33.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 33.3%\n",
      "2024-06-29 13:26:45,462 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:26:45,479 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:45,485 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:45,490 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685605.4904156 Artificial general intelligence (AGI) aims to create machines that can perform any intellectual task that a human can. What are some current challenges in the development of artificial general intelligence? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685605.4904156 Artificial general intelligence (AGI) aims to create machines that can perform any intellectual task that a human can. What are some current challenges in the development of artificial general intelligence? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:26:45,496 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:45,499 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:45.499735, (GMT): 2024-06-29 18:26:45.499735+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:45.499735, (GMT): 2024-06-29 18:26:45.499735+00:00\n",
      "2024-06-29 13:26:46,359 - micro - MainProcess - INFO     CPU usage: 13.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.9%\n",
      "2024-06-29 13:26:46,369 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:26:46,395 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:46,407 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:46,411 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685606.4101374 Augmented reality (AR) is being used in retail to create interactive shopping experiences for customers. How is augmented reality being integrated into retail experiences to enhance customer engagement? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685606.4101374 Augmented reality (AR) is being used in retail to create interactive shopping experiences for customers. How is augmented reality being integrated into retail experiences to enhance customer engagement? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:26:46,415 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:46,418 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:46.418423, (GMT): 2024-06-29 18:26:46.418423+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:46.418423, (GMT): 2024-06-29 18:26:46.418423+00:00\n",
      "2024-06-29 13:26:46,652 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:46,682 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.43 seconds or 3426.43 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.43 seconds or 3426.43 milliseconds.\n",
      "2024-06-29 13:26:46,730 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:47,193 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:47,226 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.67 seconds or 5665.12 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.67 seconds or 5665.12 milliseconds.\n",
      "2024-06-29 13:26:47,287 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:47,737 - micro - MainProcess - INFO     CPU usage: 14.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.9%\n",
      "2024-06-29 13:26:47,749 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:47,769 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:47,777 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:47,786 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685607.7863562 Autonomous vehicles, or self-driving cars, have the potential to revolutionize transportation, but they also pose significant challenges. What are the benefits and risks of autonomous vehicles on our roads? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 75 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685607.7863562 Autonomous vehicles, or self-driving cars, have the potential to revolutionize transportation, but they also pose significant challenges. What are the benefits and risks of autonomous vehicles on our roads? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 75\n",
      "2024-06-29 13:26:47,795 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:47,820 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:47.820913, (GMT): 2024-06-29 18:26:47.820913+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:47.820913, (GMT): 2024-06-29 18:26:47.820913+00:00\n",
      "2024-06-29 13:26:48,296 - micro - MainProcess - INFO     CPU usage: 50.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 50.1%\n",
      "2024-06-29 13:26:48,334 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:26:48,360 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:48,368 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:48,374 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685608.374412 Machine learning is a subset of artificial intelligence where algorithms learn from data to make predictions or decisions. How do machine learning algorithms improve over time, and what are some common applications? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685608.374412 Machine learning is a subset of artificial intelligence where algorithms learn from data to make predictions or decisions. How do machine learning algorithms improve over time, and what are some common applications? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:26:48,382 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:48,385 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:48.385779, (GMT): 2024-06-29 18:26:48.385779+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:48.385779, (GMT): 2024-06-29 18:26:48.385779+00:00\n",
      "2024-06-29 13:26:48,435 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:48,444 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.05 seconds or 7050.35 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.05 seconds or 7050.35 milliseconds.\n",
      "2024-06-29 13:26:48,493 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:48,503 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:48,509 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:48,516 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.05 seconds or 7047.98 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.05 seconds or 7047.98 milliseconds.\n",
      "2024-06-29 13:26:49,577 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:49,581 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.7 seconds or 4699.19 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.7 seconds or 4699.19 milliseconds.\n",
      "2024-06-29 13:26:49,634 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:49,649 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:49,657 - micro - MainProcess - INFO     CPU usage: 10.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 10.9%\n",
      "2024-06-29 13:26:49,669 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:26:49,685 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:49,694 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:49,701 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685609.7014658 Quantum cryptography uses the principles of quantum mechanics to secure communication. How is quantum cryptography enhancing the security of digital communications? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 62 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685609.7014658 Quantum cryptography uses the principles of quantum mechanics to secure communication. How is quantum cryptography enhancing the security of digital communications? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 62\n",
      "2024-06-29 13:26:49,709 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:49,720 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:49.720392, (GMT): 2024-06-29 18:26:49.720392+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:49.720392, (GMT): 2024-06-29 18:26:49.720392+00:00\n",
      "2024-06-29 13:26:49,742 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.24 seconds or 4240.11 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.24 seconds or 4240.11 milliseconds.\n",
      "2024-06-29 13:26:49,821 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:49,911 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:49,943 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.52 seconds or 3521.56 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.52 seconds or 3521.56 milliseconds.\n",
      "2024-06-29 13:26:50,002 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:50,605 - micro - MainProcess - INFO     CPU usage: 24.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 24.6%\n",
      "2024-06-29 13:26:50,615 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:50,647 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:50,655 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:50,659 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685610.6597655 3D printing, also known as additive manufacturing, creates objects layer by layer from digital models. What are some innovative uses of 3D printing in manufacturing and healthcare? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685610.6597655 3D printing, also known as additive manufacturing, creates objects layer by layer from digital models. What are some innovative uses of 3D printing in manufacturing and healthcare? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:26:50,665 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:50,669 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:50.669457, (GMT): 2024-06-29 18:26:50.669457+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:50.669457, (GMT): 2024-06-29 18:26:50.669457+00:00\n",
      "2024-06-29 13:26:50,676 - micro - MainProcess - INFO     CPU usage: 10.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 10.5%\n",
      "2024-06-29 13:26:50,689 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:26:50,705 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:50,711 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:50,715 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685610.714943 Fintech innovations are transforming the financial industry, making services more accessible and efficient. How is fintech innovation changing the banking and finance industry? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685610.714943 Fintech innovations are transforming the financial industry, making services more accessible and efficient. How is fintech innovation changing the banking and finance industry? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:26:50,722 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:50,726 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:50.726688, (GMT): 2024-06-29 18:26:50.726688+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:50.726688, (GMT): 2024-06-29 18:26:50.726688+00:00\n",
      "2024-06-29 13:26:50,839 - micro - MainProcess - INFO     CPU usage: 26.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 26.6%\n",
      "2024-06-29 13:26:50,849 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:50,869 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:50,875 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:50,881 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685610.880883 Nanotechnology involves manipulating matter at the atomic and molecular scale for various applications. How is nanotechnology being used in medical treatments and drug delivery systems? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685610.880883 Nanotechnology involves manipulating matter at the atomic and molecular scale for various applications. How is nanotechnology being used in medical treatments and drug delivery systems? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:26:50,889 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:50,893 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:50.893465, (GMT): 2024-06-29 18:26:50.893465+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:50.893465, (GMT): 2024-06-29 18:26:50.893465+00:00\n",
      "2024-06-29 13:26:50,910 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:50,932 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.4 seconds or 7400.72 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.4 seconds or 7400.72 milliseconds.\n",
      "2024-06-29 13:26:50,979 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:51,022 - micro - MainProcess - INFO     CPU usage: 10.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 10.6%\n",
      "2024-06-29 13:26:51,032 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:26:51,047 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:51,055 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:51,060 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685611.0605555 Electric vehicles (EVs) offer a cleaner alternative to traditional gasoline-powered cars, but their widespread adoption poses challenges. What are the potential environmental impacts of widespread adoption of electric vehicles? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 75 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685611.0605555 Electric vehicles (EVs) offer a cleaner alternative to traditional gasoline-powered cars, but their widespread adoption poses challenges. What are the potential environmental impacts of widespread adoption of electric vehicles? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 75\n",
      "2024-06-29 13:26:51,066 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:51,070 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:51.070582, (GMT): 2024-06-29 18:26:51.070582+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:51.070582, (GMT): 2024-06-29 18:26:51.070582+00:00\n",
      "2024-06-29 13:26:51,077 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:51,097 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.24 seconds or 3243.05 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.24 seconds or 3243.05 milliseconds.\n",
      "2024-06-29 13:26:51,142 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:51,969 - micro - MainProcess - INFO     CPU usage: 10.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 10.7%\n",
      "2024-06-29 13:26:51,985 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:26:52,026 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:52,031 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:52,035 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685612.0358863 Precision medicine tailors medical treatment to the individual characteristics of each patient. Can you explain the concept of precision medicine and its advantages in treating diseases? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685612.0358863 Precision medicine tailors medical treatment to the individual characteristics of each patient. Can you explain the concept of precision medicine and its advantages in treating diseases? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:26:52,043 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:52,046 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:52.046185, (GMT): 2024-06-29 18:26:52.046185+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:52.046185, (GMT): 2024-06-29 18:26:52.046185+00:00\n",
      "2024-06-29 13:26:52,154 - micro - MainProcess - INFO     CPU usage: 37.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 37.7%\n",
      "2024-06-29 13:26:52,163 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:52,183 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:52,188 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:52,192 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685612.1917856 Augmented reality (AR) overlays digital information onto the real world, providing new ways to interact with our environment. How is augmented reality being used in education and training programs? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685612.1917856 Augmented reality (AR) overlays digital information onto the real world, providing new ways to interact with our environment. How is augmented reality being used in education and training programs? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:26:52,198 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:52,202 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:52.202308, (GMT): 2024-06-29 18:26:52.202308+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:52.202308, (GMT): 2024-06-29 18:26:52.202308+00:00\n",
      "2024-06-29 13:26:53,884 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:53,915 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.19 seconds or 3186.71 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.19 seconds or 3186.71 milliseconds.\n",
      "2024-06-29 13:26:53,975 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:54,676 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:54,712 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.82 seconds or 3815.06 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.82 seconds or 3815.06 milliseconds.\n",
      "2024-06-29 13:26:54,774 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:54,789 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:54,824 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.75 seconds or 3750.4 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.75 seconds or 3750.4 milliseconds.\n",
      "2024-06-29 13:26:54,885 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:54,967 - micro - MainProcess - INFO     CPU usage: 13.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.5%\n",
      "2024-06-29 13:26:54,979 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:54,999 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:55,006 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:55,012 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685615.0092025 Telemedicine allows healthcare providers to consult with patients remotely, increasing access to care. What are the benefits and challenges of telemedicine for both patients and healthcare providers? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685615.0092025 Telemedicine allows healthcare providers to consult with patients remotely, increasing access to care. What are the benefits and challenges of telemedicine for both patients and healthcare providers? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:26:55,017 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:55,021 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:55.021669, (GMT): 2024-06-29 18:26:55.021669+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:55.021669, (GMT): 2024-06-29 18:26:55.021669+00:00\n",
      "2024-06-29 13:26:55,781 - micro - MainProcess - INFO     CPU usage: 9.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 9.7%\n",
      "2024-06-29 13:26:55,792 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:26:55,818 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:55,823 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:55,826 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685615.8263905 Smart homes use connected devices to automate and control household systems, improving convenience and efficiency. What are the key components of a smart home, and how do they work together? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685615.8263905 Smart homes use connected devices to automate and control household systems, improving convenience and efficiency. What are the key components of a smart home, and how do they work together? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:26:55,834 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:55,837 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:55.837086, (GMT): 2024-06-29 18:26:55.837086+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:55.837086, (GMT): 2024-06-29 18:26:55.837086+00:00\n",
      "2024-06-29 13:26:55,862 - micro - MainProcess - INFO     CPU usage: 17.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 17.2%\n",
      "2024-06-29 13:26:55,874 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:55,889 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:55,895 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:55,899 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685615.8991365 Robots are being programmed to perform increasingly complex tasks in various industries, from manufacturing to healthcare. How do robots learn to perform complex tasks, and what are some examples of their use in industry? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 77 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685615.8991365 Robots are being programmed to perform increasingly complex tasks in various industries, from manufacturing to healthcare. How do robots learn to perform complex tasks, and what are some examples of their use in industry? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 77\n",
      "2024-06-29 13:26:55,905 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:55,910 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:55.910338, (GMT): 2024-06-29 18:26:55.910338+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:55.910338, (GMT): 2024-06-29 18:26:55.910338+00:00\n",
      "2024-06-29 13:26:55,983 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:56,016 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.81 seconds or 3808.45 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.81 seconds or 3808.45 milliseconds.\n",
      "2024-06-29 13:26:56,066 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:56,626 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:56,677 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.29 seconds or 8286.96 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.29 seconds or 8286.96 milliseconds.\n",
      "2024-06-29 13:26:56,721 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:56,852 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:56,884 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.14 seconds or 7141.66 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.14 seconds or 7141.66 milliseconds.\n",
      "2024-06-29 13:26:56,932 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:57,080 - micro - MainProcess - INFO     CPU usage: 14.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.7%\n",
      "2024-06-29 13:26:57,107 - micro - MainProcess - INFO     RAM usage: 86.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.1%\n",
      "2024-06-29 13:26:57,125 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:57,133 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:57,141 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685617.1405592 Genetic engineering allows scientists to modify the DNA of organisms, leading to advancements in medicine and agriculture. What are the latest advancements in genetic engineering, and how might they affect healthcare? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685617.1405592 Genetic engineering allows scientists to modify the DNA of organisms, leading to advancements in medicine and agriculture. What are the latest advancements in genetic engineering, and how might they affect healthcare? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:26:57,147 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:57,150 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:57.150545, (GMT): 2024-06-29 18:26:57.150545+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:57.150545, (GMT): 2024-06-29 18:26:57.150545+00:00\n",
      "2024-06-29 13:26:57,741 - micro - MainProcess - INFO     CPU usage: 20.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 20.8%\n",
      "2024-06-29 13:26:57,752 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:57,773 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:57,780 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:57,784 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685617.7847874 As artificial intelligence becomes more integrated into our daily lives, ethical considerations become increasingly important. Can you discuss the ethical considerations surrounding artificial intelligence? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 66 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685617.7847874 As artificial intelligence becomes more integrated into our daily lives, ethical considerations become increasingly important. Can you discuss the ethical considerations surrounding artificial intelligence? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 66\n",
      "2024-06-29 13:26:57,791 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:57,794 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:57.794950, (GMT): 2024-06-29 18:26:57.794950+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:57.794950, (GMT): 2024-06-29 18:26:57.794950+00:00\n",
      "2024-06-29 13:26:57,801 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:57,809 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.14 seconds or 7135.6 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.14 seconds or 7135.6 milliseconds.\n",
      "2024-06-29 13:26:57,898 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:57,908 - micro - MainProcess - INFO     CPU usage: 16.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.1%\n",
      "2024-06-29 13:26:57,918 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:57,936 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:57,943 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:57,949 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685617.9494102 Artificial general intelligence (AGI) aims to create machines that can perform any intellectual task that a human can. What are some current challenges in the development of artificial general intelligence? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685617.9494102 Artificial general intelligence (AGI) aims to create machines that can perform any intellectual task that a human can. What are some current challenges in the development of artificial general intelligence? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:26:57,955 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:57,959 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:57.959942, (GMT): 2024-06-29 18:26:57.959942+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:57.959942, (GMT): 2024-06-29 18:26:57.959942+00:00\n",
      "2024-06-29 13:26:58,108 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:58,141 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.11 seconds or 3114.76 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.11 seconds or 3114.76 milliseconds.\n",
      "2024-06-29 13:26:58,186 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:58,910 - micro - MainProcess - INFO     CPU usage: 16.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.4%\n",
      "2024-06-29 13:26:58,920 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:26:58,946 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:58,952 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:58,959 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685618.9590955 Augmented reality (AR) is being used in retail to create interactive shopping experiences for customers. How is augmented reality being integrated into retail experiences to enhance customer engagement? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685618.9590955 Augmented reality (AR) is being used in retail to create interactive shopping experiences for customers. How is augmented reality being integrated into retail experiences to enhance customer engagement? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:26:58,966 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:58,969 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:58.969620, (GMT): 2024-06-29 18:26:58.969620+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:26:58.969620, (GMT): 2024-06-29 18:26:58.969620+00:00\n",
      "2024-06-29 13:26:59,043 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:59,075 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.03 seconds or 7025.37 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.03 seconds or 7025.37 milliseconds.\n",
      "2024-06-29 13:26:59,290 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:59,305 - micro - MainProcess - INFO     CPU usage: 42.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 42.8%\n",
      "2024-06-29 13:26:59,319 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:26:59,346 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:26:59,354 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:59,360 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685619.3601453 Bioinformatics combines biology, computer science, and information technology to analyze biological data. Can you discuss the role of bioinformatics in modern biology and medical research? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685619.3601453 Bioinformatics combines biology, computer science, and information technology to analyze biological data. Can you discuss the role of bioinformatics in modern biology and medical research? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:26:59,368 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:26:59,371 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:59.371326, (GMT): 2024-06-29 18:26:59.371326+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:26:59.371326, (GMT): 2024-06-29 18:26:59.371326+00:00\n",
      "2024-06-29 13:26:59,381 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:59,390 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.55 seconds or 3548.31 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.55 seconds or 3548.31 milliseconds.\n",
      "2024-06-29 13:26:59,435 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:26:59,439 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:26:59,447 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.53 seconds or 3533.97 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.53 seconds or 3533.97 milliseconds.\n",
      "2024-06-29 13:26:59,499 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:00,282 - micro - MainProcess - INFO     CPU usage: 18.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 18.4%\n",
      "2024-06-29 13:27:00,297 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:27:00,321 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:00,327 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:00,330 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685620.3300219 Smart cities use technology to improve urban living conditions, making cities more efficient and sustainable. What are some examples of how smart cities are improving urban living conditions? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685620.3300219 Smart cities use technology to improve urban living conditions, making cities more efficient and sustainable. What are some examples of how smart cities are improving urban living conditions? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:27:00,338 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:00,341 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:00.341219, (GMT): 2024-06-29 18:27:00.341219+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:00.341219, (GMT): 2024-06-29 18:27:00.341219+00:00\n",
      "2024-06-29 13:27:00,451 - micro - MainProcess - INFO     CPU usage: 13.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.8%\n",
      "2024-06-29 13:27:00,462 - micro - MainProcess - INFO     RAM usage: 85.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.6%\n",
      "2024-06-29 13:27:00,504 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:00,516 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:00,521 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685620.5218508 Advancements in neuroscience are providing new insights into how the brain functions and how we can treat neurological disorders. Can you describe the advancements in neuroscience that are helping us understand the brain? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 75 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685620.5218508 Advancements in neuroscience are providing new insights into how the brain functions and how we can treat neurological disorders. Can you describe the advancements in neuroscience that are helping us understand the brain? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 75\n",
      "2024-06-29 13:27:00,528 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:00,531 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:00.531787, (GMT): 2024-06-29 18:27:00.531787+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:00.531787, (GMT): 2024-06-29 18:27:00.531787+00:00\n",
      "2024-06-29 13:27:00,538 - micro - MainProcess - INFO     CPU usage: 28.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 28.8%\n",
      "2024-06-29 13:27:00,551 - micro - MainProcess - INFO     RAM usage: 85.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.6%\n",
      "2024-06-29 13:27:00,596 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:00,607 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:00,611 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685620.6113238 Sustainable development seeks to meet the needs of the present without compromising the ability of future generations to meet their own needs. What are some challenges and solutions in implementing sustainable development practices? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685620.6113238 Sustainable development seeks to meet the needs of the present without compromising the ability of future generations to meet their own needs. What are some challenges and solutions in implementing sustainable development practices? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:27:00,617 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:00,623 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:00.623052, (GMT): 2024-06-29 18:27:00.623052+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:00.623052, (GMT): 2024-06-29 18:27:00.623052+00:00\n",
      "2024-06-29 13:27:00,728 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:00,857 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.7 seconds or 3702.21 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.7 seconds or 3702.21 milliseconds.\n",
      "2024-06-29 13:27:00,916 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:01,923 - micro - MainProcess - INFO     CPU usage: 21.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 21.5%\n",
      "2024-06-29 13:27:01,935 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:27:01,962 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:01,970 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:01,974 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685621.9734912 The Internet of Things (IoT) refers to a network of interconnected devices that communicate and share data. Can you explain the concept of the Internet of Things and provide some real-world examples? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 77 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685621.9734912 The Internet of Things (IoT) refers to a network of interconnected devices that communicate and share data. Can you explain the concept of the Internet of Things and provide some real-world examples? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 77\n",
      "2024-06-29 13:27:01,982 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:01,986 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:01.986537, (GMT): 2024-06-29 18:27:01.986537+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:01.986537, (GMT): 2024-06-29 18:27:01.986537+00:00\n",
      "2024-06-29 13:27:02,975 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:02,993 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.62 seconds or 3619.09 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.62 seconds or 3619.09 milliseconds.\n",
      "2024-06-29 13:27:03,048 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:04,055 - micro - MainProcess - INFO     CPU usage: 14.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.5%\n",
      "2024-06-29 13:27:04,066 - micro - MainProcess - INFO     RAM usage: 85.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.6%\n",
      "2024-06-29 13:27:04,085 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:04,092 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:04,095 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685624.0954204 Natural language processing (NLP) enables computers to understand and generate human language. How does natural language processing enable computers to understand human language? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685624.0954204 Natural language processing (NLP) enables computers to understand and generate human language. How does natural language processing enable computers to understand human language? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:27:04,104 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:04,109 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:04.108181, (GMT): 2024-06-29 18:27:04.108181+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:04.108181, (GMT): 2024-06-29 18:27:04.108181+00:00\n",
      "2024-06-29 13:27:04,563 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:04,596 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:04,600 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.97 seconds or 3971.6 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.97 seconds or 3971.6 milliseconds.\n",
      "2024-06-29 13:27:04,653 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:04,657 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.12 seconds or 4120.91 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.12 seconds or 4120.91 milliseconds.\n",
      "2024-06-29 13:27:04,705 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:04,752 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:04,784 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.98 seconds or 6983.96 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.98 seconds or 6983.96 milliseconds.\n",
      "2024-06-29 13:27:04,862 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:05,549 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:05,582 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.59 seconds or 3592.32 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.59 seconds or 3592.32 milliseconds.\n",
      "2024-06-29 13:27:05,640 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:05,645 - micro - MainProcess - INFO     CPU usage: 19.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.6%\n",
      "2024-06-29 13:27:05,656 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:27:05,672 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:05,680 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:05,694 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685625.6931374 Social media trends influence consumer behavior and marketing strategies, shaping how brands interact with their audiences. Can you discuss the impact of social media trends on consumer behavior and marketing? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685625.6931374 Social media trends influence consumer behavior and marketing strategies, shaping how brands interact with their audiences. Can you discuss the impact of social media trends on consumer behavior and marketing? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:27:05,701 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:05,704 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:05.704883, (GMT): 2024-06-29 18:27:05.704883+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:05.704883, (GMT): 2024-06-29 18:27:05.704883+00:00\n",
      "2024-06-29 13:27:05,743 - micro - MainProcess - INFO     CPU usage: 22.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 22.2%\n",
      "2024-06-29 13:27:05,760 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:27:05,814 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:05,829 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:05,834 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685625.834339 The circular economy aims to minimize waste and make the most of resources by creating closed-loop systems. What are the benefits of a circular economy, and how does it promote sustainability? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685625.834339 The circular economy aims to minimize waste and make the most of resources by creating closed-loop systems. What are the benefits of a circular economy, and how does it promote sustainability? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:27:05,842 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:05,845 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:05.845706, (GMT): 2024-06-29 18:27:05.845706+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:05.845706, (GMT): 2024-06-29 18:27:05.845706+00:00\n",
      "2024-06-29 13:27:05,862 - micro - MainProcess - INFO     CPU usage: 70.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 70.0%\n",
      "2024-06-29 13:27:05,984 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:27:06,007 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:06,015 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:06,020 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685626.020871 Autonomous vehicles, or self-driving cars, have the potential to revolutionize transportation, but they also pose significant challenges. What are the benefits and risks of autonomous vehicles on our roads? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685626.020871 Autonomous vehicles, or self-driving cars, have the potential to revolutionize transportation, but they also pose significant challenges. What are the benefits and risks of autonomous vehicles on our roads? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:27:06,027 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:06,030 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:06.030969, (GMT): 2024-06-29 18:27:06.030969+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:06.030969, (GMT): 2024-06-29 18:27:06.030969+00:00\n",
      "2024-06-29 13:27:06,044 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:06,051 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.08 seconds or 7076.91 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.08 seconds or 7076.91 milliseconds.\n",
      "2024-06-29 13:27:06,113 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:06,666 - micro - MainProcess - INFO     CPU usage: 24.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 24.6%\n",
      "2024-06-29 13:27:06,680 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:27:06,701 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:06,708 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:06,713 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685626.7121258 Cybersecurity is crucial in protecting our personal and professional data from malicious attacks. How does cybersecurity protect our personal data, and what measures can individuals take? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 69 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685626.7121258 Cybersecurity is crucial in protecting our personal and professional data from malicious attacks. How does cybersecurity protect our personal data, and what measures can individuals take? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 69\n",
      "2024-06-29 13:27:06,717 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:06,719 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:06.719653, (GMT): 2024-06-29 18:27:06.719653+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:06.719653, (GMT): 2024-06-29 18:27:06.719653+00:00\n",
      "2024-06-29 13:27:07,127 - micro - MainProcess - INFO     CPU usage: 9.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 9.4%\n",
      "2024-06-29 13:27:07,138 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:27:07,157 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:07,162 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:07,167 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685627.166653 Electric vehicles (EVs) offer a cleaner alternative to traditional gasoline-powered cars, but their widespread adoption poses challenges. What are the potential environmental impacts of widespread adoption of electric vehicles? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685627.166653 Electric vehicles (EVs) offer a cleaner alternative to traditional gasoline-powered cars, but their widespread adoption poses challenges. What are the potential environmental impacts of widespread adoption of electric vehicles? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:27:07,175 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:07,187 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:07.187544, (GMT): 2024-06-29 18:27:07.187544+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:07.187544, (GMT): 2024-06-29 18:27:07.187544+00:00\n",
      "2024-06-29 13:27:07,453 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:07,457 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.35 seconds or 3345.47 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.35 seconds or 3345.47 milliseconds.\n",
      "2024-06-29 13:27:07,585 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:07,591 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:07,596 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.25 seconds or 7251.62 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.25 seconds or 7251.62 milliseconds.\n",
      "2024-06-29 13:27:07,642 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:07,868 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:07,901 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.94 seconds or 9936.33 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.94 seconds or 9936.33 milliseconds.\n",
      "2024-06-29 13:27:07,949 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:08,583 - micro - MainProcess - INFO     CPU usage: 17.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 17.9%\n",
      "2024-06-29 13:27:08,593 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:27:08,608 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:08,614 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:08,624 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685628.6248825 Drones are being used in various industries, from agriculture to logistics, due to their versatility. What are the potential uses of drones in agriculture and other industries? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685628.6248825 Drones are being used in various industries, from agriculture to logistics, due to their versatility. What are the potential uses of drones in agriculture and other industries? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:27:08,632 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:08,636 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:08.636938, (GMT): 2024-06-29 18:27:08.636938+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:08.636938, (GMT): 2024-06-29 18:27:08.636938+00:00\n",
      "2024-06-29 13:27:08,643 - micro - MainProcess - INFO     CPU usage: 6.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 6.1%\n",
      "2024-06-29 13:27:08,657 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:27:08,694 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:08,705 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:08,710 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685628.710316 Fintech innovations are transforming the financial industry, making services more accessible and efficient. How is fintech innovation changing the banking and finance industry? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685628.710316 Fintech innovations are transforming the financial industry, making services more accessible and efficient. How is fintech innovation changing the banking and finance industry? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:27:08,716 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:08,719 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:08.719970, (GMT): 2024-06-29 18:27:08.719970+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:08.719970, (GMT): 2024-06-29 18:27:08.719970+00:00\n",
      "2024-06-29 13:27:08,951 - micro - MainProcess - INFO     CPU usage: 10.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 10.4%\n",
      "2024-06-29 13:27:08,963 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:27:08,984 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:08,990 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:08,995 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685628.9956481 Nanotechnology involves manipulating matter at the atomic and molecular scale for various applications. How is nanotechnology being used in medical treatments and drug delivery systems? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685628.9956481 Nanotechnology involves manipulating matter at the atomic and molecular scale for various applications. How is nanotechnology being used in medical treatments and drug delivery systems? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:27:09,002 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:09,007 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:09.007581, (GMT): 2024-06-29 18:27:09.007581+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:09.007581, (GMT): 2024-06-29 18:27:09.007581+00:00\n",
      "2024-06-29 13:27:09,471 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:09,474 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.76 seconds or 3763.07 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.76 seconds or 3763.07 milliseconds.\n",
      "2024-06-29 13:27:09,537 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:09,541 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:09,546 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.7 seconds or 3695.75 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.7 seconds or 3695.75 milliseconds.\n",
      "2024-06-29 13:27:09,595 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:10,146 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:10,178 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.45 seconds or 3454.79 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.45 seconds or 3454.79 milliseconds.\n",
      "2024-06-29 13:27:10,234 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:10,559 - micro - MainProcess - INFO     CPU usage: 15.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.6%\n",
      "2024-06-29 13:27:10,570 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:27:10,584 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:10,594 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:10,597 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685630.5975149 Artificial intelligence (AI) is being used to improve the accuracy and efficiency of medical diagnoses. How is artificial intelligence being used to improve the accuracy of medical diagnoses? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685630.5975149 Artificial intelligence (AI) is being used to improve the accuracy and efficiency of medical diagnoses. How is artificial intelligence being used to improve the accuracy of medical diagnoses? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:27:10,611 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:10,614 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:10.614309, (GMT): 2024-06-29 18:27:10.614309+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:10.614309, (GMT): 2024-06-29 18:27:10.614309+00:00\n",
      "2024-06-29 13:27:10,620 - micro - MainProcess - INFO     CPU usage: 15.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.2%\n",
      "2024-06-29 13:27:10,633 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:27:10,656 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:10,660 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:10,665 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685630.6656785 Agritech innovations are improving agricultural productivity and sustainability through the use of technology. How are advancements in agritech improving food production and sustainability? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 66 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685630.6656785 Agritech innovations are improving agricultural productivity and sustainability through the use of technology. How are advancements in agritech improving food production and sustainability? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 66\n",
      "2024-06-29 13:27:10,679 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:10,691 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:10.691251, (GMT): 2024-06-29 18:27:10.691251+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:10.691251, (GMT): 2024-06-29 18:27:10.691251+00:00\n",
      "2024-06-29 13:27:11,242 - micro - MainProcess - INFO     CPU usage: 12.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.4%\n",
      "2024-06-29 13:27:11,254 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:27:11,277 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:11,283 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:11,288 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685631.2877903 Renewable energy sources, such as solar and wind power, are essential in reducing our reliance on fossil fuels. What are the environmental benefits of renewable energy sources compared to fossil fuels? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685631.2877903 Renewable energy sources, such as solar and wind power, are essential in reducing our reliance on fossil fuels. What are the environmental benefits of renewable energy sources compared to fossil fuels? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:27:11,293 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:11,296 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:11.296307, (GMT): 2024-06-29 18:27:11.296307+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:11.296307, (GMT): 2024-06-29 18:27:11.296307+00:00\n",
      "2024-06-29 13:27:12,238 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:12,269 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.63 seconds or 3628.62 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.63 seconds or 3628.62 milliseconds.\n",
      "2024-06-29 13:27:12,439 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:12,741 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:12,773 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.74 seconds or 6737.26 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.74 seconds or 6737.26 milliseconds.\n",
      "2024-06-29 13:27:12,829 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:13,455 - micro - MainProcess - INFO     CPU usage: 17.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 17.3%\n",
      "2024-06-29 13:27:13,465 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:27:13,490 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:13,495 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:13,498 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685633.498373 Cloud computing provides on-demand access to computing resources over the internet. How does cloud computing enhance business operations and data management? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 62 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685633.498373 Cloud computing provides on-demand access to computing resources over the internet. How does cloud computing enhance business operations and data management? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 62\n",
      "2024-06-29 13:27:13,508 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:13,512 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:13.512118, (GMT): 2024-06-29 18:27:13.512118+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:13.512118, (GMT): 2024-06-29 18:27:13.512118+00:00\n",
      "2024-06-29 13:27:13,724 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:13,757 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.57 seconds or 6566.73 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.57 seconds or 6566.73 milliseconds.\n",
      "2024-06-29 13:27:13,814 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:13,856 - micro - MainProcess - INFO     CPU usage: 20.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 20.3%\n",
      "2024-06-29 13:27:13,866 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:27:13,907 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:13,912 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:13,916 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685633.916216 Augmented reality (AR) overlays digital information onto the real world, providing new ways to interact with our environment. How is augmented reality being used in education and training programs? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685633.916216 Augmented reality (AR) overlays digital information onto the real world, providing new ways to interact with our environment. How is augmented reality being used in education and training programs? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:27:13,924 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:13,928 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:13.927913, (GMT): 2024-06-29 18:27:13.927913+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:13.927913, (GMT): 2024-06-29 18:27:13.927913+00:00\n",
      "2024-06-29 13:27:14,376 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:14,394 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:14,408 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.71 seconds or 3712.65 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.71 seconds or 3712.65 milliseconds.\n",
      "2024-06-29 13:27:14,462 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:14,470 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.85 seconds or 3854.04 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.85 seconds or 3854.04 milliseconds.\n",
      "2024-06-29 13:27:14,621 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:14,822 - micro - MainProcess - INFO     CPU usage: 23.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 23.2%\n",
      "2024-06-29 13:27:14,834 - micro - MainProcess - INFO     RAM usage: 86.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.0%\n",
      "2024-06-29 13:27:14,850 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:14,856 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:14,860 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685634.8604627 Robots are being programmed to perform increasingly complex tasks in various industries, from manufacturing to healthcare. How do robots learn to perform complex tasks, and what are some examples of their use in industry? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 77 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685634.8604627 Robots are being programmed to perform increasingly complex tasks in various industries, from manufacturing to healthcare. How do robots learn to perform complex tasks, and what are some examples of their use in industry? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 77\n",
      "2024-06-29 13:27:14,866 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:14,870 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:14.870999, (GMT): 2024-06-29 18:27:14.870999+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:14.870999, (GMT): 2024-06-29 18:27:14.870999+00:00\n",
      "2024-06-29 13:27:14,880 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:14,908 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.61 seconds or 3609.57 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.61 seconds or 3609.57 milliseconds.\n",
      "2024-06-29 13:27:14,954 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:15,419 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:15,448 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.72 seconds or 6723.2 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.72 seconds or 6723.2 milliseconds.\n",
      "2024-06-29 13:27:15,502 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:15,508 - micro - MainProcess - INFO     CPU usage: 19.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.4%\n",
      "2024-06-29 13:27:15,521 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:27:15,555 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:15,561 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:15,564 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685635.5640342 Urban planning involves designing and organizing urban spaces to improve the quality of life for residents. What is the role of urban planning in creating more livable and sustainable cities? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685635.5640342 Urban planning involves designing and organizing urban spaces to improve the quality of life for residents. What is the role of urban planning in creating more livable and sustainable cities? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:27:15,570 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:15,573 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:15.573554, (GMT): 2024-06-29 18:27:15.573554+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:15.573554, (GMT): 2024-06-29 18:27:15.573554+00:00\n",
      "2024-06-29 13:27:15,619 - micro - MainProcess - INFO     CPU usage: 25.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 25.9%\n",
      "2024-06-29 13:27:15,632 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:27:15,658 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:15,668 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:15,672 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685635.672562 Blockchain technology offers transparent and secure ways to track products through the supply chain. What are the key benefits of using blockchain for supply chain management? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 66 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685635.672562 Blockchain technology offers transparent and secure ways to track products through the supply chain. What are the key benefits of using blockchain for supply chain management? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 66\n",
      "2024-06-29 13:27:15,678 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:15,681 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:15.681813, (GMT): 2024-06-29 18:27:15.681813+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:15.681813, (GMT): 2024-06-29 18:27:15.681813+00:00\n",
      "2024-06-29 13:27:15,691 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:15,735 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.72 seconds or 6724.28 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.72 seconds or 6724.28 milliseconds.\n",
      "2024-06-29 13:27:15,790 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:15,960 - micro - MainProcess - INFO     CPU usage: 49.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 49.6%\n",
      "2024-06-29 13:27:15,972 - micro - MainProcess - INFO     RAM usage: 86.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.2%\n",
      "2024-06-29 13:27:15,995 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:16,005 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:16,011 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685636.009077 Deep learning, a subset of machine learning, uses neural networks with many layers to analyze complex data. Can you describe the process of deep learning and how it differs from traditional machine learning? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 75 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685636.009077 Deep learning, a subset of machine learning, uses neural networks with many layers to analyze complex data. Can you describe the process of deep learning and how it differs from traditional machine learning? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 75\n",
      "2024-06-29 13:27:16,018 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:16,024 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:16.024972, (GMT): 2024-06-29 18:27:16.024972+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:16.024972, (GMT): 2024-06-29 18:27:16.024972+00:00\n",
      "2024-06-29 13:27:16,511 - micro - MainProcess - INFO     CPU usage: 16.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.3%\n",
      "2024-06-29 13:27:16,522 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:27:16,539 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:16,547 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:16,550 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685636.5503407 Telemedicine allows healthcare providers to consult with patients remotely, increasing access to care. What are the benefits and challenges of telemedicine for both patients and healthcare providers? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685636.5503407 Telemedicine allows healthcare providers to consult with patients remotely, increasing access to care. What are the benefits and challenges of telemedicine for both patients and healthcare providers? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:27:16,557 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:16,565 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:16.563387, (GMT): 2024-06-29 18:27:16.563387+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:16.563387, (GMT): 2024-06-29 18:27:16.563387+00:00\n",
      "2024-06-29 13:27:16,748 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:16,779 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.26 seconds or 3263.65 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.26 seconds or 3263.65 milliseconds.\n",
      "2024-06-29 13:27:16,839 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:16,847 - micro - MainProcess - INFO     CPU usage: 39.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 39.0%\n",
      "2024-06-29 13:27:16,867 - micro - MainProcess - INFO     RAM usage: 86.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.0%\n",
      "2024-06-29 13:27:16,887 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:16,896 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:16,904 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685636.903001 Smart homes use connected devices to automate and control household systems, improving convenience and efficiency. What are the key components of a smart home, and how do they work together? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685636.903001 Smart homes use connected devices to automate and control household systems, improving convenience and efficiency. What are the key components of a smart home, and how do they work together? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:27:16,910 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:16,913 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:16.913989, (GMT): 2024-06-29 18:27:16.913989+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:16.913989, (GMT): 2024-06-29 18:27:16.913989+00:00\n",
      "2024-06-29 13:27:17,847 - micro - MainProcess - INFO     CPU usage: 16.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.6%\n",
      "2024-06-29 13:27:17,857 - micro - MainProcess - INFO     RAM usage: 86.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.0%\n",
      "2024-06-29 13:27:17,877 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:17,885 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:17,966 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685637.9663312 Digital marketing is evolving with new trends and technologies that help businesses reach their audiences. What are some emerging trends in digital marketing that businesses should be aware of? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685637.9663312 Digital marketing is evolving with new trends and technologies that help businesses reach their audiences. What are some emerging trends in digital marketing that businesses should be aware of? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:27:17,973 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:17,975 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:17.975196, (GMT): 2024-06-29 18:27:17.975196+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:17.975196, (GMT): 2024-06-29 18:27:17.975196+00:00\n",
      "2024-06-29 13:27:18,805 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:18,837 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.15 seconds or 3148.58 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.15 seconds or 3148.58 milliseconds.\n",
      "2024-06-29 13:27:18,889 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:19,064 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:19,096 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.07 seconds or 3065.59 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.07 seconds or 3065.59 milliseconds.\n",
      "2024-06-29 13:27:19,151 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:19,862 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:19,913 - micro - MainProcess - INFO     CPU usage: 14.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.8%\n",
      "2024-06-29 13:27:19,923 - micro - MainProcess - INFO     RAM usage: 86.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.1%\n",
      "2024-06-29 13:27:19,943 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:19,951 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:19,955 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685639.9541903 Smart grids use digital technology to manage the production and distribution of electricity more efficiently. How is the development of smart grids contributing to more efficient energy distribution? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 69 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685639.9541903 Smart grids use digital technology to manage the production and distribution of electricity more efficiently. How is the development of smart grids contributing to more efficient energy distribution? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 69\n",
      "2024-06-29 13:27:19,981 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:19,989 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:19.989391, (GMT): 2024-06-29 18:27:19.989391+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:19.989391, (GMT): 2024-06-29 18:27:19.989391+00:00\n",
      "2024-06-29 13:27:19,994 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.42 seconds or 4417.62 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.42 seconds or 4417.62 milliseconds.\n",
      "2024-06-29 13:27:20,052 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:20,159 - micro - MainProcess - INFO     CPU usage: 35.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 35.8%\n",
      "2024-06-29 13:27:20,170 - micro - MainProcess - INFO     RAM usage: 86.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.0%\n",
      "2024-06-29 13:27:20,202 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:20,208 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:20,212 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685640.2129142 The rollout of 5G technology promises faster internet speeds and more reliable connections. What are some potential applications of 5G technology in everyday life? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 69 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685640.2129142 The rollout of 5G technology promises faster internet speeds and more reliable connections. What are some potential applications of 5G technology in everyday life? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 69\n",
      "2024-06-29 13:27:20,220 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:20,225 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:20.225447, (GMT): 2024-06-29 18:27:20.225447+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:20.225447, (GMT): 2024-06-29 18:27:20.225447+00:00\n",
      "2024-06-29 13:27:20,847 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:20,876 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.94 seconds or 6942.9 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.94 seconds or 6942.9 milliseconds.\n",
      "2024-06-29 13:27:20,948 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:21,064 - micro - MainProcess - INFO     CPU usage: 12.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.6%\n",
      "2024-06-29 13:27:21,074 - micro - MainProcess - INFO     RAM usage: 86.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.0%\n",
      "2024-06-29 13:27:21,091 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:21,097 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:21,101 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685641.1010852 Autonomous drones can operate without human intervention, offering various applications in different industries. How do autonomous drones operate, and what are their potential applications? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685641.1010852 Autonomous drones can operate without human intervention, offering various applications in different industries. How do autonomous drones operate, and what are their potential applications? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:27:21,106 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:21,122 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:21.122362, (GMT): 2024-06-29 18:27:21.122362+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:21.122362, (GMT): 2024-06-29 18:27:21.122362+00:00\n",
      "2024-06-29 13:27:21,953 - micro - MainProcess - INFO     CPU usage: 20.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 20.7%\n",
      "2024-06-29 13:27:21,963 - micro - MainProcess - INFO     RAM usage: 86.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.2%\n",
      "2024-06-29 13:27:21,991 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:21,998 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:22,001 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685642.0011678 Genetic engineering allows scientists to modify the DNA of organisms, leading to advancements in medicine and agriculture. What are the latest advancements in genetic engineering, and how might they affect healthcare? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685642.0011678 Genetic engineering allows scientists to modify the DNA of organisms, leading to advancements in medicine and agriculture. What are the latest advancements in genetic engineering, and how might they affect healthcare? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:27:22,007 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:22,011 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:22.011062, (GMT): 2024-06-29 18:27:22.011062+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:22.011062, (GMT): 2024-06-29 18:27:22.011062+00:00\n",
      "2024-06-29 13:27:22,201 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:22,230 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.36 seconds or 7356.37 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.36 seconds or 7356.37 milliseconds.\n",
      "2024-06-29 13:27:22,305 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:22,413 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:22,446 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.47 seconds or 4467.91 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.47 seconds or 4467.91 milliseconds.\n",
      "2024-06-29 13:27:22,504 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:23,315 - micro - MainProcess - INFO     CPU usage: 9.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 9.6%\n",
      "2024-06-29 13:27:23,329 - micro - MainProcess - INFO     RAM usage: 86.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.2%\n",
      "2024-06-29 13:27:23,371 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:23,375 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:23,383 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685643.3831103 Sustainable development seeks to meet the needs of the present without compromising the ability of future generations to meet their own needs. What are some challenges and solutions in implementing sustainable development practices? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685643.3831103 Sustainable development seeks to meet the needs of the present without compromising the ability of future generations to meet their own needs. What are some challenges and solutions in implementing sustainable development practices? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:27:23,389 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:23,394 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:23.394419, (GMT): 2024-06-29 18:27:23.394419+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:23.394419, (GMT): 2024-06-29 18:27:23.394419+00:00\n",
      "2024-06-29 13:27:23,515 - micro - MainProcess - INFO     CPU usage: 56.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 56.1%\n",
      "2024-06-29 13:27:23,551 - micro - MainProcess - INFO     RAM usage: 86.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.1%\n",
      "2024-06-29 13:27:23,569 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:23,578 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:23,584 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685643.5834563 Genetic modification in crops aims to improve yield, resistance to pests, and nutritional value. Can you explain the principles of genetic modification in crops and its impact on agriculture? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685643.5834563 Genetic modification in crops aims to improve yield, resistance to pests, and nutritional value. Can you explain the principles of genetic modification in crops and its impact on agriculture? Please write a response that should be at least 250 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:27:23,592 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:23,595 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:23.595905, (GMT): 2024-06-29 18:27:23.595905+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-29 13:27:23.595905, (GMT): 2024-06-29 18:27:23.595905+00:00\n",
      "2024-06-29 13:27:23,665 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:23,678 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:23,694 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.7 seconds or 3700.02 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.7 seconds or 3700.02 milliseconds.\n",
      "2024-06-29 13:27:23,738 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:23,751 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.52 seconds or 3522.3 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.52 seconds or 3522.3 milliseconds.\n",
      "2024-06-29 13:27:23,797 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:23,990 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:24,018 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.45 seconds or 7448.13 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.45 seconds or 7448.13 milliseconds.\n",
      "2024-06-29 13:27:24,070 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:24,229 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:24,256 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.34 seconds or 7338.56 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.34 seconds or 7338.56 milliseconds.\n",
      "2024-06-29 13:27:24,299 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:24,661 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:24,696 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.57 seconds or 3572.21 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.57 seconds or 3572.21 milliseconds.\n",
      "2024-06-29 13:27:24,756 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:25,087 - micro - MainProcess - INFO     CPU usage: 23.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 23.0%\n",
      "2024-06-29 13:27:25,098 - micro - MainProcess - INFO     RAM usage: 86.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.0%\n",
      "2024-06-29 13:27:25,120 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:25,127 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:25,131 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685645.1312191 Bioinformatics combines biology, computer science, and information technology to analyze biological data. Can you discuss the role of bioinformatics in modern biology and medical research? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685645.1312191 Bioinformatics combines biology, computer science, and information technology to analyze biological data. Can you discuss the role of bioinformatics in modern biology and medical research? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:27:25,139 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:25,142 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:25.142315, (GMT): 2024-06-29 18:27:25.142315+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:25.142315, (GMT): 2024-06-29 18:27:25.142315+00:00\n",
      "2024-06-29 13:27:25,293 - micro - MainProcess - INFO     CPU usage: 46.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 46.9%\n",
      "2024-06-29 13:27:25,305 - micro - MainProcess - INFO     RAM usage: 86.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.0%\n",
      "2024-06-29 13:27:25,326 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:25,333 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:25,339 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685645.3395553 Advancements in neuroscience are providing new insights into how the brain functions and how we can treat neurological disorders. Can you describe the advancements in neuroscience that are helping us understand the brain? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 75 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685645.3395553 Advancements in neuroscience are providing new insights into how the brain functions and how we can treat neurological disorders. Can you describe the advancements in neuroscience that are helping us understand the brain? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 75\n",
      "2024-06-29 13:27:25,345 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:25,349 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:25.349087, (GMT): 2024-06-29 18:27:25.349161+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:25.349087, (GMT): 2024-06-29 18:27:25.349161+00:00\n",
      "2024-06-29 13:27:26,624 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:26,654 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.06 seconds or 3055.08 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.06 seconds or 3055.08 milliseconds.\n",
      "2024-06-29 13:27:26,799 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:29,266 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:29,310 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.3 seconds or 7295.74 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.3 seconds or 7295.74 milliseconds.\n",
      "2024-06-29 13:27:29,379 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:29,405 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:29,433 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.03 seconds or 6034.39 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.03 seconds or 6034.39 milliseconds.\n",
      "2024-06-29 13:27:29,493 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:30,379 - micro - MainProcess - INFO     CPU usage: 17.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 17.5%\n",
      "2024-06-29 13:27:30,390 - micro - MainProcess - INFO     RAM usage: 86.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.3%\n",
      "2024-06-29 13:27:30,412 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:30,420 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:30,425 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685650.4243302 The Internet of Things (IoT) refers to a network of interconnected devices that communicate and share data. Can you explain the concept of the Internet of Things and provide some real-world examples? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 77 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685650.4243302 The Internet of Things (IoT) refers to a network of interconnected devices that communicate and share data. Can you explain the concept of the Internet of Things and provide some real-world examples? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 77\n",
      "2024-06-29 13:27:30,431 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:30,433 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:30.433344, (GMT): 2024-06-29 18:27:30.433344+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:30.433344, (GMT): 2024-06-29 18:27:30.433344+00:00\n",
      "2024-06-29 13:27:30,487 - micro - MainProcess - INFO     CPU usage: 18.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 18.4%\n",
      "2024-06-29 13:27:30,497 - micro - MainProcess - INFO     RAM usage: 86.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.3%\n",
      "2024-06-29 13:27:30,521 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:30,528 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:30,531 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685650.5312898 Social media trends influence consumer behavior and marketing strategies, shaping how brands interact with their audiences. Can you discuss the impact of social media trends on consumer behavior and marketing? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685650.5312898 Social media trends influence consumer behavior and marketing strategies, shaping how brands interact with their audiences. Can you discuss the impact of social media trends on consumer behavior and marketing? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:27:30,542 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:30,548 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:30.548054, (GMT): 2024-06-29 18:27:30.548054+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:30.548054, (GMT): 2024-06-29 18:27:30.548054+00:00\n",
      "2024-06-29 13:27:31,147 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:31,152 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.01 seconds or 6006.0 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.01 seconds or 6006.0 milliseconds.\n",
      "2024-06-29 13:27:31,215 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:31,265 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:31,301 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.95 seconds or 5948.87 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.95 seconds or 5948.87 milliseconds.\n",
      "2024-06-29 13:27:31,436 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:32,233 - micro - MainProcess - INFO     CPU usage: 20.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 20.9%\n",
      "2024-06-29 13:27:32,263 - micro - MainProcess - INFO     RAM usage: 86.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.3%\n",
      "2024-06-29 13:27:32,297 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:32,304 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:32,310 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685652.3087704 Natural language processing (NLP) enables computers to understand and generate human language. How does natural language processing enable computers to understand human language? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685652.3087704 Natural language processing (NLP) enables computers to understand and generate human language. How does natural language processing enable computers to understand human language? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:27:32,317 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:32,322 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:32.322504, (GMT): 2024-06-29 18:27:32.322504+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:32.322504, (GMT): 2024-06-29 18:27:32.322504+00:00\n",
      "2024-06-29 13:27:32,447 - micro - MainProcess - INFO     CPU usage: 40.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 40.5%\n",
      "2024-06-29 13:27:32,457 - micro - MainProcess - INFO     RAM usage: 86.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.4%\n",
      "2024-06-29 13:27:32,497 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:32,502 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:32,508 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685652.5081227 The circular economy aims to minimize waste and make the most of resources by creating closed-loop systems. What are the benefits of a circular economy, and how does it promote sustainability? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685652.5081227 The circular economy aims to minimize waste and make the most of resources by creating closed-loop systems. What are the benefits of a circular economy, and how does it promote sustainability? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 74\n",
      "2024-06-29 13:27:32,515 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:32,519 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:32.519170, (GMT): 2024-06-29 18:27:32.519170+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:32.519170, (GMT): 2024-06-29 18:27:32.519170+00:00\n",
      "2024-06-29 13:27:36,707 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:36,711 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:36,739 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.3 seconds or 6301.74 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.3 seconds or 6301.74 milliseconds.\n",
      "2024-06-29 13:27:36,820 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:36,826 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.27 seconds or 6272.1 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.27 seconds or 6272.1 milliseconds.\n",
      "2024-06-29 13:27:36,876 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:37,823 - micro - MainProcess - INFO     CPU usage: 12.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.9%\n",
      "2024-06-29 13:27:37,833 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:27:37,851 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:37,857 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:37,861 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685657.8618524 Cybersecurity is crucial in protecting our personal and professional data from malicious attacks. How does cybersecurity protect our personal data, and what measures can individuals take? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 69 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685657.8618524 Cybersecurity is crucial in protecting our personal and professional data from malicious attacks. How does cybersecurity protect our personal data, and what measures can individuals take? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 69\n",
      "2024-06-29 13:27:37,869 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:37,874 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:37.874393, (GMT): 2024-06-29 18:27:37.874393+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:37.874393, (GMT): 2024-06-29 18:27:37.874393+00:00\n",
      "2024-06-29 13:27:37,882 - micro - MainProcess - INFO     CPU usage: 16.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.0%\n",
      "2024-06-29 13:27:37,895 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:27:37,930 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:37,939 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:37,943 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685657.9433637 Artificial intelligence (AI) is being used to improve the accuracy and efficiency of medical diagnoses. How is artificial intelligence being used to improve the accuracy of medical diagnoses? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 71 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685657.9433637 Artificial intelligence (AI) is being used to improve the accuracy and efficiency of medical diagnoses. How is artificial intelligence being used to improve the accuracy of medical diagnoses? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 71\n",
      "2024-06-29 13:27:37,948 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:37,952 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:37.952481, (GMT): 2024-06-29 18:27:37.952481+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:37.952481, (GMT): 2024-06-29 18:27:37.952481+00:00\n",
      "2024-06-29 13:27:39,007 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:39,037 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.71 seconds or 6709.28 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.71 seconds or 6709.28 milliseconds.\n",
      "2024-06-29 13:27:39,106 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:39,162 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:39,184 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.66 seconds or 6660.5 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.66 seconds or 6660.5 milliseconds.\n",
      "2024-06-29 13:27:39,295 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:40,108 - micro - MainProcess - INFO     CPU usage: 16.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.9%\n",
      "2024-06-29 13:27:40,118 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:27:40,132 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:40,139 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:40,142 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685660.142985 Drones are being used in various industries, from agriculture to logistics, due to their versatility. What are the potential uses of drones in agriculture and other industries? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685660.142985 Drones are being used in various industries, from agriculture to logistics, due to their versatility. What are the potential uses of drones in agriculture and other industries? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:27:40,150 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:40,153 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:40.153418, (GMT): 2024-06-29 18:27:40.153418+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:40.153418, (GMT): 2024-06-29 18:27:40.153418+00:00\n",
      "2024-06-29 13:27:40,308 - micro - MainProcess - INFO     CPU usage: 30.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 30.2%\n",
      "2024-06-29 13:27:40,318 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:27:40,337 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:40,343 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:40,347 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685660.3463156 Agritech innovations are improving agricultural productivity and sustainability through the use of technology. How are advancements in agritech improving food production and sustainability? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 66 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685660.3463156 Agritech innovations are improving agricultural productivity and sustainability through the use of technology. How are advancements in agritech improving food production and sustainability? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 66\n",
      "2024-06-29 13:27:40,353 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:40,358 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:40.358608, (GMT): 2024-06-29 18:27:40.358608+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:40.358608, (GMT): 2024-06-29 18:27:40.358608+00:00\n",
      "2024-06-29 13:27:44,314 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:44,346 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.47 seconds or 6467.4 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.47 seconds or 6467.4 milliseconds.\n",
      "2024-06-29 13:27:44,424 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:44,797 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:44,829 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.87 seconds or 6873.27 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.87 seconds or 6873.27 milliseconds.\n",
      "2024-06-29 13:27:44,880 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:45,423 - micro - MainProcess - INFO     CPU usage: 10.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 10.7%\n",
      "2024-06-29 13:27:45,433 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:27:45,461 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:45,467 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:45,471 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685665.470518 Renewable energy sources, such as solar and wind power, are essential in reducing our reliance on fossil fuels. What are the environmental benefits of renewable energy sources compared to fossil fuels? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685665.470518 Renewable energy sources, such as solar and wind power, are essential in reducing our reliance on fossil fuels. What are the environmental benefits of renewable energy sources compared to fossil fuels? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 73\n",
      "2024-06-29 13:27:45,528 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:45,539 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:45.539582, (GMT): 2024-06-29 18:27:45.539582+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:45.539582, (GMT): 2024-06-29 18:27:45.539582+00:00\n",
      "2024-06-29 13:27:45,889 - micro - MainProcess - INFO     CPU usage: 28.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 28.1%\n",
      "2024-06-29 13:27:45,899 - micro - MainProcess - INFO     RAM usage: 85.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.5%\n",
      "2024-06-29 13:27:45,916 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:45,923 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:45,927 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685665.9275467 Blockchain technology offers transparent and secure ways to track products through the supply chain. What are the key benefits of using blockchain for supply chain management? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 67 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685665.9275467 Blockchain technology offers transparent and secure ways to track products through the supply chain. What are the key benefits of using blockchain for supply chain management? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 67\n",
      "2024-06-29 13:27:45,934 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:45,937 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:45.937598, (GMT): 2024-06-29 18:27:45.937598+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:45.937598, (GMT): 2024-06-29 18:27:45.937598+00:00\n",
      "2024-06-29 13:27:46,809 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:46,819 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:46,841 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.68 seconds or 6683.64 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.68 seconds or 6683.64 milliseconds.\n",
      "2024-06-29 13:27:46,889 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:46,896 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.53 seconds or 6533.21 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.53 seconds or 6533.21 milliseconds.\n",
      "2024-06-29 13:27:46,966 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:47,906 - micro - MainProcess - INFO     CPU usage: 16.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.2%\n",
      "2024-06-29 13:27:47,916 - micro - MainProcess - INFO     RAM usage: 85.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.6%\n",
      "2024-06-29 13:27:47,942 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:47,950 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:47,953 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685667.9537215 Cloud computing provides on-demand access to computing resources over the internet. How does cloud computing enhance business operations and data management? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 63 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685667.9537215 Cloud computing provides on-demand access to computing resources over the internet. How does cloud computing enhance business operations and data management? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 63\n",
      "2024-06-29 13:27:47,959 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:47,962 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:47.962745, (GMT): 2024-06-29 18:27:47.962745+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:47.962745, (GMT): 2024-06-29 18:27:47.962745+00:00\n",
      "2024-06-29 13:27:47,965 - micro - MainProcess - INFO     CPU usage: 20.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 20.4%\n",
      "2024-06-29 13:27:47,975 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:27:48,015 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:48,022 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:48,026 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685668.0266707 Urban planning involves designing and organizing urban spaces to improve the quality of life for residents. What is the role of urban planning in creating more livable and sustainable cities? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685668.0266707 Urban planning involves designing and organizing urban spaces to improve the quality of life for residents. What is the role of urban planning in creating more livable and sustainable cities? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:27:48,034 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:48,037 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:48.037449, (GMT): 2024-06-29 18:27:48.037449+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:48.037449, (GMT): 2024-06-29 18:27:48.037449+00:00\n",
      "2024-06-29 13:27:52,571 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:52,577 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.02 seconds or 7020.16 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.02 seconds or 7020.16 milliseconds.\n",
      "2024-06-29 13:27:52,647 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:52,900 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:52,931 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.99 seconds or 6990.15 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 6.99 seconds or 6990.15 milliseconds.\n",
      "2024-06-29 13:27:53,102 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:53,646 - micro - MainProcess - INFO     CPU usage: 12.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.7%\n",
      "2024-06-29 13:27:53,657 - micro - MainProcess - INFO     RAM usage: 85.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.5%\n",
      "2024-06-29 13:27:53,673 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:53,681 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:53,684 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685673.6849089 Deep learning, a subset of machine learning, uses neural networks with many layers to analyze complex data. Can you describe the process of deep learning and how it differs from traditional machine learning? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 76 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685673.6849089 Deep learning, a subset of machine learning, uses neural networks with many layers to analyze complex data. Can you describe the process of deep learning and how it differs from traditional machine learning? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 76\n",
      "2024-06-29 13:27:53,692 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:53,695 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:53.695120, (GMT): 2024-06-29 18:27:53.695120+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:53.695120, (GMT): 2024-06-29 18:27:53.695120+00:00\n",
      "2024-06-29 13:27:54,095 - micro - MainProcess - INFO     CPU usage: 35.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 35.4%\n",
      "2024-06-29 13:27:54,105 - micro - MainProcess - INFO     RAM usage: 85.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.5%\n",
      "2024-06-29 13:27:54,122 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:54,127 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:54,132 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685674.1314588 Smart grids use digital technology to manage the production and distribution of electricity more efficiently. How is the development of smart grids contributing to more efficient energy distribution? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 69 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685674.1314588 Smart grids use digital technology to manage the production and distribution of electricity more efficiently. How is the development of smart grids contributing to more efficient energy distribution? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 69\n",
      "2024-06-29 13:27:54,139 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:54,143 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:54.141979, (GMT): 2024-06-29 18:27:54.141979+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:54.141979, (GMT): 2024-06-29 18:27:54.141979+00:00\n",
      "2024-06-29 13:27:55,336 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:55,368 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.4 seconds or 7403.07 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.4 seconds or 7403.07 milliseconds.\n",
      "2024-06-29 13:27:55,460 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:55,464 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:27:55,469 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.43 seconds or 7427.5 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.43 seconds or 7427.5 milliseconds.\n",
      "2024-06-29 13:27:55,562 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:27:56,469 - micro - MainProcess - INFO     CPU usage: 15.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.2%\n",
      "2024-06-29 13:27:56,480 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:27:56,495 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:56,505 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:56,510 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685676.5109882 Digital marketing is evolving with new trends and technologies that help businesses reach their audiences. What are some emerging trends in digital marketing that businesses should be aware of? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685676.5109882 Digital marketing is evolving with new trends and technologies that help businesses reach their audiences. What are some emerging trends in digital marketing that businesses should be aware of? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 70\n",
      "2024-06-29 13:27:56,515 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:56,519 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:56.519517, (GMT): 2024-06-29 18:27:56.519517+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:56.519517, (GMT): 2024-06-29 18:27:56.519517+00:00\n",
      "2024-06-29 13:27:56,570 - micro - MainProcess - INFO     CPU usage: 28.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 28.7%\n",
      "2024-06-29 13:27:56,582 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:27:56,632 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:27:56,644 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:56,658 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685676.658579 Autonomous drones can operate without human intervention, offering various applications in different industries. How do autonomous drones operate, and what are their potential applications? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 66 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685676.658579 Autonomous drones can operate without human intervention, offering various applications in different industries. How do autonomous drones operate, and what are their potential applications? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 66\n",
      "2024-06-29 13:27:56,670 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:27:56,673 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:56.673110, (GMT): 2024-06-29 18:27:56.673110+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:27:56.673110, (GMT): 2024-06-29 18:27:56.673110+00:00\n",
      "2024-06-29 13:28:01,115 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:28:01,150 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.45 seconds or 7451.31 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.45 seconds or 7451.31 milliseconds.\n",
      "2024-06-29 13:28:01,219 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:28:01,521 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:28:01,548 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.4 seconds or 7402.42 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.4 seconds or 7402.42 milliseconds.\n",
      "2024-06-29 13:28:01,609 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:28:02,241 - micro - MainProcess - INFO     CPU usage: 15.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.1%\n",
      "2024-06-29 13:28:02,251 - micro - MainProcess - INFO     RAM usage: 85.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.4%\n",
      "2024-06-29 13:28:02,275 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:02,282 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:02,287 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685682.286015 The rollout of 5G technology promises faster internet speeds and more reliable connections. What are some potential applications of 5G technology in everyday life? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685682.286015 The rollout of 5G technology promises faster internet speeds and more reliable connections. What are some potential applications of 5G technology in everyday life? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 68\n",
      "2024-06-29 13:28:02,294 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:02,298 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:28:02.297279, (GMT): 2024-06-29 18:28:02.297279+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:28:02.297279, (GMT): 2024-06-29 18:28:02.297279+00:00\n",
      "2024-06-29 13:28:03,831 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:28:03,837 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.31 seconds or 7313.16 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.31 seconds or 7313.16 milliseconds.\n",
      "2024-06-29 13:28:03,896 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:28:03,901 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:28:03,905 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.23 seconds or 7227.89 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.23 seconds or 7227.89 milliseconds.\n",
      "2024-06-29 13:28:03,953 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:28:04,915 - micro - MainProcess - INFO     CPU usage: 12.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.5%\n",
      "2024-06-29 13:28:04,926 - micro - MainProcess - INFO     RAM usage: 85.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.5%\n",
      "2024-06-29 13:28:04,975 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:809)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:04,984 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:05,024 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685685.0233626 Genetic modification in crops aims to improve yield, resistance to pests, and nutritional value. Can you explain the principles of genetic modification in crops and its impact on agriculture? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72 (latencytest.py:make_call:818)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719685685.0233626 Genetic modification in crops aims to improve yield, resistance to pests, and nutritional value. Can you explain the principles of genetic modification in crops and its impact on agriculture? Please write a response that should be at least 500 tokens long.'}] and Context Tokens: 72\n",
      "2024-06-29 13:28:05,032 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:05,044 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:28:05.044345, (GMT): 2024-06-29 18:28:05.044345+00:00 (latencytest.py:make_call:840)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-29 13:28:05.044345, (GMT): 2024-06-29 18:28:05.044345+00:00\n",
      "2024-06-29 13:28:09,306 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:28:09,333 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.03 seconds or 7032.52 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 7.03 seconds or 7032.52 milliseconds.\n",
      "2024-06-29 13:28:09,383 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:28:10,861 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:868)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-29 13:28:10,893 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.83 seconds or 5826.6 milliseconds. (latencytest.py:make_call:879)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.83 seconds or 5826.6 milliseconds.\n",
      "2024-06-29 13:28:10,940 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-29 13:28:16,965 - micro - MainProcess - INFO     Split list into 4 parts. (utils.py:split_list_into_variable_parts:174)\n",
      "INFO:micro:Split list into 4 parts.\n",
      "2024-06-29 13:28:16,968 - micro - MainProcess - INFO     CPU usage: 13.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.5%\n",
      "2024-06-29 13:28:16,979 - micro - MainProcess - INFO     RAM usage: 85.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.2%\n",
      "2024-06-29 13:28:16,999 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:17,004 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:17,009 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:17,014 - micro - MainProcess - INFO     CPU usage: 16.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.7%\n",
      "2024-06-29 13:28:17,029 - micro - MainProcess - INFO     RAM usage: 85.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.3%\n",
      "2024-06-29 13:28:17,083 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:17,086 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:17,090 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:17,093 - micro - MainProcess - INFO     CPU usage: 45.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 45.2%\n",
      "2024-06-29 13:28:17,103 - micro - MainProcess - INFO     RAM usage: 85.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.4%\n",
      "2024-06-29 13:28:17,128 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:17,132 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:17,137 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:17,141 - micro - MainProcess - INFO     CPU usage: 8.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 8.1%\n",
      "2024-06-29 13:28:17,156 - micro - MainProcess - INFO     RAM usage: 85.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.3%\n",
      "2024-06-29 13:28:17,182 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:17,186 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:17,190 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:17,197 - micro - MainProcess - INFO     CPU usage: 19.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.6%\n",
      "2024-06-29 13:28:17,211 - micro - MainProcess - INFO     RAM usage: 85.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.4%\n",
      "2024-06-29 13:28:17,235 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:17,241 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:17,242 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:17,249 - micro - MainProcess - INFO     CPU usage: 20.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 20.0%\n",
      "2024-06-29 13:28:17,261 - micro - MainProcess - INFO     RAM usage: 85.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.4%\n",
      "2024-06-29 13:28:17,287 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:17,290 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:17,294 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:17,297 - micro - MainProcess - INFO     CPU usage: 12.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.5%\n",
      "2024-06-29 13:28:17,309 - micro - MainProcess - INFO     RAM usage: 85.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.5%\n",
      "2024-06-29 13:28:17,333 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:17,336 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:17,342 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:17,346 - micro - MainProcess - INFO     CPU usage: 11.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 11.4%\n",
      "2024-06-29 13:28:17,358 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:28:17,382 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:17,384 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:17,389 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:26,876 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.16 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 3.16 seconds.\n",
      "2024-06-29 13:28:26,882 - micro - MainProcess - INFO     Succesful Run - Time taken: 9.54 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 9.54 seconds.\n",
      "2024-06-29 13:28:26,886 - micro - MainProcess - INFO     Succesful Run - Time taken: 9.49 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 9.49 seconds.\n",
      "2024-06-29 13:28:26,891 - micro - MainProcess - INFO     Succesful Run - Time taken: 9.75 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 9.75 seconds.\n",
      "2024-06-29 13:28:26,895 - micro - MainProcess - INFO     Succesful Run - Time taken: 9.65 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 9.65 seconds.\n",
      "2024-06-29 13:28:26,899 - micro - MainProcess - INFO     Succesful Run - Time taken: 9.70 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 9.70 seconds.\n",
      "2024-06-29 13:28:26,911 - micro - MainProcess - INFO     Succesful Run - Time taken: 9.90 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 9.90 seconds.\n",
      "2024-06-29 13:28:26,917 - micro - MainProcess - INFO     Succesful Run - Time taken: 9.82 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 9.82 seconds.\n",
      "2024-06-29 13:28:27,892 - micro - MainProcess - INFO     CPU usage: 14.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.4%\n",
      "2024-06-29 13:28:27,904 - micro - MainProcess - INFO     RAM usage: 85.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.4%\n",
      "2024-06-29 13:28:27,927 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:27,930 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:27,933 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:27,943 - micro - MainProcess - INFO     CPU usage: 18.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 18.2%\n",
      "2024-06-29 13:28:27,956 - micro - MainProcess - INFO     RAM usage: 85.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.4%\n",
      "2024-06-29 13:28:27,981 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:27,984 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:27,987 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:27,991 - micro - MainProcess - INFO     CPU usage: 42.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 42.5%\n",
      "2024-06-29 13:28:28,004 - micro - MainProcess - INFO     RAM usage: 85.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.5%\n",
      "2024-06-29 13:28:28,031 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:28,033 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:28,054 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:28,058 - micro - MainProcess - INFO     CPU usage: 25.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 25.5%\n",
      "2024-06-29 13:28:28,071 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:28:28,169 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:28,175 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:28,179 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:28,183 - micro - MainProcess - INFO     CPU usage: 75.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 75.8%\n",
      "2024-06-29 13:28:28,210 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:28:28,237 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:28,242 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:28,249 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:28,254 - micro - MainProcess - INFO     CPU usage: 76.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 76.8%\n",
      "2024-06-29 13:28:28,267 - micro - MainProcess - INFO     RAM usage: 86.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.0%\n",
      "2024-06-29 13:28:28,304 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:28,307 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:28,313 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:28,317 - micro - MainProcess - INFO     CPU usage: 49.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 49.0%\n",
      "2024-06-29 13:28:28,334 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:28:28,359 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:28,362 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:28,368 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:28,373 - micro - MainProcess - INFO     CPU usage: 24.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 24.4%\n",
      "2024-06-29 13:28:28,389 - micro - MainProcess - INFO     RAM usage: 86.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.0%\n",
      "2024-06-29 13:28:28,415 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:28,419 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:28,426 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:33,197 - micro - MainProcess - INFO     Succesful Run - Time taken: 5.21 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 5.21 seconds.\n",
      "2024-06-29 13:28:33,287 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.92 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.92 seconds.\n",
      "2024-06-29 13:28:34,206 - micro - MainProcess - INFO     CPU usage: 13.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.8%\n",
      "2024-06-29 13:28:34,216 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:28:34,306 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:34,310 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:34,313 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:34,320 - micro - MainProcess - INFO     CPU usage: 29.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 29.7%\n",
      "2024-06-29 13:28:34,330 - micro - MainProcess - INFO     RAM usage: 85.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.6%\n",
      "2024-06-29 13:28:34,371 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:34,374 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:34,378 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:34,412 - micro - MainProcess - INFO     Succesful Run - Time taken: 6.47 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 6.47 seconds.\n",
      "2024-06-29 13:28:34,441 - micro - MainProcess - INFO     Succesful Run - Time taken: 6.38 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 6.38 seconds.\n",
      "2024-06-29 13:28:34,693 - micro - MainProcess - INFO     Succesful Run - Time taken: 6.51 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 6.51 seconds.\n",
      "2024-06-29 13:28:35,421 - micro - MainProcess - INFO     CPU usage: 19.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.7%\n",
      "2024-06-29 13:28:35,431 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:28:35,455 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:35,460 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:35,463 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:35,473 - micro - MainProcess - INFO     CPU usage: 25.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 25.0%\n",
      "2024-06-29 13:28:35,487 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:28:35,512 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:35,514 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:35,520 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:35,690 - micro - MainProcess - INFO     CPU usage: 32.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 32.8%\n",
      "2024-06-29 13:28:35,702 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:28:35,730 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:35,735 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:35,739 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:36,745 - micro - MainProcess - INFO     Succesful Run - Time taken: 8.49 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 8.49 seconds.\n",
      "2024-06-29 13:28:36,808 - micro - MainProcess - INFO     Succesful Run - Time taken: 8.49 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 8.49 seconds.\n",
      "2024-06-29 13:28:36,827 - micro - MainProcess - INFO     Succesful Run - Time taken: 8.40 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 8.40 seconds.\n",
      "2024-06-29 13:28:37,740 - micro - MainProcess - INFO     CPU usage: 16.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.3%\n",
      "2024-06-29 13:28:37,750 - micro - MainProcess - INFO     RAM usage: 85.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.6%\n",
      "2024-06-29 13:28:37,784 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:37,786 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:37,790 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:37,795 - micro - MainProcess - INFO     CPU usage: 9.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 9.3%\n",
      "2024-06-29 13:28:37,806 - micro - MainProcess - INFO     RAM usage: 85.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.6%\n",
      "2024-06-29 13:28:37,943 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:37,955 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:37,967 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:37,975 - micro - MainProcess - INFO     CPU usage: 62.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 62.1%\n",
      "2024-06-29 13:28:37,989 - micro - MainProcess - INFO     RAM usage: 85.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.6%\n",
      "2024-06-29 13:28:38,030 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:38,033 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:38,037 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:38,345 - micro - MainProcess - INFO     Succesful Run - Time taken: 2.88 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 2.88 seconds.\n",
      "2024-06-29 13:28:38,569 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.25 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.25 seconds.\n",
      "2024-06-29 13:28:38,585 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.20 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.20 seconds.\n",
      "2024-06-29 13:28:39,371 - micro - MainProcess - INFO     CPU usage: 15.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.7%\n",
      "2024-06-29 13:28:39,381 - micro - MainProcess - INFO     RAM usage: 85.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.6%\n",
      "2024-06-29 13:28:39,407 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:39,452 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:39,456 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:39,503 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.98 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 3.98 seconds.\n",
      "2024-06-29 13:28:39,572 - micro - MainProcess - INFO     CPU usage: 56.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 56.6%\n",
      "2024-06-29 13:28:39,630 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:28:39,656 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:39,662 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:39,667 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:39,681 - micro - MainProcess - INFO     CPU usage: 65.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 65.5%\n",
      "2024-06-29 13:28:39,697 - micro - MainProcess - INFO     RAM usage: 86.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.0%\n",
      "2024-06-29 13:28:39,733 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:39,738 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:39,746 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:40,514 - micro - MainProcess - INFO     CPU usage: 28.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 28.2%\n",
      "2024-06-29 13:28:40,525 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:28:40,552 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:40,555 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:40,559 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:42,761 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.02 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.02 seconds.\n",
      "2024-06-29 13:28:43,776 - micro - MainProcess - INFO     CPU usage: 8.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 8.0%\n",
      "2024-06-29 13:28:43,786 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:28:43,815 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:43,818 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:43,822 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:43,849 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.29 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 3.29 seconds.\n",
      "2024-06-29 13:28:44,121 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.66 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.66 seconds.\n",
      "2024-06-29 13:28:44,182 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.43 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.43 seconds.\n",
      "2024-06-29 13:28:44,189 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.52 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.52 seconds.\n",
      "2024-06-29 13:28:44,868 - micro - MainProcess - INFO     CPU usage: 27.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 27.7%\n",
      "2024-06-29 13:28:44,880 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:28:44,905 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:44,908 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:44,912 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:44,917 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.12 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.12 seconds.\n",
      "2024-06-29 13:28:45,129 - micro - MainProcess - INFO     CPU usage: 12.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.7%\n",
      "2024-06-29 13:28:45,139 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:28:45,165 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:45,169 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:45,172 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:45,176 - micro - MainProcess - INFO     CPU usage: 19.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.4%\n",
      "2024-06-29 13:28:45,186 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:28:45,215 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:45,219 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:45,222 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:45,227 - micro - MainProcess - INFO     CPU usage: 22.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 22.9%\n",
      "2024-06-29 13:28:45,241 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:28:45,384 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:45,387 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:45,392 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:45,565 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.59 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.59 seconds.\n",
      "2024-06-29 13:28:45,966 - micro - MainProcess - INFO     CPU usage: 23.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 23.8%\n",
      "2024-06-29 13:28:45,976 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:28:46,148 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:46,154 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:46,158 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:46,664 - micro - MainProcess - INFO     CPU usage: 23.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 23.1%\n",
      "2024-06-29 13:28:46,675 - micro - MainProcess - INFO     RAM usage: 85.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.6%\n",
      "2024-06-29 13:28:46,709 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:46,714 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:46,717 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:47,102 - micro - MainProcess - INFO     Succesful Run - Time taken: 9.06 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 9.06 seconds.\n",
      "2024-06-29 13:28:48,108 - micro - MainProcess - INFO     CPU usage: 18.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 18.6%\n",
      "2024-06-29 13:28:48,117 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:28:48,146 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:48,149 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:48,156 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:48,787 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.56 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 3.56 seconds.\n",
      "2024-06-29 13:28:49,801 - micro - MainProcess - INFO     CPU usage: 13.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.1%\n",
      "2024-06-29 13:28:49,810 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:28:49,830 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:49,833 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:49,836 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:49,977 - micro - MainProcess - INFO     Succesful Run - Time taken: 5.06 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 5.06 seconds.\n",
      "2024-06-29 13:28:50,282 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.89 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.89 seconds.\n",
      "2024-06-29 13:28:50,297 - micro - MainProcess - INFO     Succesful Run - Time taken: 5.12 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 5.12 seconds.\n",
      "2024-06-29 13:28:50,978 - micro - MainProcess - INFO     CPU usage: 19.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.1%\n",
      "2024-06-29 13:28:50,987 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:28:51,002 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:51,005 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:51,009 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:51,287 - micro - MainProcess - INFO     CPU usage: 37.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 37.4%\n",
      "2024-06-29 13:28:51,297 - micro - MainProcess - INFO     RAM usage: 85.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.6%\n",
      "2024-06-29 13:28:51,321 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:51,323 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:51,327 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:51,330 - micro - MainProcess - INFO     CPU usage: 14.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.8%\n",
      "2024-06-29 13:28:51,343 - micro - MainProcess - INFO     RAM usage: 85.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.6%\n",
      "2024-06-29 13:28:51,360 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:51,363 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:51,367 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:52,462 - micro - MainProcess - INFO     Succesful Run - Time taken: 6.30 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 6.30 seconds.\n",
      "2024-06-29 13:28:52,729 - micro - MainProcess - INFO     Succesful Run - Time taken: 8.91 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 8.91 seconds.\n",
      "2024-06-29 13:28:53,483 - micro - MainProcess - INFO     CPU usage: 12.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.3%\n",
      "2024-06-29 13:28:53,493 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:28:53,508 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:53,511 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:53,514 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:53,546 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.71 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 3.71 seconds.\n",
      "2024-06-29 13:28:53,722 - micro - MainProcess - INFO     CPU usage: 41.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 41.9%\n",
      "2024-06-29 13:28:53,732 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:28:53,758 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:53,761 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:53,764 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:54,334 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.01 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 3.01 seconds.\n",
      "2024-06-29 13:28:54,566 - micro - MainProcess - INFO     CPU usage: 11.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 11.0%\n",
      "2024-06-29 13:28:54,577 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:28:54,601 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:54,634 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:54,639 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:54,642 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.92 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.92 seconds.\n",
      "2024-06-29 13:28:55,090 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.08 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.08 seconds.\n",
      "2024-06-29 13:28:55,352 - micro - MainProcess - INFO     CPU usage: 22.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 22.6%\n",
      "2024-06-29 13:28:55,362 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:28:55,495 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:55,507 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:55,511 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:55,519 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.15 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.15 seconds.\n",
      "2024-06-29 13:28:55,632 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.47 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.47 seconds.\n",
      "2024-06-29 13:28:55,666 - micro - MainProcess - INFO     CPU usage: 40.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 40.5%\n",
      "2024-06-29 13:28:55,677 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:28:55,699 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:55,702 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:55,706 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:56,086 - micro - MainProcess - INFO     CPU usage: 26.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 26.7%\n",
      "2024-06-29 13:28:56,096 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:28:56,122 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:56,124 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:56,128 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:56,521 - micro - MainProcess - INFO     CPU usage: 8.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 8.9%\n",
      "2024-06-29 13:28:56,531 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:28:56,553 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:56,560 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:56,563 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:28:56,629 - micro - MainProcess - INFO     CPU usage: 32.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 32.5%\n",
      "2024-06-29 13:28:56,640 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:28:56,665 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:28:56,669 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:28:56,673 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:28:58,978 - micro - MainProcess - INFO     Succesful Run - Time taken: 2.85 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 2.85 seconds.\n",
      "2024-06-29 13:28:59,075 - micro - MainProcess - INFO     Succesful Run - Time taken: 5.55 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 5.55 seconds.\n",
      "2024-06-29 13:28:59,998 - micro - MainProcess - INFO     CPU usage: 13.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.9%\n",
      "2024-06-29 13:29:00,006 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:29:00,098 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:00,100 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:00,103 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:00,109 - micro - MainProcess - INFO     CPU usage: 32.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 32.6%\n",
      "2024-06-29 13:29:00,118 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:29:00,134 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:00,137 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:00,142 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:02,080 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.44 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.44 seconds.\n",
      "2024-06-29 13:29:02,464 - micro - MainProcess - INFO     Succesful Run - Time taken: 6.76 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 6.76 seconds.\n",
      "2024-06-29 13:29:03,093 - micro - MainProcess - INFO     CPU usage: 17.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 17.2%\n",
      "2024-06-29 13:29:03,104 - micro - MainProcess - INFO     RAM usage: 85.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.6%\n",
      "2024-06-29 13:29:03,123 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:03,129 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:03,133 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:03,256 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.74 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.74 seconds.\n",
      "2024-06-29 13:29:03,464 - micro - MainProcess - INFO     CPU usage: 37.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 37.5%\n",
      "2024-06-29 13:29:03,475 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:29:03,507 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:03,510 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:03,517 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:03,772 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.20 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.20 seconds.\n",
      "2024-06-29 13:29:04,270 - micro - MainProcess - INFO     CPU usage: 25.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 25.8%\n",
      "2024-06-29 13:29:04,279 - micro - MainProcess - INFO     RAM usage: 85.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.8%\n",
      "2024-06-29 13:29:04,389 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:04,403 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:04,404 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:04,781 - micro - MainProcess - INFO     CPU usage: 23.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 23.7%\n",
      "2024-06-29 13:29:04,791 - micro - MainProcess - INFO     RAM usage: 85.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.7%\n",
      "2024-06-29 13:29:04,818 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:04,822 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:04,825 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:05,083 - micro - MainProcess - INFO     Succesful Run - Time taken: 11.31 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 11.31 seconds.\n",
      "2024-06-29 13:29:05,152 - micro - MainProcess - INFO     Succesful Run - Time taken: 5.05 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 5.05 seconds.\n",
      "2024-06-29 13:29:06,100 - micro - MainProcess - INFO     CPU usage: 20.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 20.0%\n",
      "2024-06-29 13:29:06,110 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:29:06,131 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:06,135 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:06,141 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:06,146 - micro - MainProcess - INFO     CPU usage: 16.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.1%\n",
      "2024-06-29 13:29:06,164 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:29:06,219 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:06,228 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:06,233 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:06,996 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.86 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 3.86 seconds.\n",
      "2024-06-29 13:29:07,261 - micro - MainProcess - INFO     Succesful Run - Time taken: 10.58 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 10.58 seconds.\n",
      "2024-06-29 13:29:08,008 - micro - MainProcess - INFO     CPU usage: 20.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 20.3%\n",
      "2024-06-29 13:29:08,025 - micro - MainProcess - INFO     RAM usage: 85.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.9%\n",
      "2024-06-29 13:29:08,056 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:08,060 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:08,066 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:08,253 - micro - MainProcess - INFO     CPU usage: 84.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 84.8%\n",
      "2024-06-29 13:29:08,266 - micro - MainProcess - INFO     RAM usage: 86.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.1%\n",
      "2024-06-29 13:29:08,291 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:08,295 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:08,303 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:08,558 - micro - MainProcess - INFO     Succesful Run - Time taken: 8.41 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 8.41 seconds.\n",
      "2024-06-29 13:29:08,669 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.84 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 3.84 seconds.\n",
      "2024-06-29 13:29:09,557 - micro - MainProcess - INFO     CPU usage: 31.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 31.0%\n",
      "2024-06-29 13:29:09,567 - micro - MainProcess - INFO     RAM usage: 86.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.1%\n",
      "2024-06-29 13:29:09,595 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:09,599 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:09,604 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:09,680 - micro - MainProcess - INFO     CPU usage: 27.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 27.8%\n",
      "2024-06-29 13:29:09,691 - micro - MainProcess - INFO     RAM usage: 86.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.3%\n",
      "2024-06-29 13:29:09,713 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:09,717 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:09,722 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:10,147 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.91 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 3.91 seconds.\n",
      "2024-06-29 13:29:10,907 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.39 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.39 seconds.\n",
      "2024-06-29 13:29:11,149 - micro - MainProcess - INFO     CPU usage: 25.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 25.7%\n",
      "2024-06-29 13:29:11,159 - micro - MainProcess - INFO     RAM usage: 86.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.1%\n",
      "2024-06-29 13:29:11,186 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:11,188 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:11,193 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:11,924 - micro - MainProcess - INFO     CPU usage: 22.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 22.4%\n",
      "2024-06-29 13:29:11,934 - micro - MainProcess - INFO     RAM usage: 86.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.2%\n",
      "2024-06-29 13:29:11,970 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:11,978 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:11,981 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:12,172 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.10 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.10 seconds.\n",
      "2024-06-29 13:29:13,178 - micro - MainProcess - INFO     CPU usage: 40.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 40.6%\n",
      "2024-06-29 13:29:13,189 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 13:29:13,216 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:13,220 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:13,222 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:13,820 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.09 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.09 seconds.\n",
      "2024-06-29 13:29:13,911 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.77 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.77 seconds.\n",
      "2024-06-29 13:29:14,337 - micro - MainProcess - INFO     Succesful Run - Time taken: 6.03 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 6.03 seconds.\n",
      "2024-06-29 13:29:14,834 - micro - MainProcess - INFO     CPU usage: 14.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.5%\n",
      "2024-06-29 13:29:14,845 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 13:29:14,859 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:14,861 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:14,866 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:14,916 - micro - MainProcess - INFO     CPU usage: 8.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 8.1%\n",
      "2024-06-29 13:29:14,929 - micro - MainProcess - INFO     RAM usage: 86.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.6%\n",
      "2024-06-29 13:29:15,024 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:15,027 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:15,032 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:15,039 - micro - MainProcess - INFO     Succesful Run - Time taken: 10.63 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 10.63 seconds.\n",
      "2024-06-29 13:29:15,345 - micro - MainProcess - INFO     CPU usage: 28.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 28.1%\n",
      "2024-06-29 13:29:15,357 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 13:29:15,380 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:15,383 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:15,387 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:15,394 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.17 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.17 seconds.\n",
      "2024-06-29 13:29:16,058 - micro - MainProcess - INFO     CPU usage: 28.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 28.8%\n",
      "2024-06-29 13:29:16,070 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-06-29 13:29:16,089 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:16,101 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:16,106 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:16,414 - micro - MainProcess - INFO     CPU usage: 21.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 21.6%\n",
      "2024-06-29 13:29:16,425 - micro - MainProcess - INFO     RAM usage: 86.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.4%\n",
      "2024-06-29 13:29:16,447 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:16,449 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:16,454 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:17,436 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.21 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.21 seconds.\n",
      "2024-06-29 13:29:17,570 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.96 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.96 seconds.\n",
      "2024-06-29 13:29:18,453 - micro - MainProcess - INFO     CPU usage: 14.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.8%\n",
      "2024-06-29 13:29:18,463 - micro - MainProcess - INFO     RAM usage: 86.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.4%\n",
      "2024-06-29 13:29:18,499 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:18,518 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:18,520 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:18,591 - micro - MainProcess - INFO     CPU usage: 24.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 24.3%\n",
      "2024-06-29 13:29:18,601 - micro - MainProcess - INFO     RAM usage: 86.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.6%\n",
      "2024-06-29 13:29:18,631 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:18,639 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:18,643 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:18,650 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.78 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 3.78 seconds.\n",
      "2024-06-29 13:29:19,656 - micro - MainProcess - INFO     CPU usage: 20.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 20.8%\n",
      "2024-06-29 13:29:19,667 - micro - MainProcess - INFO     RAM usage: 86.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.6%\n",
      "2024-06-29 13:29:19,703 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:19,707 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:19,711 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:19,744 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.63 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 3.63 seconds.\n",
      "2024-06-29 13:29:20,143 - micro - MainProcess - INFO     Succesful Run - Time taken: 8.16 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 8.16 seconds.\n",
      "2024-06-29 13:29:20,744 - micro - MainProcess - INFO     CPU usage: 15.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.6%\n",
      "2024-06-29 13:29:20,754 - micro - MainProcess - INFO     RAM usage: 86.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.4%\n",
      "2024-06-29 13:29:20,795 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:20,799 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:20,802 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:20,806 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.35 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.35 seconds.\n",
      "2024-06-29 13:29:21,165 - micro - MainProcess - INFO     CPU usage: 32.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 32.1%\n",
      "2024-06-29 13:29:21,176 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 13:29:21,208 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:21,213 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:21,218 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:21,825 - micro - MainProcess - INFO     CPU usage: 27.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 27.1%\n",
      "2024-06-29 13:29:21,837 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 13:29:21,861 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:21,864 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:21,870 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:22,839 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.32 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.32 seconds.\n",
      "2024-06-29 13:29:23,153 - micro - MainProcess - INFO     Succesful Run - Time taken: 8.12 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 8.12 seconds.\n",
      "2024-06-29 13:29:23,549 - micro - MainProcess - INFO     Succesful Run - Time taken: 8.16 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 8.16 seconds.\n",
      "2024-06-29 13:29:23,758 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.04 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.04 seconds.\n",
      "2024-06-29 13:29:23,850 - micro - MainProcess - INFO     CPU usage: 20.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 20.0%\n",
      "2024-06-29 13:29:23,862 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 13:29:23,927 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:23,934 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:23,937 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:24,153 - micro - MainProcess - INFO     CPU usage: 47.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 47.2%\n",
      "2024-06-29 13:29:24,165 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 13:29:24,191 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:24,194 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:24,199 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:24,561 - micro - MainProcess - INFO     CPU usage: 30.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 30.2%\n",
      "2024-06-29 13:29:24,572 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 13:29:24,599 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:24,601 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:24,607 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:24,777 - micro - MainProcess - INFO     CPU usage: 23.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 23.7%\n",
      "2024-06-29 13:29:24,789 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 13:29:24,812 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:24,815 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:24,819 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:26,007 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.13 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.13 seconds.\n",
      "2024-06-29 13:29:26,547 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.90 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.90 seconds.\n",
      "2024-06-29 13:29:27,016 - micro - MainProcess - INFO     CPU usage: 16.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.8%\n",
      "2024-06-29 13:29:27,027 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 13:29:27,055 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:27,058 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:27,061 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:27,213 - micro - MainProcess - INFO     Succesful Run - Time taken: 6.41 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 6.41 seconds.\n",
      "2024-06-29 13:29:27,559 - micro - MainProcess - INFO     CPU usage: 26.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 26.0%\n",
      "2024-06-29 13:29:27,569 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 13:29:27,599 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:27,601 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:27,604 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:27,764 - micro - MainProcess - INFO     Succesful Run - Time taken: 3.82 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 3.82 seconds.\n",
      "2024-06-29 13:29:28,226 - micro - MainProcess - INFO     CPU usage: 25.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 25.1%\n",
      "2024-06-29 13:29:28,243 - micro - MainProcess - INFO     RAM usage: 86.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.6%\n",
      "2024-06-29 13:29:28,274 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:28,277 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:28,279 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:29,033 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.81 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.81 seconds.\n",
      "2024-06-29 13:29:29,036 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.21 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.21 seconds.\n",
      "2024-06-29 13:29:30,047 - micro - MainProcess - INFO     CPU usage: 16.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.0%\n",
      "2024-06-29 13:29:30,064 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-06-29 13:29:30,095 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:30,105 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:30,110 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:30,114 - micro - MainProcess - INFO     CPU usage: 33.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 33.3%\n",
      "2024-06-29 13:29:30,130 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-06-29 13:29:30,150 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:30,153 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:30,159 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:30,561 - micro - MainProcess - INFO     Succesful Run - Time taken: 5.95 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 5.95 seconds.\n",
      "2024-06-29 13:29:31,573 - micro - MainProcess - INFO     CPU usage: 14.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.5%\n",
      "2024-06-29 13:29:31,582 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 13:29:31,613 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:31,616 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:31,617 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:31,966 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.90 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.90 seconds.\n",
      "2024-06-29 13:29:32,186 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.98 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.98 seconds.\n",
      "2024-06-29 13:29:32,719 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.44 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.44 seconds.\n",
      "2024-06-29 13:29:33,198 - micro - MainProcess - INFO     CPU usage: 19.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.1%\n",
      "2024-06-29 13:29:33,207 - micro - MainProcess - INFO     RAM usage: 86.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.6%\n",
      "2024-06-29 13:29:33,241 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:33,246 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:33,249 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:33,739 - micro - MainProcess - INFO     CPU usage: 23.4% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 23.4%\n",
      "2024-06-29 13:29:33,749 - micro - MainProcess - INFO     RAM usage: 86.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.4%\n",
      "2024-06-29 13:29:33,781 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:33,784 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:33,787 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-29 13:29:34,423 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.25 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 4.25 seconds.\n",
      "2024-06-29 13:29:35,288 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.68 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.68 seconds.\n",
      "2024-06-29 13:29:36,295 - micro - MainProcess - INFO     CPU usage: 12.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.5%\n",
      "2024-06-29 13:29:36,306 - micro - MainProcess - INFO     RAM usage: 86.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.4%\n",
      "2024-06-29 13:29:36,324 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:36,328 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:36,332 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:37,731 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.62 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.62 seconds.\n",
      "2024-06-29 13:29:38,744 - micro - MainProcess - INFO     CPU usage: 13.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.3%\n",
      "2024-06-29 13:29:38,754 - micro - MainProcess - INFO     RAM usage: 86.6% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.6%\n",
      "2024-06-29 13:29:38,796 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:38,799 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:38,805 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:39,151 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.53 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.53 seconds.\n",
      "2024-06-29 13:29:39,527 - micro - MainProcess - INFO     Succesful Run - Time taken: 5.74 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 5.74 seconds.\n",
      "2024-06-29 13:29:40,168 - micro - MainProcess - INFO     CPU usage: 14.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.1%\n",
      "2024-06-29 13:29:40,178 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-06-29 13:29:40,330 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:40,333 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:40,334 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:41,039 - micro - MainProcess - INFO     Succesful Run - Time taken: 7.79 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 7.79 seconds.\n",
      "2024-06-29 13:29:42,054 - micro - MainProcess - INFO     CPU usage: 16.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.1%\n",
      "2024-06-29 13:29:42,064 - micro - MainProcess - INFO     RAM usage: 86.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.7%\n",
      "2024-06-29 13:29:42,092 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:42,098 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:42,104 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:43,001 - micro - MainProcess - INFO     Succesful Run - Time taken: 6.67 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 6.67 seconds.\n",
      "2024-06-29 13:29:44,023 - micro - MainProcess - INFO     CPU usage: 22.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 22.9%\n",
      "2024-06-29 13:29:44,031 - micro - MainProcess - INFO     RAM usage: 86.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.3%\n",
      "2024-06-29 13:29:44,051 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:44,059 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:44,063 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:45,139 - micro - MainProcess - INFO     Succesful Run - Time taken: 6.33 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 6.33 seconds.\n",
      "2024-06-29 13:29:46,156 - micro - MainProcess - INFO     CPU usage: 9.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 9.9%\n",
      "2024-06-29 13:29:46,166 - micro - MainProcess - INFO     RAM usage: 86.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.3%\n",
      "2024-06-29 13:29:46,183 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:46,186 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:46,188 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:47,180 - micro - MainProcess - INFO     Succesful Run - Time taken: 6.84 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 6.84 seconds.\n",
      "2024-06-29 13:29:48,190 - micro - MainProcess - INFO     CPU usage: 16.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 16.6%\n",
      "2024-06-29 13:29:48,200 - micro - MainProcess - INFO     RAM usage: 86.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.2%\n",
      "2024-06-29 13:29:48,237 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:48,243 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:48,245 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:50,742 - micro - MainProcess - INFO     Succesful Run - Time taken: 8.54 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 8.54 seconds.\n",
      "2024-06-29 13:29:51,759 - micro - MainProcess - INFO     CPU usage: 13.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.6%\n",
      "2024-06-29 13:29:51,779 - micro - MainProcess - INFO     RAM usage: 86.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.1%\n",
      "2024-06-29 13:29:51,813 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:51,817 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:51,820 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:53,807 - micro - MainProcess - INFO     Succesful Run - Time taken: 9.74 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 9.74 seconds.\n",
      "2024-06-29 13:29:54,169 - micro - MainProcess - INFO     Succesful Run - Time taken: 5.91 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 5.91 seconds.\n",
      "2024-06-29 13:29:54,814 - micro - MainProcess - INFO     CPU usage: 19.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.1%\n",
      "2024-06-29 13:29:54,825 - micro - MainProcess - INFO     RAM usage: 86.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.3%\n",
      "2024-06-29 13:29:54,870 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:54,873 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:54,877 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:55,188 - micro - MainProcess - INFO     CPU usage: 41.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 41.5%\n",
      "2024-06-29 13:29:55,199 - micro - MainProcess - INFO     RAM usage: 86.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.1%\n",
      "2024-06-29 13:29:55,218 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:55,221 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:55,227 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:56,507 - micro - MainProcess - INFO     Succesful Run - Time taken: 10.32 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 10.32 seconds.\n",
      "2024-06-29 13:29:57,514 - micro - MainProcess - INFO     CPU usage: 15.2% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.2%\n",
      "2024-06-29 13:29:57,534 - micro - MainProcess - INFO     RAM usage: 86.2% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.2%\n",
      "2024-06-29 13:29:57,563 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:57,567 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:57,572 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:29:58,374 - micro - MainProcess - INFO     Succesful Run - Time taken: 6.55 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 6.55 seconds.\n",
      "2024-06-29 13:29:59,387 - micro - MainProcess - INFO     CPU usage: 11.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 11.5%\n",
      "2024-06-29 13:29:59,398 - micro - MainProcess - INFO     RAM usage: 86.5% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.5%\n",
      "2024-06-29 13:29:59,578 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:29:59,582 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:29:59,585 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:30:05,599 - micro - MainProcess - INFO     Succesful Run - Time taken: 10.72 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 10.72 seconds.\n",
      "2024-06-29 13:30:05,897 - micro - MainProcess - INFO     Succesful Run - Time taken: 10.67 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 10.67 seconds.\n",
      "2024-06-29 13:30:06,620 - micro - MainProcess - INFO     CPU usage: 13.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 13.1%\n",
      "2024-06-29 13:30:06,630 - micro - MainProcess - INFO     RAM usage: 85.4% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 85.4%\n",
      "2024-06-29 13:30:06,648 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:30:06,652 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:30:06,655 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:30:08,171 - micro - MainProcess - INFO     Succesful Run - Time taken: 10.60 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 10.60 seconds.\n",
      "2024-06-29 13:30:09,973 - micro - MainProcess - INFO     Succesful Run - Time taken: 10.39 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 10.39 seconds.\n",
      "2024-06-29 13:30:10,985 - micro - MainProcess - INFO     CPU usage: 14.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.8%\n",
      "2024-06-29 13:30:10,995 - micro - MainProcess - INFO     RAM usage: 84.7% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 84.7%\n",
      "2024-06-29 13:30:11,018 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:82)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-29 13:30:11,045 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:generate_test_messages:651)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-29 13:30:11,049 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:742)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-29 13:30:13,145 - micro - MainProcess - INFO     Succesful Run - Time taken: 6.49 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 6.49 seconds.\n",
      "2024-06-29 13:30:16,773 - micro - MainProcess - INFO     Succesful Run - Time taken: 5.72 seconds. (latencytest.py:make_call:771)\n",
      "INFO:micro:Succesful Run - Time taken: 5.72 seconds.\n"
     ]
    }
   ],
   "source": [
    "await benchmark_streaming.run_latency_benchmark_bulk(deployment_names=[DEPLOYMENT_ID], max_tokens_list=[500,250], byop=prompts)\n",
    "await benchmark_non_streaming.run_latency_benchmark_bulk(deployment_names=[DEPLOYMENT_ID], max_tokens_list=[500,250], byop=prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 13:30:33,062 - micro - MainProcess - INFO     Calculating statistics for data: [3.2, 3.41, 4.1, 4.05, 4.03, 3.95, 3.79, 4.01, 2.88, 4.52, 3.14, 4.15, 4.27, 4.5, 3.56, 3.62, 3.41, 4.05, 3.52, 3.85, 3.87, 5.48, 3.8, 3.74, 3.81, 3.6, 3.43, 4.7, 4.24, 3.52, 3.24, 3.19, 3.82, 3.75, 3.81, 3.11, 3.55, 3.53, 3.7, 3.62, 3.97, 4.12, 3.59, 3.35, 3.76, 3.7, 3.45, 3.63, 3.71, 3.85, 3.61, 3.26, 3.15, 3.07, 4.42, 4.47, 3.7, 3.52, 3.57, 3.06] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [3.2, 3.41, 4.1, 4.05, 4.03, 3.95, 3.79, 4.01, 2.88, 4.52, 3.14, 4.15, 4.27, 4.5, 3.56, 3.62, 3.41, 4.05, 3.52, 3.85, 3.87, 5.48, 3.8, 3.74, 3.81, 3.6, 3.43, 4.7, 4.24, 3.52, 3.24, 3.19, 3.82, 3.75, 3.81, 3.11, 3.55, 3.53, 3.7, 3.62, 3.97, 4.12, 3.59, 3.35, 3.76, 3.7, 3.45, 3.63, 3.71, 3.85, 3.61, 3.26, 3.15, 3.07, 4.42, 4.47, 3.7, 3.52, 3.57, 3.06]\n",
      "2024-06-29 13:30:33,066 - micro - MainProcess - INFO     Data converted to numpy array: [3.2  3.41 4.1  4.05 4.03 3.95 3.79 4.01 2.88 4.52 3.14 4.15 4.27 4.5\n",
      " 3.56 3.62 3.41 4.05 3.52 3.85 3.87 5.48 3.8  3.74 3.81 3.6  3.43 4.7\n",
      " 4.24 3.52 3.24 3.19 3.82 3.75 3.81 3.11 3.55 3.53 3.7  3.62 3.97 4.12\n",
      " 3.59 3.35 3.76 3.7  3.45 3.63 3.71 3.85 3.61 3.26 3.15 3.07 4.42 4.47\n",
      " 3.7  3.52 3.57 3.06] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [3.2  3.41 4.1  4.05 4.03 3.95 3.79 4.01 2.88 4.52 3.14 4.15 4.27 4.5\n",
      " 3.56 3.62 3.41 4.05 3.52 3.85 3.87 5.48 3.8  3.74 3.81 3.6  3.43 4.7\n",
      " 4.24 3.52 3.24 3.19 3.82 3.75 3.81 3.11 3.55 3.53 3.7  3.62 3.97 4.12\n",
      " 3.59 3.35 3.76 3.7  3.45 3.63 3.71 3.85 3.61 3.26 3.15 3.07 4.42 4.47\n",
      " 3.7  3.52 3.57 3.06]\n",
      "2024-06-29 13:30:33,069 - micro - MainProcess - INFO     Calculated median: 3.7 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 3.7\n",
      "2024-06-29 13:30:33,073 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.48 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.48\n",
      "2024-06-29 13:30:33,077 - micro - MainProcess - INFO     Calculated 95th percentile: 4.5 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 4.5\n",
      "2024-06-29 13:30:33,080 - micro - MainProcess - INFO     Calculated 99th percentile: 5.02 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 5.02\n",
      "2024-06-29 13:30:33,084 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.12 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.12\n",
      "2024-06-29 13:30:33,086 - micro - MainProcess - INFO     Result: (3.7, 0.48, 4.5, 5.02, 0.12) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (3.7, 0.48, 4.5, 5.02, 0.12)\n",
      "2024-06-29 13:30:33,088 - micro - MainProcess - INFO     Calculating statistics for data: [255, 252, 248, 246, 256, 250, 253, 250, 250, 251, 250, 253, 254, 250, 248, 251, 250, 252, 246, 250, 247, 249, 248, 252, 247, 252, 250, 247, 250, 252, 250, 257, 252, 253, 251, 251, 248, 250, 259, 252, 249, 251, 248, 253, 253, 251, 253, 252, 252, 252, 254, 255, 247, 247, 254, 249, 252, 252, 247, 249] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [255, 252, 248, 246, 256, 250, 253, 250, 250, 251, 250, 253, 254, 250, 248, 251, 250, 252, 246, 250, 247, 249, 248, 252, 247, 252, 250, 247, 250, 252, 250, 257, 252, 253, 251, 251, 248, 250, 259, 252, 249, 251, 248, 253, 253, 251, 253, 252, 252, 252, 254, 255, 247, 247, 254, 249, 252, 252, 247, 249]\n",
      "2024-06-29 13:30:33,091 - micro - MainProcess - INFO     Data converted to numpy array: [255 252 248 246 256 250 253 250 250 251 250 253 254 250 248 251 250 252\n",
      " 246 250 247 249 248 252 247 252 250 247 250 252 250 257 252 253 251 251\n",
      " 248 250 259 252 249 251 248 253 253 251 253 252 252 252 254 255 247 247\n",
      " 254 249 252 252 247 249] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [255 252 248 246 256 250 253 250 250 251 250 253 254 250 248 251 250 252\n",
      " 246 250 247 249 248 252 247 252 250 247 250 252 250 257 252 253 251 251\n",
      " 248 250 259 252 249 251 248 253 253 251 253 252 252 252 254 255 247 247\n",
      " 254 249 252 252 247 249]\n",
      "2024-06-29 13:30:33,095 - micro - MainProcess - INFO     Calculated median: 251.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 251.0\n",
      "2024-06-29 13:30:33,101 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 3.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 3.0\n",
      "2024-06-29 13:30:33,104 - micro - MainProcess - INFO     Calculated 95th percentile: 255.05 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 255.05\n",
      "2024-06-29 13:30:33,108 - micro - MainProcess - INFO     Calculated 99th percentile: 257.82 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 257.82\n",
      "2024-06-29 13:30:33,112 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.01 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.01\n",
      "2024-06-29 13:30:33,118 - micro - MainProcess - INFO     Result: (251.0, 3.0, 255.05, 257.82, 0.01) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (251.0, 3.0, 255.05, 257.82, 0.01)\n",
      "2024-06-29 13:30:33,123 - micro - MainProcess - INFO     Calculating statistics for data: [74, 77, 73, 76, 73, 73, 68, 66, 75, 80, 77, 68, 68, 73, 72, 67, 78, 73, 80, 64, 71, 72, 74, 68, 61, 74, 65, 70, 74, 72, 75, 67, 67, 75, 74, 71, 73, 77, 74, 70, 74, 75, 77, 67, 72, 73, 69, 71, 66, 71, 74, 62, 66, 75, 72, 70, 69, 69, 67, 72] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [74, 77, 73, 76, 73, 73, 68, 66, 75, 80, 77, 68, 68, 73, 72, 67, 78, 73, 80, 64, 71, 72, 74, 68, 61, 74, 65, 70, 74, 72, 75, 67, 67, 75, 74, 71, 73, 77, 74, 70, 74, 75, 77, 67, 72, 73, 69, 71, 66, 71, 74, 62, 66, 75, 72, 70, 69, 69, 67, 72]\n",
      "2024-06-29 13:30:33,126 - micro - MainProcess - INFO     Data converted to numpy array: [74 77 73 76 73 73 68 66 75 80 77 68 68 73 72 67 78 73 80 64 71 72 74 68\n",
      " 61 74 65 70 74 72 75 67 67 75 74 71 73 77 74 70 74 75 77 67 72 73 69 71\n",
      " 66 71 74 62 66 75 72 70 69 69 67 72] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [74 77 73 76 73 73 68 66 75 80 77 68 68 73 72 67 78 73 80 64 71 72 74 68\n",
      " 61 74 65 70 74 72 75 67 67 75 74 71 73 77 74 70 74 75 77 67 72 73 69 71\n",
      " 66 71 74 62 66 75 72 70 69 69 67 72]\n",
      "2024-06-29 13:30:33,132 - micro - MainProcess - INFO     Calculated median: 72.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 72.0\n",
      "2024-06-29 13:30:33,137 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 6.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 6.0\n",
      "2024-06-29 13:30:33,142 - micro - MainProcess - INFO     Calculated 95th percentile: 77.05 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 77.05\n",
      "2024-06-29 13:30:33,147 - micro - MainProcess - INFO     Calculated 99th percentile: 80.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 80.0\n",
      "2024-06-29 13:30:33,154 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.06 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.06\n",
      "2024-06-29 13:30:33,158 - micro - MainProcess - INFO     Result: (72.0, 6.0, 77.05, 80.0, 0.06) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (72.0, 6.0, 77.05, 80.0, 0.06)\n",
      "2024-06-29 13:30:33,169 - micro - MainProcess - INFO     Calculating statistics for data: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 243.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 233.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 242.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 205.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.73, 1, 1, 1, 1, 42.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 217.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 231.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 254.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 262.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 12.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 441.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 16.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 366.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 423.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 452.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 650.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.28, 1, 1, 1, 324.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 195.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 744.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 263.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 221.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 525.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 601.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 540.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 97.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 240.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 235.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 245.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 215.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 476.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 422.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 564.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 240.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.29, 1, 1, 1, 1, 1, 1, 49.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 243.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.32, 1, 1, 1, 44.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 209.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 239.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 230.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 240.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 418.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 380.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 396.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 485.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 165.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 687.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 597.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 215.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 68.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 461.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 236.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 289.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 161.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 245.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 259.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 198.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 366.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 494.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 494.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 63.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 263.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 366.48, 1, 1, 1, 1, 1, 1, 1, 1, 48.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 386.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 80.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 380.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 480.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 119.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 405.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1637.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 438.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 425.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 39.98, 1, 1, 1, 1, 1, 1, 358.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 76.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 451.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 426.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 153.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 386.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 228.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 163.95, 1, 1, 1, 1, 1, 1, 298.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 430.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 426.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 176.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 185.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1386.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 409.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1475.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 179.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 82.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1152.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 170.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 185.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 188.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 168.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 231.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 171.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 278.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 56.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 398.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 51.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 222.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 437.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.71, 1, 1, 1, 1, 1, 279.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 146.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 16.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 430.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 138.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 182.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 137.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 544.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 76.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 285.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 133.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 66.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 263.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 86.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 352.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 93.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 31.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 201.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 215.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 245.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 254.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 163.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 417.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 454.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 114.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 196.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 239.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 83.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 428.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 300.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 34.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 461.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 200.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 247.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 18.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 216.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 244.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 232.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 249.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 417.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 135.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.58, 1, 1, 1, 1, 1, 1, 1, 1, 47.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 352.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 67.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 464.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 469.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 159.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 262.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 263.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 229.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 66.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 186.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 247.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.79, 1, 1, 1, 1, 1, 268.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.16, 1, 1, 1, 1, 1, 1, 253.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 262.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.75, 1, 1, 1, 1, 1, 1, 43.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 416.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 66.34, 1, 1, 1, 1, 1, 1, 169.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 274.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1206.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 389.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 243.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 205.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 258.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 223.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 448.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 67.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 243.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 233.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 242.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 205.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.73, 1, 1, 1, 1, 42.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 217.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 231.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 254.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 262.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 12.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 441.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 16.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 366.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 423.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 452.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 650.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.28, 1, 1, 1, 324.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 195.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 744.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 263.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 221.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 525.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 601.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 540.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 97.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 240.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 235.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 245.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 215.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 476.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 422.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 564.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 240.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.29, 1, 1, 1, 1, 1, 1, 49.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 243.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.32, 1, 1, 1, 44.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 209.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 239.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 230.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 240.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 418.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 432.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 380.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 396.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 485.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 165.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 687.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 597.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 215.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 68.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 461.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 236.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 289.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 161.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 245.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 259.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 198.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 366.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 494.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 494.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 63.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 263.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 366.48, 1, 1, 1, 1, 1, 1, 1, 1, 48.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 386.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 80.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 380.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 480.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 119.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 405.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1637.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 438.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 425.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 39.98, 1, 1, 1, 1, 1, 1, 358.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 76.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 451.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 426.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 153.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 386.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 228.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 163.95, 1, 1, 1, 1, 1, 1, 298.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 430.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 426.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 176.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 185.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1386.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 409.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1475.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 179.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 82.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1152.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 170.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 185.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 188.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 168.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 231.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 171.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 278.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 56.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 398.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 51.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 222.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 437.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.71, 1, 1, 1, 1, 1, 279.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 146.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 16.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 430.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 138.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 182.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 137.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 544.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 76.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 285.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 133.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 66.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 263.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 86.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 352.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 93.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 31.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 201.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 215.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 245.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 254.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 163.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 417.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 454.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 114.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 196.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 239.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 83.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 428.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 300.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 34.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 461.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 200.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 247.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 18.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 216.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 244.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 232.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 249.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 417.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 135.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.58, 1, 1, 1, 1, 1, 1, 1, 1, 47.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 375.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 352.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 67.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 464.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 469.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 159.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 262.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 263.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 229.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 66.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 186.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 247.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.79, 1, 1, 1, 1, 1, 268.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.16, 1, 1, 1, 1, 1, 1, 253.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 262.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.75, 1, 1, 1, 1, 1, 1, 43.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 416.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 66.34, 1, 1, 1, 1, 1, 1, 169.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 274.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1206.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 389.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 243.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 205.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 258.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 223.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 448.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 67.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 264.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "2024-06-29 13:30:33,178 - micro - MainProcess - INFO     Data converted to numpy array: [1. 1. 1. ... 1. 1. 1.] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [1. 1. 1. ... 1. 1. 1.]\n",
      "2024-06-29 13:30:33,183 - micro - MainProcess - INFO     Calculated median: 1.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 1.0\n",
      "2024-06-29 13:30:33,191 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-29 13:30:33,196 - micro - MainProcess - INFO     Calculated 95th percentile: 1.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 1.0\n",
      "2024-06-29 13:30:33,201 - micro - MainProcess - INFO     Calculated 99th percentile: 355.42 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 355.42\n",
      "2024-06-29 13:30:33,212 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 5.17 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 5.17\n",
      "2024-06-29 13:30:33,214 - micro - MainProcess - INFO     Result: (1.0, 0.0, 1.0, 355.42, 5.17) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (1.0, 0.0, 1.0, 355.42, 5.17)\n",
      "2024-06-29 13:30:33,217 - micro - MainProcess - INFO     Calculating statistics for data: [0.88, 1.01, 1.05, 0.97, 0.82, 0.75, 0.67, 0.7, 0.6, 0.81, 0.88, 0.77, 0.82, 1.18, 0.73, 1.01, 0.85, 0.98, 0.65, 0.69, 0.71, 0.8, 0.77, 0.62, 0.68, 0.7, 0.63, 0.63, 0.69, 0.69, 0.65, 0.62, 0.77, 0.69, 0.67, 0.6, 0.73, 0.72, 0.82, 0.73, 1.46, 1.03, 0.73, 0.67, 1.02, 0.88, 0.7, 0.76, 0.62, 0.73, 0.68, 0.66, 0.68, 0.57, 0.67, 1.51, 0.96, 0.73, 0.71, 0.65] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.88, 1.01, 1.05, 0.97, 0.82, 0.75, 0.67, 0.7, 0.6, 0.81, 0.88, 0.77, 0.82, 1.18, 0.73, 1.01, 0.85, 0.98, 0.65, 0.69, 0.71, 0.8, 0.77, 0.62, 0.68, 0.7, 0.63, 0.63, 0.69, 0.69, 0.65, 0.62, 0.77, 0.69, 0.67, 0.6, 0.73, 0.72, 0.82, 0.73, 1.46, 1.03, 0.73, 0.67, 1.02, 0.88, 0.7, 0.76, 0.62, 0.73, 0.68, 0.66, 0.68, 0.57, 0.67, 1.51, 0.96, 0.73, 0.71, 0.65]\n",
      "2024-06-29 13:30:33,222 - micro - MainProcess - INFO     Data converted to numpy array: [0.88 1.01 1.05 0.97 0.82 0.75 0.67 0.7  0.6  0.81 0.88 0.77 0.82 1.18\n",
      " 0.73 1.01 0.85 0.98 0.65 0.69 0.71 0.8  0.77 0.62 0.68 0.7  0.63 0.63\n",
      " 0.69 0.69 0.65 0.62 0.77 0.69 0.67 0.6  0.73 0.72 0.82 0.73 1.46 1.03\n",
      " 0.73 0.67 1.02 0.88 0.7  0.76 0.62 0.73 0.68 0.66 0.68 0.57 0.67 1.51\n",
      " 0.96 0.73 0.71 0.65] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.88 1.01 1.05 0.97 0.82 0.75 0.67 0.7  0.6  0.81 0.88 0.77 0.82 1.18\n",
      " 0.73 1.01 0.85 0.98 0.65 0.69 0.71 0.8  0.77 0.62 0.68 0.7  0.63 0.63\n",
      " 0.69 0.69 0.65 0.62 0.77 0.69 0.67 0.6  0.73 0.72 0.82 0.73 1.46 1.03\n",
      " 0.73 0.67 1.02 0.88 0.7  0.76 0.62 0.73 0.68 0.66 0.68 0.57 0.67 1.51\n",
      " 0.96 0.73 0.71 0.65]\n",
      "2024-06-29 13:30:33,227 - micro - MainProcess - INFO     Calculated median: 0.73 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.73\n",
      "2024-06-29 13:30:33,233 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.16 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.16\n",
      "2024-06-29 13:30:33,237 - micro - MainProcess - INFO     Calculated 95th percentile: 1.06 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 1.06\n",
      "2024-06-29 13:30:33,244 - micro - MainProcess - INFO     Calculated 99th percentile: 1.48 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 1.48\n",
      "2024-06-29 13:30:33,249 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.24 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.24\n",
      "2024-06-29 13:30:33,252 - micro - MainProcess - INFO     Result: (0.73, 0.16, 1.06, 1.48, 0.24) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.73, 0.16, 1.06, 1.48, 0.24)\n",
      "2024-06-29 13:30:33,260 - micro - MainProcess - INFO     Calculating statistics for data: [8.09, 8.06, 8.19, 9.01, 8.08, 7.68, 8.02, 8.25, 6.85, 8.85, 7.62, 7.79, 7.66, 9.64, 7.04, 6.94, 7.11, 7.15, 5.67, 7.05, 7.05, 7.4, 8.29, 7.14, 7.14, 7.03, 6.98, 7.08, 7.25, 9.94, 6.74, 6.57, 6.72, 6.72, 6.94, 7.36, 7.45, 7.34, 7.3, 6.03, 6.01, 5.95, 6.3, 6.27, 6.71, 6.66, 6.47, 6.87, 6.68, 6.53, 7.02, 6.99, 7.4, 7.43, 7.45, 7.4, 7.31, 7.23, 7.03, 5.83] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [8.09, 8.06, 8.19, 9.01, 8.08, 7.68, 8.02, 8.25, 6.85, 8.85, 7.62, 7.79, 7.66, 9.64, 7.04, 6.94, 7.11, 7.15, 5.67, 7.05, 7.05, 7.4, 8.29, 7.14, 7.14, 7.03, 6.98, 7.08, 7.25, 9.94, 6.74, 6.57, 6.72, 6.72, 6.94, 7.36, 7.45, 7.34, 7.3, 6.03, 6.01, 5.95, 6.3, 6.27, 6.71, 6.66, 6.47, 6.87, 6.68, 6.53, 7.02, 6.99, 7.4, 7.43, 7.45, 7.4, 7.31, 7.23, 7.03, 5.83]\n",
      "2024-06-29 13:30:33,265 - micro - MainProcess - INFO     Data converted to numpy array: [8.09 8.06 8.19 9.01 8.08 7.68 8.02 8.25 6.85 8.85 7.62 7.79 7.66 9.64\n",
      " 7.04 6.94 7.11 7.15 5.67 7.05 7.05 7.4  8.29 7.14 7.14 7.03 6.98 7.08\n",
      " 7.25 9.94 6.74 6.57 6.72 6.72 6.94 7.36 7.45 7.34 7.3  6.03 6.01 5.95\n",
      " 6.3  6.27 6.71 6.66 6.47 6.87 6.68 6.53 7.02 6.99 7.4  7.43 7.45 7.4\n",
      " 7.31 7.23 7.03 5.83] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [8.09 8.06 8.19 9.01 8.08 7.68 8.02 8.25 6.85 8.85 7.62 7.79 7.66 9.64\n",
      " 7.04 6.94 7.11 7.15 5.67 7.05 7.05 7.4  8.29 7.14 7.14 7.03 6.98 7.08\n",
      " 7.25 9.94 6.74 6.57 6.72 6.72 6.94 7.36 7.45 7.34 7.3  6.03 6.01 5.95\n",
      " 6.3  6.27 6.71 6.66 6.47 6.87 6.68 6.53 7.02 6.99 7.4  7.43 7.45 7.4\n",
      " 7.31 7.23 7.03 5.83]\n",
      "2024-06-29 13:30:33,268 - micro - MainProcess - INFO     Calculated median: 7.12 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 7.12\n",
      "2024-06-29 13:30:33,273 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.76 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.76\n",
      "2024-06-29 13:30:33,278 - micro - MainProcess - INFO     Calculated 95th percentile: 8.86 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 8.86\n",
      "2024-06-29 13:30:33,282 - micro - MainProcess - INFO     Calculated 99th percentile: 9.76 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 9.76\n",
      "2024-06-29 13:30:33,285 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.11 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.11\n",
      "2024-06-29 13:30:33,293 - micro - MainProcess - INFO     Result: (7.12, 0.76, 8.86, 9.76, 0.11) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (7.12, 0.76, 8.86, 9.76, 0.11)\n",
      "2024-06-29 13:30:33,300 - micro - MainProcess - INFO     Calculating statistics for data: [495, 494, 503, 496, 502, 493, 509, 501, 500, 498, 508, 500, 499, 502, 496, 503, 498, 497, 498, 501, 492, 503, 495, 499, 504, 503, 501, 503, 503, 500, 498, 505, 514, 509, 509, 502, 493, 505, 507, 496, 503, 503, 488, 505, 510, 501, 506, 503, 500, 507, 501, 495, 502, 505, 496, 504, 503, 500, 504, 495] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [495, 494, 503, 496, 502, 493, 509, 501, 500, 498, 508, 500, 499, 502, 496, 503, 498, 497, 498, 501, 492, 503, 495, 499, 504, 503, 501, 503, 503, 500, 498, 505, 514, 509, 509, 502, 493, 505, 507, 496, 503, 503, 488, 505, 510, 501, 506, 503, 500, 507, 501, 495, 502, 505, 496, 504, 503, 500, 504, 495]\n",
      "2024-06-29 13:30:33,310 - micro - MainProcess - INFO     Data converted to numpy array: [495 494 503 496 502 493 509 501 500 498 508 500 499 502 496 503 498 497\n",
      " 498 501 492 503 495 499 504 503 501 503 503 500 498 505 514 509 509 502\n",
      " 493 505 507 496 503 503 488 505 510 501 506 503 500 507 501 495 502 505\n",
      " 496 504 503 500 504 495] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [495 494 503 496 502 493 509 501 500 498 508 500 499 502 496 503 498 497\n",
      " 498 501 492 503 495 499 504 503 501 503 503 500 498 505 514 509 509 502\n",
      " 493 505 507 496 503 503 488 505 510 501 506 503 500 507 501 495 502 505\n",
      " 496 504 503 500 504 495]\n",
      "2024-06-29 13:30:33,314 - micro - MainProcess - INFO     Calculated median: 501.5 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 501.5\n",
      "2024-06-29 13:30:33,320 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 6.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 6.0\n",
      "2024-06-29 13:30:33,323 - micro - MainProcess - INFO     Calculated 95th percentile: 509.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 509.0\n",
      "2024-06-29 13:30:33,327 - micro - MainProcess - INFO     Calculated 99th percentile: 511.64 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 511.64\n",
      "2024-06-29 13:30:33,334 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.01 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.01\n",
      "2024-06-29 13:30:33,337 - micro - MainProcess - INFO     Result: (501.5, 6.0, 509.0, 511.64, 0.01) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (501.5, 6.0, 509.0, 511.64, 0.01)\n",
      "2024-06-29 13:30:33,341 - micro - MainProcess - INFO     Calculating statistics for data: [74, 77, 74, 77, 66, 73, 74, 69, 80, 75, 68, 77, 68, 73, 73, 67, 73, 78, 80, 71, 72, 64, 73, 62, 74, 68, 66, 72, 70, 74, 74, 74, 67, 68, 73, 77, 71, 72, 74, 74, 70, 75, 77, 72, 67, 74, 69, 71, 70, 66, 73, 67, 63, 72, 76, 69, 70, 66, 68, 72] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [74, 77, 74, 77, 66, 73, 74, 69, 80, 75, 68, 77, 68, 73, 73, 67, 73, 78, 80, 71, 72, 64, 73, 62, 74, 68, 66, 72, 70, 74, 74, 74, 67, 68, 73, 77, 71, 72, 74, 74, 70, 75, 77, 72, 67, 74, 69, 71, 70, 66, 73, 67, 63, 72, 76, 69, 70, 66, 68, 72]\n",
      "2024-06-29 13:30:33,346 - micro - MainProcess - INFO     Data converted to numpy array: [74 77 74 77 66 73 74 69 80 75 68 77 68 73 73 67 73 78 80 71 72 64 73 62\n",
      " 74 68 66 72 70 74 74 74 67 68 73 77 71 72 74 74 70 75 77 72 67 74 69 71\n",
      " 70 66 73 67 63 72 76 69 70 66 68 72] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [74 77 74 77 66 73 74 69 80 75 68 77 68 73 73 67 73 78 80 71 72 64 73 62\n",
      " 74 68 66 72 70 74 74 74 67 68 73 77 71 72 74 74 70 75 77 72 67 74 69 71\n",
      " 70 66 73 67 63 72 76 69 70 66 68 72]\n",
      "2024-06-29 13:30:33,352 - micro - MainProcess - INFO     Calculated median: 72.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 72.0\n",
      "2024-06-29 13:30:33,358 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 6.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 6.0\n",
      "2024-06-29 13:30:33,363 - micro - MainProcess - INFO     Calculated 95th percentile: 77.05 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 77.05\n",
      "2024-06-29 13:30:33,367 - micro - MainProcess - INFO     Calculated 99th percentile: 80.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 80.0\n",
      "2024-06-29 13:30:33,373 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.06 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.06\n",
      "2024-06-29 13:30:33,377 - micro - MainProcess - INFO     Result: (72.0, 6.0, 77.05, 80.0, 0.06) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (72.0, 6.0, 77.05, 80.0, 0.06)\n",
      "2024-06-29 13:30:33,384 - micro - MainProcess - INFO     Calculating statistics for data: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 448.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 119.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 546.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 410.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.27, 1, 1, 1, 1, 1, 1, 1, 1, 731.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 469.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 62.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 527.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 463.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 638.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 55.27, 1, 1, 1, 1, 1, 1, 1, 1, 273.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 457.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 435.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 580.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 107.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 57.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 438.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 448.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 416.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 599.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 554.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 396.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 405.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 426.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 484.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 411.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 398.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 448.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 400.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 407.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 238.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 449.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 393.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 502.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 75.51, 1, 1, 1, 521.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 461.65, 1, 1, 1, 1, 1, 44.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 387.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 398.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 24.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 441.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 417.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 441.74, 1, 1, 1, 42.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 315.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 500.95, 1, 1, 1, 44.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 76.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 440.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 409.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 435.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 559.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.13, 1, 1, 1, 1, 1, 1, 1, 318.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 473.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 429.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 134.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 39.29, 1, 1, 1, 1, 1, 1, 1, 1, 287.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 40.78, 1, 1, 1, 1, 259.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 40.43, 1, 1, 1, 1, 1, 1, 363.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1236.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 515.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 542.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 465.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 520.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 468.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 448.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 109.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 386.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 417.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 434.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 389.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 396.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 438.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 117.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 657.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 502.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 387.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 242.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 376.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 507.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 387.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 234.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 462.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 169.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 189.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 489.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 466.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 600.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 622.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 389.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 445.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 480.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 411.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 503.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 542.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 213.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 455.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 465.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 502.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 278.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 285.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.42, 273.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 387.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 436.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 380.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 203.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 239.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 247.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 434.98, 1, 1, 1, 1, 52.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 416.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 54.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 396.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.21, 1, 1, 1, 1, 1, 456.79, 1, 1, 1, 1, 1, 55.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 458.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 414.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 414.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 479.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 471.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 435.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 412.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 508.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 409.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 85.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 174.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 245.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 236.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 263.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 258.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 244.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 146.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 218.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 233.2, 1, 1, 1, 6.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 246.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 245.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 352.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 241.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 243.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 407.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 300.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 258.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 419.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 259.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 479.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 400.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 274.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 19.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1427.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 172.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 425.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 235.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 236.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 376.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 398.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 470.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.22, 1, 1, 1, 1, 1, 1, 1, 1, 430.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.79, 1, 1, 1, 1, 1, 1, 350.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 285.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 484.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 352.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 387.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 504.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 524.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 498.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 398.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 184.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 246.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 366.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 201.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 65.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 61.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 376.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 218.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 492.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 190.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 443.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 262.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.7, 1, 1, 1, 1, 1, 1.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 315.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 274.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 189.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 396.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 554.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 486.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 546.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 476.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 557.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 623.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 517.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 451.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 563.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3755.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 32.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 13.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 13.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 30.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 15.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 315.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 219.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 163.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 51.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 577.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 228.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 141.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 210.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 112.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 425.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 150.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 409.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 197.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 429.03, 1, 1, 1, 1, 1, 1, 41.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 387.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 491.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 97.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 101.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 194.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 183.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 352.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 245.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 259.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 166.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 216.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1228.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 315.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 447.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 258.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1308.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 315.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.55, 280.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 366.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 240.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1322.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 455.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 187.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 173.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 412.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.5, 1, 1, 1, 1, 1, 1, 1, 1, 37.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 116.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 243.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.66, 1, 1, 1, 1, 1, 266.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1556.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 56.45, 1, 1, 1, 250.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 465.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 67.19, 1, 1, 1, 1, 1, 1, 151.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 239.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 249.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.09, 1, 1, 1, 1, 1, 1, 1, 1, 45.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 190.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.21, 1, 1, 1, 45.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 238.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.3, 1, 1, 1, 1, 42.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 183.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 74.33, 1, 1, 1, 1, 1, 1, 22.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 201.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 289.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 200.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 247.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 28.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 124.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 199.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 236.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 202.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 278.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 241.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 211.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 21.36, 1, 1, 236.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 51.18, 1, 1, 236.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 228.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 446.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.54, 322.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 51.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 56.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 209.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 244.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 239.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 95.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 225.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 477.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 238.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 259.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 119.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 434.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.0, 270.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 16.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 468.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 533.11, 1, 1, 1, 1, 31.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 162.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 405.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.73, 1, 1, 1, 1, 1, 347.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.39, 1, 1, 1, 1, 1, 244.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 226.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 416.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 386.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 25.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 238.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 233.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 437.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 419.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 274.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 247.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 120.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 416.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 507.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 213.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 413.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 436.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 246.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 242.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 278.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 246.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 240.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 57.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.29, 1, 1, 1, 1, 431.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 263.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 442.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 387.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 285.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 232.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 470.27, 1, 1, 1, 1, 1, 1, 1, 38.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 476.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 470.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.19, 1, 1, 1, 1, 1, 1, 1, 246.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 449.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 289.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 380.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 454.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 105.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 93.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 425.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 376.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.48, 1.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 262.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 423.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 491.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 452.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 428.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 453.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 411.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 481.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 54.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 400.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 108.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 414.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 400.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 176.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 428.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 376.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 39.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 274.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 39.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 461.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 38.7, 1, 1, 1, 1, 1, 424.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 33.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 454.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 464.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 15.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.87, 1, 1, 1, 1, 271.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 55.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 696.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 773.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 585.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 485.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.85, 1, 1, 1, 1, 49.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 208.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.8, 1, 1, 1, 1, 1, 1, 1, 1, 46.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 214.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 225.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 133.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 300.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 398.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 223.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 241.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 204.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 136.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 448.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 119.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 546.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 410.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.27, 1, 1, 1, 1, 1, 1, 1, 1, 731.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 469.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 62.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 527.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 463.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 638.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 55.27, 1, 1, 1, 1, 1, 1, 1, 1, 273.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 457.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 435.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 580.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 107.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 424.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 57.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 438.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 448.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 416.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 599.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 554.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 396.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 405.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 426.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 484.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 411.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 398.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 448.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 400.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 407.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 238.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 449.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 393.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 502.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 75.51, 1, 1, 1, 521.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 461.65, 1, 1, 1, 1, 1, 44.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 387.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 398.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 24.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 441.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 417.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 441.74, 1, 1, 1, 42.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 315.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 500.95, 1, 1, 1, 44.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 76.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 440.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 409.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 435.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 559.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.13, 1, 1, 1, 1, 1, 1, 1, 318.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 473.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 429.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 134.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 39.29, 1, 1, 1, 1, 1, 1, 1, 1, 287.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 40.78, 1, 1, 1, 1, 259.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 40.43, 1, 1, 1, 1, 1, 1, 363.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1236.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 515.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 542.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 465.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 520.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 468.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 448.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 109.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 386.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 417.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 434.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 389.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 396.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 438.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 117.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 657.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 502.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 387.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 297.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 242.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 376.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 507.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 387.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 268.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 234.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 462.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 169.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 189.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 489.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 466.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 600.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 622.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 389.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 445.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 480.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 411.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 503.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 542.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 213.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 455.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 465.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 502.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 278.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 285.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.42, 273.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 387.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 436.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 380.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 203.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 239.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 277.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 247.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 434.98, 1, 1, 1, 1, 52.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 416.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 54.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 396.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.21, 1, 1, 1, 1, 1, 456.79, 1, 1, 1, 1, 1, 55.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 458.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 52.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 414.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 414.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 479.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 471.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 435.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 412.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 508.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 409.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 85.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 174.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 245.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 236.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 263.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 258.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 244.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 146.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 218.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 233.2, 1, 1, 1, 6.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 246.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 314.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 245.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 352.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 241.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 243.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 407.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 300.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 258.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 419.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 259.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 479.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 400.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 274.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 19.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1427.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 172.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 420.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 425.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 235.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 236.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 376.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 398.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 470.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.22, 1, 1, 1, 1, 1, 1, 1, 1, 430.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 379.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.79, 1, 1, 1, 1, 1, 1, 350.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 285.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 484.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 352.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 387.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 504.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 524.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 498.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 398.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 184.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 246.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 366.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 201.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 408.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 65.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 358.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 61.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 376.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 218.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 492.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 190.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 443.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 262.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.7, 1, 1, 1, 1, 1, 1.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 315.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 253.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 274.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 189.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 396.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 554.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 486.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 546.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 476.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 557.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 623.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 517.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 451.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 563.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3755.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 32.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 13.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 13.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 30.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 15.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 315.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 219.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 163.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 369.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 51.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 577.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 228.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 141.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 210.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 112.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 291.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 425.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 150.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 409.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 197.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 429.03, 1, 1, 1, 1, 1, 1, 41.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 387.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 491.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 97.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 101.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 194.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 183.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 352.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 245.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 346.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 259.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 166.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 216.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1228.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 315.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 447.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 258.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1308.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 315.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.55, 280.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 366.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 350.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 240.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1322.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 455.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 187.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 173.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 360.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 412.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 330.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.5, 1, 1, 1, 1, 1, 1, 1, 1, 37.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 116.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 243.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.66, 1, 1, 1, 1, 1, 266.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1556.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 56.45, 1, 1, 1, 250.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 465.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 67.19, 1, 1, 1, 1, 1, 1, 151.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 260.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 239.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 249.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.09, 1, 1, 1, 1, 1, 1, 1, 1, 45.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 190.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.21, 1, 1, 1, 45.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 238.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 340.3, 1, 1, 1, 1, 42.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 183.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 318.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 394.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 74.33, 1, 1, 1, 1, 1, 1, 22.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 421.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 201.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 289.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 270.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 317.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 200.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 255.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 247.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 28.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 124.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 199.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 250.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 266.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 236.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 202.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 278.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 241.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 211.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 21.36, 1, 1, 236.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 51.18, 1, 1, 236.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 228.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 343.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 329.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 446.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 53.54, 322.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 51.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 261.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 56.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 209.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 244.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 239.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 95.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 225.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 252.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 477.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 248.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 238.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 259.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 257.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 119.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 434.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.0, 270.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 256.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 16.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 468.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 319.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 533.11, 1, 1, 1, 1, 31.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 162.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 405.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.73, 1, 1, 1, 1, 1, 347.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 50.39, 1, 1, 1, 1, 1, 244.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 295.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 226.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 294.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 416.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 386.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 25.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 292.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 238.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 44.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 273.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 233.83, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 437.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 313.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 419.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 274.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 247.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 120.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 416.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 378.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 507.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 399.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 213.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 267.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 281.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 309.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 265.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 391.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 388.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 413.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 436.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 246.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 271.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 242.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 278.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 246.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 337.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 279.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 240.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 276.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 327.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 57.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 237.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.29, 1, 1, 1, 1, 431.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 263.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 442.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 362.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 387.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 385.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 290.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 383.12, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 280.71, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 285.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 232.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 470.27, 1, 1, 1, 1, 1, 1, 1, 38.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 345.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 476.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 41.77, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 373.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.59, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 331.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 470.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.19, 1, 1, 1, 1, 1, 1, 1, 246.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 361.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 304.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.63, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 449.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 392.65, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 289.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 380.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 454.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 105.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 288.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 328.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 324.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 403.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.79, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 93.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 425.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 303.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 376.84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.44, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.04, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 349.48, 1.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 357.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 311.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.97, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.27, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 262.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 338.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 423.67, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 351.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 348.23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 491.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 336.16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 286.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 452.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 404.42, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 374.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 428.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 390.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 453.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.02, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 411.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 48.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 481.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 54.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 400.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 49.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 370.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 108.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 402.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 299.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 333.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 320.1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 298.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 354.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 414.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.64, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 384.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 427.93, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.91, 1, 1, 1, 1, 1, 1, 1, 1, 1, 353.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 332.72, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 400.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 176.57, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 428.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 371.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 376.55, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 368.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 323.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 401.99, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 382.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 433.51, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 431.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 39.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 344.69, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 335.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 46.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.45, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 302.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 274.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 326.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 269.19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 39.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 347.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.43, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 461.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 38.7, 1, 1, 1, 1, 1, 424.76, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 33.78, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 397.09, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 415.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 454.11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 464.82, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 15.6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 372.37, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 341.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 365.31, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.87, 1, 1, 1, 1, 271.95, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 364.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 321.94, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 325.86, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 55.15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 287.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 696.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 773.3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 45.73, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 585.68, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 485.18, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 339.39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 363.85, 1, 1, 1, 1, 49.85, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 208.21, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 283.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 312.8, 1, 1, 1, 1, 1, 1, 1, 1, 46.74, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 214.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 225.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 133.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 322.36, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 282.29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 306.61, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 284.05, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 293.87, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 300.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 398.92, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 367.9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 223.03, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 316.41, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 241.96, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 334.24, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 204.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 296.07, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 356.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 136.26, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "2024-06-29 13:30:33,416 - micro - MainProcess - INFO     Data converted to numpy array: [1. 1. 1. ... 1. 1. 1.] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [1. 1. 1. ... 1. 1. 1.]\n",
      "2024-06-29 13:30:33,422 - micro - MainProcess - INFO     Calculated median: 1.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 1.0\n",
      "2024-06-29 13:30:33,428 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-29 13:30:33,432 - micro - MainProcess - INFO     Calculated 95th percentile: 1.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 1.0\n",
      "2024-06-29 13:30:33,435 - micro - MainProcess - INFO     Calculated 99th percentile: 378.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 378.0\n",
      "2024-06-29 13:30:33,445 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 5.19 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 5.19\n",
      "2024-06-29 13:30:33,448 - micro - MainProcess - INFO     Result: (1.0, 0.0, 1.0, 378.0, 5.19) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (1.0, 0.0, 1.0, 378.0, 5.19)\n",
      "2024-06-29 13:30:33,451 - micro - MainProcess - INFO     Calculating statistics for data: [1.28, 1.2, 1.19, 1.97, 1.16, 0.67, 0.9, 1.13, 0.78, 0.8, 1.17, 1.28, 1.11, 2.94, 0.76, 0.65, 0.71, 0.67, 0.92, 1.09, 0.86, 0.69, 1.95, 0.75, 0.71, 0.66, 0.77, 0.87, 1.16, 0.78, 0.74, 0.71, 0.65, 0.69, 0.94, 0.63, 0.66, 0.53, 0.55, 0.72, 0.67, 0.61, 0.78, 0.59, 0.71, 0.59, 0.73, 0.68, 0.83, 0.64, 0.67, 0.56, 0.74, 0.76, 0.68, 0.62, 0.8, 0.74, 0.66, 0.77] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [1.28, 1.2, 1.19, 1.97, 1.16, 0.67, 0.9, 1.13, 0.78, 0.8, 1.17, 1.28, 1.11, 2.94, 0.76, 0.65, 0.71, 0.67, 0.92, 1.09, 0.86, 0.69, 1.95, 0.75, 0.71, 0.66, 0.77, 0.87, 1.16, 0.78, 0.74, 0.71, 0.65, 0.69, 0.94, 0.63, 0.66, 0.53, 0.55, 0.72, 0.67, 0.61, 0.78, 0.59, 0.71, 0.59, 0.73, 0.68, 0.83, 0.64, 0.67, 0.56, 0.74, 0.76, 0.68, 0.62, 0.8, 0.74, 0.66, 0.77]\n",
      "2024-06-29 13:30:33,460 - micro - MainProcess - INFO     Data converted to numpy array: [1.28 1.2  1.19 1.97 1.16 0.67 0.9  1.13 0.78 0.8  1.17 1.28 1.11 2.94\n",
      " 0.76 0.65 0.71 0.67 0.92 1.09 0.86 0.69 1.95 0.75 0.71 0.66 0.77 0.87\n",
      " 1.16 0.78 0.74 0.71 0.65 0.69 0.94 0.63 0.66 0.53 0.55 0.72 0.67 0.61\n",
      " 0.78 0.59 0.71 0.59 0.73 0.68 0.83 0.64 0.67 0.56 0.74 0.76 0.68 0.62\n",
      " 0.8  0.74 0.66 0.77] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [1.28 1.2  1.19 1.97 1.16 0.67 0.9  1.13 0.78 0.8  1.17 1.28 1.11 2.94\n",
      " 0.76 0.65 0.71 0.67 0.92 1.09 0.86 0.69 1.95 0.75 0.71 0.66 0.77 0.87\n",
      " 1.16 0.78 0.74 0.71 0.65 0.69 0.94 0.63 0.66 0.53 0.55 0.72 0.67 0.61\n",
      " 0.78 0.59 0.71 0.59 0.73 0.68 0.83 0.64 0.67 0.56 0.74 0.76 0.68 0.62\n",
      " 0.8  0.74 0.66 0.77]\n",
      "2024-06-29 13:30:33,466 - micro - MainProcess - INFO     Calculated median: 0.74 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.74\n",
      "2024-06-29 13:30:33,490 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.24 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.24\n",
      "2024-06-29 13:30:33,495 - micro - MainProcess - INFO     Calculated 95th percentile: 1.31 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 1.31\n",
      "2024-06-29 13:30:33,500 - micro - MainProcess - INFO     Calculated 99th percentile: 2.37 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 2.37\n",
      "2024-06-29 13:30:33,507 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.45 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.45\n",
      "2024-06-29 13:30:33,511 - micro - MainProcess - INFO     Result: (0.74, 0.24, 1.31, 2.37, 0.45) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.74, 0.24, 1.31, 2.37, 0.45)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------+------------+---------+--------------+-------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+---------+---------------------+---------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|    Model_MaxTokens    | is_Streaming | Iterations | Regions | Average TTLT | Median TTLT | IQR TTLT | 95th Percentile TTLT | 99th Percentile TTLT | CV TTLT | Median Prompt Tokens | IQR Prompt Tokens | Median Completion Tokens | IQR Completion Tokens | 95th Percentile Completion Tokens | 99th Percentile Completion Tokens | CV Completion Tokens | Average TBT | Median TBT | IQR TBT | 95th Percentile TBT | 99th Percentile TBT | Average TTFT | Median TTFT | IQR TTFT | 95th Percentile TTFT | 99th Percentile TTFT | Error Rate | Error Types | Successful Runs | Unsuccessful Runs | Throttle Count | Throttle Rate |                                                                  Best Run                                                                  |                                                                 Worst Run                                                                  |\n",
      "+-----------------------+--------------+------------+---------+--------------+-------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+---------+---------------------+---------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| gpt-4o-2024-05-13_250 |     True     |     60     |   N/A   |     3.74     |     3.7     |   0.48   |         4.5          |         5.02         |  0.12   |         72.0         |        6.0        |          251.0           |          3.0          |              255.05               |              257.82               |         0.01         |    12.58    |    1.0     |   0.0   |         1.0         |       355.42        |     0.79     |    0.73     |   0.16   |         1.06         |         1.48         |    0.0     |     []      |       60        |         0         |       0        |      0.0      | {\"ttlt\": 2.88, \"completion_tokens\": 250, \"prompt_tokens\": 75, \"region\": \"N/A\", \"utilization\": \"N/A\", \"local_time\": \"2024-06-29 13:24:26 \"} | {\"ttlt\": 5.48, \"completion_tokens\": 249, \"prompt_tokens\": 72, \"region\": \"N/A\", \"utilization\": \"N/A\", \"local_time\": \"2024-06-29 13:26:40 \"} |\n",
      "| gpt-4o-2024-05-13_500 |     True     |     60     |   N/A   |     7.25     |    7.12     |   0.76   |         8.86         |         9.76         |  0.11   |         72.0         |        6.0        |          501.5           |          6.0          |               509.0               |              511.64               |         0.01         |    13.62    |    1.0     |   0.0   |         1.0         |        378.0        |     0.87     |    0.74     |   0.24   |         1.31         |         2.37         |    0.0     |     []      |       60        |         0         |       0        |      0.0      | {\"ttlt\": 5.67, \"completion_tokens\": 498, \"prompt_tokens\": 80, \"region\": \"N/A\", \"utilization\": \"N/A\", \"local_time\": \"2024-06-29 13:26:47 \"} | {\"ttlt\": 9.94, \"completion_tokens\": 500, \"prompt_tokens\": 74, \"region\": \"N/A\", \"utilization\": \"N/A\", \"local_time\": \"2024-06-29 13:27:07 \"} |\n",
      "+-----------------------+--------------+------------+---------+--------------+-------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+---------+---------------------+---------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_250': {'median_ttlt': 3.7,\n",
       "  'is_Streaming': True,\n",
       "  'regions': ['N/A'],\n",
       "  'iqr_ttlt': 0.48,\n",
       "  'percentile_95_ttlt': 4.5,\n",
       "  'percentile_99_ttlt': 5.02,\n",
       "  'cv_ttlt': 0.12,\n",
       "  'median_completion_tokens': 251.0,\n",
       "  'iqr_completion_tokens': 3.0,\n",
       "  'percentile_95_completion_tokens': 255.05,\n",
       "  'percentile_99_completion_tokens': 257.82,\n",
       "  'cv_completion_tokens': 0.01,\n",
       "  'median_prompt_tokens': 72.0,\n",
       "  'iqr_prompt_tokens': 6.0,\n",
       "  'percentile_95_prompt_tokens': 77.05,\n",
       "  'percentile_99_prompt_tokens': 80.0,\n",
       "  'cv_prompt_tokens': 0.06,\n",
       "  'average_ttlt': 3.74,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 60,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 60,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 1.0,\n",
       "  'iqr_tbt': 0.0,\n",
       "  'percentile_95_tbt': 1.0,\n",
       "  'percentile_99_tbt': 355.42,\n",
       "  'cv_tbt': 5.17,\n",
       "  'average_tbt': 12.58,\n",
       "  'median_ttft': 0.73,\n",
       "  'iqr_ttft': 0.16,\n",
       "  'percentile_95_ttft': 1.06,\n",
       "  'percentile_99_ttft': 1.48,\n",
       "  'cv_ttft': 0.24,\n",
       "  'average_ttft': 0.79,\n",
       "  'best_run': {'ttlt': 2.88,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 75,\n",
       "   'region': 'N/A',\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-29 13:24:26 '},\n",
       "  'worst_run': {'ttlt': 5.48,\n",
       "   'completion_tokens': 249,\n",
       "   'prompt_tokens': 72,\n",
       "   'region': 'N/A',\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-29 13:26:40 '}},\n",
       " 'gpt-4o-2024-05-13_500': {'median_ttlt': 7.12,\n",
       "  'is_Streaming': True,\n",
       "  'regions': ['N/A'],\n",
       "  'iqr_ttlt': 0.76,\n",
       "  'percentile_95_ttlt': 8.86,\n",
       "  'percentile_99_ttlt': 9.76,\n",
       "  'cv_ttlt': 0.11,\n",
       "  'median_completion_tokens': 501.5,\n",
       "  'iqr_completion_tokens': 6.0,\n",
       "  'percentile_95_completion_tokens': 509.0,\n",
       "  'percentile_99_completion_tokens': 511.64,\n",
       "  'cv_completion_tokens': 0.01,\n",
       "  'median_prompt_tokens': 72.0,\n",
       "  'iqr_prompt_tokens': 6.0,\n",
       "  'percentile_95_prompt_tokens': 77.05,\n",
       "  'percentile_99_prompt_tokens': 80.0,\n",
       "  'cv_prompt_tokens': 0.06,\n",
       "  'average_ttlt': 7.25,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 60,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 60,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 1.0,\n",
       "  'iqr_tbt': 0.0,\n",
       "  'percentile_95_tbt': 1.0,\n",
       "  'percentile_99_tbt': 378.0,\n",
       "  'cv_tbt': 5.19,\n",
       "  'average_tbt': 13.62,\n",
       "  'median_ttft': 0.74,\n",
       "  'iqr_ttft': 0.24,\n",
       "  'percentile_95_ttft': 1.31,\n",
       "  'percentile_99_ttft': 2.37,\n",
       "  'cv_ttft': 0.45,\n",
       "  'average_ttft': 0.87,\n",
       "  'best_run': {'ttlt': 5.67,\n",
       "   'completion_tokens': 498,\n",
       "   'prompt_tokens': 80,\n",
       "   'region': 'N/A',\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-29 13:26:47 '},\n",
       "  'worst_run': {'ttlt': 9.94,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 74,\n",
       "   'region': 'N/A',\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-29 13:27:07 '}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_streaming.calculate_and_show_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 13:30:39,124 - micro - MainProcess - INFO     Calculating statistics for data: [3.1645096999999964, 9.53728030000002, 9.49380670000005, 9.645866000000012, 5.206454399999984, 4.915370999999993, 6.470371999999998, 6.383262000000002, 2.8779327999999964, 4.251231100000041, 4.203759200000036, 3.9812952999999993, 3.2857230000000186, 4.659821099999988, 4.43161200000003, 4.516898200000014, 3.562340199999994, 5.0621997999999735, 4.885093100000006, 5.122121499999992, 3.705830600000013, 3.0054256999999893, 4.076218400000016, 4.148935199999983, 2.8454222999999956, 7.439819900000032, 7.737992799999972, 7.204791, 5.045396500000038, 3.859495200000026, 3.836447899999996, 3.9097689000000173, 4.10140530000001, 4.093308400000012, 10.632616299999995, 4.173042100000032, 4.2076693000000205, 3.780752199999995, 3.6338537000000315, 4.349870199999998, 4.3156627000000185, 4.04470189999995, 4.133800199999996, 6.409432400000014, 3.8213812999999845, 4.213982999999985, 4.902133399999968, 4.436455299999977, 4.253569599999992, 5.737172999999984] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [3.1645096999999964, 9.53728030000002, 9.49380670000005, 9.645866000000012, 5.206454399999984, 4.915370999999993, 6.470371999999998, 6.383262000000002, 2.8779327999999964, 4.251231100000041, 4.203759200000036, 3.9812952999999993, 3.2857230000000186, 4.659821099999988, 4.43161200000003, 4.516898200000014, 3.562340199999994, 5.0621997999999735, 4.885093100000006, 5.122121499999992, 3.705830600000013, 3.0054256999999893, 4.076218400000016, 4.148935199999983, 2.8454222999999956, 7.439819900000032, 7.737992799999972, 7.204791, 5.045396500000038, 3.859495200000026, 3.836447899999996, 3.9097689000000173, 4.10140530000001, 4.093308400000012, 10.632616299999995, 4.173042100000032, 4.2076693000000205, 3.780752199999995, 3.6338537000000315, 4.349870199999998, 4.3156627000000185, 4.04470189999995, 4.133800199999996, 6.409432400000014, 3.8213812999999845, 4.213982999999985, 4.902133399999968, 4.436455299999977, 4.253569599999992, 5.737172999999984]\n",
      "2024-06-29 13:30:39,128 - micro - MainProcess - INFO     Data converted to numpy array: [ 3.1645097  9.5372803  9.4938067  9.645866   5.2064544  4.915371\n",
      "  6.470372   6.383262   2.8779328  4.2512311  4.2037592  3.9812953\n",
      "  3.285723   4.6598211  4.431612   4.5168982  3.5623402  5.0621998\n",
      "  4.8850931  5.1221215  3.7058306  3.0054257  4.0762184  4.1489352\n",
      "  2.8454223  7.4398199  7.7379928  7.204791   5.0453965  3.8594952\n",
      "  3.8364479  3.9097689  4.1014053  4.0933084 10.6326163  4.1730421\n",
      "  4.2076693  3.7807522  3.6338537  4.3498702  4.3156627  4.0447019\n",
      "  4.1338002  6.4094324  3.8213813  4.213983   4.9021334  4.4364553\n",
      "  4.2535696  5.737173 ] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [ 3.1645097  9.5372803  9.4938067  9.645866   5.2064544  4.915371\n",
      "  6.470372   6.383262   2.8779328  4.2512311  4.2037592  3.9812953\n",
      "  3.285723   4.6598211  4.431612   4.5168982  3.5623402  5.0621998\n",
      "  4.8850931  5.1221215  3.7058306  3.0054257  4.0762184  4.1489352\n",
      "  2.8454223  7.4398199  7.7379928  7.204791   5.0453965  3.8594952\n",
      "  3.8364479  3.9097689  4.1014053  4.0933084 10.6326163  4.1730421\n",
      "  4.2076693  3.7807522  3.6338537  4.3498702  4.3156627  4.0447019\n",
      "  4.1338002  6.4094324  3.8213813  4.213983   4.9021334  4.4364553\n",
      "  4.2535696  5.737173 ]\n",
      "2024-06-29 13:30:39,132 - micro - MainProcess - INFO     Calculated median: 4.25 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 4.25\n",
      "2024-06-29 13:30:39,137 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 1.18 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 1.18\n",
      "2024-06-29 13:30:39,141 - micro - MainProcess - INFO     Calculated 95th percentile: 9.52 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 9.52\n",
      "2024-06-29 13:30:39,147 - micro - MainProcess - INFO     Calculated 99th percentile: 10.15 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 10.15\n",
      "2024-06-29 13:30:39,152 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.36 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.36\n",
      "2024-06-29 13:30:39,155 - micro - MainProcess - INFO     Result: (4.25, 1.18, 9.52, 10.15, 0.36) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (4.25, 1.18, 9.52, 10.15, 0.36)\n",
      "2024-06-29 13:30:39,158 - micro - MainProcess - INFO     Calculating statistics for data: [250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250]\n",
      "2024-06-29 13:30:39,162 - micro - MainProcess - INFO     Data converted to numpy array: [250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250\n",
      " 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250\n",
      " 250 250 250 250 250 250 250 250 250 250 250 250 250 250] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250\n",
      " 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250 250\n",
      " 250 250 250 250 250 250 250 250 250 250 250 250 250 250]\n",
      "2024-06-29 13:30:39,165 - micro - MainProcess - INFO     Calculated median: 250.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 250.0\n",
      "2024-06-29 13:30:39,170 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-29 13:30:39,174 - micro - MainProcess - INFO     Calculated 95th percentile: 250.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 250.0\n",
      "2024-06-29 13:30:39,177 - micro - MainProcess - INFO     Calculated 99th percentile: 250.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 250.0\n",
      "2024-06-29 13:30:39,181 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-29 13:30:39,183 - micro - MainProcess - INFO     Result: (250.0, 0.0, 250.0, 250.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (250.0, 0.0, 250.0, 250.0, 0.0)\n",
      "2024-06-29 13:30:39,185 - micro - MainProcess - INFO     Calculating statistics for data: [74, 67, 66, 76, 73, 66, 77, 72, 63, 71, 73, 79, 74, 68, 74, 64, 71, 65, 74, 70, 75, 68, 75, 66, 74, 77, 72, 71, 74, 74, 70, 77, 72, 67, 75, 68, 71, 71, 74, 74, 66, 63, 76, 66, 69, 70, 69, 71, 72, 67] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [74, 67, 66, 76, 73, 66, 77, 72, 63, 71, 73, 79, 74, 68, 74, 64, 71, 65, 74, 70, 75, 68, 75, 66, 74, 77, 72, 71, 74, 74, 70, 77, 72, 67, 75, 68, 71, 71, 74, 74, 66, 63, 76, 66, 69, 70, 69, 71, 72, 67]\n",
      "2024-06-29 13:30:39,189 - micro - MainProcess - INFO     Data converted to numpy array: [74 67 66 76 73 66 77 72 63 71 73 79 74 68 74 64 71 65 74 70 75 68 75 66\n",
      " 74 77 72 71 74 74 70 77 72 67 75 68 71 71 74 74 66 63 76 66 69 70 69 71\n",
      " 72 67] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [74 67 66 76 73 66 77 72 63 71 73 79 74 68 74 64 71 65 74 70 75 68 75 66\n",
      " 74 77 72 71 74 74 70 77 72 67 75 68 71 71 74 74 66 63 76 66 69 70 69 71\n",
      " 72 67]\n",
      "2024-06-29 13:30:39,194 - micro - MainProcess - INFO     Calculated median: 71.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 71.0\n",
      "2024-06-29 13:30:39,201 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 6.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 6.0\n",
      "2024-06-29 13:30:39,207 - micro - MainProcess - INFO     Calculated 95th percentile: 77.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 77.0\n",
      "2024-06-29 13:30:39,210 - micro - MainProcess - INFO     Calculated 99th percentile: 78.02 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 78.02\n",
      "2024-06-29 13:30:39,218 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.06 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.06\n",
      "2024-06-29 13:30:39,221 - micro - MainProcess - INFO     Result: (71.0, 6.0, 77.0, 78.02, 0.06) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (71.0, 6.0, 77.0, 78.02, 0.06)\n",
      "2024-06-29 13:30:39,227 - micro - MainProcess - INFO     Calculating statistics for data: [0.01, 0.04, 0.04, 0.04, 0.02, 0.02, 0.03, 0.03, 0.01, 0.02, 0.02, 0.02, 0.01, 0.02, 0.02, 0.02, 0.01, 0.02, 0.02, 0.02, 0.01, 0.01, 0.02, 0.02, 0.01, 0.03, 0.03, 0.03, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.04, 0.02, 0.02, 0.02, 0.01, 0.02, 0.02, 0.02, 0.02, 0.03, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.01, 0.04, 0.04, 0.04, 0.02, 0.02, 0.03, 0.03, 0.01, 0.02, 0.02, 0.02, 0.01, 0.02, 0.02, 0.02, 0.01, 0.02, 0.02, 0.02, 0.01, 0.01, 0.02, 0.02, 0.01, 0.03, 0.03, 0.03, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.04, 0.02, 0.02, 0.02, 0.01, 0.02, 0.02, 0.02, 0.02, 0.03, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02]\n",
      "2024-06-29 13:30:39,231 - micro - MainProcess - INFO     Data converted to numpy array: [0.01 0.04 0.04 0.04 0.02 0.02 0.03 0.03 0.01 0.02 0.02 0.02 0.01 0.02\n",
      " 0.02 0.02 0.01 0.02 0.02 0.02 0.01 0.01 0.02 0.02 0.01 0.03 0.03 0.03\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.04 0.02 0.02 0.02 0.01 0.02 0.02 0.02\n",
      " 0.02 0.03 0.02 0.02 0.02 0.02 0.02 0.02] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.01 0.04 0.04 0.04 0.02 0.02 0.03 0.03 0.01 0.02 0.02 0.02 0.01 0.02\n",
      " 0.02 0.02 0.01 0.02 0.02 0.02 0.01 0.01 0.02 0.02 0.01 0.03 0.03 0.03\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.04 0.02 0.02 0.02 0.01 0.02 0.02 0.02\n",
      " 0.02 0.03 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "2024-06-29 13:30:39,235 - micro - MainProcess - INFO     Calculated median: 0.02 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.02\n",
      "2024-06-29 13:30:39,240 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-29 13:30:39,244 - micro - MainProcess - INFO     Calculated 95th percentile: 0.04 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.04\n",
      "2024-06-29 13:30:39,253 - micro - MainProcess - INFO     Calculated 99th percentile: 0.04 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.04\n",
      "2024-06-29 13:30:39,261 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.36 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.36\n",
      "2024-06-29 13:30:39,265 - micro - MainProcess - INFO     Result: (0.02, 0.0, 0.04, 0.04, 0.36) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.02, 0.0, 0.04, 0.04, 0.36)\n",
      "2024-06-29 13:30:39,268 - micro - MainProcess - INFO     Calculating statistics for data: [3.16, 9.54, 9.49, 9.65, 5.21, 4.92, 6.47, 6.38, 2.88, 4.25, 4.2, 3.98, 3.29, 4.66, 4.43, 4.52, 3.56, 5.06, 4.89, 5.12, 3.71, 3.01, 4.08, 4.15, 2.85, 7.44, 7.74, 7.2, 5.05, 3.86, 3.84, 3.91, 4.1, 4.09, 10.63, 4.17, 4.21, 3.78, 3.63, 4.35, 4.32, 4.04, 4.13, 6.41, 3.82, 4.21, 4.9, 4.44, 4.25, 5.74] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [3.16, 9.54, 9.49, 9.65, 5.21, 4.92, 6.47, 6.38, 2.88, 4.25, 4.2, 3.98, 3.29, 4.66, 4.43, 4.52, 3.56, 5.06, 4.89, 5.12, 3.71, 3.01, 4.08, 4.15, 2.85, 7.44, 7.74, 7.2, 5.05, 3.86, 3.84, 3.91, 4.1, 4.09, 10.63, 4.17, 4.21, 3.78, 3.63, 4.35, 4.32, 4.04, 4.13, 6.41, 3.82, 4.21, 4.9, 4.44, 4.25, 5.74]\n",
      "2024-06-29 13:30:39,275 - micro - MainProcess - INFO     Data converted to numpy array: [ 3.16  9.54  9.49  9.65  5.21  4.92  6.47  6.38  2.88  4.25  4.2   3.98\n",
      "  3.29  4.66  4.43  4.52  3.56  5.06  4.89  5.12  3.71  3.01  4.08  4.15\n",
      "  2.85  7.44  7.74  7.2   5.05  3.86  3.84  3.91  4.1   4.09 10.63  4.17\n",
      "  4.21  3.78  3.63  4.35  4.32  4.04  4.13  6.41  3.82  4.21  4.9   4.44\n",
      "  4.25  5.74] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [ 3.16  9.54  9.49  9.65  5.21  4.92  6.47  6.38  2.88  4.25  4.2   3.98\n",
      "  3.29  4.66  4.43  4.52  3.56  5.06  4.89  5.12  3.71  3.01  4.08  4.15\n",
      "  2.85  7.44  7.74  7.2   5.05  3.86  3.84  3.91  4.1   4.09 10.63  4.17\n",
      "  4.21  3.78  3.63  4.35  4.32  4.04  4.13  6.41  3.82  4.21  4.9   4.44\n",
      "  4.25  5.74]\n",
      "2024-06-29 13:30:39,279 - micro - MainProcess - INFO     Calculated median: 4.25 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 4.25\n",
      "2024-06-29 13:30:39,284 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 1.18 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 1.18\n",
      "2024-06-29 13:30:39,288 - micro - MainProcess - INFO     Calculated 95th percentile: 9.52 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 9.52\n",
      "2024-06-29 13:30:39,291 - micro - MainProcess - INFO     Calculated 99th percentile: 10.15 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 10.15\n",
      "2024-06-29 13:30:39,296 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.36 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.36\n",
      "2024-06-29 13:30:39,299 - micro - MainProcess - INFO     Result: (4.25, 1.18, 9.52, 10.15, 0.36) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (4.25, 1.18, 9.52, 10.15, 0.36)\n",
      "2024-06-29 13:30:39,302 - micro - MainProcess - INFO     Calculating statistics for data: [9.750699300000008, 9.702598899999998, 9.899967700000047, 9.823248800000044, 6.511075099999971, 8.49161939999999, 8.49168149999997, 8.397500999999977, 7.016990600000042, 7.124224200000015, 7.592838400000005, 9.059844999999996, 6.300760499999967, 8.905212199999994, 7.920472899999993, 7.467701000000034, 5.546355500000004, 6.755018500000006, 11.314878700000008, 10.584204999999997, 8.412597300000016, 7.387469699999997, 7.76785430000001, 6.031563100000028, 7.963663599999961, 8.16012440000003, 8.11550470000003, 8.15943390000001, 7.900277700000004, 7.8119102999999654, 5.950271799999996, 7.981589699999972, 7.681413599999985, 7.617659199999991, 7.527652199999977, 7.785452399999997, 6.666113999999993, 6.329974100000015, 6.8424547999999845, 8.54312490000001, 9.741795100000047, 5.913496899999984, 10.315681700000027, 6.5509442000000035, 10.717728300000033, 10.666689900000051, 10.596295499999997, 10.385106300000075, 6.486483500000077, 5.720544199999949] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [9.750699300000008, 9.702598899999998, 9.899967700000047, 9.823248800000044, 6.511075099999971, 8.49161939999999, 8.49168149999997, 8.397500999999977, 7.016990600000042, 7.124224200000015, 7.592838400000005, 9.059844999999996, 6.300760499999967, 8.905212199999994, 7.920472899999993, 7.467701000000034, 5.546355500000004, 6.755018500000006, 11.314878700000008, 10.584204999999997, 8.412597300000016, 7.387469699999997, 7.76785430000001, 6.031563100000028, 7.963663599999961, 8.16012440000003, 8.11550470000003, 8.15943390000001, 7.900277700000004, 7.8119102999999654, 5.950271799999996, 7.981589699999972, 7.681413599999985, 7.617659199999991, 7.527652199999977, 7.785452399999997, 6.666113999999993, 6.329974100000015, 6.8424547999999845, 8.54312490000001, 9.741795100000047, 5.913496899999984, 10.315681700000027, 6.5509442000000035, 10.717728300000033, 10.666689900000051, 10.596295499999997, 10.385106300000075, 6.486483500000077, 5.720544199999949]\n",
      "2024-06-29 13:30:39,305 - micro - MainProcess - INFO     Data converted to numpy array: [ 9.7506993  9.7025989  9.8999677  9.8232488  6.5110751  8.4916194\n",
      "  8.4916815  8.397501   7.0169906  7.1242242  7.5928384  9.059845\n",
      "  6.3007605  8.9052122  7.9204729  7.467701   5.5463555  6.7550185\n",
      " 11.3148787 10.584205   8.4125973  7.3874697  7.7678543  6.0315631\n",
      "  7.9636636  8.1601244  8.1155047  8.1594339  7.9002777  7.8119103\n",
      "  5.9502718  7.9815897  7.6814136  7.6176592  7.5276522  7.7854524\n",
      "  6.666114   6.3299741  6.8424548  8.5431249  9.7417951  5.9134969\n",
      " 10.3156817  6.5509442 10.7177283 10.6666899 10.5962955 10.3851063\n",
      "  6.4864835  5.7205442] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [ 9.7506993  9.7025989  9.8999677  9.8232488  6.5110751  8.4916194\n",
      "  8.4916815  8.397501   7.0169906  7.1242242  7.5928384  9.059845\n",
      "  6.3007605  8.9052122  7.9204729  7.467701   5.5463555  6.7550185\n",
      " 11.3148787 10.584205   8.4125973  7.3874697  7.7678543  6.0315631\n",
      "  7.9636636  8.1601244  8.1155047  8.1594339  7.9002777  7.8119103\n",
      "  5.9502718  7.9815897  7.6814136  7.6176592  7.5276522  7.7854524\n",
      "  6.666114   6.3299741  6.8424548  8.5431249  9.7417951  5.9134969\n",
      " 10.3156817  6.5509442 10.7177283 10.6666899 10.5962955 10.3851063\n",
      "  6.4864835  5.7205442]\n",
      "2024-06-29 13:30:39,310 - micro - MainProcess - INFO     Calculated median: 7.91 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 7.91\n",
      "2024-06-29 13:30:39,315 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 2.14 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 2.14\n",
      "2024-06-29 13:30:39,319 - micro - MainProcess - INFO     Calculated 95th percentile: 10.64 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 10.64\n",
      "2024-06-29 13:30:39,323 - micro - MainProcess - INFO     Calculated 99th percentile: 11.02 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 11.02\n",
      "2024-06-29 13:30:39,329 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.19 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.19\n",
      "2024-06-29 13:30:39,333 - micro - MainProcess - INFO     Result: (7.91, 2.14, 10.64, 11.02, 0.19) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (7.91, 2.14, 10.64, 11.02, 0.19)\n",
      "2024-06-29 13:30:39,335 - micro - MainProcess - INFO     Calculating statistics for data: [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]\n",
      "2024-06-29 13:30:39,339 - micro - MainProcess - INFO     Data converted to numpy array: [500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500\n",
      " 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500\n",
      " 500 500 500 500 500 500 500 500 500 500 500 500 500 500] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500\n",
      " 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500\n",
      " 500 500 500 500 500 500 500 500 500 500 500 500 500 500]\n",
      "2024-06-29 13:30:39,343 - micro - MainProcess - INFO     Calculated median: 500.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 500.0\n",
      "2024-06-29 13:30:39,350 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-29 13:30:39,354 - micro - MainProcess - INFO     Calculated 95th percentile: 500.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 500.0\n",
      "2024-06-29 13:30:39,358 - micro - MainProcess - INFO     Calculated 99th percentile: 500.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 500.0\n",
      "2024-06-29 13:30:39,363 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-29 13:30:39,367 - micro - MainProcess - INFO     Result: (500.0, 0.0, 500.0, 500.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (500.0, 0.0, 500.0, 500.0, 0.0)\n",
      "2024-06-29 13:30:39,369 - micro - MainProcess - INFO     Calculating statistics for data: [68, 66, 77, 73, 73, 78, 67, 73, 79, 63, 73, 71, 68, 74, 74, 64, 70, 71, 65, 73, 66, 75, 75, 68, 71, 77, 74, 73, 70, 73, 74, 74, 67, 72, 74, 77, 70, 70, 65, 69, 63, 72, 67, 74, 69, 67, 69, 75, 71, 68] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [68, 66, 77, 73, 73, 78, 67, 73, 79, 63, 73, 71, 68, 74, 74, 64, 70, 71, 65, 73, 66, 75, 75, 68, 71, 77, 74, 73, 70, 73, 74, 74, 67, 72, 74, 77, 70, 70, 65, 69, 63, 72, 67, 74, 69, 67, 69, 75, 71, 68]\n",
      "2024-06-29 13:30:39,375 - micro - MainProcess - INFO     Data converted to numpy array: [68 66 77 73 73 78 67 73 79 63 73 71 68 74 74 64 70 71 65 73 66 75 75 68\n",
      " 71 77 74 73 70 73 74 74 67 72 74 77 70 70 65 69 63 72 67 74 69 67 69 75\n",
      " 71 68] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [68 66 77 73 73 78 67 73 79 63 73 71 68 74 74 64 70 71 65 73 66 75 75 68\n",
      " 71 77 74 73 70 73 74 74 67 72 74 77 70 70 65 69 63 72 67 74 69 67 69 75\n",
      " 71 68]\n",
      "2024-06-29 13:30:39,378 - micro - MainProcess - INFO     Calculated median: 71.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 71.0\n",
      "2024-06-29 13:30:39,386 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 6.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 6.0\n",
      "2024-06-29 13:30:39,391 - micro - MainProcess - INFO     Calculated 95th percentile: 77.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 77.0\n",
      "2024-06-29 13:30:39,395 - micro - MainProcess - INFO     Calculated 99th percentile: 78.51 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 78.51\n",
      "2024-06-29 13:30:39,400 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.06 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.06\n",
      "2024-06-29 13:30:39,403 - micro - MainProcess - INFO     Result: (71.0, 6.0, 77.0, 78.51, 0.06) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (71.0, 6.0, 77.0, 78.51, 0.06)\n",
      "2024-06-29 13:30:39,408 - micro - MainProcess - INFO     Calculating statistics for data: [0.02, 0.02, 0.02, 0.02, 0.01, 0.02, 0.02, 0.02, 0.01, 0.01, 0.02, 0.02, 0.01, 0.02, 0.02, 0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.01, 0.02, 0.01, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.01, 0.02, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.02, 0.02, 0.01, 0.02, 0.01, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.02, 0.02, 0.02, 0.02, 0.01, 0.02, 0.02, 0.02, 0.01, 0.01, 0.02, 0.02, 0.01, 0.02, 0.02, 0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.01, 0.02, 0.01, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.01, 0.02, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.02, 0.02, 0.01, 0.02, 0.01, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01]\n",
      "2024-06-29 13:30:39,413 - micro - MainProcess - INFO     Data converted to numpy array: [0.02 0.02 0.02 0.02 0.01 0.02 0.02 0.02 0.01 0.01 0.02 0.02 0.01 0.02\n",
      " 0.02 0.01 0.01 0.01 0.02 0.02 0.02 0.01 0.02 0.01 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.01 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.02 0.02 0.01\n",
      " 0.02 0.01 0.02 0.02 0.02 0.02 0.01 0.01] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.02 0.02 0.02 0.02 0.01 0.02 0.02 0.02 0.01 0.01 0.02 0.02 0.01 0.02\n",
      " 0.02 0.01 0.01 0.01 0.02 0.02 0.02 0.01 0.02 0.01 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.01 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.02 0.02 0.01\n",
      " 0.02 0.01 0.02 0.02 0.02 0.02 0.01 0.01]\n",
      "2024-06-29 13:30:39,418 - micro - MainProcess - INFO     Calculated median: 0.02 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.02\n",
      "2024-06-29 13:30:39,425 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.01 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.01\n",
      "2024-06-29 13:30:39,428 - micro - MainProcess - INFO     Calculated 95th percentile: 0.02 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.02\n",
      "2024-06-29 13:30:39,432 - micro - MainProcess - INFO     Calculated 99th percentile: 0.02 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.02\n",
      "2024-06-29 13:30:39,437 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.29 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.29\n",
      "2024-06-29 13:30:39,440 - micro - MainProcess - INFO     Result: (0.02, 0.01, 0.02, 0.02, 0.29) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.02, 0.01, 0.02, 0.02, 0.29)\n",
      "2024-06-29 13:30:39,443 - micro - MainProcess - INFO     Calculating statistics for data: [9.75, 9.7, 9.9, 9.82, 6.51, 8.49, 8.49, 8.4, 7.02, 7.12, 7.59, 9.06, 6.3, 8.91, 7.92, 7.47, 5.55, 6.76, 11.31, 10.58, 8.41, 7.39, 7.77, 6.03, 7.96, 8.16, 8.12, 8.16, 7.9, 7.81, 5.95, 7.98, 7.68, 7.62, 7.53, 7.79, 6.67, 6.33, 6.84, 8.54, 9.74, 5.91, 10.32, 6.55, 10.72, 10.67, 10.6, 10.39, 6.49, 5.72] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [9.75, 9.7, 9.9, 9.82, 6.51, 8.49, 8.49, 8.4, 7.02, 7.12, 7.59, 9.06, 6.3, 8.91, 7.92, 7.47, 5.55, 6.76, 11.31, 10.58, 8.41, 7.39, 7.77, 6.03, 7.96, 8.16, 8.12, 8.16, 7.9, 7.81, 5.95, 7.98, 7.68, 7.62, 7.53, 7.79, 6.67, 6.33, 6.84, 8.54, 9.74, 5.91, 10.32, 6.55, 10.72, 10.67, 10.6, 10.39, 6.49, 5.72]\n",
      "2024-06-29 13:30:39,454 - micro - MainProcess - INFO     Data converted to numpy array: [ 9.75  9.7   9.9   9.82  6.51  8.49  8.49  8.4   7.02  7.12  7.59  9.06\n",
      "  6.3   8.91  7.92  7.47  5.55  6.76 11.31 10.58  8.41  7.39  7.77  6.03\n",
      "  7.96  8.16  8.12  8.16  7.9   7.81  5.95  7.98  7.68  7.62  7.53  7.79\n",
      "  6.67  6.33  6.84  8.54  9.74  5.91 10.32  6.55 10.72 10.67 10.6  10.39\n",
      "  6.49  5.72] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [ 9.75  9.7   9.9   9.82  6.51  8.49  8.49  8.4   7.02  7.12  7.59  9.06\n",
      "  6.3   8.91  7.92  7.47  5.55  6.76 11.31 10.58  8.41  7.39  7.77  6.03\n",
      "  7.96  8.16  8.12  8.16  7.9   7.81  5.95  7.98  7.68  7.62  7.53  7.79\n",
      "  6.67  6.33  6.84  8.54  9.74  5.91 10.32  6.55 10.72 10.67 10.6  10.39\n",
      "  6.49  5.72]\n",
      "2024-06-29 13:30:39,459 - micro - MainProcess - INFO     Calculated median: 7.91 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 7.91\n",
      "2024-06-29 13:30:39,463 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 2.14 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 2.14\n",
      "2024-06-29 13:30:39,468 - micro - MainProcess - INFO     Calculated 95th percentile: 10.64 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 10.64\n",
      "2024-06-29 13:30:39,473 - micro - MainProcess - INFO     Calculated 99th percentile: 11.02 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 11.02\n",
      "2024-06-29 13:30:39,478 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.19 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.19\n",
      "2024-06-29 13:30:39,480 - micro - MainProcess - INFO     Result: (7.91, 2.14, 10.64, 11.02, 0.19) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (7.91, 2.14, 10.64, 11.02, 0.19)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------+------------+-----------+--------------+-------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+---------+---------------------+---------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|    Model_MaxTokens    | is_Streaming | Iterations |  Regions  | Average TTLT | Median TTLT | IQR TTLT | 95th Percentile TTLT | 99th Percentile TTLT | CV TTLT | Median Prompt Tokens | IQR Prompt Tokens | Median Completion Tokens | IQR Completion Tokens | 95th Percentile Completion Tokens | 99th Percentile Completion Tokens | CV Completion Tokens | Average TBT | Median TBT | IQR TBT | 95th Percentile TBT | 99th Percentile TBT | Average TTFT | Median TTFT | IQR TTFT | 95th Percentile TTFT | 99th Percentile TTFT | Error Rate | Error Types | Successful Runs | Unsuccessful Runs | Throttle Count | Throttle Rate |                                                                      Best Run                                                                      |                                                                      Worst Run                                                                      |\n",
      "+-----------------------+--------------+------------+-----------+--------------+-------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+---------+---------------------+---------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| gpt-4o-2024-05-13_250 |    False     |     50     | East US 2 |     4.95     |    4.25     |   1.18   |         9.52         |        10.15         |  0.36   |         71.0         |        6.0        |          250.0           |          0.0          |               250.0               |               250.0               |         0.0          |    0.02     |    0.02    |   0.0   |        0.04         |        0.04         |     4.95     |    4.25     |   1.18   |         9.52         |        10.15         |    0.0     |     []      |       50        |         0         |       0        |      0.0      | {\"ttlt\": 2.85, \"completion_tokens\": 250, \"prompt_tokens\": 74, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-29 14:28:58 EDT\"} | {\"ttlt\": 10.63, \"completion_tokens\": 250, \"prompt_tokens\": 75, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-29 14:29:15 EDT\"} |\n",
      "| gpt-4o-2024-05-13_500 |    False     |     50     | East US 2 |     8.09     |    7.91     |   2.14   |        10.64         |        11.02         |  0.19   |         71.0         |        6.0        |          500.0           |          0.0          |               500.0               |               500.0               |         0.0          |    0.02     |    0.02    |  0.01   |        0.02         |        0.02         |     8.09     |    7.91     |   2.14   |        10.64         |        11.02         |    0.0     |     []      |       50        |         0         |       0        |      0.0      | {\"ttlt\": 5.55, \"completion_tokens\": 500, \"prompt_tokens\": 70, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-29 14:28:59 EDT\"} | {\"ttlt\": 11.31, \"completion_tokens\": 500, \"prompt_tokens\": 65, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-29 14:29:05 EDT\"} |\n",
      "+-----------------------+--------------+------------+-----------+--------------+-------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+---------+---------------------+---------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_250': {'median_ttlt': 4.25,\n",
       "  'is_Streaming': False,\n",
       "  'regions': ['East US 2'],\n",
       "  'iqr_ttlt': 1.18,\n",
       "  'percentile_95_ttlt': 9.52,\n",
       "  'percentile_99_ttlt': 10.15,\n",
       "  'cv_ttlt': 0.36,\n",
       "  'median_completion_tokens': 250.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 250.0,\n",
       "  'percentile_99_completion_tokens': 250.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 71.0,\n",
       "  'iqr_prompt_tokens': 6.0,\n",
       "  'percentile_95_prompt_tokens': 77.0,\n",
       "  'percentile_99_prompt_tokens': 78.02,\n",
       "  'cv_prompt_tokens': 0.06,\n",
       "  'average_ttlt': 4.95,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 50,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 50,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 0.02,\n",
       "  'iqr_tbt': 0.0,\n",
       "  'percentile_95_tbt': 0.04,\n",
       "  'percentile_99_tbt': 0.04,\n",
       "  'cv_tbt': 0.36,\n",
       "  'average_tbt': 0.02,\n",
       "  'median_ttft': 4.25,\n",
       "  'iqr_ttft': 1.18,\n",
       "  'percentile_95_ttft': 9.52,\n",
       "  'percentile_99_ttft': 10.15,\n",
       "  'cv_ttft': 0.36,\n",
       "  'average_ttft': 4.95,\n",
       "  'best_run': {'ttlt': 2.85,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 74,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-29 14:28:58 EDT'},\n",
       "  'worst_run': {'ttlt': 10.63,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 75,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-29 14:29:15 EDT'}},\n",
       " 'gpt-4o-2024-05-13_500': {'median_ttlt': 7.91,\n",
       "  'is_Streaming': False,\n",
       "  'regions': ['East US 2'],\n",
       "  'iqr_ttlt': 2.14,\n",
       "  'percentile_95_ttlt': 10.64,\n",
       "  'percentile_99_ttlt': 11.02,\n",
       "  'cv_ttlt': 0.19,\n",
       "  'median_completion_tokens': 500.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 500.0,\n",
       "  'percentile_99_completion_tokens': 500.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 71.0,\n",
       "  'iqr_prompt_tokens': 6.0,\n",
       "  'percentile_95_prompt_tokens': 77.0,\n",
       "  'percentile_99_prompt_tokens': 78.51,\n",
       "  'cv_prompt_tokens': 0.06,\n",
       "  'average_ttlt': 8.09,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 50,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 50,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 0.02,\n",
       "  'iqr_tbt': 0.01,\n",
       "  'percentile_95_tbt': 0.02,\n",
       "  'percentile_99_tbt': 0.02,\n",
       "  'cv_tbt': 0.29,\n",
       "  'average_tbt': 0.02,\n",
       "  'median_ttft': 7.91,\n",
       "  'iqr_ttft': 2.14,\n",
       "  'percentile_95_ttft': 10.64,\n",
       "  'percentile_99_ttft': 11.02,\n",
       "  'cv_ttft': 0.19,\n",
       "  'average_ttft': 8.09,\n",
       "  'best_run': {'ttlt': 5.55,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 70,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-29 14:28:59 EDT'},\n",
       "  'worst_run': {'ttlt': 11.31,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 65,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-29 14:29:05 EDT'}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_non_streaming.calculate_and_show_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning, a subset of artificial intelligence, has revolutionized numerous fields by enabling systems to learn from data and improve their performance over time without being explicitly programmed. This technology leverages algorithms to parse data, learn from it, and make informed decisions. The core idea is to build models that can generalize from specific examples to broader applications.\\n\\nOne of the most significant impacts of machine learning is in the realm of data analysis. Traditional data analysis methods often require manual intervention and are limited by human capacity to'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 22:12:59,804 - micro - MainProcess - INFO     CPU usage: 12.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.7%\n",
      "2024-06-27 22:12:59,822 - micro - MainProcess - INFO     RAM usage: 94.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 94.3%\n",
      "2024-06-27 22:12:59,843 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:12:59,845 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:12:59.845862, (GMT): 2024-06-28 03:12:59.845862+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:12:59.845862, (GMT): 2024-06-28 03:12:59.845862+00:00\n",
      "2024-06-27 22:12:59,849 - micro - MainProcess - INFO     CPU usage: 6.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 6.9%\n",
      "2024-06-27 22:12:59,862 - micro - MainProcess - INFO     RAM usage: 94.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 94.3%\n",
      "2024-06-27 22:12:59,887 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:12:59,891 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:12:59.890828, (GMT): 2024-06-28 03:12:59.890828+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:12:59.890828, (GMT): 2024-06-28 03:12:59.890828+00:00\n",
      "2024-06-27 22:13:00,321 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 426.36, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 426.36, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:00,349 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 501.44, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 501.44, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:00,625 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 303.89, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 303.89, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:00,850 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' development', 'Token size': 1, 'Time taken (ms)': 224.24, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' development', 'Token size': 1, 'Time taken (ms)': 224.24, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:00,854 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 504.75, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 504.75, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:01,091 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' are', 'Token size': 1, 'Time taken (ms)': 242.19, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' are', 'Token size': 1, 'Time taken (ms)': 242.19, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:01,379 - micro - MainProcess - INFO     {'Count': 5, 'Content': ' be', 'Token size': 1, 'Time taken (ms)': 287.44, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': ' be', 'Token size': 1, 'Time taken (ms)': 287.44, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:01,386 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 532.28, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 532.28, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:01,655 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' computational', 'Token size': 1, 'Time taken (ms)': 275.03, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' computational', 'Token size': 1, 'Time taken (ms)': 275.03, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:01,897 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 511.32, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 511.32, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:01,901 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' programmed', 'Token size': 1, 'Time taken (ms)': 247.32, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' programmed', 'Token size': 1, 'Time taken (ms)': 247.32, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:02,176 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 274.24, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 274.24, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:02,372 - micro - MainProcess - INFO     {'Count': 5, 'Content': ' its', 'Token size': 1, 'Time taken (ms)': 474.96, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': ' its', 'Token size': 1, 'Time taken (ms)': 474.96, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:02,472 - micro - MainProcess - INFO     {'Count': 9, 'Content': ' used', 'Token size': 1, 'Time taken (ms)': 296.24, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': ' used', 'Token size': 1, 'Time taken (ms)': 296.24, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:02,785 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' labeled', 'Token size': 1, 'Time taken (ms)': 312.75, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' labeled', 'Token size': 1, 'Time taken (ms)': 312.75, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:02,834 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' identify', 'Token size': 1, 'Time taken (ms)': 49.27, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' identify', 'Token size': 1, 'Time taken (ms)': 49.27, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:02,851 - micro - MainProcess - INFO     {'Count': 12, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 16.68, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 16.68, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:02,878 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 2.98 seconds or 2982.86 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 2.98 seconds or 2982.86 milliseconds.\n",
      "2024-06-27 22:13:02,941 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:02,981 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 608.74, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 608.74, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:03,035 - micro - MainProcess - INFO     {'Count': 7, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 53.21, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 53.21, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:03,551 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' dataset', 'Token size': 1, 'Time taken (ms)': 517.66, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' dataset', 'Token size': 1, 'Time taken (ms)': 517.66, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:03,602 - micro - MainProcess - INFO     {'Count': 9, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 50.11, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 50.11, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:03,954 - micro - MainProcess - INFO     CPU usage: 20.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 20.5%\n",
      "2024-06-27 22:13:03,968 - micro - MainProcess - INFO     RAM usage: 94.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 94.3%\n",
      "2024-06-27 22:13:04,000 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:04,002 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:04.002970, (GMT): 2024-06-28 03:13:04.002970+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:04.002970, (GMT): 2024-06-28 03:13:04.002970+00:00\n",
      "2024-06-27 22:13:04,053 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 450.86, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 450.86, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:04,325 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 319.17, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 319.17, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:04,745 - micro - MainProcess - INFO     {'Count': 11, 'Content': '.\\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 692.99, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': '.\\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 692.99, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:04,841 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 516.4, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 516.4, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:04,896 - micro - MainProcess - INFO     {'Count': 3, 'Content': 'ized', 'Token size': 1, 'Time taken (ms)': 55.57, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': 'ized', 'Token size': 1, 'Time taken (ms)': 55.57, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:05,153 - micro - MainProcess - INFO     {'Count': 12, 'Content': ' present', 'Token size': 1, 'Time taken (ms)': 406.79, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ' present', 'Token size': 1, 'Time taken (ms)': 406.79, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:05,233 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 336.8, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 336.8, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:05,614 - micro - MainProcess - INFO     {'Count': 5, 'Content': ' technology', 'Token size': 1, 'Time taken (ms)': 381.09, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': ' technology', 'Token size': 1, 'Time taken (ms)': 381.09, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:05,710 - micro - MainProcess - INFO     {'Count': 13, 'Content': ' principal', 'Token size': 1, 'Time taken (ms)': 558.46, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 13, 'Content': ' principal', 'Token size': 1, 'Time taken (ms)': 558.46, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:05,758 - micro - MainProcess - INFO     {'Count': 14, 'Content': ' typical', 'Token size': 1, 'Time taken (ms)': 47.37, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 14, 'Content': ' typical', 'Token size': 1, 'Time taken (ms)': 47.37, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:06,011 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' concepts', 'Token size': 1, 'Time taken (ms)': 396.35, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' concepts', 'Token size': 1, 'Time taken (ms)': 396.35, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:06,174 - micro - MainProcess - INFO     {'Count': 15, 'Content': ' by', 'Token size': 1, 'Time taken (ms)': 415.61, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 15, 'Content': ' by', 'Token size': 1, 'Time taken (ms)': 415.61, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:06,509 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 498.96, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 498.96, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:06,594 - micro - MainProcess - INFO     {'Count': 16, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 419.81, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 16, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 419.81, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:06,882 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' during', 'Token size': 1, 'Time taken (ms)': 372.26, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' during', 'Token size': 1, 'Time taken (ms)': 372.26, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:07,078 - micro - MainProcess - INFO     {'Count': 17, 'Content': ' (', 'Token size': 1, 'Time taken (ms)': 484.7, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 17, 'Content': ' (', 'Token size': 1, 'Time taken (ms)': 484.7, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:07,128 - micro - MainProcess - INFO     {'Count': 18, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 49.3, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 18, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 49.3, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:07,377 - micro - MainProcess - INFO     {'Count': 9, 'Content': ' images', 'Token size': 1, 'Time taken (ms)': 495.59, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': ' images', 'Token size': 1, 'Time taken (ms)': 495.59, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:07,500 - micro - MainProcess - INFO     {'Count': 19, 'Content': ' industries', 'Token size': 1, 'Time taken (ms)': 372.92, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 19, 'Content': ' industries', 'Token size': 1, 'Time taken (ms)': 372.92, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:07,781 - micro - MainProcess - INFO     {'Count': 10, 'Content': 'abeled', 'Token size': 1, 'Time taken (ms)': 403.62, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': 'abeled', 'Token size': 1, 'Time taken (ms)': 403.62, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:07,935 - micro - MainProcess - INFO     {'Count': 20, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 434.28, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 20, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 434.28, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:08,179 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 397.73, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 397.73, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:08,424 - micro - MainProcess - INFO     {'Count': 21, 'Content': ' high', 'Token size': 1, 'Time taken (ms)': 488.67, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 21, 'Content': ' high', 'Token size': 1, 'Time taken (ms)': 488.67, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:08,470 - micro - MainProcess - INFO     {'Count': 22, 'Content': ' for', 'Token size': 1, 'Time taken (ms)': 46.77, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 22, 'Content': ' for', 'Token size': 1, 'Time taken (ms)': 46.77, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:08,556 - micro - MainProcess - INFO     {'Count': 12, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 377.06, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 377.06, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:08,589 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.58 seconds or 4583.76 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.58 seconds or 4583.76 milliseconds.\n",
      "2024-06-27 22:13:08,642 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:08,823 - micro - MainProcess - INFO     {'Count': 23, 'Content': ' management', 'Token size': 1, 'Time taken (ms)': 352.69, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 23, 'Content': ' management', 'Token size': 1, 'Time taken (ms)': 352.69, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:09,129 - micro - MainProcess - INFO     {'Count': 24, 'Content': '**', 'Token size': 1, 'Time taken (ms)': 305.58, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 24, 'Content': '**', 'Token size': 1, 'Time taken (ms)': 305.58, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:09,260 - micro - MainProcess - INFO     {'Count': 25, 'Content': ' based', 'Token size': 1, 'Time taken (ms)': 130.28, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 25, 'Content': ' based', 'Token size': 1, 'Time taken (ms)': 130.28, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:09,294 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.45 seconds or 9446.67 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.45 seconds or 9446.67 milliseconds.\n",
      "2024-06-27 22:13:09,456 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:09,648 - micro - MainProcess - INFO     CPU usage: 15.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.8%\n",
      "2024-06-27 22:13:09,688 - micro - MainProcess - INFO     RAM usage: 94.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 94.3%\n",
      "2024-06-27 22:13:09,709 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:09,712 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:09.712534, (GMT): 2024-06-28 03:13:09.712534+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:09.712534, (GMT): 2024-06-28 03:13:09.712534+00:00\n",
      "2024-06-27 22:13:10,050 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 331.96, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 331.96, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:10,461 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 411.97, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 411.97, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:10,467 - micro - MainProcess - INFO     CPU usage: 10.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 10.1%\n",
      "2024-06-27 22:13:10,480 - micro - MainProcess - INFO     RAM usage: 94.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 94.3%\n",
      "2024-06-27 22:13:10,504 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:10,508 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:10.508699, (GMT): 2024-06-28 03:13:10.508699+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:10.508699, (GMT): 2024-06-28 03:13:10.508699+00:00\n",
      "2024-06-27 22:13:10,812 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 300.73, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 300.73, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:10,893 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 431.34, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 431.34, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:11,241 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' technology', 'Token size': 1, 'Time taken (ms)': 347.81, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' technology', 'Token size': 1, 'Time taken (ms)': 347.81, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:11,244 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 433.01, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 433.01, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:11,636 - micro - MainProcess - INFO     {'Count': 5, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 394.4, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 394.4, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:11,698 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' development', 'Token size': 1, 'Time taken (ms)': 454.35, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' development', 'Token size': 1, 'Time taken (ms)': 454.35, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:12,175 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' that', 'Token size': 1, 'Time taken (ms)': 539.77, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' that', 'Token size': 1, 'Time taken (ms)': 539.77, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:12,236 - micro - MainProcess - INFO     {'Count': 4, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 536.79, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 536.79, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:12,524 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 348.29, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 348.29, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:12,680 - micro - MainProcess - INFO     {'Count': 5, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 444.38, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 444.38, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:12,974 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 450.98, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 450.98, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:13,089 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' begins', 'Token size': 1, 'Time taken (ms)': 408.81, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' begins', 'Token size': 1, 'Time taken (ms)': 408.81, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:13,366 - micro - MainProcess - INFO     {'Count': 9, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 390.86, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 390.86, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:13,371 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' without', 'Token size': 1, 'Time taken (ms)': 4.64, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' without', 'Token size': 1, 'Time taken (ms)': 4.64, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:13,516 - micro - MainProcess - INFO     {'Count': 7, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 427.19, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 427.19, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:13,788 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' tasks', 'Token size': 1, 'Time taken (ms)': 417.61, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' tasks', 'Token size': 1, 'Time taken (ms)': 417.61, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:13,970 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' applications', 'Token size': 1, 'Time taken (ms)': 453.46, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' applications', 'Token size': 1, 'Time taken (ms)': 453.46, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:14,073 - micro - MainProcess - INFO     {'Count': 12, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 285.21, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 285.21, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:14,102 - micro - MainProcess - INFO     {'Count': 13, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 29.07, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 13, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 29.07, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:14,105 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.39 seconds or 4387.32 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.39 seconds or 4387.32 milliseconds.\n",
      "2024-06-27 22:13:14,170 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:14,336 - micro - MainProcess - INFO     {'Count': 9, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 366.38, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 366.38, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:14,748 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' linear', 'Token size': 1, 'Time taken (ms)': 412.26, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' linear', 'Token size': 1, 'Time taken (ms)': 412.26, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:14,803 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' on', 'Token size': 1, 'Time taken (ms)': 54.87, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' on', 'Token size': 1, 'Time taken (ms)': 54.87, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:15,185 - micro - MainProcess - INFO     CPU usage: 17.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 17.6%\n",
      "2024-06-27 22:13:15,196 - micro - MainProcess - INFO     RAM usage: 94.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 94.3%\n",
      "2024-06-27 22:13:15,215 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:15,218 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:15.218357, (GMT): 2024-06-28 03:13:15.218357+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:15.218357, (GMT): 2024-06-28 03:13:15.218357+00:00\n",
      "2024-06-27 22:13:15,387 - micro - MainProcess - INFO     {'Count': 12, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 583.96, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 583.96, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:15,512 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 287.57, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 287.57, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:15,792 - micro - MainProcess - INFO     {'Count': 13, 'Content': 'uper', 'Token size': 1, 'Time taken (ms)': 404.99, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 13, 'Content': 'uper', 'Token size': 1, 'Time taken (ms)': 404.99, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:16,092 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 580.66, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 580.66, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:16,154 - micro - MainProcess - INFO     {'Count': 14, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 361.75, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 14, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 361.75, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:16,404 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 311.6, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 311.6, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:16,576 - micro - MainProcess - INFO     {'Count': 15, 'Content': ' decisions', 'Token size': 1, 'Time taken (ms)': 422.22, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 15, 'Content': ' decisions', 'Token size': 1, 'Time taken (ms)': 422.22, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:16,778 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' from', 'Token size': 1, 'Time taken (ms)': 374.03, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' from', 'Token size': 1, 'Time taken (ms)': 374.03, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:16,914 - micro - MainProcess - INFO     {'Count': 16, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 338.04, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 16, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 338.04, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:17,140 - micro - MainProcess - INFO     {'Count': 5, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 361.06, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 361.06, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:17,290 - micro - MainProcess - INFO     {'Count': 17, 'Content': '.\\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 375.96, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 17, 'Content': '.\\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 375.96, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:17,411 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 272.1, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 272.1, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:17,772 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 361.85, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 361.85, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:17,875 - micro - MainProcess - INFO     {'Count': 18, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 585.13, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 18, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 585.13, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:18,110 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' is', 'Token size': 1, 'Time taken (ms)': 337.19, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' is', 'Token size': 1, 'Time taken (ms)': 337.19, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:18,474 - micro - MainProcess - INFO     {'Count': 9, 'Content': ' improved', 'Token size': 1, 'Time taken (ms)': 363.16, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': ' improved', 'Token size': 1, 'Time taken (ms)': 363.16, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:18,768 - micro - MainProcess - INFO     {'Count': 10, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 294.47, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 294.47, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:18,889 - micro - MainProcess - INFO     {'Count': 19, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1013.82, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 19, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1013.82, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:19,030 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 261.68, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 261.68, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:19,059 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.83 seconds or 3834.88 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.83 seconds or 3834.88 milliseconds.\n",
      "2024-06-27 22:13:19,119 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:19,482 - micro - MainProcess - INFO     {'Count': 20, 'Content': ' experience', 'Token size': 1, 'Time taken (ms)': 592.45, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 20, 'Content': ' experience', 'Token size': 1, 'Time taken (ms)': 592.45, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:19,885 - micro - MainProcess - INFO     {'Count': 21, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 403.21, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 21, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 403.21, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:19,914 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.4 seconds or 9404.0 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.4 seconds or 9404.0 milliseconds.\n",
      "2024-06-27 22:13:19,967 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:20,120 - micro - MainProcess - INFO     CPU usage: 19.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.6%\n",
      "2024-06-27 22:13:20,131 - micro - MainProcess - INFO     RAM usage: 93.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 93.9%\n",
      "2024-06-27 22:13:20,154 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:20,156 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:20.156569, (GMT): 2024-06-28 03:13:20.156569+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:20.156569, (GMT): 2024-06-28 03:13:20.156569+00:00\n",
      "2024-06-27 22:13:20,551 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 392.78, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 392.78, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:20,989 - micro - MainProcess - INFO     CPU usage: 25.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 25.8%\n",
      "2024-06-27 22:13:21,007 - micro - MainProcess - INFO     RAM usage: 93.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 93.0%\n",
      "2024-06-27 22:13:21,040 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:21,043 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:21.043877, (GMT): 2024-06-28 03:13:21.043877+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:21.043877, (GMT): 2024-06-28 03:13:21.043877+00:00\n",
      "2024-06-27 22:13:21,277 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 726.39, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 726.39, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:21,366 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 317.02, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 317.02, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:21,694 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 416.04, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 416.04, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:21,859 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 493.14, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 493.14, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:22,051 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' programming', 'Token size': 1, 'Time taken (ms)': 356.89, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' programming', 'Token size': 1, 'Time taken (ms)': 356.89, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:22,341 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' development', 'Token size': 1, 'Time taken (ms)': 482.6, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' development', 'Token size': 1, 'Time taken (ms)': 482.6, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:22,587 - micro - MainProcess - INFO     {'Count': 5, 'Content': '.\\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 536.17, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': '.\\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 536.17, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:22,806 - micro - MainProcess - INFO     {'Count': 4, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 465.19, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 465.19, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:23,028 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 440.75, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 440.75, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:23,342 - micro - MainProcess - INFO     {'Count': 5, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 535.92, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 535.92, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:23,369 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' applications', 'Token size': 1, 'Time taken (ms)': 342.37, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' applications', 'Token size': 1, 'Time taken (ms)': 342.37, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:23,394 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' goal', 'Token size': 1, 'Time taken (ms)': 51.9, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' goal', 'Token size': 1, 'Time taken (ms)': 51.9, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:23,736 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 342.07, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 342.07, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:23,828 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 457.52, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 457.52, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:24,231 - micro - MainProcess - INFO     {'Count': 8, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 494.4, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 494.4, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:24,282 - micro - MainProcess - INFO     {'Count': 9, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 454.93, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 454.93, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:24,770 - micro - MainProcess - INFO     {'Count': 9, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 539.06, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 539.06, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:24,777 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' neural', 'Token size': 1, 'Time taken (ms)': 494.73, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' neural', 'Token size': 1, 'Time taken (ms)': 494.73, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:24,824 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 53.94, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 53.94, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:25,124 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' technique', 'Token size': 1, 'Time taken (ms)': 346.27, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' technique', 'Token size': 1, 'Time taken (ms)': 346.27, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:25,155 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.0 seconds or 4996.1 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.0 seconds or 4996.1 milliseconds.\n",
      "2024-06-27 22:13:25,208 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:25,211 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' applications', 'Token size': 1, 'Time taken (ms)': 387.96, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' applications', 'Token size': 1, 'Time taken (ms)': 387.96, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:25,563 - micro - MainProcess - INFO     {'Count': 12, 'Content': ' images', 'Token size': 1, 'Time taken (ms)': 351.89, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ' images', 'Token size': 1, 'Time taken (ms)': 351.89, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:25,965 - micro - MainProcess - INFO     {'Count': 13, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 401.4, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 13, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 401.4, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:26,306 - micro - MainProcess - INFO     {'Count': 14, 'Content': ' find', 'Token size': 1, 'Time taken (ms)': 341.56, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 14, 'Content': ' find', 'Token size': 1, 'Time taken (ms)': 341.56, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:26,720 - micro - MainProcess - INFO     {'Count': 15, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 413.75, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 15, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 413.75, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:26,773 - micro - MainProcess - INFO     {'Count': 16, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 52.74, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 16, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 52.74, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:27,088 - micro - MainProcess - INFO     {'Count': 17, 'Content': 'ity', 'Token size': 1, 'Time taken (ms)': 314.15, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 17, 'Content': 'ity', 'Token size': 1, 'Time taken (ms)': 314.15, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:27,422 - micro - MainProcess - INFO     {'Count': 18, 'Content': ' interpret', 'Token size': 1, 'Time taken (ms)': 335.55, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 18, 'Content': ' interpret', 'Token size': 1, 'Time taken (ms)': 335.55, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:27,873 - micro - MainProcess - INFO     {'Count': 19, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 450.04, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 19, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 450.04, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:28,372 - micro - MainProcess - INFO     {'Count': 20, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 499.2, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 20, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 499.2, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:28,823 - micro - MainProcess - INFO     {'Count': 21, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 450.56, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 21, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 450.56, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:29,263 - micro - MainProcess - INFO     {'Count': 22, 'Content': ' faces', 'Token size': 1, 'Time taken (ms)': 440.59, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 22, 'Content': ' faces', 'Token size': 1, 'Time taken (ms)': 440.59, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:29,466 - micro - MainProcess - INFO     {'Count': 23, 'Content': ' can', 'Token size': 1, 'Time taken (ms)': 202.79, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 23, 'Content': ' can', 'Token size': 1, 'Time taken (ms)': 202.79, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:29,495 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.45 seconds or 8446.44 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.45 seconds or 8446.44 milliseconds.\n",
      "2024-06-27 22:13:29,552 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:30,566 - micro - MainProcess - INFO     CPU usage: 19.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.6%\n",
      "2024-06-27 22:13:30,579 - micro - MainProcess - INFO     RAM usage: 86.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.8%\n",
      "2024-06-27 22:13:30,607 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:30,609 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:30.609616, (GMT): 2024-06-28 03:13:30.609616+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:30.609616, (GMT): 2024-06-28 03:13:30.609616+00:00\n",
      "2024-06-27 22:13:30,973 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 361.33, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 361.33, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:31,376 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 403.12, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 403.12, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:31,803 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 427.35, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 427.35, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:32,278 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 474.25, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 474.25, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:32,710 - micro - MainProcess - INFO     {'Count': 5, 'Content': ' its', 'Token size': 1, 'Time taken (ms)': 433.11, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': ' its', 'Token size': 1, 'Time taken (ms)': 433.11, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:33,101 - micro - MainProcess - INFO     {'Count': 6, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 390.57, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 390.57, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:33,491 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 389.97, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 389.97, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:33,965 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' are', 'Token size': 1, 'Time taken (ms)': 473.68, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' are', 'Token size': 1, 'Time taken (ms)': 473.68, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:34,436 - micro - MainProcess - INFO     {'Count': 9, 'Content': ':', 'Token size': 1, 'Time taken (ms)': 470.58, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': ':', 'Token size': 1, 'Time taken (ms)': 470.58, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:34,958 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' that', 'Token size': 1, 'Time taken (ms)': 522.65, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' that', 'Token size': 1, 'Time taken (ms)': 522.65, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:35,006 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 48.02, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 48.02, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:35,636 - micro - MainProcess - INFO     {'Count': 12, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 629.48, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 629.48, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:36,074 - micro - MainProcess - INFO     {'Count': 13, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 437.75, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 13, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 437.75, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:36,498 - micro - MainProcess - INFO     {'Count': 14, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 424.44, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 14, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 424.44, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:36,983 - micro - MainProcess - INFO     {'Count': 15, 'Content': ' are', 'Token size': 1, 'Time taken (ms)': 484.96, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 15, 'Content': ' are', 'Token size': 1, 'Time taken (ms)': 484.96, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:37,419 - micro - MainProcess - INFO     {'Count': 16, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 435.81, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 16, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 435.81, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:37,955 - micro - MainProcess - INFO     {'Count': 17, 'Content': ' over', 'Token size': 1, 'Time taken (ms)': 536.26, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 17, 'Content': ' over', 'Token size': 1, 'Time taken (ms)': 536.26, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:38,496 - micro - MainProcess - INFO     {'Count': 18, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 540.63, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 18, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 540.63, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:39,107 - micro - MainProcess - INFO     {'Count': 19, 'Content': ' outbreaks', 'Token size': 1, 'Time taken (ms)': 611.61, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 19, 'Content': ' outbreaks', 'Token size': 1, 'Time taken (ms)': 611.61, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:39,561 - micro - MainProcess - INFO     {'Count': 20, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 454.29, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 20, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 454.29, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:39,968 - micro - MainProcess - INFO     {'Count': 21, 'Content': 'ic', 'Token size': 1, 'Time taken (ms)': 406.24, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 21, 'Content': 'ic', 'Token size': 1, 'Time taken (ms)': 406.24, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:40,115 - micro - MainProcess - INFO     {'Count': 22, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 147.57, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 22, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 147.57, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:40,148 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.54 seconds or 9535.73 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.54 seconds or 9535.73 milliseconds.\n",
      "2024-06-27 22:13:40,257 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:41,264 - micro - MainProcess - INFO     CPU usage: 12.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.5%\n",
      "2024-06-27 22:13:41,277 - micro - MainProcess - INFO     RAM usage: 86.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.8%\n",
      "2024-06-27 22:13:41,304 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:41,307 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:41.307750, (GMT): 2024-06-28 03:13:41.307750+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:41.307750, (GMT): 2024-06-28 03:13:41.307750+00:00\n",
      "2024-06-27 22:13:41,673 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 363.75, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 363.75, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:42,212 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 538.71, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 538.71, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:42,769 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 557.01, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 557.01, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:43,351 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 582.38, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 582.38, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:43,871 - micro - MainProcess - INFO     {'Count': 5, 'Content': ' its', 'Token size': 1, 'Time taken (ms)': 519.65, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': ' its', 'Token size': 1, 'Time taken (ms)': 519.65, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:45,497 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' is', 'Token size': 1, 'Time taken (ms)': 1625.05, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' is', 'Token size': 1, 'Time taken (ms)': 1625.05, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:46,098 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' steps', 'Token size': 1, 'Time taken (ms)': 602.36, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' steps', 'Token size': 1, 'Time taken (ms)': 602.36, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:46,146 - micro - MainProcess - INFO     {'Count': 8, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 47.98, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 47.98, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:46,656 - micro - MainProcess - INFO     {'Count': 9, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 509.07, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 509.07, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:47,204 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 547.95, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 547.95, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:47,665 - micro - MainProcess - INFO     {'Count': 11, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 461.1, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 461.1, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:48,250 - micro - MainProcess - INFO     {'Count': 12, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 585.54, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 585.54, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:48,813 - micro - MainProcess - INFO     {'Count': 13, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 562.89, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 13, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 562.89, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:49,387 - micro - MainProcess - INFO     {'Count': 14, 'Content': ' trees', 'Token size': 1, 'Time taken (ms)': 574.39, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 14, 'Content': ' trees', 'Token size': 1, 'Time taken (ms)': 574.39, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:49,449 - micro - MainProcess - INFO     {'Count': 15, 'Content': ' During', 'Token size': 1, 'Time taken (ms)': 61.47, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 15, 'Content': ' During', 'Token size': 1, 'Time taken (ms)': 61.47, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:49,927 - micro - MainProcess - INFO     {'Count': 16, 'Content': ' patterns', 'Token size': 1, 'Time taken (ms)': 478.2, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 16, 'Content': ' patterns', 'Token size': 1, 'Time taken (ms)': 478.2, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:50,500 - micro - MainProcess - INFO     {'Count': 17, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 572.39, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 17, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 572.39, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:51,125 - micro - MainProcess - INFO     {'Count': 18, 'Content': ' dataset', 'Token size': 1, 'Time taken (ms)': 625.19, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 18, 'Content': ' dataset', 'Token size': 1, 'Time taken (ms)': 625.19, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:51,175 - micro - MainProcess - INFO     {'Count': 19, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 49.44, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 19, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 49.44, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:51,929 - micro - MainProcess - INFO     {'Count': 20, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 754.54, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 20, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 754.54, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:52,388 - micro - MainProcess - INFO     {'Count': 21, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 459.93, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 21, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 459.93, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:52,901 - micro - MainProcess - INFO     {'Count': 22, 'Content': ' categorized', 'Token size': 1, 'Time taken (ms)': 512.98, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 22, 'Content': ' categorized', 'Token size': 1, 'Time taken (ms)': 512.98, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:53,025 - micro - MainProcess - INFO     {'Count': 23, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 123.13, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 23, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 123.13, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:53,055 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.75 seconds or 11745.29 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.75 seconds or 11745.29 milliseconds.\n",
      "2024-06-27 22:13:53,125 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n"
     ]
    }
   ],
   "source": [
    "await benchmark_streaming.run_latency_benchmark_bulk(deployment_names=[DEPLOYMENT_ID], max_tokens_list=[500,250], iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_100': {'ttlt_successful': [2.6457064],\n",
       "  'ttlt_unsuccessful': [],\n",
       "  'tbt': [336.87],\n",
       "  'ttft': [0.95],\n",
       "  'regions': [None],\n",
       "  'number_of_iterations': 1,\n",
       "  'completion_tokens': [6],\n",
       "  'prompt_tokens': [1008],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 2.6457064,\n",
       "   'completion_tokens': 6,\n",
       "   'prompt_tokens': 1008,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:12:01 '},\n",
       "  'worst_run': {'ttlt': 2.6457064,\n",
       "   'completion_tokens': 6,\n",
       "   'prompt_tokens': 1008,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:12:01 '}},\n",
       " 'gpt-4o-2024-05-13_250': {'ttlt_successful': [2.9828582000000097,\n",
       "   4.583761499999994,\n",
       "   4.387315100000009,\n",
       "   3.834885,\n",
       "   4.996095199999999],\n",
       "  'ttlt_unsuccessful': [],\n",
       "  'tbt': [229.94, 384.68, 337.66, 351.78, 457.21],\n",
       "  'ttft': [8.53, 6.38, 6.64, 5.75, 7.86],\n",
       "  'regions': [None, None, None, None, None],\n",
       "  'number_of_iterations': 5,\n",
       "  'completion_tokens': [12, 12, 13, 11, 11],\n",
       "  'prompt_tokens': [50, 50, 50, 50, 50],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 2.9828582000000097,\n",
       "   'completion_tokens': 12,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:02 '},\n",
       "  'worst_run': {'ttlt': 4.996095199999999,\n",
       "   'completion_tokens': 11,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:25 '}},\n",
       " 'gpt-4o-2024-05-13_500': {'ttlt_successful': [9.446672300000003,\n",
       "   9.403997600000011,\n",
       "   8.446443699999989,\n",
       "   9.535728200000008,\n",
       "   11.745287300000001],\n",
       "  'ttlt_unsuccessful': [],\n",
       "  'tbt': [371.25, 453.65, 368.2, 435.35, 515.97],\n",
       "  'ttft': [10.03, 6.01, 6.34, 7.23, 7.28],\n",
       "  'regions': [None, None, None, None, None],\n",
       "  'number_of_iterations': 5,\n",
       "  'completion_tokens': [25, 21, 23, 22, 23],\n",
       "  'prompt_tokens': [50, 50, 50, 50, 50],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 8.446443699999989,\n",
       "   'completion_tokens': 23,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:29 '},\n",
       "  'worst_run': {'ttlt': 11.745287300000001,\n",
       "   'completion_tokens': 23,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:53 '}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_streaming.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 22:15:06,079 - micro - MainProcess - INFO     Calculating statistics for data: [2.6457064] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [2.6457064]\n",
      "2024-06-27 22:15:06,088 - micro - MainProcess - INFO     Data converted to numpy array: [2.6457064] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [2.6457064]\n",
      "2024-06-27 22:15:06,095 - micro - MainProcess - INFO     Calculated median: 2.6457064 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 2.6457064\n",
      "2024-06-27 22:15:06,102 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 22:15:06,107 - micro - MainProcess - INFO     Calculated 95th percentile: 2.6457064 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 2.6457064\n",
      "2024-06-27 22:15:06,108 - micro - MainProcess - INFO     Calculated 99th percentile: 2.6457064 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 2.6457064\n",
      "2024-06-27 22:15:06,117 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 22:15:06,119 - micro - MainProcess - INFO     Result: (2.6457064, 0.0, 2.6457064, 2.6457064, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (2.6457064, 0.0, 2.6457064, 2.6457064, 0.0)\n",
      "2024-06-27 22:15:06,121 - micro - MainProcess - INFO     Calculating statistics for data: [6] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [6]\n",
      "2024-06-27 22:15:06,123 - micro - MainProcess - INFO     Data converted to numpy array: [6] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [6]\n",
      "2024-06-27 22:15:06,125 - micro - MainProcess - INFO     Calculated median: 6.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 6.0\n",
      "2024-06-27 22:15:06,129 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 22:15:06,132 - micro - MainProcess - INFO     Calculated 95th percentile: 6.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 6.0\n",
      "2024-06-27 22:15:06,133 - micro - MainProcess - INFO     Calculated 99th percentile: 6.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 6.0\n",
      "2024-06-27 22:15:06,136 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 22:15:06,137 - micro - MainProcess - INFO     Result: (6.0, 0.0, 6.0, 6.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (6.0, 0.0, 6.0, 6.0, 0.0)\n",
      "2024-06-27 22:15:06,139 - micro - MainProcess - INFO     Calculating statistics for data: [1008] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [1008]\n",
      "2024-06-27 22:15:06,142 - micro - MainProcess - INFO     Data converted to numpy array: [1008] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [1008]\n",
      "2024-06-27 22:15:06,144 - micro - MainProcess - INFO     Calculated median: 1008.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 1008.0\n",
      "2024-06-27 22:15:06,147 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 22:15:06,149 - micro - MainProcess - INFO     Calculated 95th percentile: 1008.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 1008.0\n",
      "2024-06-27 22:15:06,152 - micro - MainProcess - INFO     Calculated 99th percentile: 1008.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 1008.0\n",
      "2024-06-27 22:15:06,155 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 22:15:06,160 - micro - MainProcess - INFO     Result: (1008.0, 0.0, 1008.0, 1008.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (1008.0, 0.0, 1008.0, 1008.0, 0.0)\n",
      "2024-06-27 22:15:06,176 - micro - MainProcess - INFO     Calculating statistics for data: [336.87] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [336.87]\n",
      "2024-06-27 22:15:06,179 - micro - MainProcess - INFO     Data converted to numpy array: [336.87] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [336.87]\n",
      "2024-06-27 22:15:06,183 - micro - MainProcess - INFO     Calculated median: 336.87 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 336.87\n",
      "2024-06-27 22:15:06,187 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 22:15:06,190 - micro - MainProcess - INFO     Calculated 95th percentile: 336.87 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 336.87\n",
      "2024-06-27 22:15:06,196 - micro - MainProcess - INFO     Calculated 99th percentile: 336.87 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 336.87\n",
      "2024-06-27 22:15:06,200 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 22:15:06,204 - micro - MainProcess - INFO     Result: (336.87, 0.0, 336.87, 336.87, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (336.87, 0.0, 336.87, 336.87, 0.0)\n",
      "2024-06-27 22:15:06,206 - micro - MainProcess - INFO     Calculating statistics for data: [0.95] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.95]\n",
      "2024-06-27 22:15:06,208 - micro - MainProcess - INFO     Data converted to numpy array: [0.95] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.95]\n",
      "2024-06-27 22:15:06,212 - micro - MainProcess - INFO     Calculated median: 0.95 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.95\n",
      "2024-06-27 22:15:06,215 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 22:15:06,219 - micro - MainProcess - INFO     Calculated 95th percentile: 0.95 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.95\n",
      "2024-06-27 22:15:06,221 - micro - MainProcess - INFO     Calculated 99th percentile: 0.95 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.95\n",
      "2024-06-27 22:15:06,226 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 22:15:06,229 - micro - MainProcess - INFO     Result: (0.95, 0.0, 0.95, 0.95, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.95, 0.0, 0.95, 0.95, 0.0)\n",
      "2024-06-27 22:15:06,233 - micro - MainProcess - INFO     Calculating statistics for data: [2.9828582000000097, 4.583761499999994, 4.387315100000009, 3.834885, 4.996095199999999] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [2.9828582000000097, 4.583761499999994, 4.387315100000009, 3.834885, 4.996095199999999]\n",
      "2024-06-27 22:15:06,237 - micro - MainProcess - INFO     Data converted to numpy array: [2.9828582 4.5837615 4.3873151 3.834885  4.9960952] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [2.9828582 4.5837615 4.3873151 3.834885  4.9960952]\n",
      "2024-06-27 22:15:06,241 - micro - MainProcess - INFO     Calculated median: 4.387315100000009 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 4.387315100000009\n",
      "2024-06-27 22:15:06,245 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.7488764999999944 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.7488764999999944\n",
      "2024-06-27 22:15:06,249 - micro - MainProcess - INFO     Calculated 95th percentile: 4.913628459999998 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 4.913628459999998\n",
      "2024-06-27 22:15:06,251 - micro - MainProcess - INFO     Calculated 99th percentile: 4.979601851999999 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 4.979601851999999\n",
      "2024-06-27 22:15:06,254 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.16741315722934866 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.16741315722934866\n",
      "2024-06-27 22:15:06,256 - micro - MainProcess - INFO     Result: (4.387315100000009, 0.7488764999999944, 4.913628459999998, 4.979601851999999, 0.16741315722934866) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (4.387315100000009, 0.7488764999999944, 4.913628459999998, 4.979601851999999, 0.16741315722934866)\n",
      "2024-06-27 22:15:06,258 - micro - MainProcess - INFO     Calculating statistics for data: [12, 12, 13, 11, 11] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [12, 12, 13, 11, 11]\n",
      "2024-06-27 22:15:06,261 - micro - MainProcess - INFO     Data converted to numpy array: [12 12 13 11 11] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [12 12 13 11 11]\n",
      "2024-06-27 22:15:06,263 - micro - MainProcess - INFO     Calculated median: 12.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 12.0\n",
      "2024-06-27 22:15:06,267 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 1.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 1.0\n",
      "2024-06-27 22:15:06,270 - micro - MainProcess - INFO     Calculated 95th percentile: 12.8 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 12.8\n",
      "2024-06-27 22:15:06,273 - micro - MainProcess - INFO     Calculated 99th percentile: 12.96 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 12.96\n",
      "2024-06-27 22:15:06,278 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.06341792180972781 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.06341792180972781\n",
      "2024-06-27 22:15:06,280 - micro - MainProcess - INFO     Result: (12.0, 1.0, 12.8, 12.96, 0.06341792180972781) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (12.0, 1.0, 12.8, 12.96, 0.06341792180972781)\n",
      "2024-06-27 22:15:06,283 - micro - MainProcess - INFO     Calculating statistics for data: [50, 50, 50, 50, 50] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [50, 50, 50, 50, 50]\n",
      "2024-06-27 22:15:06,287 - micro - MainProcess - INFO     Data converted to numpy array: [50 50 50 50 50] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [50 50 50 50 50]\n",
      "2024-06-27 22:15:06,291 - micro - MainProcess - INFO     Calculated median: 50.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 50.0\n",
      "2024-06-27 22:15:06,295 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 22:15:06,300 - micro - MainProcess - INFO     Calculated 95th percentile: 50.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 50.0\n",
      "2024-06-27 22:15:06,303 - micro - MainProcess - INFO     Calculated 99th percentile: 50.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 50.0\n",
      "2024-06-27 22:15:06,307 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 22:15:06,310 - micro - MainProcess - INFO     Result: (50.0, 0.0, 50.0, 50.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (50.0, 0.0, 50.0, 50.0, 0.0)\n",
      "2024-06-27 22:15:06,313 - micro - MainProcess - INFO     Calculating statistics for data: [229.94, 384.68, 337.66, 351.78, 457.21] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [229.94, 384.68, 337.66, 351.78, 457.21]\n",
      "2024-06-27 22:15:06,316 - micro - MainProcess - INFO     Data converted to numpy array: [229.94 384.68 337.66 351.78 457.21] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [229.94 384.68 337.66 351.78 457.21]\n",
      "2024-06-27 22:15:06,322 - micro - MainProcess - INFO     Calculated median: 351.78 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 351.78\n",
      "2024-06-27 22:15:06,326 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 47.01999999999998 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 47.01999999999998\n",
      "2024-06-27 22:15:06,330 - micro - MainProcess - INFO     Calculated 95th percentile: 442.70399999999995 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 442.70399999999995\n",
      "2024-06-27 22:15:06,333 - micro - MainProcess - INFO     Calculated 99th percentile: 454.30879999999996 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 454.30879999999996\n",
      "2024-06-27 22:15:06,339 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.20954226591739528 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.20954226591739528\n",
      "2024-06-27 22:15:06,341 - micro - MainProcess - INFO     Result: (351.78, 47.01999999999998, 442.70399999999995, 454.30879999999996, 0.20954226591739528) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (351.78, 47.01999999999998, 442.70399999999995, 454.30879999999996, 0.20954226591739528)\n",
      "2024-06-27 22:15:06,346 - micro - MainProcess - INFO     Calculating statistics for data: [8.53, 6.38, 6.64, 5.75, 7.86] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [8.53, 6.38, 6.64, 5.75, 7.86]\n",
      "2024-06-27 22:15:06,350 - micro - MainProcess - INFO     Data converted to numpy array: [8.53 6.38 6.64 5.75 7.86] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [8.53 6.38 6.64 5.75 7.86]\n",
      "2024-06-27 22:15:06,353 - micro - MainProcess - INFO     Calculated median: 6.64 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 6.64\n",
      "2024-06-27 22:15:06,357 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 1.4800000000000004 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 1.4800000000000004\n",
      "2024-06-27 22:15:06,360 - micro - MainProcess - INFO     Calculated 95th percentile: 8.395999999999999 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 8.395999999999999\n",
      "2024-06-27 22:15:06,363 - micro - MainProcess - INFO     Calculated 99th percentile: 8.5032 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 8.5032\n",
      "2024-06-27 22:15:06,368 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.14435073684741606 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.14435073684741606\n",
      "2024-06-27 22:15:06,371 - micro - MainProcess - INFO     Result: (6.64, 1.4800000000000004, 8.395999999999999, 8.5032, 0.14435073684741606) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (6.64, 1.4800000000000004, 8.395999999999999, 8.5032, 0.14435073684741606)\n",
      "2024-06-27 22:15:06,379 - micro - MainProcess - INFO     Calculating statistics for data: [9.446672300000003, 9.403997600000011, 8.446443699999989, 9.535728200000008, 11.745287300000001] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [9.446672300000003, 9.403997600000011, 8.446443699999989, 9.535728200000008, 11.745287300000001]\n",
      "2024-06-27 22:15:06,383 - micro - MainProcess - INFO     Data converted to numpy array: [ 9.4466723  9.4039976  8.4464437  9.5357282 11.7452873] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [ 9.4466723  9.4039976  8.4464437  9.5357282 11.7452873]\n",
      "2024-06-27 22:15:06,387 - micro - MainProcess - INFO     Calculated median: 9.446672300000003 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 9.446672300000003\n",
      "2024-06-27 22:15:06,392 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.13173059999999737 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.13173059999999737\n",
      "2024-06-27 22:15:06,395 - micro - MainProcess - INFO     Calculated 95th percentile: 11.303375480000001 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 11.303375480000001\n",
      "2024-06-27 22:15:06,401 - micro - MainProcess - INFO     Calculated 99th percentile: 11.656904936000002 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 11.656904936000002\n",
      "2024-06-27 22:15:06,406 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.11211162708448552 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.11211162708448552\n",
      "2024-06-27 22:15:06,409 - micro - MainProcess - INFO     Result: (9.446672300000003, 0.13173059999999737, 11.303375480000001, 11.656904936000002, 0.11211162708448552) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (9.446672300000003, 0.13173059999999737, 11.303375480000001, 11.656904936000002, 0.11211162708448552)\n",
      "2024-06-27 22:15:06,412 - micro - MainProcess - INFO     Calculating statistics for data: [25, 21, 23, 22, 23] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [25, 21, 23, 22, 23]\n",
      "2024-06-27 22:15:06,415 - micro - MainProcess - INFO     Data converted to numpy array: [25 21 23 22 23] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [25 21 23 22 23]\n",
      "2024-06-27 22:15:06,418 - micro - MainProcess - INFO     Calculated median: 23.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 23.0\n",
      "2024-06-27 22:15:06,422 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 1.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 1.0\n",
      "2024-06-27 22:15:06,425 - micro - MainProcess - INFO     Calculated 95th percentile: 24.6 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 24.6\n",
      "2024-06-27 22:15:06,430 - micro - MainProcess - INFO     Calculated 99th percentile: 24.92 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 24.92\n",
      "2024-06-27 22:15:06,434 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.05818639983079649 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.05818639983079649\n",
      "2024-06-27 22:15:06,437 - micro - MainProcess - INFO     Result: (23.0, 1.0, 24.6, 24.92, 0.05818639983079649) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (23.0, 1.0, 24.6, 24.92, 0.05818639983079649)\n",
      "2024-06-27 22:15:06,441 - micro - MainProcess - INFO     Calculating statistics for data: [50, 50, 50, 50, 50] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [50, 50, 50, 50, 50]\n",
      "2024-06-27 22:15:06,444 - micro - MainProcess - INFO     Data converted to numpy array: [50 50 50 50 50] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [50 50 50 50 50]\n",
      "2024-06-27 22:15:06,449 - micro - MainProcess - INFO     Calculated median: 50.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 50.0\n",
      "2024-06-27 22:15:06,453 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 22:15:06,459 - micro - MainProcess - INFO     Calculated 95th percentile: 50.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 50.0\n",
      "2024-06-27 22:15:06,463 - micro - MainProcess - INFO     Calculated 99th percentile: 50.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 50.0\n",
      "2024-06-27 22:15:06,468 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 22:15:06,471 - micro - MainProcess - INFO     Result: (50.0, 0.0, 50.0, 50.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (50.0, 0.0, 50.0, 50.0, 0.0)\n",
      "2024-06-27 22:15:06,474 - micro - MainProcess - INFO     Calculating statistics for data: [371.25, 453.65, 368.2, 435.35, 515.97] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [371.25, 453.65, 368.2, 435.35, 515.97]\n",
      "2024-06-27 22:15:06,478 - micro - MainProcess - INFO     Data converted to numpy array: [371.25 453.65 368.2  435.35 515.97] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [371.25 453.65 368.2  435.35 515.97]\n",
      "2024-06-27 22:15:06,482 - micro - MainProcess - INFO     Calculated median: 435.35 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 435.35\n",
      "2024-06-27 22:15:06,488 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 82.39999999999998 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 82.39999999999998\n",
      "2024-06-27 22:15:06,492 - micro - MainProcess - INFO     Calculated 95th percentile: 503.50600000000003 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 503.50600000000003\n",
      "2024-06-27 22:15:06,495 - micro - MainProcess - INFO     Calculated 99th percentile: 513.4772 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 513.4772\n",
      "2024-06-27 22:15:06,499 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.12874059805977855 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.12874059805977855\n",
      "2024-06-27 22:15:06,502 - micro - MainProcess - INFO     Result: (435.35, 82.39999999999998, 503.50600000000003, 513.4772, 0.12874059805977855) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (435.35, 82.39999999999998, 503.50600000000003, 513.4772, 0.12874059805977855)\n",
      "2024-06-27 22:15:06,505 - micro - MainProcess - INFO     Calculating statistics for data: [10.03, 6.01, 6.34, 7.23, 7.28] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [10.03, 6.01, 6.34, 7.23, 7.28]\n",
      "2024-06-27 22:15:06,508 - micro - MainProcess - INFO     Data converted to numpy array: [10.03  6.01  6.34  7.23  7.28] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [10.03  6.01  6.34  7.23  7.28]\n",
      "2024-06-27 22:15:06,511 - micro - MainProcess - INFO     Calculated median: 7.23 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 7.23\n",
      "2024-06-27 22:15:06,516 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.9400000000000004 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.9400000000000004\n",
      "2024-06-27 22:15:06,526 - micro - MainProcess - INFO     Calculated 95th percentile: 9.479999999999999 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 9.479999999999999\n",
      "2024-06-27 22:15:06,530 - micro - MainProcess - INFO     Calculated 99th percentile: 9.92 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 9.92\n",
      "2024-06-27 22:15:06,562 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.1918089484018454 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.1918089484018454\n",
      "2024-06-27 22:15:06,568 - micro - MainProcess - INFO     Result: (7.23, 0.9400000000000004, 9.479999999999999, 9.92, 0.1918089484018454) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (7.23, 0.9400000000000004, 9.479999999999999, 9.92, 0.1918089484018454)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------------+---------+-------------------+-------------------+---------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+-------------------+---------------------+---------------------+-------------------+-------------+--------------------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|    Model_MaxTokens    | Iterations | Regions |   Average TTLT    |    Median TTLT    |      IQR TTLT       | 95th Percentile TTLT | 99th Percentile TTLT |       CV TTLT       | Median Prompt Tokens | IQR Prompt Tokens | Median Completion Tokens | IQR Completion Tokens | 95th Percentile Completion Tokens | 99th Percentile Completion Tokens | CV Completion Tokens | Average TBT | Median TBT |      IQR TBT      | 95th Percentile TBT | 99th Percentile TBT |   Average TTFT    | Median TTFT |      IQR TTFT      | 95th Percentile TTFT | 99th Percentile TTFT | Error Rate | Error Types | Successful Runs | Unsuccessful Runs | Throttle Count | Throttle Rate |                                                                        Best Run                                                                        |                                                                       Worst Run                                                                        |\n",
      "+-----------------------+------------+---------+-------------------+-------------------+---------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+-------------------+---------------------+---------------------+-------------------+-------------+--------------------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| gpt-4o-2024-05-13_100 |     1      |   N/A   |     2.6457064     |     2.6457064     |         0.0         |      2.6457064       |      2.6457064       |         0.0         |        1008.0        |        0.0        |           6.0            |          0.0          |                6.0                |                6.0                |         0.0          |   336.87    |   336.87   |        0.0        |       336.87        |       336.87        |       0.95        |    0.95     |        0.0         |         0.95         |         0.95         |    0.0     |     []      |        1        |         0         |       0        |      0.0      |     {\"ttlt\": 2.6457064, \"completion_tokens\": 6, \"prompt_tokens\": 1008, \"region\": null, \"utilization\": \"N/A\", \"local_time\": \"2024-06-27 22:12:01 \"}     |     {\"ttlt\": 2.6457064, \"completion_tokens\": 6, \"prompt_tokens\": 1008, \"region\": null, \"utilization\": \"N/A\", \"local_time\": \"2024-06-27 22:12:01 \"}     |\n",
      "| gpt-4o-2024-05-13_250 |     5      |   N/A   | 4.156983000000002 | 4.387315100000009 | 0.7488764999999944  |  4.913628459999998   |  4.979601851999999   | 0.16741315722934866 |         50.0         |        0.0        |           12.0           |          1.0          |               12.8                |               12.96               | 0.06341792180972781  |   352.254   |   351.78   | 47.01999999999998 | 442.70399999999995  | 454.30879999999996  | 7.032000000000001 |    6.64     | 1.4800000000000004 |  8.395999999999999   |        8.5032        |    0.0     |     []      |        5        |         0         |       0        |      0.0      | {\"ttlt\": 2.9828582000000097, \"completion_tokens\": 12, \"prompt_tokens\": 50, \"region\": null, \"utilization\": \"N/A\", \"local_time\": \"2024-06-27 22:13:02 \"} | {\"ttlt\": 4.996095199999999, \"completion_tokens\": 11, \"prompt_tokens\": 50, \"region\": null, \"utilization\": \"N/A\", \"local_time\": \"2024-06-27 22:13:25 \"}  |\n",
      "| gpt-4o-2024-05-13_500 |     5      |   N/A   | 9.715625820000003 | 9.446672300000003 | 0.13173059999999737 |  11.303375480000001  |  11.656904936000002  | 0.11211162708448552 |         50.0         |        0.0        |           23.0           |          1.0          |               24.6                |               24.92               | 0.05818639983079649  |   428.884   |   435.35   | 82.39999999999998 | 503.50600000000003  |      513.4772       |       7.378       |    7.23     | 0.9400000000000004 |  9.479999999999999   |         9.92         |    0.0     |     []      |        5        |         0         |       0        |      0.0      | {\"ttlt\": 8.446443699999989, \"completion_tokens\": 23, \"prompt_tokens\": 50, \"region\": null, \"utilization\": \"N/A\", \"local_time\": \"2024-06-27 22:13:29 \"}  | {\"ttlt\": 11.745287300000001, \"completion_tokens\": 23, \"prompt_tokens\": 50, \"region\": null, \"utilization\": \"N/A\", \"local_time\": \"2024-06-27 22:13:53 \"} |\n",
      "+-----------------------+------------+---------+-------------------+-------------------+---------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+-------------------+---------------------+---------------------+-------------------+-------------+--------------------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_100': {'median_ttlt': 2.6457064,\n",
       "  'regions': [None],\n",
       "  'iqr_ttlt': 0.0,\n",
       "  'percentile_95_ttlt': 2.6457064,\n",
       "  'percentile_99_ttlt': 2.6457064,\n",
       "  'cv_ttlt': 0.0,\n",
       "  'median_completion_tokens': 6.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 6.0,\n",
       "  'percentile_99_completion_tokens': 6.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 1008.0,\n",
       "  'iqr_prompt_tokens': 0.0,\n",
       "  'percentile_95_prompt_tokens': 1008.0,\n",
       "  'percentile_99_prompt_tokens': 1008.0,\n",
       "  'cv_prompt_tokens': 0.0,\n",
       "  'average_ttlt': 2.6457064,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 1,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 1,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 336.87,\n",
       "  'iqr_tbt': 0.0,\n",
       "  'percentile_95_tbt': 336.87,\n",
       "  'percentile_99_tbt': 336.87,\n",
       "  'cv_tbt': 0.0,\n",
       "  'average_tbt': 336.87,\n",
       "  'median_ttft': 0.95,\n",
       "  'iqr_ttft': 0.0,\n",
       "  'percentile_95_ttft': 0.95,\n",
       "  'percentile_99_ttft': 0.95,\n",
       "  'cv_ttft': 0.0,\n",
       "  'average_ttft': 0.95,\n",
       "  'best_run': {'ttlt': 2.6457064,\n",
       "   'completion_tokens': 6,\n",
       "   'prompt_tokens': 1008,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:12:01 '},\n",
       "  'worst_run': {'ttlt': 2.6457064,\n",
       "   'completion_tokens': 6,\n",
       "   'prompt_tokens': 1008,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:12:01 '}},\n",
       " 'gpt-4o-2024-05-13_250': {'median_ttlt': 4.387315100000009,\n",
       "  'regions': [None],\n",
       "  'iqr_ttlt': 0.7488764999999944,\n",
       "  'percentile_95_ttlt': 4.913628459999998,\n",
       "  'percentile_99_ttlt': 4.979601851999999,\n",
       "  'cv_ttlt': 0.16741315722934866,\n",
       "  'median_completion_tokens': 12.0,\n",
       "  'iqr_completion_tokens': 1.0,\n",
       "  'percentile_95_completion_tokens': 12.8,\n",
       "  'percentile_99_completion_tokens': 12.96,\n",
       "  'cv_completion_tokens': 0.06341792180972781,\n",
       "  'median_prompt_tokens': 50.0,\n",
       "  'iqr_prompt_tokens': 0.0,\n",
       "  'percentile_95_prompt_tokens': 50.0,\n",
       "  'percentile_99_prompt_tokens': 50.0,\n",
       "  'cv_prompt_tokens': 0.0,\n",
       "  'average_ttlt': 4.156983000000002,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 5,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 5,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 351.78,\n",
       "  'iqr_tbt': 47.01999999999998,\n",
       "  'percentile_95_tbt': 442.70399999999995,\n",
       "  'percentile_99_tbt': 454.30879999999996,\n",
       "  'cv_tbt': 0.20954226591739528,\n",
       "  'average_tbt': 352.254,\n",
       "  'median_ttft': 6.64,\n",
       "  'iqr_ttft': 1.4800000000000004,\n",
       "  'percentile_95_ttft': 8.395999999999999,\n",
       "  'percentile_99_ttft': 8.5032,\n",
       "  'cv_ttft': 0.14435073684741606,\n",
       "  'average_ttft': 7.032000000000001,\n",
       "  'best_run': {'ttlt': 2.9828582000000097,\n",
       "   'completion_tokens': 12,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:02 '},\n",
       "  'worst_run': {'ttlt': 4.996095199999999,\n",
       "   'completion_tokens': 11,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:25 '}},\n",
       " 'gpt-4o-2024-05-13_500': {'median_ttlt': 9.446672300000003,\n",
       "  'regions': [None],\n",
       "  'iqr_ttlt': 0.13173059999999737,\n",
       "  'percentile_95_ttlt': 11.303375480000001,\n",
       "  'percentile_99_ttlt': 11.656904936000002,\n",
       "  'cv_ttlt': 0.11211162708448552,\n",
       "  'median_completion_tokens': 23.0,\n",
       "  'iqr_completion_tokens': 1.0,\n",
       "  'percentile_95_completion_tokens': 24.6,\n",
       "  'percentile_99_completion_tokens': 24.92,\n",
       "  'cv_completion_tokens': 0.05818639983079649,\n",
       "  'median_prompt_tokens': 50.0,\n",
       "  'iqr_prompt_tokens': 0.0,\n",
       "  'percentile_95_prompt_tokens': 50.0,\n",
       "  'percentile_99_prompt_tokens': 50.0,\n",
       "  'cv_prompt_tokens': 0.0,\n",
       "  'average_ttlt': 9.715625820000003,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 5,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 5,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 435.35,\n",
       "  'iqr_tbt': 82.39999999999998,\n",
       "  'percentile_95_tbt': 503.50600000000003,\n",
       "  'percentile_99_tbt': 513.4772,\n",
       "  'cv_tbt': 0.12874059805977855,\n",
       "  'average_tbt': 428.884,\n",
       "  'median_ttft': 7.23,\n",
       "  'iqr_ttft': 0.9400000000000004,\n",
       "  'percentile_95_ttft': 9.479999999999999,\n",
       "  'percentile_99_ttft': 9.92,\n",
       "  'cv_ttft': 0.1918089484018454,\n",
       "  'average_ttft': 7.378,\n",
       "  'best_run': {'ttlt': 8.446443699999989,\n",
       "   'completion_tokens': 23,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:29 '},\n",
       "  'worst_run': {'ttlt': 11.745287300000001,\n",
       "   'completion_tokens': 23,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:53 '}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_streaming.calculate_and_show_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_nonstreaming = AzureOpenAIBenchmarkNonStreaming(api_key=OPENAI_API_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=DEPLOYMENT_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 11:44:43,273 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:602)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-27 11:44:43,384 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 1000 (latencytest.py:make_call:625)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 1000\n",
      "2024-06-27 11:45:14,868 - micro - MainProcess - INFO     Succesful Run - Time taken: 31.48 seconds. (latencytest.py:make_call:648)\n",
      "INFO:micro:Succesful Run - Time taken: 31.48 seconds.\n"
     ]
    }
   ],
   "source": [
    "await benchmark_nonstreaming.make_call(deployment_name=DEPLOYMENT_ID, max_tokens=1000)\n",
    "await benchmark_nonstreaming.run_latency_benchmark_bulk(deployment_names=[DEPLOYMENT_ID], max_tokens_list=[1000,500,250], iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_1000': {'ttlt_successful': [31.47952219999999,\n",
       "   18.452650199999994,\n",
       "   23.416592199999968,\n",
       "   45.44973810000005,\n",
       "   14.786188600000003,\n",
       "   26.359097200000008],\n",
       "  'ttlt_unsuccessful': [],\n",
       "  'tbt': [0.03147952219999999,\n",
       "   0.018452650199999993,\n",
       "   0.023416592199999968,\n",
       "   0.045449738100000046,\n",
       "   0.014786188600000003,\n",
       "   0.026359097200000008],\n",
       "  'ttft': [None, None, None, None, None, None],\n",
       "  'regions': ['East US 2',\n",
       "   'East US 2',\n",
       "   'East US 2',\n",
       "   'East US 2',\n",
       "   'East US 2',\n",
       "   'East US 2'],\n",
       "  'number_of_iterations': 6,\n",
       "  'completion_tokens': [1000, 1000, 1000, 1000, 1000, 1000],\n",
       "  'prompt_tokens': [986, 52, 50, 52, 50, 52],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 14.786188600000003,\n",
       "   'completion_tokens': 1000,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:48 EDT'},\n",
       "  'worst_run': {'ttlt': 45.44973810000005,\n",
       "   'completion_tokens': 1000,\n",
       "   'prompt_tokens': 52,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:32 EDT'}},\n",
       " 'gpt-4o-2024-05-13_250': {'ttlt_successful': [6.5350243999999975,\n",
       "   7.10248039999999,\n",
       "   8.431264599999963,\n",
       "   2.9964409000000387,\n",
       "   7.201789399999996],\n",
       "  'ttlt_unsuccessful': [],\n",
       "  'tbt': [0.02614009759999999,\n",
       "   0.02840992159999996,\n",
       "   0.033725058399999855,\n",
       "   0.011985763600000155,\n",
       "   0.028807157599999984],\n",
       "  'ttft': [None, None, None, None, None],\n",
       "  'regions': ['East US 2', 'East US 2', 'East US 2', 'East US 2', 'East US 2'],\n",
       "  'number_of_iterations': 5,\n",
       "  'completion_tokens': [250, 250, 250, 250, 250],\n",
       "  'prompt_tokens': [51, 51, 49, 49, 51],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 2.9964409000000387,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 49,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:46:31 EDT'},\n",
       "  'worst_run': {'ttlt': 8.431264599999963,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 49,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:46:27 EDT'}},\n",
       " 'gpt-4o-2024-05-13_500': {'ttlt_successful': [13.453411500000016,\n",
       "   10.463891999999987,\n",
       "   17.72546410000001,\n",
       "   20.02827719999999,\n",
       "   7.849451299999998],\n",
       "  'ttlt_unsuccessful': [],\n",
       "  'tbt': [0.02690682300000003,\n",
       "   0.020927783999999974,\n",
       "   0.03545092820000002,\n",
       "   0.04005655439999998,\n",
       "   0.0156989026],\n",
       "  'ttft': [None, None, None, None, None],\n",
       "  'regions': ['East US 2', 'East US 2', 'East US 2', 'East US 2', 'East US 2'],\n",
       "  'number_of_iterations': 5,\n",
       "  'completion_tokens': [500, 500, 500, 500, 500],\n",
       "  'prompt_tokens': [49, 51, 51, 51, 51],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 7.849451299999998,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 51,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:16 EDT'},\n",
       "  'worst_run': {'ttlt': 20.02827719999999,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 51,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:07 EDT'}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_nonstreaming.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 11:48:53,157 - micro - MainProcess - INFO     Calculating statistics for data: [31.47952219999999, 18.452650199999994, 23.416592199999968, 45.44973810000005, 14.786188600000003, 26.359097200000008] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [31.47952219999999, 18.452650199999994, 23.416592199999968, 45.44973810000005, 14.786188600000003, 26.359097200000008]\n",
      "2024-06-27 11:48:53,164 - micro - MainProcess - INFO     Data converted to numpy array: [31.4795222 18.4526502 23.4165922 45.4497381 14.7861886 26.3590972] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [31.4795222 18.4526502 23.4165922 45.4497381 14.7861886 26.3590972]\n",
      "2024-06-27 11:48:53,167 - micro - MainProcess - INFO     Calculated median: 24.887844699999988 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 24.887844699999988\n",
      "2024-06-27 11:48:53,172 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 10.505780250000008 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 10.505780250000008\n",
      "2024-06-27 11:48:53,175 - micro - MainProcess - INFO     Calculated 95th percentile: 41.95718412500003 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 41.95718412500003\n",
      "2024-06-27 11:48:53,177 - micro - MainProcess - INFO     Calculated 99th percentile: 44.75122730500005 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 44.75122730500005\n",
      "2024-06-27 11:48:53,179 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.37364087930274653 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.37364087930274653\n",
      "2024-06-27 11:48:53,182 - micro - MainProcess - INFO     Result: (24.887844699999988, 10.505780250000008, 41.95718412500003, 44.75122730500005, 0.37364087930274653) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (24.887844699999988, 10.505780250000008, 41.95718412500003, 44.75122730500005, 0.37364087930274653)\n",
      "2024-06-27 11:48:53,184 - micro - MainProcess - INFO     Calculating statistics for data: [1000, 1000, 1000, 1000, 1000, 1000] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [1000, 1000, 1000, 1000, 1000, 1000]\n",
      "2024-06-27 11:48:53,186 - micro - MainProcess - INFO     Data converted to numpy array: [1000 1000 1000 1000 1000 1000] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [1000 1000 1000 1000 1000 1000]\n",
      "2024-06-27 11:48:53,188 - micro - MainProcess - INFO     Calculated median: 1000.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 1000.0\n",
      "2024-06-27 11:48:53,191 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 11:48:53,193 - micro - MainProcess - INFO     Calculated 95th percentile: 1000.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 1000.0\n",
      "2024-06-27 11:48:53,195 - micro - MainProcess - INFO     Calculated 99th percentile: 1000.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 1000.0\n",
      "2024-06-27 11:48:53,198 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 11:48:53,200 - micro - MainProcess - INFO     Result: (1000.0, 0.0, 1000.0, 1000.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (1000.0, 0.0, 1000.0, 1000.0, 0.0)\n",
      "2024-06-27 11:48:53,204 - micro - MainProcess - INFO     Calculating statistics for data: [986, 52, 50, 52, 50, 52] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [986, 52, 50, 52, 50, 52]\n",
      "2024-06-27 11:48:53,207 - micro - MainProcess - INFO     Data converted to numpy array: [986  52  50  52  50  52] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [986  52  50  52  50  52]\n",
      "2024-06-27 11:48:53,209 - micro - MainProcess - INFO     Calculated median: 52.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 52.0\n",
      "2024-06-27 11:48:53,212 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 1.5 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 1.5\n",
      "2024-06-27 11:48:53,215 - micro - MainProcess - INFO     Calculated 95th percentile: 752.5 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 752.5\n",
      "2024-06-27 11:48:53,218 - micro - MainProcess - INFO     Calculated 99th percentile: 939.3000000000002 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 939.3000000000002\n",
      "2024-06-27 11:48:53,222 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 1.6829977732662775 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 1.6829977732662775\n",
      "2024-06-27 11:48:53,223 - micro - MainProcess - INFO     Result: (52.0, 1.5, 752.5, 939.3000000000002, 1.6829977732662775) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (52.0, 1.5, 752.5, 939.3000000000002, 1.6829977732662775)\n",
      "2024-06-27 11:48:53,226 - micro - MainProcess - INFO     Calculating statistics for data: [0.03147952219999999, 0.018452650199999993, 0.023416592199999968, 0.045449738100000046, 0.014786188600000003, 0.026359097200000008] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.03147952219999999, 0.018452650199999993, 0.023416592199999968, 0.045449738100000046, 0.014786188600000003, 0.026359097200000008]\n",
      "2024-06-27 11:48:53,228 - micro - MainProcess - INFO     Data converted to numpy array: [0.03147952 0.01845265 0.02341659 0.04544974 0.01478619 0.0263591 ] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.03147952 0.01845265 0.02341659 0.04544974 0.01478619 0.0263591 ]\n",
      "2024-06-27 11:48:53,232 - micro - MainProcess - INFO     Calculated median: 0.024887844699999988 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.024887844699999988\n",
      "2024-06-27 11:48:53,236 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.01050578025000001 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.01050578025000001\n",
      "2024-06-27 11:48:53,241 - micro - MainProcess - INFO     Calculated 95th percentile: 0.04195718412500003 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.04195718412500003\n",
      "2024-06-27 11:48:53,244 - micro - MainProcess - INFO     Calculated 99th percentile: 0.044751227305000044 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.044751227305000044\n",
      "2024-06-27 11:48:53,251 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.3736408793027465 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.3736408793027465\n",
      "2024-06-27 11:48:53,252 - micro - MainProcess - INFO     Result: (0.024887844699999988, 0.01050578025000001, 0.04195718412500003, 0.044751227305000044, 0.3736408793027465) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.024887844699999988, 0.01050578025000001, 0.04195718412500003, 0.044751227305000044, 0.3736408793027465)\n",
      "2024-06-27 11:48:53,255 - micro - MainProcess - INFO     Calculating statistics for data: [6.5350243999999975, 7.10248039999999, 8.431264599999963, 2.9964409000000387, 7.201789399999996] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [6.5350243999999975, 7.10248039999999, 8.431264599999963, 2.9964409000000387, 7.201789399999996]\n",
      "2024-06-27 11:48:53,258 - micro - MainProcess - INFO     Data converted to numpy array: [6.5350244 7.1024804 8.4312646 2.9964409 7.2017894] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [6.5350244 7.1024804 8.4312646 2.9964409 7.2017894]\n",
      "2024-06-27 11:48:53,261 - micro - MainProcess - INFO     Calculated median: 7.10248039999999 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 7.10248039999999\n",
      "2024-06-27 11:48:53,265 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.666764999999998 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.666764999999998\n",
      "2024-06-27 11:48:53,269 - micro - MainProcess - INFO     Calculated 95th percentile: 8.18536955999997 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 8.18536955999997\n",
      "2024-06-27 11:48:53,272 - micro - MainProcess - INFO     Calculated 99th percentile: 8.382085591999964 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 8.382085591999964\n",
      "2024-06-27 11:48:53,277 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.2844681870071126 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.2844681870071126\n",
      "2024-06-27 11:48:53,279 - micro - MainProcess - INFO     Result: (7.10248039999999, 0.666764999999998, 8.18536955999997, 8.382085591999964, 0.2844681870071126) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (7.10248039999999, 0.666764999999998, 8.18536955999997, 8.382085591999964, 0.2844681870071126)\n",
      "2024-06-27 11:48:53,281 - micro - MainProcess - INFO     Calculating statistics for data: [250, 250, 250, 250, 250] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [250, 250, 250, 250, 250]\n",
      "2024-06-27 11:48:53,284 - micro - MainProcess - INFO     Data converted to numpy array: [250 250 250 250 250] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [250 250 250 250 250]\n",
      "2024-06-27 11:48:53,286 - micro - MainProcess - INFO     Calculated median: 250.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 250.0\n",
      "2024-06-27 11:48:53,288 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 11:48:53,294 - micro - MainProcess - INFO     Calculated 95th percentile: 250.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 250.0\n",
      "2024-06-27 11:48:53,298 - micro - MainProcess - INFO     Calculated 99th percentile: 250.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 250.0\n",
      "2024-06-27 11:48:53,301 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 11:48:53,304 - micro - MainProcess - INFO     Result: (250.0, 0.0, 250.0, 250.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (250.0, 0.0, 250.0, 250.0, 0.0)\n",
      "2024-06-27 11:48:53,305 - micro - MainProcess - INFO     Calculating statistics for data: [51, 51, 49, 49, 51] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [51, 51, 49, 49, 51]\n",
      "2024-06-27 11:48:53,309 - micro - MainProcess - INFO     Data converted to numpy array: [51 51 49 49 51] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [51 51 49 49 51]\n",
      "2024-06-27 11:48:53,315 - micro - MainProcess - INFO     Calculated median: 51.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 51.0\n",
      "2024-06-27 11:48:53,318 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 2.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 2.0\n",
      "2024-06-27 11:48:53,321 - micro - MainProcess - INFO     Calculated 95th percentile: 51.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 51.0\n",
      "2024-06-27 11:48:53,324 - micro - MainProcess - INFO     Calculated 99th percentile: 51.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 51.0\n",
      "2024-06-27 11:48:53,328 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.019517846556041257 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.019517846556041257\n",
      "2024-06-27 11:48:53,330 - micro - MainProcess - INFO     Result: (51.0, 2.0, 51.0, 51.0, 0.019517846556041257) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (51.0, 2.0, 51.0, 51.0, 0.019517846556041257)\n",
      "2024-06-27 11:48:53,333 - micro - MainProcess - INFO     Calculating statistics for data: [0.02614009759999999, 0.02840992159999996, 0.033725058399999855, 0.011985763600000155, 0.028807157599999984] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.02614009759999999, 0.02840992159999996, 0.033725058399999855, 0.011985763600000155, 0.028807157599999984]\n",
      "2024-06-27 11:48:53,335 - micro - MainProcess - INFO     Data converted to numpy array: [0.0261401  0.02840992 0.03372506 0.01198576 0.02880716] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.0261401  0.02840992 0.03372506 0.01198576 0.02880716]\n",
      "2024-06-27 11:48:53,338 - micro - MainProcess - INFO     Calculated median: 0.02840992159999996 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.02840992159999996\n",
      "2024-06-27 11:48:53,342 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.002667059999999992 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.002667059999999992\n",
      "2024-06-27 11:48:53,346 - micro - MainProcess - INFO     Calculated 95th percentile: 0.03274147823999988 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.03274147823999988\n",
      "2024-06-27 11:48:53,349 - micro - MainProcess - INFO     Calculated 99th percentile: 0.03352834236799986 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.03352834236799986\n",
      "2024-06-27 11:48:53,352 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.28446818700711257 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.28446818700711257\n",
      "2024-06-27 11:48:53,355 - micro - MainProcess - INFO     Result: (0.02840992159999996, 0.002667059999999992, 0.03274147823999988, 0.03352834236799986, 0.28446818700711257) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.02840992159999996, 0.002667059999999992, 0.03274147823999988, 0.03352834236799986, 0.28446818700711257)\n",
      "2024-06-27 11:48:53,360 - micro - MainProcess - INFO     Calculating statistics for data: [13.453411500000016, 10.463891999999987, 17.72546410000001, 20.02827719999999, 7.849451299999998] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [13.453411500000016, 10.463891999999987, 17.72546410000001, 20.02827719999999, 7.849451299999998]\n",
      "2024-06-27 11:48:53,363 - micro - MainProcess - INFO     Data converted to numpy array: [13.4534115 10.463892  17.7254641 20.0282772  7.8494513] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [13.4534115 10.463892  17.7254641 20.0282772  7.8494513]\n",
      "2024-06-27 11:48:53,368 - micro - MainProcess - INFO     Calculated median: 13.453411500000016 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 13.453411500000016\n",
      "2024-06-27 11:48:53,372 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 7.2615721000000235 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 7.2615721000000235\n",
      "2024-06-27 11:48:53,376 - micro - MainProcess - INFO     Calculated 95th percentile: 19.567714579999993 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 19.567714579999993\n",
      "2024-06-27 11:48:53,379 - micro - MainProcess - INFO     Calculated 99th percentile: 19.93616467599999 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 19.93616467599999\n",
      "2024-06-27 11:48:53,383 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.3229340250559107 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.3229340250559107\n",
      "2024-06-27 11:48:53,387 - micro - MainProcess - INFO     Result: (13.453411500000016, 7.2615721000000235, 19.567714579999993, 19.93616467599999, 0.3229340250559107) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (13.453411500000016, 7.2615721000000235, 19.567714579999993, 19.93616467599999, 0.3229340250559107)\n",
      "2024-06-27 11:48:53,390 - micro - MainProcess - INFO     Calculating statistics for data: [500, 500, 500, 500, 500] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [500, 500, 500, 500, 500]\n",
      "2024-06-27 11:48:53,410 - micro - MainProcess - INFO     Data converted to numpy array: [500 500 500 500 500] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [500 500 500 500 500]\n",
      "2024-06-27 11:48:53,412 - micro - MainProcess - INFO     Calculated median: 500.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 500.0\n",
      "2024-06-27 11:48:53,445 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 11:48:53,472 - micro - MainProcess - INFO     Calculated 95th percentile: 500.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 500.0\n",
      "2024-06-27 11:48:53,476 - micro - MainProcess - INFO     Calculated 99th percentile: 500.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 500.0\n",
      "2024-06-27 11:48:53,481 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 11:48:53,485 - micro - MainProcess - INFO     Result: (500.0, 0.0, 500.0, 500.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (500.0, 0.0, 500.0, 500.0, 0.0)\n",
      "2024-06-27 11:48:53,489 - micro - MainProcess - INFO     Calculating statistics for data: [49, 51, 51, 51, 51] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [49, 51, 51, 51, 51]\n",
      "2024-06-27 11:48:53,492 - micro - MainProcess - INFO     Data converted to numpy array: [49 51 51 51 51] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [49 51 51 51 51]\n",
      "2024-06-27 11:48:53,496 - micro - MainProcess - INFO     Calculated median: 51.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 51.0\n",
      "2024-06-27 11:48:53,500 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 11:48:53,503 - micro - MainProcess - INFO     Calculated 95th percentile: 51.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 51.0\n",
      "2024-06-27 11:48:53,508 - micro - MainProcess - INFO     Calculated 99th percentile: 51.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 51.0\n",
      "2024-06-27 11:48:53,513 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.015810276679841896 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.015810276679841896\n",
      "2024-06-27 11:48:53,517 - micro - MainProcess - INFO     Result: (51.0, 0.0, 51.0, 51.0, 0.015810276679841896) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (51.0, 0.0, 51.0, 51.0, 0.015810276679841896)\n",
      "2024-06-27 11:48:53,524 - micro - MainProcess - INFO     Calculating statistics for data: [0.02690682300000003, 0.020927783999999974, 0.03545092820000002, 0.04005655439999998, 0.0156989026] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.02690682300000003, 0.020927783999999974, 0.03545092820000002, 0.04005655439999998, 0.0156989026]\n",
      "2024-06-27 11:48:53,529 - micro - MainProcess - INFO     Data converted to numpy array: [0.02690682 0.02092778 0.03545093 0.04005655 0.0156989 ] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.02690682 0.02092778 0.03545093 0.04005655 0.0156989 ]\n",
      "2024-06-27 11:48:53,533 - micro - MainProcess - INFO     Calculated median: 0.02690682300000003 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.02690682300000003\n",
      "2024-06-27 11:48:53,539 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.01452314420000005 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.01452314420000005\n",
      "2024-06-27 11:48:53,545 - micro - MainProcess - INFO     Calculated 95th percentile: 0.039135429159999985 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.039135429159999985\n",
      "2024-06-27 11:48:53,548 - micro - MainProcess - INFO     Calculated 99th percentile: 0.03987232935199998 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.03987232935199998\n",
      "2024-06-27 11:48:53,552 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.3229340250559106 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.3229340250559106\n",
      "2024-06-27 11:48:53,556 - micro - MainProcess - INFO     Result: (0.02690682300000003, 0.01452314420000005, 0.039135429159999985, 0.03987232935199998, 0.3229340250559106) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.02690682300000003, 0.01452314420000005, 0.039135429159999985, 0.03987232935199998, 0.3229340250559106)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------+-----------+--------------------+--------------------+--------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|    Model_MaxTokens     | Iterations |  Regions  |    Average TTLT    |    Median TTLT     |      IQR TTLT      | 95th Percentile TTLT | 99th Percentile TTLT |       CV TTLT       | Median Prompt Tokens | IQR Prompt Tokens | Median Completion Tokens | IQR Completion Tokens | 95th Percentile Completion Tokens | 99th Percentile Completion Tokens | CV Completion Tokens |     Average TBT      |      Median TBT      |       IQR TBT        | 95th Percentile TBT  | 99th Percentile TBT  | Average TTFT | Median TTFT | IQR TTFT | 95th Percentile TTFT | 99th Percentile TTFT | Error Rate | Error Types | Successful Runs | Unsuccessful Runs | Throttle Count | Throttle Rate |                                                                             Best Run                                                                              |                                                                            Worst Run                                                                             |\n",
      "+------------------------+------------+-----------+--------------------+--------------------+--------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| gpt-4o-2024-05-13_250  |     5      | East US 2 | 6.453399939999997  |  7.10248039999999  | 0.666764999999998  |   8.18536955999997   |  8.382085591999964   | 0.2844681870071126  |         51.0         |        2.0        |          250.0           |          0.0          |               250.0               |               250.0               |         0.0          | 0.02581359975999999  | 0.02840992159999996  | 0.002667059999999992 | 0.03274147823999988  | 0.03352834236799986  |              |             |          |                      |                      |    0.0     |     []      |        5        |         0         |       0        |      0.0      | {\"ttlt\": 2.9964409000000387, \"completion_tokens\": 250, \"prompt_tokens\": 49, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-27 12:46:31 EDT\"}  | {\"ttlt\": 8.431264599999963, \"completion_tokens\": 250, \"prompt_tokens\": 49, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-27 12:46:27 EDT\"}  |\n",
      "| gpt-4o-2024-05-13_500  |     5      | East US 2 |    13.90409922     | 13.453411500000016 | 7.2615721000000235 |  19.567714579999993  |  19.93616467599999   | 0.3229340250559107  |         51.0         |        0.0        |          500.0           |          0.0          |               500.0               |               500.0               |         0.0          | 0.027808198440000004 | 0.02690682300000003  | 0.01452314420000005  | 0.039135429159999985 | 0.03987232935199998  |              |             |          |                      |                      |    0.0     |     []      |        5        |         0         |       0        |      0.0      |  {\"ttlt\": 7.849451299999998, \"completion_tokens\": 500, \"prompt_tokens\": 51, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-27 12:47:16 EDT\"}  | {\"ttlt\": 20.02827719999999, \"completion_tokens\": 500, \"prompt_tokens\": 51, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-27 12:47:07 EDT\"}  |\n",
      "| gpt-4o-2024-05-13_1000 |     6      | East US 2 | 26.657298083333334 | 24.887844699999988 | 10.505780250000008 |  41.95718412500003   |  44.75122730500005   | 0.37364087930274653 |         52.0         |        1.5        |          1000.0          |          0.0          |              1000.0               |              1000.0               |         0.0          | 0.026657298083333336 | 0.024887844699999988 | 0.01050578025000001  | 0.04195718412500003  | 0.044751227305000044 |              |             |          |                      |                      |    0.0     |     []      |        6        |         0         |       0        |      0.0      | {\"ttlt\": 14.786188600000003, \"completion_tokens\": 1000, \"prompt_tokens\": 50, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-27 12:47:48 EDT\"} | {\"ttlt\": 45.44973810000005, \"completion_tokens\": 1000, \"prompt_tokens\": 52, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-27 12:47:32 EDT\"} |\n",
      "+------------------------+------------+-----------+--------------------+--------------------+--------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_1000': {'median_ttlt': 24.887844699999988,\n",
       "  'regions': ['East US 2'],\n",
       "  'iqr_ttlt': 10.505780250000008,\n",
       "  'percentile_95_ttlt': 41.95718412500003,\n",
       "  'percentile_99_ttlt': 44.75122730500005,\n",
       "  'cv_ttlt': 0.37364087930274653,\n",
       "  'median_completion_tokens': 1000.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 1000.0,\n",
       "  'percentile_99_completion_tokens': 1000.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 52.0,\n",
       "  'iqr_prompt_tokens': 1.5,\n",
       "  'percentile_95_prompt_tokens': 752.5,\n",
       "  'percentile_99_prompt_tokens': 939.3000000000002,\n",
       "  'cv_prompt_tokens': 1.6829977732662775,\n",
       "  'average_ttlt': 26.657298083333334,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 6,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 6,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 0.024887844699999988,\n",
       "  'iqr_tbt': 0.01050578025000001,\n",
       "  'percentile_95_tbt': 0.04195718412500003,\n",
       "  'percentile_99_tbt': 0.044751227305000044,\n",
       "  'cv_tbt': 0.3736408793027465,\n",
       "  'average_tbt': 0.026657298083333336,\n",
       "  'median_ttft': None,\n",
       "  'iqr_ttft': None,\n",
       "  'percentile_95_ttft': None,\n",
       "  'percentile_99_ttft': None,\n",
       "  'cv_ttft': None,\n",
       "  'average_ttft': None,\n",
       "  'best_run': {'ttlt': 14.786188600000003,\n",
       "   'completion_tokens': 1000,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:48 EDT'},\n",
       "  'worst_run': {'ttlt': 45.44973810000005,\n",
       "   'completion_tokens': 1000,\n",
       "   'prompt_tokens': 52,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:32 EDT'}},\n",
       " 'gpt-4o-2024-05-13_250': {'median_ttlt': 7.10248039999999,\n",
       "  'regions': ['East US 2'],\n",
       "  'iqr_ttlt': 0.666764999999998,\n",
       "  'percentile_95_ttlt': 8.18536955999997,\n",
       "  'percentile_99_ttlt': 8.382085591999964,\n",
       "  'cv_ttlt': 0.2844681870071126,\n",
       "  'median_completion_tokens': 250.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 250.0,\n",
       "  'percentile_99_completion_tokens': 250.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 51.0,\n",
       "  'iqr_prompt_tokens': 2.0,\n",
       "  'percentile_95_prompt_tokens': 51.0,\n",
       "  'percentile_99_prompt_tokens': 51.0,\n",
       "  'cv_prompt_tokens': 0.019517846556041257,\n",
       "  'average_ttlt': 6.453399939999997,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 5,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 5,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 0.02840992159999996,\n",
       "  'iqr_tbt': 0.002667059999999992,\n",
       "  'percentile_95_tbt': 0.03274147823999988,\n",
       "  'percentile_99_tbt': 0.03352834236799986,\n",
       "  'cv_tbt': 0.28446818700711257,\n",
       "  'average_tbt': 0.02581359975999999,\n",
       "  'median_ttft': None,\n",
       "  'iqr_ttft': None,\n",
       "  'percentile_95_ttft': None,\n",
       "  'percentile_99_ttft': None,\n",
       "  'cv_ttft': None,\n",
       "  'average_ttft': None,\n",
       "  'best_run': {'ttlt': 2.9964409000000387,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 49,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:46:31 EDT'},\n",
       "  'worst_run': {'ttlt': 8.431264599999963,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 49,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:46:27 EDT'}},\n",
       " 'gpt-4o-2024-05-13_500': {'median_ttlt': 13.453411500000016,\n",
       "  'regions': ['East US 2'],\n",
       "  'iqr_ttlt': 7.2615721000000235,\n",
       "  'percentile_95_ttlt': 19.567714579999993,\n",
       "  'percentile_99_ttlt': 19.93616467599999,\n",
       "  'cv_ttlt': 0.3229340250559107,\n",
       "  'median_completion_tokens': 500.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 500.0,\n",
       "  'percentile_99_completion_tokens': 500.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 51.0,\n",
       "  'iqr_prompt_tokens': 0.0,\n",
       "  'percentile_95_prompt_tokens': 51.0,\n",
       "  'percentile_99_prompt_tokens': 51.0,\n",
       "  'cv_prompt_tokens': 0.015810276679841896,\n",
       "  'average_ttlt': 13.90409922,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 5,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 5,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 0.02690682300000003,\n",
       "  'iqr_tbt': 0.01452314420000005,\n",
       "  'percentile_95_tbt': 0.039135429159999985,\n",
       "  'percentile_99_tbt': 0.03987232935199998,\n",
       "  'cv_tbt': 0.3229340250559106,\n",
       "  'average_tbt': 0.027808198440000004,\n",
       "  'median_ttft': None,\n",
       "  'iqr_ttft': None,\n",
       "  'percentile_95_ttft': None,\n",
       "  'percentile_99_ttft': None,\n",
       "  'cv_ttft': None,\n",
       "  'average_ttft': None,\n",
       "  'best_run': {'ttlt': 7.849451299999998,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 51,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:16 EDT'},\n",
       "  'worst_run': {'ttlt': 20.02827719999999,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 51,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:07 EDT'}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_nonstreaming.calculate_and_show_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = AzureOpenAIBenchmarkStreaming(api_key=OPENAI_API_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=DEPLOYMENT_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 23:36:50,322 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 100 at (Local time): 2024-06-26 23:36:50.322042, (GMT): 2024-06-27 04:36:50.322042+00:00 (latencytest.py:make_call:529)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 971.27}\n",
      "{'Count': 2, 'Content': 'The', 'Token size': 1, 'Time taken (ms)': 787.63}\n",
      "{'Count': 3, 'Content': ' some', 'Token size': 1, 'Time taken (ms)': 1068.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 23:36:54,501 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.18 seconds or 4178.88 milliseconds. (latencytest.py:make_call:581)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Count': 4, 'Content': ' by', 'Token size': 1, 'Time taken (ms)': 1264.66}\n",
      "{'Count': 5, 'Content': 'qu', 'Token size': 1, 'Time taken (ms)': 54.4}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m benchmark\u001b[38;5;241m.\u001b[39mmake_call(deployment_name\u001b[38;5;241m=\u001b[39mDEPLOYMENT_ID, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\upgrade-llm\\lib\\site-packages\\backoff\\_async.py:151\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m details \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: target,\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m: args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melapsed\u001b[39m\u001b[38;5;124m\"\u001b[39m: elapsed,\n\u001b[0;32m    148\u001b[0m }\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    153\u001b[0m     giveup_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m giveup(e)\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\Desktop\\gbb-ai-upgrade-llm\\src\\performance\\latencytest.py:595\u001b[0m, in \u001b[0;36mAzureOpenAIBenchmarkStreaming.make_call\u001b[1;34m(self, deployment_name, max_tokens, timeout)\u001b[0m\n\u001b[0;32m    589\u001b[0m     TTFT \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(first_token_time \u001b[38;5;241m/\u001b[39m context_tokens_size, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m context_tokens_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    590\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    591\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTBT\u001b[39m\u001b[38;5;124m\"\u001b[39m: TBT,\n\u001b[0;32m    592\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTFT\u001b[39m\u001b[38;5;124m\"\u001b[39m: TTFT,\n\u001b[0;32m    593\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTLT\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mround\u001b[39m(total_time_taken \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    594\u001b[0m     }\n\u001b[1;32m--> 595\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_time_taken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_results(deployment_name, max_tokens, headers, total_time_taken)\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\Desktop\\gbb-ai-upgrade-llm\\src\\performance\\latencytest.py:299\u001b[0m, in \u001b[0;36mAzureOpenAIBenchmarkLatency._store_results\u001b[1;34m(self, deployment_name, max_tokens, headers, time_taken, metrics)\u001b[0m\n\u001b[0;32m    297\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeployment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults:\n\u001b[1;32m--> 299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimes_succesful\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimes_unsucessfull\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregions\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber_of_iterations\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodes\u001b[39m\u001b[38;5;124m\"\u001b[39m: []},\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_run\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    308\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    309\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    310\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    311\u001b[0m         },\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworst_run\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    313\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    314\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    315\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    316\u001b[0m         },\n\u001b[0;32m    317\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTBT\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTFT\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTLT\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    320\u001b[0m     }\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time_taken \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults[key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber_of_iterations\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "await benchmark.make_call(deployment_name=DEPLOYMENT_ID, max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import logging\n",
    "import aiohttp\n",
    "import backoff\n",
    "from datetime import datetime, timezone\n",
    "from tabulate import tabulate\n",
    "import tiktoken\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def _terminal_http_code(e):\n",
    "    return 400 <= e.status < 500\n",
    "\n",
    "MAX_RETRY_ATTEMPTS = 3\n",
    "MAX_TIMEOUT_SECONDS = 60\n",
    "\n",
    "class AzureOpenAIBenchmarkStreaming(AzureOpenAIBenchmarkLatency):\n",
    "    def __init__(self, api_key, azure_endpoint, api_version=\"2024-02-15-preview\"):\n",
    "        \"\"\"\n",
    "        Initialize the AzureOpenAILatencyBenchmark with the API key, API version, and endpoint.\n",
    "        \"\"\"\n",
    "        super().__init__(api_key, azure_endpoint, api_version)\n",
    "        self.api_key = api_key\n",
    "        self.azure_endpoint = azure_endpoint\n",
    "        self.api_version = api_version\n",
    "        self.results = []\n",
    "\n",
    "    @backoff.on_exception(\n",
    "        backoff.expo,\n",
    "        aiohttp.ClientError,\n",
    "        jitter=backoff.full_jitter,\n",
    "        max_tries=MAX_RETRY_ATTEMPTS,\n",
    "        giveup=_terminal_http_code,\n",
    "    )\n",
    "    async def make_call(self, deployment_name, max_tokens, timeout=60):\n",
    "        \"\"\"\n",
    "        Make a chat completion call and print the time taken for the call.\n",
    "        \"\"\"\n",
    "        base_url = self.azure_endpoint\n",
    "        url = f\"{base_url}/openai/deployments/{deployment_name}/chat/completions?api-version={self.api_version}\"\n",
    "        start_phrase = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Give me history of New York\"}\n",
    "        ]\n",
    "        payload = {\n",
    "            \"messages\": start_phrase,\n",
    "            \"stream\": True,\n",
    "            \"max_tokens\": max_tokens\n",
    "        }\n",
    "        headers = {\n",
    "            \"api-key\": self.api_key,\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        logger.info(\n",
    "            f\"Starting call to model {deployment_name} with max tokens {max_tokens} at (Local time): {datetime.now()}, (GMT): {datetime.now(timezone.utc)}\"\n",
    "        )\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            try:\n",
    "                async with session.post(url, headers=headers, json=payload, timeout=timeout) as response:\n",
    "                    response.raise_for_status()\n",
    "                    prev_end_time = start_time  # Initialize prev_end_time to store the previous end_time\n",
    "                    count = 0  # Initialize a counter for chunks\n",
    "                    token_times = []  # List to store times for each token\n",
    "                    first_token_time = None\n",
    "\n",
    "                    async for chunk in response.content.iter_any():\n",
    "                        if chunk:  # filter out keep-alive new lines\n",
    "                            try:\n",
    "                                response_chunk = json.loads(chunk)\n",
    "                            except json.JSONDecodeError:\n",
    "                                # Extract content from the chunk string\n",
    "                                content_match = re.search(r'\"content\":\"(.*?)\"', chunk.decode('utf-8'))\n",
    "                                if content_match:\n",
    "                                    count += 1  # Increment the counter\n",
    "                                    content = content_match.group(1)\n",
    "\n",
    "                                    token_size = num_tokens_from_string(content, \"cl100k_base\")\n",
    "\n",
    "                                    end_time = time.perf_counter()\n",
    "                                    time_taken = (end_time - prev_end_time) * 1000  # Subtract prev_end_time from start_time\n",
    "                                    time_taken = max(time_taken, 1)  # Set a minimum value of 1 ms for time_taken\n",
    "                                    time_taken = round(time_taken, 2)  # Round time_taken to 2 decimal places\n",
    "\n",
    "                                    result = {\"Count\": count, \"Content\": content, \"Token size\": token_size, \"Time taken (ms)\": time_taken}\n",
    "                                    self.results.append(result)\n",
    "\n",
    "                                    # Print the result as it is added to the list\n",
    "                                    print(result)\n",
    "                                    \n",
    "                                    # Record the time for each token\n",
    "                                    token_times.append(time_taken)\n",
    "                                    if first_token_time is None:\n",
    "                                        first_token_time = time_taken\n",
    "\n",
    "                                    prev_end_time = end_time  # Update prev_end_time for the next iteration\n",
    "\n",
    "            except aiohttp.ClientError as e:\n",
    "                logger.error(f\"Error during API call: {str(e)}\")\n",
    "                raise\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        total_time_taken = end_time - start_time\n",
    "\n",
    "        logger.info(\n",
    "            f\"Finished call to model {deployment_name}. Time taken for chat: {round(total_time_taken, 2)} seconds or {round(total_time_taken * 1000, 2)} milliseconds.\"\n",
    "        )\n",
    "\n",
    "        # Calculate TBT and TTFT\n",
    "        if token_times:\n",
    "            TBT = round(sum(token_times[1:]) / (len(token_times) - 1), 2) if len(token_times) > 1 else 0\n",
    "            context_tokens_size = num_tokens_from_string(\"Give me history of New York\", \"cl100k_base\")\n",
    "            TTFT = round(first_token_time / context_tokens_size, 2) if context_tokens_size > 0 else 0\n",
    "            self.results.append({\"Count\": \"TBT\", \"Content\": \"\", \"Token size\": \"\", \"Time taken (ms)\": TBT})\n",
    "            self.results.append({\"Count\": \"TTFT\", \"Content\": \"\", \"Token size\": \"\", \"Time taken (ms)\": TTFT})\n",
    "\n",
    "        # Calculate the cumulative time\n",
    "        cumulative_time = sum(result[\"Time taken (ms)\"] for result in self.results if isinstance(result[\"Time taken (ms)\"], (int, float)))\n",
    "        cumulative_time = round(cumulative_time, 2)  # Round cumulative_time to 2 decimal places\n",
    "\n",
    "        # Add the cumulative time to the results list as an extra row\n",
    "        self.results.append({\"Count\": \"TTLT\", \"Content\": \"\", \"Token size\": \"\", \"Time taken (ms)\": cumulative_time})\n",
    "\n",
    "        # Display results in tabular form\n",
    "        print(\"\\nResults Table:\")\n",
    "        print(tabulate([result.values() for result in self.results], headers=self.results[0].keys(), tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the environment variables using os.getenv\n",
    "OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_API_ENDPOINT\")\n",
    "DEPLOYMENT_ID = os.getenv(\"AZURE_AOAI_CHAT_MODEL_NAME_DEPLOYMENT_ID\")\n",
    "DEPLOYMENT_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:  \n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"  \n",
    "    encoding = tiktoken.get_encoding(encoding_name)  \n",
    "    num_tokens = len(encoding.encode(string))  \n",
    "    return num_tokens  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin:openai.ChatCompletion.create\n",
      "END:openai.ChatCompletion.create\n",
      "Time taken: 3.7182253000000856 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "url = AZURE_OPENAI_ENDPOINT + \"/openai/deployments/\" + DEPLOYMENT_ID + \"/chat/completions?api-version=2023-05-15\"\n",
    "start_phrase = [{\"role\":\"system\",\"content\":\"You are an AI assistant that helps people find information.\"},\n",
    "                {\"role\":\"user\",\"content\":\"Write 5000 word essay on soccer\"}]\n",
    "payload = {        \n",
    "    \"messages\":start_phrase,\n",
    "    #\"stream\":True,\n",
    "    \"max_tokens\":200\n",
    "    }\n",
    "\n",
    "headers = {  \n",
    "    \"api-key\": OPENAI_API_KEY,  \n",
    "    \"Content-Type\": \"application/json\"  \n",
    "} \n",
    "print(\"Begin:openai.ChatCompletion.create\")\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "try:  \n",
    "    r = requests.post(url,  \n",
    "                      headers=headers,  \n",
    "                      json=payload,  \n",
    "                      timeout=10  \n",
    "                      )  \n",
    "except requests.exceptions.Timeout:  \n",
    "    print(\"The request has timed out. Please try again.\")  \n",
    "    \n",
    "print(\"END:openai.ChatCompletion.create\")\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin:openai.ChatCompletion.create\n",
      "{'Count': 1, 'Content': 'Sure', 'Token size': 1, 'Time taken (ms)': 709.08}\n",
      "{'Count': 2, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1.58}\n",
      "{'Count': 3, 'Content': ' here', 'Token size': 1, 'Time taken (ms)': 1.95}\n",
      "{'Count': 4, 'Content': ' is', 'Token size': 1, 'Time taken (ms)': 1.21}\n",
      "{'Count': 5, 'Content': ' an', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 6, 'Content': ' essay', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 7, 'Content': ' on', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 8, 'Content': ' soccer', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 9, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 10, 'Content': ' Due', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 11, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 12, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 13, 'Content': ' platform', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 14, 'Content': \"'s\", 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 15, 'Content': ' constraints', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 16, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 17, 'Content': ' I', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 18, 'Content': \" can't\", 'Token size': 2, 'Time taken (ms)': 1}\n",
      "{'Count': 19, 'Content': ' provide', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 20, 'Content': ' a', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 21, 'Content': ' full', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 22, 'Content': ' ', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 23, 'Content': '500', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 24, 'Content': '0', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 25, 'Content': ' words', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 26, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 27, 'Content': ' one', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 28, 'Content': ' go', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 29, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 30, 'Content': ' but', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 31, 'Content': \" I'll\", 'Token size': 2, 'Time taken (ms)': 1.0}\n",
      "{'Count': 32, 'Content': ' give', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 33, 'Content': ' you', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 34, 'Content': ' a', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 35, 'Content': ' sizeable', 'Token size': 2, 'Time taken (ms)': 3.0}\n",
      "{'Count': 36, 'Content': ' portion', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 37, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 640.83}\n",
      "{'Count': 38, 'Content': ' get', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 39, 'Content': ' started', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 40, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 41, 'Content': ' \\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 1}\n",
      "{'Count': 42, 'Content': '---\\\\n\\\\n', 'Token size': 4, 'Time taken (ms)': 6.95}\n",
      "{'Count': 43, 'Content': '###', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 44, 'Content': ' The', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 45, 'Content': ' Global', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 46, 'Content': ' Phen', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 47, 'Content': 'omen', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 48, 'Content': 'on', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 49, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 50, 'Content': ' Soccer', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 51, 'Content': '\\\\n\\\\n', 'Token size': 2, 'Time taken (ms)': 1.02}\n",
      "{'Count': 52, 'Content': '####', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 53, 'Content': ' Introduction', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 54, 'Content': '\\\\n\\\\n', 'Token size': 2, 'Time taken (ms)': 1}\n",
      "{'Count': 55, 'Content': 'Soc', 'Token size': 2, 'Time taken (ms)': 1}\n",
      "{'Count': 56, 'Content': 'cer', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 57, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1.57}\n",
      "{'Count': 58, 'Content': ' known', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 59, 'Content': ' as', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 60, 'Content': ' football', 'Token size': 1, 'Time taken (ms)': 1.07}\n",
      "{'Count': 61, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 62, 'Content': ' most', 'Token size': 1, 'Time taken (ms)': 1.08}\n",
      "{'Count': 63, 'Content': ' countries', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 64, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 65, 'Content': ' stands', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 66, 'Content': ' as', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 67, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 68, 'Content': ' world', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 69, 'Content': 's', 'Token size': 1, 'Time taken (ms)': 1.07}\n",
      "{'Count': 70, 'Content': ' most', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 71, 'Content': ' popular', 'Token size': 1, 'Time taken (ms)': 472.87}\n",
      "{'Count': 72, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 73, 'Content': ' beloved', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 74, 'Content': ' sport', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 75, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 76, 'Content': ' Its', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 77, 'Content': ' simplicity', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 78, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 79, 'Content': ' accessibility', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 80, 'Content': ' have', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 81, 'Content': ' allowed', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 82, 'Content': ' it', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 83, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 84, 'Content': ' transcend', 'Token size': 1, 'Time taken (ms)': 2.0}\n",
      "{'Count': 85, 'Content': ' cultural', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 86, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 87, 'Content': ' economic', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 88, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 89, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 90, 'Content': ' geographical', 'Token size': 1, 'Time taken (ms)': 1.51}\n",
      "{'Count': 91, 'Content': ' barriers', 'Token size': 1, 'Time taken (ms)': 1.02}\n",
      "{'Count': 92, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 1.01}\n",
      "{'Count': 93, 'Content': ' Whether', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 94, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 95, 'Content': ' urban', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 96, 'Content': ' meg', 'Token size': 1, 'Time taken (ms)': 986.48}\n",
      "{'Count': 97, 'Content': 'ac', 'Token size': 1, 'Time taken (ms)': 1.01}\n",
      "{'Count': 98, 'Content': 'ities', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 99, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 100, 'Content': ' rural', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 101, 'Content': ' communities', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 102, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 103, 'Content': ' soccer', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 104, 'Content': ' has', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 105, 'Content': ' established', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 106, 'Content': ' itself', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 107, 'Content': ' as', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 108, 'Content': ' not', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 109, 'Content': ' merely', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 110, 'Content': ' a', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 111, 'Content': ' sport', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 112, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 113, 'Content': ' but', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 114, 'Content': ' a', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 115, 'Content': ' significant', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 116, 'Content': ' cultural', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 117, 'Content': ' force', 'Token size': 1, 'Time taken (ms)': 1.03}\n",
      "{'Count': 118, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 119, 'Content': ' This', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 120, 'Content': ' essay', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 121, 'Content': ' del', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 122, 'Content': 'ves', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 123, 'Content': ' into', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 124, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 125, 'Content': ' intric', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 126, 'Content': 'acies', 'Token size': 1, 'Time taken (ms)': 618.69}\n",
      "{'Count': 127, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 128, 'Content': ' soccer', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 129, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 130, 'Content': ' its', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 131, 'Content': ' history', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 132, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 133, 'Content': ' global', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 134, 'Content': ' influence', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 135, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 136, 'Content': ' economic', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 137, 'Content': ' impact', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 138, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 139, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 140, 'Content': ' social', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 141, 'Content': ' significance', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 142, 'Content': '.\\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 1}\n",
      "{'Count': 143, 'Content': '####', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 144, 'Content': ' History', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 145, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 146, 'Content': ' Soccer', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 147, 'Content': '\\\\n\\\\n', 'Token size': 2, 'Time taken (ms)': 1}\n",
      "{'Count': 148, 'Content': 'The', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 149, 'Content': ' origins', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 150, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 151, 'Content': ' soccer', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 152, 'Content': ' can', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 153, 'Content': ' be', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 154, 'Content': ' traced', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 155, 'Content': ' back', 'Token size': 1, 'Time taken (ms)': 612.13}\n",
      "{'Count': 156, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 1.4}\n",
      "{'Count': 157, 'Content': ' ancient', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 158, 'Content': ' civilizations', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 159, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 160, 'Content': ' with', 'Token size': 1, 'Time taken (ms)': 1.11}\n",
      "{'Count': 161, 'Content': ' early', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 162, 'Content': ' forms', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 163, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 164, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 165, 'Content': ' game', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 166, 'Content': ' appearing', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 167, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 168, 'Content': ' China', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 169, 'Content': ' during', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 170, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 171, 'Content': ' Han', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 172, 'Content': ' Dynasty', 'Token size': 1, 'Time taken (ms)': 8.96}\n",
      "{'Count': 173, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 174, 'Content': ' Greece', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 175, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1.02}\n",
      "{'Count': 176, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 177, 'Content': ' Rome', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 178, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 179, 'Content': ' However', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 180, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 181, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 182, 'Content': ' modern', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 183, 'Content': ' version', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 184, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 185, 'Content': ' soccer', 'Token size': 1, 'Time taken (ms)': 324.38}\n",
      "{'Count': 186, 'Content': ' began', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 187, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 188, 'Content': ' take', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 189, 'Content': ' shape', 'Token size': 1, 'Time taken (ms)': 1.51}\n",
      "{'Count': 190, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 191, 'Content': ' England', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 192, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 193, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 194, 'Content': ' ', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 195, 'Content': '19', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 196, 'Content': 'th', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 197, 'Content': ' century', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 198, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 199, 'Content': ' Initially', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 200, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "END:openai.ChatCompletion.create\n",
      "Total time taken 4.79 seconds to complete.\n",
      "\n",
      "Results Table:\n",
      "+------------+---------------+------------+-----------------+\n",
      "|   Count    |    Content    | Token size | Time taken (ms) |\n",
      "+------------+---------------+------------+-----------------+\n",
      "|     1      |     Sure      |     1      |     709.08      |\n",
      "|     2      |       ,       |     1      |      1.58       |\n",
      "|     3      |     here      |     1      |      1.95       |\n",
      "|     4      |      is       |     1      |      1.21       |\n",
      "|     5      |      an       |     1      |        1        |\n",
      "|     6      |     essay     |     1      |        1        |\n",
      "|     7      |      on       |     1      |        1        |\n",
      "|     8      |    soccer     |     1      |        1        |\n",
      "|     9      |       .       |     1      |       1.0       |\n",
      "|     10     |      Due      |     1      |        1        |\n",
      "|     11     |      to       |     1      |       1.0       |\n",
      "|     12     |      the      |     1      |        1        |\n",
      "|     13     |   platform    |     1      |       1.0       |\n",
      "|     14     |      's       |     1      |        1        |\n",
      "|     15     |  constraints  |     1      |        1        |\n",
      "|     16     |       ,       |     1      |        1        |\n",
      "|     17     |       I       |     1      |        1        |\n",
      "|     18     |     can't     |     2      |        1        |\n",
      "|     19     |    provide    |     1      |       1.0       |\n",
      "|     20     |       a       |     1      |        1        |\n",
      "|     21     |     full      |     1      |        1        |\n",
      "|     22     |               |     1      |        1        |\n",
      "|     23     |      500      |     1      |        1        |\n",
      "|     24     |       0       |     1      |        1        |\n",
      "|     25     |     words     |     1      |        1        |\n",
      "|     26     |      in       |     1      |        1        |\n",
      "|     27     |      one      |     1      |        1        |\n",
      "|     28     |      go       |     1      |        1        |\n",
      "|     29     |       ,       |     1      |        1        |\n",
      "|     30     |      but      |     1      |        1        |\n",
      "|     31     |     I'll      |     2      |       1.0       |\n",
      "|     32     |     give      |     1      |        1        |\n",
      "|     33     |      you      |     1      |        1        |\n",
      "|     34     |       a       |     1      |        1        |\n",
      "|     35     |   sizeable    |     2      |       3.0       |\n",
      "|     36     |    portion    |     1      |        1        |\n",
      "|     37     |      to       |     1      |     640.83      |\n",
      "|     38     |      get      |     1      |        1        |\n",
      "|     39     |    started    |     1      |        1        |\n",
      "|     40     |       .       |     1      |        1        |\n",
      "|     41     |     \\n\\n      |     3      |        1        |\n",
      "|     42     |    ---\\n\\n    |     4      |      6.95       |\n",
      "|     43     |      ###      |     1      |        1        |\n",
      "|     44     |      The      |     1      |       1.0       |\n",
      "|     45     |    Global     |     1      |        1        |\n",
      "|     46     |     Phen      |     1      |        1        |\n",
      "|     47     |     omen      |     1      |        1        |\n",
      "|     48     |      on       |     1      |        1        |\n",
      "|     49     |      of       |     1      |        1        |\n",
      "|     50     |    Soccer     |     1      |        1        |\n",
      "|     51     |     \\n\\n      |     2      |      1.02       |\n",
      "|     52     |     ####      |     1      |        1        |\n",
      "|     53     | Introduction  |     1      |        1        |\n",
      "|     54     |     \\n\\n      |     2      |        1        |\n",
      "|     55     |      Soc      |     2      |        1        |\n",
      "|     56     |      cer      |     1      |        1        |\n",
      "|     57     |       ,       |     1      |      1.57       |\n",
      "|     58     |     known     |     1      |        1        |\n",
      "|     59     |      as       |     1      |        1        |\n",
      "|     60     |   football    |     1      |      1.07       |\n",
      "|     61     |      in       |     1      |        1        |\n",
      "|     62     |     most      |     1      |      1.08       |\n",
      "|     63     |   countries   |     1      |        1        |\n",
      "|     64     |       ,       |     1      |        1        |\n",
      "|     65     |    stands     |     1      |        1        |\n",
      "|     66     |      as       |     1      |        1        |\n",
      "|     67     |      the      |     1      |        1        |\n",
      "|     68     |     world     |     1      |        1        |\n",
      "|     69     |      s       |     1      |      1.07       |\n",
      "|     70     |     most      |     1      |        1        |\n",
      "|     71     |    popular    |     1      |     472.87      |\n",
      "|     72     |      and      |     1      |        1        |\n",
      "|     73     |    beloved    |     1      |       1.0       |\n",
      "|     74     |     sport     |     1      |        1        |\n",
      "|     75     |       .       |     1      |        1        |\n",
      "|     76     |      Its      |     1      |        1        |\n",
      "|     77     |  simplicity   |     1      |        1        |\n",
      "|     78     |      and      |     1      |        1        |\n",
      "|     79     | accessibility |     1      |        1        |\n",
      "|     80     |     have      |     1      |        1        |\n",
      "|     81     |    allowed    |     1      |        1        |\n",
      "|     82     |      it       |     1      |        1        |\n",
      "|     83     |      to       |     1      |        1        |\n",
      "|     84     |   transcend   |     1      |       2.0       |\n",
      "|     85     |   cultural    |     1      |        1        |\n",
      "|     86     |       ,       |     1      |        1        |\n",
      "|     87     |   economic    |     1      |        1        |\n",
      "|     88     |       ,       |     1      |        1        |\n",
      "|     89     |      and      |     1      |        1        |\n",
      "|     90     | geographical  |     1      |      1.51       |\n",
      "|     91     |   barriers    |     1      |      1.02       |\n",
      "|     92     |       .       |     1      |      1.01       |\n",
      "|     93     |    Whether    |     1      |        1        |\n",
      "|     94     |      in       |     1      |        1        |\n",
      "|     95     |     urban     |     1      |        1        |\n",
      "|     96     |      meg      |     1      |     986.48      |\n",
      "|     97     |      ac       |     1      |      1.01       |\n",
      "|     98     |     ities     |     1      |        1        |\n",
      "|     99     |      or       |     1      |        1        |\n",
      "|    100     |     rural     |     1      |        1        |\n",
      "|    101     |  communities  |     1      |        1        |\n",
      "|    102     |       ,       |     1      |        1        |\n",
      "|    103     |    soccer     |     1      |        1        |\n",
      "|    104     |      has      |     1      |        1        |\n",
      "|    105     |  established  |     1      |        1        |\n",
      "|    106     |    itself     |     1      |        1        |\n",
      "|    107     |      as       |     1      |        1        |\n",
      "|    108     |      not      |     1      |        1        |\n",
      "|    109     |    merely     |     1      |        1        |\n",
      "|    110     |       a       |     1      |        1        |\n",
      "|    111     |     sport     |     1      |        1        |\n",
      "|    112     |       ,       |     1      |        1        |\n",
      "|    113     |      but      |     1      |        1        |\n",
      "|    114     |       a       |     1      |        1        |\n",
      "|    115     |  significant  |     1      |        1        |\n",
      "|    116     |   cultural    |     1      |        1        |\n",
      "|    117     |     force     |     1      |      1.03       |\n",
      "|    118     |       .       |     1      |        1        |\n",
      "|    119     |     This      |     1      |        1        |\n",
      "|    120     |     essay     |     1      |        1        |\n",
      "|    121     |      del      |     1      |        1        |\n",
      "|    122     |      ves      |     1      |        1        |\n",
      "|    123     |     into      |     1      |        1        |\n",
      "|    124     |      the      |     1      |        1        |\n",
      "|    125     |    intric     |     1      |        1        |\n",
      "|    126     |     acies     |     1      |     618.69      |\n",
      "|    127     |      of       |     1      |        1        |\n",
      "|    128     |    soccer     |     1      |       1.0       |\n",
      "|    129     |       ,       |     1      |        1        |\n",
      "|    130     |      its      |     1      |       1.0       |\n",
      "|    131     |    history    |     1      |        1        |\n",
      "|    132     |       ,       |     1      |        1        |\n",
      "|    133     |    global     |     1      |        1        |\n",
      "|    134     |   influence   |     1      |        1        |\n",
      "|    135     |       ,       |     1      |        1        |\n",
      "|    136     |   economic    |     1      |        1        |\n",
      "|    137     |    impact     |     1      |        1        |\n",
      "|    138     |       ,       |     1      |        1        |\n",
      "|    139     |      and      |     1      |        1        |\n",
      "|    140     |    social     |     1      |        1        |\n",
      "|    141     | significance  |     1      |        1        |\n",
      "|    142     |     .\\n\\n     |     3      |        1        |\n",
      "|    143     |     ####      |     1      |        1        |\n",
      "|    144     |    History    |     1      |        1        |\n",
      "|    145     |      of       |     1      |        1        |\n",
      "|    146     |    Soccer     |     1      |        1        |\n",
      "|    147     |     \\n\\n      |     2      |        1        |\n",
      "|    148     |      The      |     1      |        1        |\n",
      "|    149     |    origins    |     1      |        1        |\n",
      "|    150     |      of       |     1      |        1        |\n",
      "|    151     |    soccer     |     1      |        1        |\n",
      "|    152     |      can      |     1      |        1        |\n",
      "|    153     |      be       |     1      |        1        |\n",
      "|    154     |    traced     |     1      |        1        |\n",
      "|    155     |     back      |     1      |     612.13      |\n",
      "|    156     |      to       |     1      |       1.4       |\n",
      "|    157     |    ancient    |     1      |        1        |\n",
      "|    158     | civilizations |     1      |        1        |\n",
      "|    159     |       ,       |     1      |        1        |\n",
      "|    160     |     with      |     1      |      1.11       |\n",
      "|    161     |     early     |     1      |        1        |\n",
      "|    162     |     forms     |     1      |        1        |\n",
      "|    163     |      of       |     1      |        1        |\n",
      "|    164     |      the      |     1      |        1        |\n",
      "|    165     |     game      |     1      |        1        |\n",
      "|    166     |   appearing   |     1      |        1        |\n",
      "|    167     |      in       |     1      |        1        |\n",
      "|    168     |     China     |     1      |        1        |\n",
      "|    169     |    during     |     1      |        1        |\n",
      "|    170     |      the      |     1      |        1        |\n",
      "|    171     |      Han      |     1      |        1        |\n",
      "|    172     |    Dynasty    |     1      |      8.96       |\n",
      "|    173     |       ,       |     1      |        1        |\n",
      "|    174     |    Greece     |     1      |        1        |\n",
      "|    175     |       ,       |     1      |      1.02       |\n",
      "|    176     |      and      |     1      |        1        |\n",
      "|    177     |     Rome      |     1      |        1        |\n",
      "|    178     |       .       |     1      |        1        |\n",
      "|    179     |    However    |     1      |        1        |\n",
      "|    180     |       ,       |     1      |        1        |\n",
      "|    181     |      the      |     1      |        1        |\n",
      "|    182     |    modern     |     1      |        1        |\n",
      "|    183     |    version    |     1      |        1        |\n",
      "|    184     |      of       |     1      |        1        |\n",
      "|    185     |    soccer     |     1      |     324.38      |\n",
      "|    186     |     began     |     1      |        1        |\n",
      "|    187     |      to       |     1      |        1        |\n",
      "|    188     |     take      |     1      |        1        |\n",
      "|    189     |     shape     |     1      |      1.51       |\n",
      "|    190     |      in       |     1      |        1        |\n",
      "|    191     |    England    |     1      |        1        |\n",
      "|    192     |      in       |     1      |        1        |\n",
      "|    193     |      the      |     1      |        1        |\n",
      "|    194     |               |     1      |        1        |\n",
      "|    195     |      19       |     1      |        1        |\n",
      "|    196     |      th       |     1      |        1        |\n",
      "|    197     |    century    |     1      |        1        |\n",
      "|    198     |       .       |     1      |        1        |\n",
      "|    199     |   Initially   |     1      |        1        |\n",
      "|    200     |       ,       |     1      |        1        |\n",
      "| Cumulative |               |            |     4578.54     |\n",
      "+------------+---------------+------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import regex as re\n",
    "from tabulate import tabulate  \n",
    "\n",
    "payload = {        \n",
    "    \"messages\":start_phrase,\n",
    "    \"stream\":True,\n",
    "    \"max_tokens\":200\n",
    "    }\n",
    "\n",
    "results = []  \n",
    "\n",
    "try: \n",
    "    print(\"Begin:openai.ChatCompletion.create\")  \n",
    "    start_time_api_call = time.perf_counter()  # Initialize start_time before the loop  \n",
    "    with requests.post(url, headers=headers, json=payload, timeout=10, stream=True) as r:  \n",
    "        start_time = time.time()  # Initialize start_time before the loop  \n",
    "        prev_end_time = start_time  # Initialize prev_end_time to store the previous end_time  \n",
    "        count = 0  # Initialize a counter for chunks  \n",
    "        for chunk in r.iter_lines():  \n",
    "            if chunk:  # filter out keep-alive new lines  \n",
    "                try:  \n",
    "                    response_chunk = json.loads(chunk)  \n",
    "                except json.JSONDecodeError:  \n",
    "                    # Extract content from the chunk string  \n",
    "                    content_match = re.search(r'\"content\":\"(.*?)\"', chunk.decode('utf-8'))  \n",
    "                    if content_match:  \n",
    "                        count += 1  # Increment the counter  \n",
    "                        content = content_match.group(1)  \n",
    "  \n",
    "                        token_size = num_tokens_from_string(content, \"cl100k_base\")  \n",
    "  \n",
    "                        end_time = time.time()  \n",
    "                        time_taken = (end_time - prev_end_time) * 1000  # Subtract prev_end_time from start_time  \n",
    "                        time_taken = max(time_taken, 1)  # Set a minimum value of 0.01 ms for time_taken  \n",
    "                        time_taken = round(time_taken, 2)  # Round time_taken to 2 decimal places  \n",
    "  \n",
    "                        result = {\"Count\": count, \"Content\": content, \"Token size\": token_size, \"Time taken (ms)\": time_taken}  \n",
    "                        results.append(result)  \n",
    "  \n",
    "                        # Print the result as it is added to the list  \n",
    "                        print(result)  \n",
    "                        prev_end_time = end_time  # Update prev_end_time for the next iteration  \n",
    "  \n",
    "                    continue  \n",
    "  \n",
    "except requests.exceptions.Timeout:  \n",
    "    print(\"The request has timed out. Please try again.\")  \n",
    "\n",
    "print(\"END:openai.ChatCompletion.create\")  \n",
    "end_time_api_call = time.perf_counter() \n",
    "  \n",
    "# Calculate the time taken and print the result  \n",
    "time_taken = end_time_api_call - start_time_api_call  \n",
    "print(f'Total time taken {time_taken:.2f} seconds to complete.')  \n",
    "\n",
    "# Calculate the cumulative time  \n",
    "cumulative_time = sum(result[\"Time taken (ms)\"] for result in results)  \n",
    "cumulative_time = round(cumulative_time, 2)  # Round cumulative_time to 2 decimal places  \n",
    "  \n",
    "# Add the cumulative time to the results list as an extra row  \n",
    "results.append({\"Count\": \"Cumulative\", \"Content\": \"\", \"Token size\": \"\", \"Time taken (ms)\": cumulative_time})  \n",
    "  \n",
    "# Display results in tabular form  \n",
    "print(\"\\nResults Table:\")  \n",
    "print(tabulate([result.values() for result in results], headers=results[0].keys(), tablefmt=\"pretty\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The content for this response was already consumed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\upgrade-llm\\lib\\site-packages\\requests\\models.py:974\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\upgrade-llm\\lib\\site-packages\\requests\\models.py:926\u001b[0m, in \u001b[0;36mResponse.text\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    923\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    924\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding\n\u001b[1;32m--> 926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m:\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;66;03m# Fallback to auto-detected encoding.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\upgrade-llm\\lib\\site-packages\\requests\\models.py:897\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;66;03m# Read the contents.\u001b[39;00m\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed:\n\u001b[1;32m--> 897\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe content for this response was already consumed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The content for this response was already consumed"
     ]
    }
   ],
   "source": [
    "response = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import sys  \n",
    "\n",
    "\n",
    "\n",
    "base_url = \"https://myopenAI.openai.azure.com/\"\n",
    "deployment_name  = \"mydep\"\n",
    "api_key  =\"******\" \n",
    "\n",
    "\n",
    "url = base_url + \"/openai/deployments/\" + deployment_name + \"/chat/completions?api-version=2023-05-15\"\n",
    "start_phrase = [{\"role\":\"system\",\"content\":\"You are an AI assistant that helps people find information.\"},\n",
    "                {\"role\":\"user\",\"content\":\"Write 5000 word essay on soccer\"}]\n",
    "payload = {        \n",
    "    \"messages\":start_phrase,\n",
    "    \"stream\":True,\n",
    "    \"max_tokens\":200\n",
    "    }\n",
    "\n",
    "headers = {  \n",
    "    \"api-key\": api_key,  \n",
    "    \"Content-Type\": \"application/json\"  \n",
    "} \n",
    "print(\"Begin:openai.ChatCompletion.create\")\n",
    "start_time_api_call = time.time()\n",
    "\n",
    "  \n",
    "try:  \n",
    "    with requests.post(url, headers=headers, json=payload, timeout=1, stream=True) as r:  \n",
    "        start_time = time.time()  \n",
    "        for chunk in r.iter_content(chunk_size=None, decode_unicode=True):  \n",
    "            end_time = time.time()  \n",
    "            time_taken = (end_time - start_time) * 1000  # Convert to milliseconds  \n",
    "            chunk_size = sys.getsizeof(chunk)  \n",
    "  \n",
    "            print(f\"Time taken for this chunk: {time_taken:.2f} ms\")  \n",
    "            print(f\"Size of this chunk: {chunk_size} bytes\")  \n",
    "            start_time = end_time  \n",
    "  \n",
    "except requests.exceptions.Timeout:  \n",
    "    print(\"The request has timed out. Please try again.\")  \n",
    "        \n",
    "print(\"END:openai.ChatCompletion.create\")\n",
    "end_time_api_call  = time.time()\n",
    "# Calculate the time taken and print the result\n",
    "time_taken = end_time_api_call - start_time_api_call\n",
    "print(f'Total time taken {time_taken:.2f} seconds to complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['usage']['completion_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = AzureOpenAIBenchmarkStreaming(api_key=OPENAI_API_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=DEPLOYMENT_VERSION)\n",
    "await benchmark.make_call(deployment_name=DEPLOYMENT_ID, max_tokens=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting call to model gpt-4o-2024-05-13 with max tokens 100 at (Local time): 2024-06-26 23:18:31.243877, (GMT): 2024-06-27 04:18:31.243877+00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 471.37}\n",
      "{'Count': 2, 'Content': 'Certainly', 'Token size': 1, 'Time taken (ms)': 936.2}\n",
      "{'Count': 3, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 50.16}\n",
      "{'Count': 4, 'Content': ' before', 'Token size': 1, 'Time taken (ms)': 954.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.29 seconds or 3293.49 milliseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Count': 5, 'Content': 'on', 'Token size': 1, 'Time taken (ms)': 798.28}\n",
      "{'Count': 6, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 53.11}\n",
      "\n",
      "Results Table:\n",
      "+-------+-----------+------------+-----------------+\n",
      "| Count |  Content  | Token size | Time taken (ms) |\n",
      "+-------+-----------+------------+-----------------+\n",
      "|   1   |           |     0      |     471.37      |\n",
      "|   2   | Certainly |     1      |      936.2      |\n",
      "|   3   |     .     |     1      |      50.16      |\n",
      "|   4   |  before   |     1      |     954.29      |\n",
      "|   5   |    on     |     1      |     798.28      |\n",
      "|   6   |    and    |     1      |      53.11      |\n",
      "|  TBT  |           |            |     558.41      |\n",
      "| TTFT  |           |            |      78.56      |\n",
      "| TTLT  |           |            |     3900.38     |\n",
      "+-------+-----------+------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "await benchmark.make_call(deployment_name=DEPLOYMENT_ID, max_tokens=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await benchmark.make_call(deployment_name=DEPLOYMENT_ID, max_tokens=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 506.69},\n",
       " {'Count': 2, 'Content': 'The', 'Token size': 1, 'Time taken (ms)': 1280.25},\n",
       " {'Count': 3, 'Content': '###', 'Token size': 1, 'Time taken (ms)': 47.56},\n",
       " {'Count': 4, 'Content': ' Period', 'Token size': 1, 'Time taken (ms)': 804.1},\n",
       " {'Count': 5, 'Content': ' as', 'Token size': 1, 'Time taken (ms)': 47.9},\n",
       " {'Count': 6, 'Content': 'ro', 'Token size': 1, 'Time taken (ms)': 1098.75},\n",
       " {'Count': 7, 'Content': 'acy', 'Token size': 1, 'Time taken (ms)': 47.63},\n",
       " {'Count': 'TBT', 'Content': '', 'Token size': '', 'Time taken (ms)': 554.37},\n",
       " {'Count': 'TTFT', 'Content': '', 'Token size': '', 'Time taken (ms)': 84.45},\n",
       " {'Count': 'Cumulative',\n",
       "  'Content': '',\n",
       "  'Token size': '',\n",
       "  'Time taken (ms)': 4471.7}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "upgrade-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
