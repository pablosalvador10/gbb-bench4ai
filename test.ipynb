{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory C:\\Users\\pablosal\\Desktop\\gbb-ai-upgrade does not exist.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the target directory (change yours)\n",
    "TARGET_DIRECTORY = r\"C:\\Users\\pablosal\\Desktop\\gbb-ai-upgrade\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(TARGET_DIRECTORY):\n",
    "    # Change the current working directory\n",
    "    os.chdir(TARGET_DIRECTORY)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {TARGET_DIRECTORY} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.performance.latencytest import AzureOpenAIBenchmarkStreaming, AzureOpenAIBenchmarkNonStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the environment variables using os.getenv\n",
    "OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_API_ENDPOINT\")\n",
    "DEPLOYMENT_ID = os.getenv(\"AZURE_AOAI_CHAT_MODEL_NAME_DEPLOYMENT_ID\")\n",
    "DEPLOYMENT_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_streaming = AzureOpenAIBenchmarkStreaming(api_key=OPENAI_API_KEY, \n",
    "                                                    azure_endpoint=AZURE_OPENAI_ENDPOINT, \n",
    "                                                    api_version=DEPLOYMENT_VERSION)\n",
    "\n",
    "benchmark_non_streaming = AzureOpenAIBenchmarkNonStreaming(api_key=OPENAI_API_KEY, \n",
    "                                                    azure_endpoint=AZURE_OPENAI_ENDPOINT, \n",
    "                                                    api_version=DEPLOYMENT_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 20:17:25,918 - micro - MainProcess - INFO     CPU usage: 14.7% (utils.py:log_system_info:233)\n",
      "2024-06-28 20:17:25,947 - micro - MainProcess - INFO     RAM usage: 92.6% (utils.py:log_system_info:235)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 20:17:26,638 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719623846.6385462 '}, {'role': 'user', 'content': '1719623846.6385462 write a long essay about machine learning in at least 500 tokens'}] and Context Tokens: 50 (latencytest.py:make_call:711)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719623846.6385462 '}, {'role': 'user', 'content': '1719623846.6385462 write a long essay about machine learning in at least 500 tokens'}] and Context Tokens: 50\n",
      "2024-06-28 20:17:26,638 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-28 20:17:26,646 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-28 20:17:26.646572, (GMT): 2024-06-29 01:17:26.646572+00:00 (latencytest.py:make_call:733)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-28 20:17:26.646572, (GMT): 2024-06-29 01:17:26.646572+00:00\n",
      "2024-06-28 20:17:27,393 - micro - MainProcess - INFO     CPU usage: 14.0% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 14.0%\n",
      "2024-06-28 20:17:27,402 - micro - MainProcess - INFO     RAM usage: 93.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 93.3%\n",
      "2024-06-28 20:17:27,437 - micro - MainProcess - INFO     Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719623847.4347157 '}, {'role': 'user', 'content': '1719623847.4347157 write a long essay about machine learning in at least 250 tokens'}] and Context Tokens: 50 (latencytest.py:make_call:711)\n",
      "INFO:micro:Messages: [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '1719623847.4347157 '}, {'role': 'user', 'content': '1719623847.4347157 write a long essay about machine learning in at least 250 tokens'}] and Context Tokens: 50\n",
      "2024-06-28 20:17:27,445 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-28 20:17:27,447 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-28 20:17:27.447772, (GMT): 2024-06-29 01:17:27.447772+00:00 (latencytest.py:make_call:733)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-28 20:17:27.447772, (GMT): 2024-06-29 01:17:27.447772+00:00\n",
      "2024-06-28 20:17:31,344 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:761)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-28 20:17:31,383 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.93 seconds or 3929.2 milliseconds. (latencytest.py:make_call:772)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.93 seconds or 3929.2 milliseconds.\n",
      "2024-06-28 20:17:31,505 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Chicago, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Chicago, US\n",
      "2024-06-28 20:17:36,601 - micro - MainProcess - ERROR    Error decoding JSON: Expecting value: line 1 column 2 (char 1) (latencytest.py:make_call:761)\n",
      "ERROR:micro:Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "2024-06-28 20:17:36,633 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.98 seconds or 9982.38 milliseconds. (latencytest.py:make_call:772)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.98 seconds or 9982.38 milliseconds.\n",
      "2024-06-28 20:17:36,727 - micro - MainProcess - INFO     Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Chicago, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region N/A not found, assuming local deployment. \n",
      "                    Machine location during test: Chicago, US\n",
      "2024-06-28 20:17:42,764 - micro - MainProcess - INFO     CPU usage: 12.3% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.3%\n",
      "2024-06-28 20:17:42,782 - micro - MainProcess - INFO     RAM usage: 93.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 93.1%\n",
      "2024-06-28 20:17:42,801 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500 (latencytest.py:make_call:635)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 500\n",
      "2024-06-28 20:17:42,809 - micro - MainProcess - INFO     CPU usage: 29.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 29.6%\n",
      "2024-06-28 20:17:42,830 - micro - MainProcess - INFO     RAM usage: 93.1% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 93.1%\n",
      "2024-06-28 20:17:42,852 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250 (latencytest.py:make_call:635)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 250\n",
      "2024-06-28 20:17:55,196 - micro - MainProcess - INFO     Succesful Run - Time taken: 4.45 seconds. (latencytest.py:make_call:664)\n",
      "INFO:micro:Succesful Run - Time taken: 4.45 seconds.\n",
      "2024-06-28 20:17:56,523 - micro - MainProcess - INFO     Succesful Run - Time taken: 13.72 seconds. (latencytest.py:make_call:664)\n",
      "INFO:micro:Succesful Run - Time taken: 13.72 seconds.\n"
     ]
    }
   ],
   "source": [
    "await benchmark_streaming.run_latency_benchmark_bulk(deployment_names=[DEPLOYMENT_ID], max_tokens_list=[500,250], iterations=1)\n",
    "await benchmark_non_streaming.run_latency_benchmark_bulk(deployment_names=[DEPLOYMENT_ID], max_tokens_list=[500,250], iterations=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 20:18:02,575 - micro - MainProcess - INFO     Calculating statistics for data: [4.451135999999998] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [4.451135999999998]\n",
      "2024-06-28 20:18:02,577 - micro - MainProcess - INFO     Data converted to numpy array: [4.451136] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [4.451136]\n",
      "2024-06-28 20:18:02,588 - micro - MainProcess - INFO     Calculated median: 4.451135999999998 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 4.451135999999998\n",
      "2024-06-28 20:18:02,594 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:02,596 - micro - MainProcess - INFO     Calculated 95th percentile: 4.451135999999998 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 4.451135999999998\n",
      "2024-06-28 20:18:02,605 - micro - MainProcess - INFO     Calculated 99th percentile: 4.451135999999998 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 4.451135999999998\n",
      "2024-06-28 20:18:02,610 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:02,610 - micro - MainProcess - INFO     Result: (4.451135999999998, 0.0, 4.451135999999998, 4.451135999999998, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (4.451135999999998, 0.0, 4.451135999999998, 4.451135999999998, 0.0)\n",
      "2024-06-28 20:18:02,624 - micro - MainProcess - INFO     Calculating statistics for data: [250] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [250]\n",
      "2024-06-28 20:18:02,631 - micro - MainProcess - INFO     Data converted to numpy array: [250] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [250]\n",
      "2024-06-28 20:18:02,638 - micro - MainProcess - INFO     Calculated median: 250.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 250.0\n",
      "2024-06-28 20:18:02,645 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:02,651 - micro - MainProcess - INFO     Calculated 95th percentile: 250.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 250.0\n",
      "2024-06-28 20:18:02,659 - micro - MainProcess - INFO     Calculated 99th percentile: 250.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 250.0\n",
      "2024-06-28 20:18:02,672 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:02,678 - micro - MainProcess - INFO     Result: (250.0, 0.0, 250.0, 250.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (250.0, 0.0, 250.0, 250.0, 0.0)\n",
      "2024-06-28 20:18:02,685 - micro - MainProcess - INFO     Calculating statistics for data: [49] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [49]\n",
      "2024-06-28 20:18:02,691 - micro - MainProcess - INFO     Data converted to numpy array: [49] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [49]\n",
      "2024-06-28 20:18:02,693 - micro - MainProcess - INFO     Calculated median: 49.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 49.0\n",
      "2024-06-28 20:18:02,704 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:02,708 - micro - MainProcess - INFO     Calculated 95th percentile: 49.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 49.0\n",
      "2024-06-28 20:18:02,714 - micro - MainProcess - INFO     Calculated 99th percentile: 49.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 49.0\n",
      "2024-06-28 20:18:02,725 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:02,730 - micro - MainProcess - INFO     Result: (49.0, 0.0, 49.0, 49.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (49.0, 0.0, 49.0, 49.0, 0.0)\n",
      "2024-06-28 20:18:02,738 - micro - MainProcess - INFO     Calculating statistics for data: [0.01780454399999999] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.01780454399999999]\n",
      "2024-06-28 20:18:02,749 - micro - MainProcess - INFO     Data converted to numpy array: [0.01780454] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.01780454]\n",
      "2024-06-28 20:18:02,760 - micro - MainProcess - INFO     Calculated median: 0.01780454399999999 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.01780454399999999\n",
      "2024-06-28 20:18:02,768 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:02,776 - micro - MainProcess - INFO     Calculated 95th percentile: 0.01780454399999999 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.01780454399999999\n",
      "2024-06-28 20:18:02,782 - micro - MainProcess - INFO     Calculated 99th percentile: 0.01780454399999999 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.01780454399999999\n",
      "2024-06-28 20:18:02,794 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:02,797 - micro - MainProcess - INFO     Result: (0.01780454399999999, 0.0, 0.01780454399999999, 0.01780454399999999, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.01780454399999999, 0.0, 0.01780454399999999, 0.01780454399999999, 0.0)\n",
      "2024-06-28 20:18:02,805 - micro - MainProcess - INFO     Calculating statistics for data: [4.451135999999998] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [4.451135999999998]\n",
      "2024-06-28 20:18:02,812 - micro - MainProcess - INFO     Data converted to numpy array: [4.451136] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [4.451136]\n",
      "2024-06-28 20:18:02,828 - micro - MainProcess - INFO     Calculated median: 4.451135999999998 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 4.451135999999998\n",
      "2024-06-28 20:18:02,835 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:02,839 - micro - MainProcess - INFO     Calculated 95th percentile: 4.451135999999998 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 4.451135999999998\n",
      "2024-06-28 20:18:02,846 - micro - MainProcess - INFO     Calculated 99th percentile: 4.451135999999998 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 4.451135999999998\n",
      "2024-06-28 20:18:02,853 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:02,860 - micro - MainProcess - INFO     Result: (4.451135999999998, 0.0, 4.451135999999998, 4.451135999999998, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (4.451135999999998, 0.0, 4.451135999999998, 4.451135999999998, 0.0)\n",
      "2024-06-28 20:18:02,867 - micro - MainProcess - INFO     Calculating statistics for data: [13.717662200000007] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [13.717662200000007]\n",
      "2024-06-28 20:18:02,877 - micro - MainProcess - INFO     Data converted to numpy array: [13.7176622] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [13.7176622]\n",
      "2024-06-28 20:18:02,884 - micro - MainProcess - INFO     Calculated median: 13.717662200000007 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 13.717662200000007\n",
      "2024-06-28 20:18:02,887 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:02,895 - micro - MainProcess - INFO     Calculated 95th percentile: 13.717662200000007 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 13.717662200000007\n",
      "2024-06-28 20:18:02,902 - micro - MainProcess - INFO     Calculated 99th percentile: 13.717662200000007 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 13.717662200000007\n",
      "2024-06-28 20:18:02,910 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:02,918 - micro - MainProcess - INFO     Result: (13.717662200000007, 0.0, 13.717662200000007, 13.717662200000007, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (13.717662200000007, 0.0, 13.717662200000007, 13.717662200000007, 0.0)\n",
      "2024-06-28 20:18:02,922 - micro - MainProcess - INFO     Calculating statistics for data: [500] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [500]\n",
      "2024-06-28 20:18:02,929 - micro - MainProcess - INFO     Data converted to numpy array: [500] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [500]\n",
      "2024-06-28 20:18:02,934 - micro - MainProcess - INFO     Calculated median: 500.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 500.0\n",
      "2024-06-28 20:18:02,938 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:02,943 - micro - MainProcess - INFO     Calculated 95th percentile: 500.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 500.0\n",
      "2024-06-28 20:18:02,956 - micro - MainProcess - INFO     Calculated 99th percentile: 500.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 500.0\n",
      "2024-06-28 20:18:02,964 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:02,971 - micro - MainProcess - INFO     Result: (500.0, 0.0, 500.0, 500.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (500.0, 0.0, 500.0, 500.0, 0.0)\n",
      "2024-06-28 20:18:02,978 - micro - MainProcess - INFO     Calculating statistics for data: [51] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [51]\n",
      "2024-06-28 20:18:02,985 - micro - MainProcess - INFO     Data converted to numpy array: [51] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [51]\n",
      "2024-06-28 20:18:02,990 - micro - MainProcess - INFO     Calculated median: 51.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 51.0\n",
      "2024-06-28 20:18:02,998 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:03,006 - micro - MainProcess - INFO     Calculated 95th percentile: 51.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 51.0\n",
      "2024-06-28 20:18:03,014 - micro - MainProcess - INFO     Calculated 99th percentile: 51.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 51.0\n",
      "2024-06-28 20:18:03,021 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:03,029 - micro - MainProcess - INFO     Result: (51.0, 0.0, 51.0, 51.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (51.0, 0.0, 51.0, 51.0, 0.0)\n",
      "2024-06-28 20:18:03,036 - micro - MainProcess - INFO     Calculating statistics for data: [0.027435324400000013] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.027435324400000013]\n",
      "2024-06-28 20:18:03,043 - micro - MainProcess - INFO     Data converted to numpy array: [0.02743532] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.02743532]\n",
      "2024-06-28 20:18:03,047 - micro - MainProcess - INFO     Calculated median: 0.027435324400000013 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.027435324400000013\n",
      "2024-06-28 20:18:03,061 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:03,069 - micro - MainProcess - INFO     Calculated 95th percentile: 0.027435324400000013 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.027435324400000013\n",
      "2024-06-28 20:18:03,077 - micro - MainProcess - INFO     Calculated 99th percentile: 0.027435324400000013 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.027435324400000013\n",
      "2024-06-28 20:18:03,088 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:03,098 - micro - MainProcess - INFO     Result: (0.027435324400000013, 0.0, 0.027435324400000013, 0.027435324400000013, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.027435324400000013, 0.0, 0.027435324400000013, 0.027435324400000013, 0.0)\n",
      "2024-06-28 20:18:03,103 - micro - MainProcess - INFO     Calculating statistics for data: [13.717662200000007] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [13.717662200000007]\n",
      "2024-06-28 20:18:03,118 - micro - MainProcess - INFO     Data converted to numpy array: [13.7176622] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [13.7176622]\n",
      "2024-06-28 20:18:03,123 - micro - MainProcess - INFO     Calculated median: 13.717662200000007 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 13.717662200000007\n",
      "2024-06-28 20:18:03,133 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:03,140 - micro - MainProcess - INFO     Calculated 95th percentile: 13.717662200000007 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 13.717662200000007\n",
      "2024-06-28 20:18:03,148 - micro - MainProcess - INFO     Calculated 99th percentile: 13.717662200000007 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 13.717662200000007\n",
      "2024-06-28 20:18:03,157 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:03,163 - micro - MainProcess - INFO     Result: (13.717662200000007, 0.0, 13.717662200000007, 13.717662200000007, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (13.717662200000007, 0.0, 13.717662200000007, 13.717662200000007, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------+------------+-----------+--------------------+--------------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+----------------------+----------------------+---------+----------------------+----------------------+--------------------+--------------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|    Model_MaxTokens    | is_Streaming | Iterations |  Regions  |    Average TTLT    |    Median TTLT     | IQR TTLT | 95th Percentile TTLT | 99th Percentile TTLT | CV TTLT | Median Prompt Tokens | IQR Prompt Tokens | Median Completion Tokens | IQR Completion Tokens | 95th Percentile Completion Tokens | 99th Percentile Completion Tokens | CV Completion Tokens |     Average TBT      |      Median TBT      | IQR TBT | 95th Percentile TBT  | 99th Percentile TBT  |    Average TTFT    |    Median TTFT     | IQR TTFT | 95th Percentile TTFT | 99th Percentile TTFT | Error Rate | Error Types | Successful Runs | Unsuccessful Runs | Throttle Count | Throttle Rate |                                                                             Best Run                                                                             |                                                                            Worst Run                                                                             |\n",
      "+-----------------------+--------------+------------+-----------+--------------------+--------------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+----------------------+----------------------+---------+----------------------+----------------------+--------------------+--------------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| gpt-4o-2024-05-13_250 |    False     |     1      | East US 2 | 4.451135999999998  | 4.451135999999998  |   0.0    |  4.451135999999998   |  4.451135999999998   |   0.0   |         49.0         |        0.0        |          250.0           |          0.0          |               250.0               |               250.0               |         0.0          | 0.01780454399999999  | 0.01780454399999999  |   0.0   | 0.01780454399999999  | 0.01780454399999999  | 4.451135999999998  | 4.451135999999998  |   0.0    |  4.451135999999998   |  4.451135999999998   |    0.0     |     []      |        1        |         0         |       0        |      0.0      | {\"ttlt\": 4.451135999999998, \"completion_tokens\": 250, \"prompt_tokens\": 49, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-28 21:17:55 EDT\"}  | {\"ttlt\": 4.451135999999998, \"completion_tokens\": 250, \"prompt_tokens\": 49, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-28 21:17:55 EDT\"}  |\n",
      "| gpt-4o-2024-05-13_500 |    False     |     1      | East US 2 | 13.717662200000007 | 13.717662200000007 |   0.0    |  13.717662200000007  |  13.717662200000007  |   0.0   |         51.0         |        0.0        |          500.0           |          0.0          |               500.0               |               500.0               |         0.0          | 0.027435324400000013 | 0.027435324400000013 |   0.0   | 0.027435324400000013 | 0.027435324400000013 | 13.717662200000007 | 13.717662200000007 |   0.0    |  13.717662200000007  |  13.717662200000007  |    0.0     |     []      |        1        |         0         |       0        |      0.0      | {\"ttlt\": 13.717662200000007, \"completion_tokens\": 500, \"prompt_tokens\": 51, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-28 21:17:56 EDT\"} | {\"ttlt\": 13.717662200000007, \"completion_tokens\": 500, \"prompt_tokens\": 51, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-28 21:17:56 EDT\"} |\n",
      "+-----------------------+--------------+------------+-----------+--------------------+--------------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+----------------------+----------------------+---------+----------------------+----------------------+--------------------+--------------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_250': {'median_ttlt': 4.451135999999998,\n",
       "  'regions': ['East US 2'],\n",
       "  'iqr_ttlt': 0.0,\n",
       "  'percentile_95_ttlt': 4.451135999999998,\n",
       "  'percentile_99_ttlt': 4.451135999999998,\n",
       "  'cv_ttlt': 0.0,\n",
       "  'median_completion_tokens': 250.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 250.0,\n",
       "  'percentile_99_completion_tokens': 250.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 49.0,\n",
       "  'iqr_prompt_tokens': 0.0,\n",
       "  'percentile_95_prompt_tokens': 49.0,\n",
       "  'percentile_99_prompt_tokens': 49.0,\n",
       "  'cv_prompt_tokens': 0.0,\n",
       "  'average_ttlt': 4.451135999999998,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 1,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 1,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 0.01780454399999999,\n",
       "  'iqr_tbt': 0.0,\n",
       "  'percentile_95_tbt': 0.01780454399999999,\n",
       "  'percentile_99_tbt': 0.01780454399999999,\n",
       "  'cv_tbt': 0.0,\n",
       "  'average_tbt': 0.01780454399999999,\n",
       "  'median_ttft': 4.451135999999998,\n",
       "  'iqr_ttft': 0.0,\n",
       "  'percentile_95_ttft': 4.451135999999998,\n",
       "  'percentile_99_ttft': 4.451135999999998,\n",
       "  'cv_ttft': 0.0,\n",
       "  'average_ttft': 4.451135999999998,\n",
       "  'best_run': {'ttlt': 4.451135999999998,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 49,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-28 21:17:55 EDT'},\n",
       "  'worst_run': {'ttlt': 4.451135999999998,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 49,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-28 21:17:55 EDT'}},\n",
       " 'gpt-4o-2024-05-13_500': {'median_ttlt': 13.717662200000007,\n",
       "  'regions': ['East US 2'],\n",
       "  'iqr_ttlt': 0.0,\n",
       "  'percentile_95_ttlt': 13.717662200000007,\n",
       "  'percentile_99_ttlt': 13.717662200000007,\n",
       "  'cv_ttlt': 0.0,\n",
       "  'median_completion_tokens': 500.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 500.0,\n",
       "  'percentile_99_completion_tokens': 500.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 51.0,\n",
       "  'iqr_prompt_tokens': 0.0,\n",
       "  'percentile_95_prompt_tokens': 51.0,\n",
       "  'percentile_99_prompt_tokens': 51.0,\n",
       "  'cv_prompt_tokens': 0.0,\n",
       "  'average_ttlt': 13.717662200000007,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 1,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 1,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 0.027435324400000013,\n",
       "  'iqr_tbt': 0.0,\n",
       "  'percentile_95_tbt': 0.027435324400000013,\n",
       "  'percentile_99_tbt': 0.027435324400000013,\n",
       "  'cv_tbt': 0.0,\n",
       "  'average_tbt': 0.027435324400000013,\n",
       "  'median_ttft': 13.717662200000007,\n",
       "  'iqr_ttft': 0.0,\n",
       "  'percentile_95_ttft': 13.717662200000007,\n",
       "  'percentile_99_ttft': 13.717662200000007,\n",
       "  'cv_ttft': 0.0,\n",
       "  'average_ttft': 13.717662200000007,\n",
       "  'best_run': {'ttlt': 13.717662200000007,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 51,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-28 21:17:56 EDT'},\n",
       "  'worst_run': {'ttlt': 13.717662200000007,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 51,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-28 21:17:56 EDT'}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_non_streaming.calculate_and_show_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 20:18:03,240 - micro - MainProcess - INFO     Calculating statistics for data: [3.929197500000001] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [3.929197500000001]\n",
      "2024-06-28 20:18:03,245 - micro - MainProcess - INFO     Data converted to numpy array: [3.9291975] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [3.9291975]\n",
      "2024-06-28 20:18:03,252 - micro - MainProcess - INFO     Calculated median: 3.929197500000001 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 3.929197500000001\n",
      "2024-06-28 20:18:03,262 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:03,269 - micro - MainProcess - INFO     Calculated 95th percentile: 3.929197500000001 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 3.929197500000001\n",
      "2024-06-28 20:18:03,276 - micro - MainProcess - INFO     Calculated 99th percentile: 3.929197500000001 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 3.929197500000001\n",
      "2024-06-28 20:18:03,282 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:03,284 - micro - MainProcess - INFO     Result: (3.929197500000001, 0.0, 3.929197500000001, 3.929197500000001, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (3.929197500000001, 0.0, 3.929197500000001, 3.929197500000001, 0.0)\n",
      "2024-06-28 20:18:03,292 - micro - MainProcess - INFO     Calculating statistics for data: [250] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [250]\n",
      "2024-06-28 20:18:03,296 - micro - MainProcess - INFO     Data converted to numpy array: [250] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [250]\n",
      "2024-06-28 20:18:03,303 - micro - MainProcess - INFO     Calculated median: 250.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 250.0\n",
      "2024-06-28 20:18:03,310 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:03,319 - micro - MainProcess - INFO     Calculated 95th percentile: 250.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 250.0\n",
      "2024-06-28 20:18:03,326 - micro - MainProcess - INFO     Calculated 99th percentile: 250.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 250.0\n",
      "2024-06-28 20:18:03,352 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:03,358 - micro - MainProcess - INFO     Result: (250.0, 0.0, 250.0, 250.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (250.0, 0.0, 250.0, 250.0, 0.0)\n",
      "2024-06-28 20:18:03,363 - micro - MainProcess - INFO     Calculating statistics for data: [50] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [50]\n",
      "2024-06-28 20:18:03,368 - micro - MainProcess - INFO     Data converted to numpy array: [50] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [50]\n",
      "2024-06-28 20:18:03,374 - micro - MainProcess - INFO     Calculated median: 50.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 50.0\n",
      "2024-06-28 20:18:03,381 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:03,387 - micro - MainProcess - INFO     Calculated 95th percentile: 50.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 50.0\n",
      "2024-06-28 20:18:03,392 - micro - MainProcess - INFO     Calculated 99th percentile: 50.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 50.0\n",
      "2024-06-28 20:18:03,399 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:03,404 - micro - MainProcess - INFO     Result: (50.0, 0.0, 50.0, 50.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (50.0, 0.0, 50.0, 50.0, 0.0)\n",
      "2024-06-28 20:18:03,408 - micro - MainProcess - INFO     Calculating statistics for data: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 300.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 409.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.89, 1, 1, 1, 1, 1, 1, 1, 1.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 418.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 104.48, 1, 1, 1.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 342.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 300.34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 409.06, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 275.38, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 355.46, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 377.89, 1, 1, 1, 1, 1, 1, 1, 1.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 418.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 104.48, 1, 1, 1.33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "2024-06-28 20:18:03,416 - micro - MainProcess - INFO     Data converted to numpy array: [  1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.   342.88   1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.   300.34   1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.   409.06   1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.   275.38   1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.   355.46\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.   377.89   1.     1.     1.     1.\n",
      "   1.     1.     1.     1.4    1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.   418.4    1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.   310.35   1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.   104.48   1.     1.     1.33   1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.  ] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [  1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.   342.88   1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.   300.34   1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.   409.06   1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.   275.38   1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.   355.46\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.   377.89   1.     1.     1.     1.\n",
      "   1.     1.     1.     1.4    1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.   418.4    1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.   310.35   1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.     1.\n",
      "   1.     1.   104.48   1.     1.     1.33   1.     1.     1.     1.\n",
      "   1.     1.     1.     1.     1.     1.     1.     1.     1.  ]\n",
      "2024-06-28 20:18:03,422 - micro - MainProcess - INFO     Calculated median: 1.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 1.0\n",
      "2024-06-28 20:18:03,428 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:03,433 - micro - MainProcess - INFO     Calculated 95th percentile: 1.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 1.0\n",
      "2024-06-28 20:18:03,442 - micro - MainProcess - INFO     Calculated 99th percentile: 367.12360000000024 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 367.12360000000024\n",
      "2024-06-28 20:18:03,458 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 4.939847130789854 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 4.939847130789854\n",
      "2024-06-28 20:18:03,461 - micro - MainProcess - INFO     Result: (1.0, 0.0, 1.0, 367.12360000000024, 4.939847130789854) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (1.0, 0.0, 1.0, 367.12360000000024, 4.939847130789854)\n",
      "2024-06-28 20:18:03,468 - micro - MainProcess - INFO     Calculating statistics for data: [0.9845120999999999] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.9845120999999999]\n",
      "2024-06-28 20:18:03,472 - micro - MainProcess - INFO     Data converted to numpy array: [0.9845121] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.9845121]\n",
      "2024-06-28 20:18:03,477 - micro - MainProcess - INFO     Calculated median: 0.9845120999999999 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.9845120999999999\n",
      "2024-06-28 20:18:03,482 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:03,489 - micro - MainProcess - INFO     Calculated 95th percentile: 0.9845120999999999 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.9845120999999999\n",
      "2024-06-28 20:18:03,497 - micro - MainProcess - INFO     Calculated 99th percentile: 0.9845120999999999 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.9845120999999999\n",
      "2024-06-28 20:18:03,505 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:03,508 - micro - MainProcess - INFO     Result: (0.9845120999999999, 0.0, 0.9845120999999999, 0.9845120999999999, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.9845120999999999, 0.0, 0.9845120999999999, 0.9845120999999999, 0.0)\n",
      "2024-06-28 20:18:03,515 - micro - MainProcess - INFO     Calculating statistics for data: [9.982378699999998] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [9.982378699999998]\n",
      "2024-06-28 20:18:03,524 - micro - MainProcess - INFO     Data converted to numpy array: [9.9823787] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [9.9823787]\n",
      "2024-06-28 20:18:03,526 - micro - MainProcess - INFO     Calculated median: 9.982378699999998 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 9.982378699999998\n",
      "2024-06-28 20:18:03,535 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:03,541 - micro - MainProcess - INFO     Calculated 95th percentile: 9.982378699999998 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 9.982378699999998\n",
      "2024-06-28 20:18:03,544 - micro - MainProcess - INFO     Calculated 99th percentile: 9.982378699999998 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 9.982378699999998\n",
      "2024-06-28 20:18:03,551 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:03,556 - micro - MainProcess - INFO     Result: (9.982378699999998, 0.0, 9.982378699999998, 9.982378699999998, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (9.982378699999998, 0.0, 9.982378699999998, 9.982378699999998, 0.0)\n",
      "2024-06-28 20:18:03,558 - micro - MainProcess - INFO     Calculating statistics for data: [502] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [502]\n",
      "2024-06-28 20:18:03,565 - micro - MainProcess - INFO     Data converted to numpy array: [502] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [502]\n",
      "2024-06-28 20:18:03,569 - micro - MainProcess - INFO     Calculated median: 502.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 502.0\n",
      "2024-06-28 20:18:03,576 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:03,584 - micro - MainProcess - INFO     Calculated 95th percentile: 502.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 502.0\n",
      "2024-06-28 20:18:03,590 - micro - MainProcess - INFO     Calculated 99th percentile: 502.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 502.0\n",
      "2024-06-28 20:18:03,601 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:03,606 - micro - MainProcess - INFO     Result: (502.0, 0.0, 502.0, 502.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (502.0, 0.0, 502.0, 502.0, 0.0)\n",
      "2024-06-28 20:18:03,609 - micro - MainProcess - INFO     Calculating statistics for data: [50] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [50]\n",
      "2024-06-28 20:18:03,609 - micro - MainProcess - INFO     Data converted to numpy array: [50] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [50]\n",
      "2024-06-28 20:18:03,618 - micro - MainProcess - INFO     Calculated median: 50.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 50.0\n",
      "2024-06-28 20:18:03,625 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:03,625 - micro - MainProcess - INFO     Calculated 95th percentile: 50.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 50.0\n",
      "2024-06-28 20:18:03,639 - micro - MainProcess - INFO     Calculated 99th percentile: 50.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 50.0\n",
      "2024-06-28 20:18:03,645 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:03,651 - micro - MainProcess - INFO     Result: (50.0, 0.0, 50.0, 50.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (50.0, 0.0, 50.0, 50.0, 0.0)\n",
      "2024-06-28 20:18:03,661 - micro - MainProcess - INFO     Calculating statistics for data: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 575.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 613.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 409.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 725.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1023.16, 1, 1, 2.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 407.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 511.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 393.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.45, 1, 1, 1, 1, 1, 1, 1, 1, 1] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 575.48, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 613.81, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 409.13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 307.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 305.54, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 251.98, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 43.89, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 725.22, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1023.16, 1, 1, 2.88, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 406.58, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 407.17, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 511.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 381.47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 359.32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 395.56, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 393.08, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 308.52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 310.66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 301.49, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 42.45, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "2024-06-28 20:18:03,675 - micro - MainProcess - INFO     Data converted to numpy array: [1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 5.75480e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 6.13810e+02 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 4.09130e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 3.07250e+02 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 3.05540e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 2.51980e+02 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 4.38900e+01 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 7.25220e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.02316e+03\n",
      " 1.00000e+00 1.00000e+00 2.88000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 4.06580e+02\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 4.07170e+02 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 5.11520e+02 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 3.81470e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 3.59320e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 3.95560e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 3.93080e+02 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 3.08520e+02 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 3.10660e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 3.01490e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 4.24500e+01 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 5.75480e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 6.13810e+02 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 4.09130e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 3.07250e+02 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 3.05540e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 2.51980e+02 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 4.38900e+01 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 7.25220e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.02316e+03\n",
      " 1.00000e+00 1.00000e+00 2.88000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 4.06580e+02\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 4.07170e+02 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 5.11520e+02 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 3.81470e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 3.59320e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 3.95560e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 3.93080e+02 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 3.08520e+02 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 3.10660e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 3.01490e+02 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 4.24500e+01 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00]\n",
      "2024-06-28 20:18:03,675 - micro - MainProcess - INFO     Calculated median: 1.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 1.0\n",
      "2024-06-28 20:18:03,684 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:03,694 - micro - MainProcess - INFO     Calculated 95th percentile: 1.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 1.0\n",
      "2024-06-28 20:18:03,701 - micro - MainProcess - INFO     Calculated 99th percentile: 411.1777999999981 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 411.1777999999981\n",
      "2024-06-28 20:18:03,708 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 5.2344674060734215 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 5.2344674060734215\n",
      "2024-06-28 20:18:03,708 - micro - MainProcess - INFO     Result: (1.0, 0.0, 1.0, 411.1777999999981, 5.2344674060734215) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (1.0, 0.0, 1.0, 411.1777999999981, 5.2344674060734215)\n",
      "2024-06-28 20:18:03,717 - micro - MainProcess - INFO     Calculating statistics for data: [1.8567186000000007] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [1.8567186000000007]\n",
      "2024-06-28 20:18:03,721 - micro - MainProcess - INFO     Data converted to numpy array: [1.8567186] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [1.8567186]\n",
      "2024-06-28 20:18:03,726 - micro - MainProcess - INFO     Calculated median: 1.8567186000000007 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 1.8567186000000007\n",
      "2024-06-28 20:18:03,726 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 20:18:03,734 - micro - MainProcess - INFO     Calculated 95th percentile: 1.8567186000000007 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 1.8567186000000007\n",
      "2024-06-28 20:18:03,742 - micro - MainProcess - INFO     Calculated 99th percentile: 1.8567186000000007 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 1.8567186000000007\n",
      "2024-06-28 20:18:03,751 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 20:18:03,752 - micro - MainProcess - INFO     Result: (1.8567186000000007, 0.0, 1.8567186000000007, 1.8567186000000007, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (1.8567186000000007, 0.0, 1.8567186000000007, 1.8567186000000007, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------+------------+---------+-------------------+-------------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+--------------------+------------+---------+---------------------+---------------------+--------------------+--------------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|    Model_MaxTokens    | is_Streaming | Iterations | Regions |   Average TTLT    |    Median TTLT    | IQR TTLT | 95th Percentile TTLT | 99th Percentile TTLT | CV TTLT | Median Prompt Tokens | IQR Prompt Tokens | Median Completion Tokens | IQR Completion Tokens | 95th Percentile Completion Tokens | 99th Percentile Completion Tokens | CV Completion Tokens |    Average TBT     | Median TBT | IQR TBT | 95th Percentile TBT | 99th Percentile TBT |    Average TTFT    |    Median TTFT     | IQR TTFT | 95th Percentile TTFT | 99th Percentile TTFT | Error Rate | Error Types | Successful Runs | Unsuccessful Runs | Throttle Count | Throttle Rate |                                                                        Best Run                                                                         |                                                                        Worst Run                                                                        |\n",
      "+-----------------------+--------------+------------+---------+-------------------+-------------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+--------------------+------------+---------+---------------------+---------------------+--------------------+--------------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| gpt-4o-2024-05-13_250 |     True     |     1      |   N/A   | 3.929197500000001 | 3.929197500000001 |   0.0    |  3.929197500000001   |  3.929197500000001   |   0.0   |         50.0         |        0.0        |          250.0           |          0.0          |               250.0               |               250.0               |         0.0          | 12.59024096385542  |    1.0     |   0.0   |         1.0         | 367.12360000000024  | 0.9845120999999999 | 0.9845120999999999 |   0.0    |  0.9845120999999999  |  0.9845120999999999  |    0.0     |     []      |        1        |         0         |       0        |      0.0      | {\"ttlt\": 3.929197500000001, \"completion_tokens\": 250, \"prompt_tokens\": 50, \"region\": \"N/A\", \"utilization\": \"N/A\", \"local_time\": \"2024-06-28 20:17:31 \"} | {\"ttlt\": 3.929197500000001, \"completion_tokens\": 250, \"prompt_tokens\": 50, \"region\": \"N/A\", \"utilization\": \"N/A\", \"local_time\": \"2024-06-28 20:17:31 \"} |\n",
      "| gpt-4o-2024-05-13_500 |     True     |     1      |   N/A   | 9.982378699999998 | 9.982378699999998 |   0.0    |  9.982378699999998   |  9.982378699999998   |   0.0   |         50.0         |        0.0        |          502.0           |          0.0          |               502.0               |               502.0               |         0.0          | 17.142605210420847 |    1.0     |   0.0   |         1.0         |  411.1777999999981  | 1.8567186000000007 | 1.8567186000000007 |   0.0    |  1.8567186000000007  |  1.8567186000000007  |    0.0     |     []      |        1        |         0         |       0        |      0.0      | {\"ttlt\": 9.982378699999998, \"completion_tokens\": 502, \"prompt_tokens\": 50, \"region\": \"N/A\", \"utilization\": \"N/A\", \"local_time\": \"2024-06-28 20:17:36 \"} | {\"ttlt\": 9.982378699999998, \"completion_tokens\": 502, \"prompt_tokens\": 50, \"region\": \"N/A\", \"utilization\": \"N/A\", \"local_time\": \"2024-06-28 20:17:36 \"} |\n",
      "+-----------------------+--------------+------------+---------+-------------------+-------------------+----------+----------------------+----------------------+---------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+--------------------+------------+---------+---------------------+---------------------+--------------------+--------------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_250': {'median_ttlt': 3.929197500000001,\n",
       "  'regions': ['N/A'],\n",
       "  'iqr_ttlt': 0.0,\n",
       "  'percentile_95_ttlt': 3.929197500000001,\n",
       "  'percentile_99_ttlt': 3.929197500000001,\n",
       "  'cv_ttlt': 0.0,\n",
       "  'median_completion_tokens': 250.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 250.0,\n",
       "  'percentile_99_completion_tokens': 250.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 50.0,\n",
       "  'iqr_prompt_tokens': 0.0,\n",
       "  'percentile_95_prompt_tokens': 50.0,\n",
       "  'percentile_99_prompt_tokens': 50.0,\n",
       "  'cv_prompt_tokens': 0.0,\n",
       "  'average_ttlt': 3.929197500000001,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 1,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 1,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 1.0,\n",
       "  'iqr_tbt': 0.0,\n",
       "  'percentile_95_tbt': 1.0,\n",
       "  'percentile_99_tbt': 367.12360000000024,\n",
       "  'cv_tbt': 4.939847130789854,\n",
       "  'average_tbt': 12.59024096385542,\n",
       "  'median_ttft': 0.9845120999999999,\n",
       "  'iqr_ttft': 0.0,\n",
       "  'percentile_95_ttft': 0.9845120999999999,\n",
       "  'percentile_99_ttft': 0.9845120999999999,\n",
       "  'cv_ttft': 0.0,\n",
       "  'average_ttft': 0.9845120999999999,\n",
       "  'best_run': {'ttlt': 3.929197500000001,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': 'N/A',\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-28 20:17:31 '},\n",
       "  'worst_run': {'ttlt': 3.929197500000001,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': 'N/A',\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-28 20:17:31 '}},\n",
       " 'gpt-4o-2024-05-13_500': {'median_ttlt': 9.982378699999998,\n",
       "  'regions': ['N/A'],\n",
       "  'iqr_ttlt': 0.0,\n",
       "  'percentile_95_ttlt': 9.982378699999998,\n",
       "  'percentile_99_ttlt': 9.982378699999998,\n",
       "  'cv_ttlt': 0.0,\n",
       "  'median_completion_tokens': 502.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 502.0,\n",
       "  'percentile_99_completion_tokens': 502.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 50.0,\n",
       "  'iqr_prompt_tokens': 0.0,\n",
       "  'percentile_95_prompt_tokens': 50.0,\n",
       "  'percentile_99_prompt_tokens': 50.0,\n",
       "  'cv_prompt_tokens': 0.0,\n",
       "  'average_ttlt': 9.982378699999998,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 1,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 1,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 1.0,\n",
       "  'iqr_tbt': 0.0,\n",
       "  'percentile_95_tbt': 1.0,\n",
       "  'percentile_99_tbt': 411.1777999999981,\n",
       "  'cv_tbt': 5.2344674060734215,\n",
       "  'average_tbt': 17.142605210420847,\n",
       "  'median_ttft': 1.8567186000000007,\n",
       "  'iqr_ttft': 0.0,\n",
       "  'percentile_95_ttft': 1.8567186000000007,\n",
       "  'percentile_99_ttft': 1.8567186000000007,\n",
       "  'cv_ttft': 0.0,\n",
       "  'average_ttft': 1.8567186000000007,\n",
       "  'best_run': {'ttlt': 9.982378699999998,\n",
       "   'completion_tokens': 502,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': 'N/A',\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-28 20:17:36 '},\n",
       "  'worst_run': {'ttlt': 9.982378699999998,\n",
       "   'completion_tokens': 502,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': 'N/A',\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-28 20:17:36 '}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_streaming.calculate_and_show_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 00:07:18,616 - micro - MainProcess - INFO     Calculating statistics for data: [3.842319500000002, 2.874568400000001, 4.295362899999986, 5.541331700000001, 3.0734312000000017] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [3.842319500000002, 2.874568400000001, 4.295362899999986, 5.541331700000001, 3.0734312000000017]\n",
      "2024-06-28 00:07:18,618 - micro - MainProcess - INFO     Data converted to numpy array: [3.8423195 2.8745684 4.2953629 5.5413317 3.0734312] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [3.8423195 2.8745684 4.2953629 5.5413317 3.0734312]\n",
      "2024-06-28 00:07:18,619 - micro - MainProcess - INFO     Calculated median: 3.842319500000002 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 3.842319500000002\n",
      "2024-06-28 00:07:18,622 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 1.2219316999999847 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 1.2219316999999847\n",
      "2024-06-28 00:07:18,625 - micro - MainProcess - INFO     Calculated 95th percentile: 5.292137939999997 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 5.292137939999997\n",
      "2024-06-28 00:07:18,627 - micro - MainProcess - INFO     Calculated 99th percentile: 5.491492948 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 5.491492948\n",
      "2024-06-28 00:07:18,630 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.2439526636567278 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.2439526636567278\n",
      "2024-06-28 00:07:18,631 - micro - MainProcess - INFO     Result: (3.842319500000002, 1.2219316999999847, 5.292137939999997, 5.491492948, 0.2439526636567278) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (3.842319500000002, 1.2219316999999847, 5.292137939999997, 5.491492948, 0.2439526636567278)\n",
      "2024-06-28 00:07:18,634 - micro - MainProcess - INFO     Calculating statistics for data: [250, 250, 250, 250, 250] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [250, 250, 250, 250, 250]\n",
      "2024-06-28 00:07:18,636 - micro - MainProcess - INFO     Data converted to numpy array: [250 250 250 250 250] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [250 250 250 250 250]\n",
      "2024-06-28 00:07:18,638 - micro - MainProcess - INFO     Calculated median: 250.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 250.0\n",
      "2024-06-28 00:07:18,640 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 00:07:18,643 - micro - MainProcess - INFO     Calculated 95th percentile: 250.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 250.0\n",
      "2024-06-28 00:07:18,647 - micro - MainProcess - INFO     Calculated 99th percentile: 250.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 250.0\n",
      "2024-06-28 00:07:18,652 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 00:07:18,654 - micro - MainProcess - INFO     Result: (250.0, 0.0, 250.0, 250.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (250.0, 0.0, 250.0, 250.0, 0.0)\n",
      "2024-06-28 00:07:18,656 - micro - MainProcess - INFO     Calculating statistics for data: [51, 51, 49, 51, 49] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [51, 51, 49, 51, 49]\n",
      "2024-06-28 00:07:18,657 - micro - MainProcess - INFO     Data converted to numpy array: [51 51 49 51 49] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [51 51 49 51 49]\n",
      "2024-06-28 00:07:18,659 - micro - MainProcess - INFO     Calculated median: 51.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 51.0\n",
      "2024-06-28 00:07:18,662 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 2.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 2.0\n",
      "2024-06-28 00:07:18,664 - micro - MainProcess - INFO     Calculated 95th percentile: 51.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 51.0\n",
      "2024-06-28 00:07:18,668 - micro - MainProcess - INFO     Calculated 99th percentile: 51.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 51.0\n",
      "2024-06-28 00:07:18,673 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.019517846556041257 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.019517846556041257\n",
      "2024-06-28 00:07:18,674 - micro - MainProcess - INFO     Result: (51.0, 2.0, 51.0, 51.0, 0.019517846556041257) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (51.0, 2.0, 51.0, 51.0, 0.019517846556041257)\n",
      "2024-06-28 00:07:18,677 - micro - MainProcess - INFO     Calculating statistics for data: [0.015369278000000009, 0.011498273600000004, 0.017181451599999946, 0.022165326800000003, 0.012293724800000006] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.015369278000000009, 0.011498273600000004, 0.017181451599999946, 0.022165326800000003, 0.012293724800000006]\n",
      "2024-06-28 00:07:18,680 - micro - MainProcess - INFO     Data converted to numpy array: [0.01536928 0.01149827 0.01718145 0.02216533 0.01229372] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.01536928 0.01149827 0.01718145 0.02216533 0.01229372]\n",
      "2024-06-28 00:07:18,687 - micro - MainProcess - INFO     Calculated median: 0.015369278000000009 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.015369278000000009\n",
      "2024-06-28 00:07:18,690 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.00488772679999994 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.00488772679999994\n",
      "2024-06-28 00:07:18,694 - micro - MainProcess - INFO     Calculated 95th percentile: 0.02116855175999999 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.02116855175999999\n",
      "2024-06-28 00:07:18,696 - micro - MainProcess - INFO     Calculated 99th percentile: 0.021965971792 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.021965971792\n",
      "2024-06-28 00:07:18,704 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.24395266365672783 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.24395266365672783\n",
      "2024-06-28 00:07:18,712 - micro - MainProcess - INFO     Result: (0.015369278000000009, 0.00488772679999994, 0.02116855175999999, 0.021965971792, 0.24395266365672783) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.015369278000000009, 0.00488772679999994, 0.02116855175999999, 0.021965971792, 0.24395266365672783)\n",
      "2024-06-28 00:07:18,716 - micro - MainProcess - INFO     Calculating statistics for data: [6.4961682, 7.8651550999999955, 10.773038599999992, 10.883283500000005, 10.919364699999988] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [6.4961682, 7.8651550999999955, 10.773038599999992, 10.883283500000005, 10.919364699999988]\n",
      "2024-06-28 00:07:18,725 - micro - MainProcess - INFO     Data converted to numpy array: [ 6.4961682  7.8651551 10.7730386 10.8832835 10.9193647] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [ 6.4961682  7.8651551 10.7730386 10.8832835 10.9193647]\n",
      "2024-06-28 00:07:18,731 - micro - MainProcess - INFO     Calculated median: 10.773038599999992 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 10.773038599999992\n",
      "2024-06-28 00:07:18,741 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 3.018128400000009 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 3.018128400000009\n",
      "2024-06-28 00:07:18,747 - micro - MainProcess - INFO     Calculated 95th percentile: 10.912148459999992 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 10.912148459999992\n",
      "2024-06-28 00:07:18,749 - micro - MainProcess - INFO     Calculated 99th percentile: 10.91792145199999 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 10.91792145199999\n",
      "2024-06-28 00:07:18,757 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.19746683233805373 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.19746683233805373\n",
      "2024-06-28 00:07:18,761 - micro - MainProcess - INFO     Result: (10.773038599999992, 3.018128400000009, 10.912148459999992, 10.91792145199999, 0.19746683233805373) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (10.773038599999992, 3.018128400000009, 10.912148459999992, 10.91792145199999, 0.19746683233805373)\n",
      "2024-06-28 00:07:18,764 - micro - MainProcess - INFO     Calculating statistics for data: [500, 500, 500, 500, 500] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [500, 500, 500, 500, 500]\n",
      "2024-06-28 00:07:18,767 - micro - MainProcess - INFO     Data converted to numpy array: [500 500 500 500 500] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [500 500 500 500 500]\n",
      "2024-06-28 00:07:18,772 - micro - MainProcess - INFO     Calculated median: 500.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 500.0\n",
      "2024-06-28 00:07:18,777 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-28 00:07:18,781 - micro - MainProcess - INFO     Calculated 95th percentile: 500.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 500.0\n",
      "2024-06-28 00:07:18,784 - micro - MainProcess - INFO     Calculated 99th percentile: 500.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 500.0\n",
      "2024-06-28 00:07:18,789 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-28 00:07:18,792 - micro - MainProcess - INFO     Result: (500.0, 0.0, 500.0, 500.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (500.0, 0.0, 500.0, 500.0, 0.0)\n",
      "2024-06-28 00:07:18,795 - micro - MainProcess - INFO     Calculating statistics for data: [49, 51, 51, 51, 49] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [49, 51, 51, 51, 49]\n",
      "2024-06-28 00:07:18,797 - micro - MainProcess - INFO     Data converted to numpy array: [49 51 51 51 49] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [49 51 51 51 49]\n",
      "2024-06-28 00:07:18,801 - micro - MainProcess - INFO     Calculated median: 51.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 51.0\n",
      "2024-06-28 00:07:18,805 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 2.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 2.0\n",
      "2024-06-28 00:07:18,808 - micro - MainProcess - INFO     Calculated 95th percentile: 51.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 51.0\n",
      "2024-06-28 00:07:18,812 - micro - MainProcess - INFO     Calculated 99th percentile: 51.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 51.0\n",
      "2024-06-28 00:07:18,818 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.019517846556041257 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.019517846556041257\n",
      "2024-06-28 00:07:18,821 - micro - MainProcess - INFO     Result: (51.0, 2.0, 51.0, 51.0, 0.019517846556041257) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (51.0, 2.0, 51.0, 51.0, 0.019517846556041257)\n",
      "2024-06-28 00:07:18,825 - micro - MainProcess - INFO     Calculating statistics for data: [0.012992336399999999, 0.01573031019999999, 0.021546077199999986, 0.021766567000000007, 0.021838729399999975] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.012992336399999999, 0.01573031019999999, 0.021546077199999986, 0.021766567000000007, 0.021838729399999975]\n",
      "2024-06-28 00:07:18,829 - micro - MainProcess - INFO     Data converted to numpy array: [0.01299234 0.01573031 0.02154608 0.02176657 0.02183873] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.01299234 0.01573031 0.02154608 0.02176657 0.02183873]\n",
      "2024-06-28 00:07:18,833 - micro - MainProcess - INFO     Calculated median: 0.021546077199999986 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.021546077199999986\n",
      "2024-06-28 00:07:18,836 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.006036256800000018 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.006036256800000018\n",
      "2024-06-28 00:07:18,839 - micro - MainProcess - INFO     Calculated 95th percentile: 0.021824296919999982 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.021824296919999982\n",
      "2024-06-28 00:07:18,842 - micro - MainProcess - INFO     Calculated 99th percentile: 0.021835842903999977 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.021835842903999977\n",
      "2024-06-28 00:07:18,847 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.19746683233805373 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.19746683233805373\n",
      "2024-06-28 00:07:18,849 - micro - MainProcess - INFO     Result: (0.021546077199999986, 0.006036256800000018, 0.021824296919999982, 0.021835842903999977, 0.19746683233805373) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.021546077199999986, 0.006036256800000018, 0.021824296919999982, 0.021835842903999977, 0.19746683233805373)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------------+-----------+--------------------+--------------------+--------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|    Model_MaxTokens    | Iterations |  Regions  |    Average TTLT    |    Median TTLT     |      IQR TTLT      | 95th Percentile TTLT | 99th Percentile TTLT |       CV TTLT       | Median Prompt Tokens | IQR Prompt Tokens | Median Completion Tokens | IQR Completion Tokens | 95th Percentile Completion Tokens | 99th Percentile Completion Tokens | CV Completion Tokens |     Average TBT      |      Median TBT      |       IQR TBT        | 95th Percentile TBT  | 99th Percentile TBT  | Average TTFT | Median TTFT | IQR TTFT | 95th Percentile TTFT | 99th Percentile TTFT | Error Rate | Error Types | Successful Runs | Unsuccessful Runs | Throttle Count | Throttle Rate |                                                                            Best Run                                                                             |                                                                            Worst Run                                                                             |\n",
      "+-----------------------+------------+-----------+--------------------+--------------------+--------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| gpt-4o-2024-05-13_250 |     5      | East US 2 | 3.9254027399999982 | 3.842319500000002  | 1.2219316999999847 |  5.292137939999997   |     5.491492948      | 0.2439526636567278  |         51.0         |        2.0        |          250.0           |          0.0          |               250.0               |               250.0               |         0.0          | 0.015701610959999994 | 0.015369278000000009 | 0.00488772679999994  | 0.02116855175999999  |    0.021965971792    |              |             |          |                      |                      |    0.0     |     []      |        5        |         0         |       0        |      0.0      | {\"ttlt\": 2.874568400000001, \"completion_tokens\": 250, \"prompt_tokens\": 51, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-28 01:06:01 EDT\"} | {\"ttlt\": 5.541331700000001, \"completion_tokens\": 250, \"prompt_tokens\": 51, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-28 01:06:13 EDT\"}  |\n",
      "| gpt-4o-2024-05-13_500 |     5      | East US 2 | 9.387402019999996  | 10.773038599999992 | 3.018128400000009  |  10.912148459999992  |  10.91792145199999   | 0.19746683233805373 |         51.0         |        2.0        |          500.0           |          0.0          |               500.0               |               500.0               |         0.0          | 0.018774804039999992 | 0.021546077199999986 | 0.006036256800000018 | 0.021824296919999982 | 0.021835842903999977 |              |             |          |                      |                      |    0.0     |     []      |        5        |         0         |       0        |      0.0      |     {\"ttlt\": 6.4961682, \"completion_tokens\": 500, \"prompt_tokens\": 49, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-28 01:06:00 EDT\"}     | {\"ttlt\": 10.919364699999988, \"completion_tokens\": 500, \"prompt_tokens\": 49, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-28 01:06:45 EDT\"} |\n",
      "+-----------------------+------------+-----------+--------------------+--------------------+--------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_250': {'median_ttlt': 3.842319500000002,\n",
       "  'regions': ['East US 2'],\n",
       "  'iqr_ttlt': 1.2219316999999847,\n",
       "  'percentile_95_ttlt': 5.292137939999997,\n",
       "  'percentile_99_ttlt': 5.491492948,\n",
       "  'cv_ttlt': 0.2439526636567278,\n",
       "  'median_completion_tokens': 250.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 250.0,\n",
       "  'percentile_99_completion_tokens': 250.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 51.0,\n",
       "  'iqr_prompt_tokens': 2.0,\n",
       "  'percentile_95_prompt_tokens': 51.0,\n",
       "  'percentile_99_prompt_tokens': 51.0,\n",
       "  'cv_prompt_tokens': 0.019517846556041257,\n",
       "  'average_ttlt': 3.9254027399999982,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 5,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 5,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 0.015369278000000009,\n",
       "  'iqr_tbt': 0.00488772679999994,\n",
       "  'percentile_95_tbt': 0.02116855175999999,\n",
       "  'percentile_99_tbt': 0.021965971792,\n",
       "  'cv_tbt': 0.24395266365672783,\n",
       "  'average_tbt': 0.015701610959999994,\n",
       "  'median_ttft': None,\n",
       "  'iqr_ttft': None,\n",
       "  'percentile_95_ttft': None,\n",
       "  'percentile_99_ttft': None,\n",
       "  'cv_ttft': None,\n",
       "  'average_ttft': None,\n",
       "  'best_run': {'ttlt': 2.874568400000001,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 51,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-28 01:06:01 EDT'},\n",
       "  'worst_run': {'ttlt': 5.541331700000001,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 51,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-28 01:06:13 EDT'}},\n",
       " 'gpt-4o-2024-05-13_500': {'median_ttlt': 10.773038599999992,\n",
       "  'regions': ['East US 2'],\n",
       "  'iqr_ttlt': 3.018128400000009,\n",
       "  'percentile_95_ttlt': 10.912148459999992,\n",
       "  'percentile_99_ttlt': 10.91792145199999,\n",
       "  'cv_ttlt': 0.19746683233805373,\n",
       "  'median_completion_tokens': 500.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 500.0,\n",
       "  'percentile_99_completion_tokens': 500.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 51.0,\n",
       "  'iqr_prompt_tokens': 2.0,\n",
       "  'percentile_95_prompt_tokens': 51.0,\n",
       "  'percentile_99_prompt_tokens': 51.0,\n",
       "  'cv_prompt_tokens': 0.019517846556041257,\n",
       "  'average_ttlt': 9.387402019999996,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 5,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 5,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 0.021546077199999986,\n",
       "  'iqr_tbt': 0.006036256800000018,\n",
       "  'percentile_95_tbt': 0.021824296919999982,\n",
       "  'percentile_99_tbt': 0.021835842903999977,\n",
       "  'cv_tbt': 0.19746683233805373,\n",
       "  'average_tbt': 0.018774804039999992,\n",
       "  'median_ttft': None,\n",
       "  'iqr_ttft': None,\n",
       "  'percentile_95_ttft': None,\n",
       "  'percentile_99_ttft': None,\n",
       "  'cv_ttft': None,\n",
       "  'average_ttft': None,\n",
       "  'best_run': {'ttlt': 6.4961682,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 49,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-28 01:06:00 EDT'},\n",
       "  'worst_run': {'ttlt': 10.919364699999988,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 49,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-28 01:06:45 EDT'}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_non_streaming.calculate_and_show_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning, a subset of artificial intelligence, has revolutionized numerous fields by enabling systems to learn from data and improve their performance over time without being explicitly programmed. This technology leverages algorithms to parse data, learn from it, and make informed decisions. The core idea is to build models that can generalize from specific examples to broader applications.\\n\\nOne of the most significant impacts of machine learning is in the realm of data analysis. Traditional data analysis methods often require manual intervention and are limited by human capacity to'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 22:12:59,804 - micro - MainProcess - INFO     CPU usage: 12.7% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.7%\n",
      "2024-06-27 22:12:59,822 - micro - MainProcess - INFO     RAM usage: 94.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 94.3%\n",
      "2024-06-27 22:12:59,843 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:12:59,845 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:12:59.845862, (GMT): 2024-06-28 03:12:59.845862+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:12:59.845862, (GMT): 2024-06-28 03:12:59.845862+00:00\n",
      "2024-06-27 22:12:59,849 - micro - MainProcess - INFO     CPU usage: 6.9% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 6.9%\n",
      "2024-06-27 22:12:59,862 - micro - MainProcess - INFO     RAM usage: 94.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 94.3%\n",
      "2024-06-27 22:12:59,887 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:12:59,891 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:12:59.890828, (GMT): 2024-06-28 03:12:59.890828+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:12:59.890828, (GMT): 2024-06-28 03:12:59.890828+00:00\n",
      "2024-06-27 22:13:00,321 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 426.36, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 426.36, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:00,349 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 501.44, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 501.44, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:00,625 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 303.89, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 303.89, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:00,850 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' development', 'Token size': 1, 'Time taken (ms)': 224.24, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' development', 'Token size': 1, 'Time taken (ms)': 224.24, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:00,854 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 504.75, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 504.75, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:01,091 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' are', 'Token size': 1, 'Time taken (ms)': 242.19, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' are', 'Token size': 1, 'Time taken (ms)': 242.19, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:01,379 - micro - MainProcess - INFO     {'Count': 5, 'Content': ' be', 'Token size': 1, 'Time taken (ms)': 287.44, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': ' be', 'Token size': 1, 'Time taken (ms)': 287.44, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:01,386 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 532.28, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 532.28, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:01,655 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' computational', 'Token size': 1, 'Time taken (ms)': 275.03, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' computational', 'Token size': 1, 'Time taken (ms)': 275.03, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:01,897 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 511.32, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 511.32, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:01,901 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' programmed', 'Token size': 1, 'Time taken (ms)': 247.32, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' programmed', 'Token size': 1, 'Time taken (ms)': 247.32, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:02,176 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 274.24, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 274.24, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:02,372 - micro - MainProcess - INFO     {'Count': 5, 'Content': ' its', 'Token size': 1, 'Time taken (ms)': 474.96, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': ' its', 'Token size': 1, 'Time taken (ms)': 474.96, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:02,472 - micro - MainProcess - INFO     {'Count': 9, 'Content': ' used', 'Token size': 1, 'Time taken (ms)': 296.24, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': ' used', 'Token size': 1, 'Time taken (ms)': 296.24, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:02,785 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' labeled', 'Token size': 1, 'Time taken (ms)': 312.75, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' labeled', 'Token size': 1, 'Time taken (ms)': 312.75, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:02,834 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' identify', 'Token size': 1, 'Time taken (ms)': 49.27, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' identify', 'Token size': 1, 'Time taken (ms)': 49.27, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:02,851 - micro - MainProcess - INFO     {'Count': 12, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 16.68, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 16.68, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:02,878 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 2.98 seconds or 2982.86 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 2.98 seconds or 2982.86 milliseconds.\n",
      "2024-06-27 22:13:02,941 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:02,981 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 608.74, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 608.74, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:03,035 - micro - MainProcess - INFO     {'Count': 7, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 53.21, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 53.21, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:03,551 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' dataset', 'Token size': 1, 'Time taken (ms)': 517.66, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' dataset', 'Token size': 1, 'Time taken (ms)': 517.66, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:03,602 - micro - MainProcess - INFO     {'Count': 9, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 50.11, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 50.11, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:03,954 - micro - MainProcess - INFO     CPU usage: 20.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 20.5%\n",
      "2024-06-27 22:13:03,968 - micro - MainProcess - INFO     RAM usage: 94.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 94.3%\n",
      "2024-06-27 22:13:04,000 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:04,002 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:04.002970, (GMT): 2024-06-28 03:13:04.002970+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:04.002970, (GMT): 2024-06-28 03:13:04.002970+00:00\n",
      "2024-06-27 22:13:04,053 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 450.86, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 450.86, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:04,325 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 319.17, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 319.17, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:04,745 - micro - MainProcess - INFO     {'Count': 11, 'Content': '.\\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 692.99, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': '.\\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 692.99, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:04,841 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 516.4, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 516.4, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:04,896 - micro - MainProcess - INFO     {'Count': 3, 'Content': 'ized', 'Token size': 1, 'Time taken (ms)': 55.57, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': 'ized', 'Token size': 1, 'Time taken (ms)': 55.57, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:05,153 - micro - MainProcess - INFO     {'Count': 12, 'Content': ' present', 'Token size': 1, 'Time taken (ms)': 406.79, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ' present', 'Token size': 1, 'Time taken (ms)': 406.79, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:05,233 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 336.8, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 336.8, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:05,614 - micro - MainProcess - INFO     {'Count': 5, 'Content': ' technology', 'Token size': 1, 'Time taken (ms)': 381.09, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': ' technology', 'Token size': 1, 'Time taken (ms)': 381.09, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:05,710 - micro - MainProcess - INFO     {'Count': 13, 'Content': ' principal', 'Token size': 1, 'Time taken (ms)': 558.46, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 13, 'Content': ' principal', 'Token size': 1, 'Time taken (ms)': 558.46, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:05,758 - micro - MainProcess - INFO     {'Count': 14, 'Content': ' typical', 'Token size': 1, 'Time taken (ms)': 47.37, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 14, 'Content': ' typical', 'Token size': 1, 'Time taken (ms)': 47.37, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:06,011 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' concepts', 'Token size': 1, 'Time taken (ms)': 396.35, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' concepts', 'Token size': 1, 'Time taken (ms)': 396.35, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:06,174 - micro - MainProcess - INFO     {'Count': 15, 'Content': ' by', 'Token size': 1, 'Time taken (ms)': 415.61, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 15, 'Content': ' by', 'Token size': 1, 'Time taken (ms)': 415.61, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:06,509 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 498.96, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 498.96, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:06,594 - micro - MainProcess - INFO     {'Count': 16, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 419.81, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 16, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 419.81, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:06,882 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' during', 'Token size': 1, 'Time taken (ms)': 372.26, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' during', 'Token size': 1, 'Time taken (ms)': 372.26, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:07,078 - micro - MainProcess - INFO     {'Count': 17, 'Content': ' (', 'Token size': 1, 'Time taken (ms)': 484.7, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 17, 'Content': ' (', 'Token size': 1, 'Time taken (ms)': 484.7, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:07,128 - micro - MainProcess - INFO     {'Count': 18, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 49.3, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 18, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 49.3, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:07,377 - micro - MainProcess - INFO     {'Count': 9, 'Content': ' images', 'Token size': 1, 'Time taken (ms)': 495.59, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': ' images', 'Token size': 1, 'Time taken (ms)': 495.59, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:07,500 - micro - MainProcess - INFO     {'Count': 19, 'Content': ' industries', 'Token size': 1, 'Time taken (ms)': 372.92, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 19, 'Content': ' industries', 'Token size': 1, 'Time taken (ms)': 372.92, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:07,781 - micro - MainProcess - INFO     {'Count': 10, 'Content': 'abeled', 'Token size': 1, 'Time taken (ms)': 403.62, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': 'abeled', 'Token size': 1, 'Time taken (ms)': 403.62, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:07,935 - micro - MainProcess - INFO     {'Count': 20, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 434.28, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 20, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 434.28, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:08,179 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 397.73, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 397.73, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:08,424 - micro - MainProcess - INFO     {'Count': 21, 'Content': ' high', 'Token size': 1, 'Time taken (ms)': 488.67, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 21, 'Content': ' high', 'Token size': 1, 'Time taken (ms)': 488.67, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:08,470 - micro - MainProcess - INFO     {'Count': 22, 'Content': ' for', 'Token size': 1, 'Time taken (ms)': 46.77, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 22, 'Content': ' for', 'Token size': 1, 'Time taken (ms)': 46.77, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:08,556 - micro - MainProcess - INFO     {'Count': 12, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 377.06, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 377.06, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:08,589 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.58 seconds or 4583.76 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.58 seconds or 4583.76 milliseconds.\n",
      "2024-06-27 22:13:08,642 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:08,823 - micro - MainProcess - INFO     {'Count': 23, 'Content': ' management', 'Token size': 1, 'Time taken (ms)': 352.69, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 23, 'Content': ' management', 'Token size': 1, 'Time taken (ms)': 352.69, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:09,129 - micro - MainProcess - INFO     {'Count': 24, 'Content': '**', 'Token size': 1, 'Time taken (ms)': 305.58, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 24, 'Content': '**', 'Token size': 1, 'Time taken (ms)': 305.58, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:09,260 - micro - MainProcess - INFO     {'Count': 25, 'Content': ' based', 'Token size': 1, 'Time taken (ms)': 130.28, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 25, 'Content': ' based', 'Token size': 1, 'Time taken (ms)': 130.28, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:09,294 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.45 seconds or 9446.67 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.45 seconds or 9446.67 milliseconds.\n",
      "2024-06-27 22:13:09,456 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:09,648 - micro - MainProcess - INFO     CPU usage: 15.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 15.8%\n",
      "2024-06-27 22:13:09,688 - micro - MainProcess - INFO     RAM usage: 94.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 94.3%\n",
      "2024-06-27 22:13:09,709 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:09,712 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:09.712534, (GMT): 2024-06-28 03:13:09.712534+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:09.712534, (GMT): 2024-06-28 03:13:09.712534+00:00\n",
      "2024-06-27 22:13:10,050 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 331.96, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 331.96, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:10,461 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 411.97, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 411.97, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:10,467 - micro - MainProcess - INFO     CPU usage: 10.1% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 10.1%\n",
      "2024-06-27 22:13:10,480 - micro - MainProcess - INFO     RAM usage: 94.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 94.3%\n",
      "2024-06-27 22:13:10,504 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:10,508 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:10.508699, (GMT): 2024-06-28 03:13:10.508699+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:10.508699, (GMT): 2024-06-28 03:13:10.508699+00:00\n",
      "2024-06-27 22:13:10,812 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 300.73, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 300.73, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:10,893 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 431.34, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 431.34, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:11,241 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' technology', 'Token size': 1, 'Time taken (ms)': 347.81, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' technology', 'Token size': 1, 'Time taken (ms)': 347.81, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:11,244 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 433.01, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 433.01, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:11,636 - micro - MainProcess - INFO     {'Count': 5, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 394.4, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 394.4, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:11,698 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' development', 'Token size': 1, 'Time taken (ms)': 454.35, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' development', 'Token size': 1, 'Time taken (ms)': 454.35, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:12,175 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' that', 'Token size': 1, 'Time taken (ms)': 539.77, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' that', 'Token size': 1, 'Time taken (ms)': 539.77, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:12,236 - micro - MainProcess - INFO     {'Count': 4, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 536.79, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 536.79, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:12,524 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 348.29, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 348.29, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:12,680 - micro - MainProcess - INFO     {'Count': 5, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 444.38, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 444.38, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:12,974 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 450.98, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 450.98, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:13,089 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' begins', 'Token size': 1, 'Time taken (ms)': 408.81, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' begins', 'Token size': 1, 'Time taken (ms)': 408.81, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:13,366 - micro - MainProcess - INFO     {'Count': 9, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 390.86, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 390.86, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:13,371 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' without', 'Token size': 1, 'Time taken (ms)': 4.64, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' without', 'Token size': 1, 'Time taken (ms)': 4.64, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:13,516 - micro - MainProcess - INFO     {'Count': 7, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 427.19, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 427.19, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:13,788 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' tasks', 'Token size': 1, 'Time taken (ms)': 417.61, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' tasks', 'Token size': 1, 'Time taken (ms)': 417.61, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:13,970 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' applications', 'Token size': 1, 'Time taken (ms)': 453.46, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' applications', 'Token size': 1, 'Time taken (ms)': 453.46, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:14,073 - micro - MainProcess - INFO     {'Count': 12, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 285.21, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 285.21, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:14,102 - micro - MainProcess - INFO     {'Count': 13, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 29.07, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 13, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 29.07, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:14,105 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.39 seconds or 4387.32 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.39 seconds or 4387.32 milliseconds.\n",
      "2024-06-27 22:13:14,170 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:14,336 - micro - MainProcess - INFO     {'Count': 9, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 366.38, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 366.38, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:14,748 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' linear', 'Token size': 1, 'Time taken (ms)': 412.26, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' linear', 'Token size': 1, 'Time taken (ms)': 412.26, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:14,803 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' on', 'Token size': 1, 'Time taken (ms)': 54.87, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' on', 'Token size': 1, 'Time taken (ms)': 54.87, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:15,185 - micro - MainProcess - INFO     CPU usage: 17.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 17.6%\n",
      "2024-06-27 22:13:15,196 - micro - MainProcess - INFO     RAM usage: 94.3% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 94.3%\n",
      "2024-06-27 22:13:15,215 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:15,218 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:15.218357, (GMT): 2024-06-28 03:13:15.218357+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:15.218357, (GMT): 2024-06-28 03:13:15.218357+00:00\n",
      "2024-06-27 22:13:15,387 - micro - MainProcess - INFO     {'Count': 12, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 583.96, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 583.96, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:15,512 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 287.57, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 287.57, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:15,792 - micro - MainProcess - INFO     {'Count': 13, 'Content': 'uper', 'Token size': 1, 'Time taken (ms)': 404.99, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 13, 'Content': 'uper', 'Token size': 1, 'Time taken (ms)': 404.99, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:16,092 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 580.66, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 580.66, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:16,154 - micro - MainProcess - INFO     {'Count': 14, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 361.75, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 14, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 361.75, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:16,404 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 311.6, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 311.6, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:16,576 - micro - MainProcess - INFO     {'Count': 15, 'Content': ' decisions', 'Token size': 1, 'Time taken (ms)': 422.22, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 15, 'Content': ' decisions', 'Token size': 1, 'Time taken (ms)': 422.22, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:16,778 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' from', 'Token size': 1, 'Time taken (ms)': 374.03, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' from', 'Token size': 1, 'Time taken (ms)': 374.03, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:16,914 - micro - MainProcess - INFO     {'Count': 16, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 338.04, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 16, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 338.04, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:17,140 - micro - MainProcess - INFO     {'Count': 5, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 361.06, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 361.06, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:17,290 - micro - MainProcess - INFO     {'Count': 17, 'Content': '.\\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 375.96, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 17, 'Content': '.\\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 375.96, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:17,411 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 272.1, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 272.1, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:17,772 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 361.85, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 361.85, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:17,875 - micro - MainProcess - INFO     {'Count': 18, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 585.13, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 18, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 585.13, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:18,110 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' is', 'Token size': 1, 'Time taken (ms)': 337.19, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' is', 'Token size': 1, 'Time taken (ms)': 337.19, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:18,474 - micro - MainProcess - INFO     {'Count': 9, 'Content': ' improved', 'Token size': 1, 'Time taken (ms)': 363.16, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': ' improved', 'Token size': 1, 'Time taken (ms)': 363.16, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:18,768 - micro - MainProcess - INFO     {'Count': 10, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 294.47, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 294.47, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:18,889 - micro - MainProcess - INFO     {'Count': 19, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1013.82, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 19, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1013.82, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:19,030 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 261.68, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 261.68, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:19,059 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.83 seconds or 3834.88 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.83 seconds or 3834.88 milliseconds.\n",
      "2024-06-27 22:13:19,119 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:19,482 - micro - MainProcess - INFO     {'Count': 20, 'Content': ' experience', 'Token size': 1, 'Time taken (ms)': 592.45, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 20, 'Content': ' experience', 'Token size': 1, 'Time taken (ms)': 592.45, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:19,885 - micro - MainProcess - INFO     {'Count': 21, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 403.21, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 21, 'Content': ' data', 'Token size': 1, 'Time taken (ms)': 403.21, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:19,914 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.4 seconds or 9404.0 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.4 seconds or 9404.0 milliseconds.\n",
      "2024-06-27 22:13:19,967 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:20,120 - micro - MainProcess - INFO     CPU usage: 19.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.6%\n",
      "2024-06-27 22:13:20,131 - micro - MainProcess - INFO     RAM usage: 93.9% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 93.9%\n",
      "2024-06-27 22:13:20,154 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:20,156 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:20.156569, (GMT): 2024-06-28 03:13:20.156569+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 250 at (Local time): 2024-06-27 22:13:20.156569, (GMT): 2024-06-28 03:13:20.156569+00:00\n",
      "2024-06-27 22:13:20,551 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 392.78, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 392.78, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:20,989 - micro - MainProcess - INFO     CPU usage: 25.8% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 25.8%\n",
      "2024-06-27 22:13:21,007 - micro - MainProcess - INFO     RAM usage: 93.0% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 93.0%\n",
      "2024-06-27 22:13:21,040 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:21,043 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:21.043877, (GMT): 2024-06-28 03:13:21.043877+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:21.043877, (GMT): 2024-06-28 03:13:21.043877+00:00\n",
      "2024-06-27 22:13:21,277 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 726.39, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 726.39, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:21,366 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 317.02, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 317.02, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:21,694 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 416.04, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 416.04, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:21,859 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 493.14, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 493.14, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:22,051 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' programming', 'Token size': 1, 'Time taken (ms)': 356.89, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' programming', 'Token size': 1, 'Time taken (ms)': 356.89, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:22,341 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' development', 'Token size': 1, 'Time taken (ms)': 482.6, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' development', 'Token size': 1, 'Time taken (ms)': 482.6, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:22,587 - micro - MainProcess - INFO     {'Count': 5, 'Content': '.\\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 536.17, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': '.\\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 536.17, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:22,806 - micro - MainProcess - INFO     {'Count': 4, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 465.19, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 465.19, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:23,028 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 440.75, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 440.75, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:23,342 - micro - MainProcess - INFO     {'Count': 5, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 535.92, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 535.92, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:23,369 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' applications', 'Token size': 1, 'Time taken (ms)': 342.37, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' applications', 'Token size': 1, 'Time taken (ms)': 342.37, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:23,394 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' goal', 'Token size': 1, 'Time taken (ms)': 51.9, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' goal', 'Token size': 1, 'Time taken (ms)': 51.9, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:23,736 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 342.07, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 342.07, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:23,828 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 457.52, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 457.52, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:24,231 - micro - MainProcess - INFO     {'Count': 8, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 494.4, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 494.4, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:24,282 - micro - MainProcess - INFO     {'Count': 9, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 454.93, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 454.93, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:24,770 - micro - MainProcess - INFO     {'Count': 9, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 539.06, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 539.06, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:24,777 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' neural', 'Token size': 1, 'Time taken (ms)': 494.73, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' neural', 'Token size': 1, 'Time taken (ms)': 494.73, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:24,824 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 53.94, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 53.94, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:25,124 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' technique', 'Token size': 1, 'Time taken (ms)': 346.27, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' technique', 'Token size': 1, 'Time taken (ms)': 346.27, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:25,155 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.0 seconds or 4996.1 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 5.0 seconds or 4996.1 milliseconds.\n",
      "2024-06-27 22:13:25,208 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:25,211 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' applications', 'Token size': 1, 'Time taken (ms)': 387.96, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' applications', 'Token size': 1, 'Time taken (ms)': 387.96, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:25,563 - micro - MainProcess - INFO     {'Count': 12, 'Content': ' images', 'Token size': 1, 'Time taken (ms)': 351.89, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ' images', 'Token size': 1, 'Time taken (ms)': 351.89, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:25,965 - micro - MainProcess - INFO     {'Count': 13, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 401.4, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 13, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 401.4, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:26,306 - micro - MainProcess - INFO     {'Count': 14, 'Content': ' find', 'Token size': 1, 'Time taken (ms)': 341.56, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 14, 'Content': ' find', 'Token size': 1, 'Time taken (ms)': 341.56, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:26,720 - micro - MainProcess - INFO     {'Count': 15, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 413.75, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 15, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 413.75, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:26,773 - micro - MainProcess - INFO     {'Count': 16, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 52.74, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 16, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 52.74, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:27,088 - micro - MainProcess - INFO     {'Count': 17, 'Content': 'ity', 'Token size': 1, 'Time taken (ms)': 314.15, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 17, 'Content': 'ity', 'Token size': 1, 'Time taken (ms)': 314.15, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:27,422 - micro - MainProcess - INFO     {'Count': 18, 'Content': ' interpret', 'Token size': 1, 'Time taken (ms)': 335.55, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 18, 'Content': ' interpret', 'Token size': 1, 'Time taken (ms)': 335.55, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:27,873 - micro - MainProcess - INFO     {'Count': 19, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 450.04, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 19, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 450.04, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:28,372 - micro - MainProcess - INFO     {'Count': 20, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 499.2, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 20, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 499.2, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:28,823 - micro - MainProcess - INFO     {'Count': 21, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 450.56, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 21, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 450.56, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:29,263 - micro - MainProcess - INFO     {'Count': 22, 'Content': ' faces', 'Token size': 1, 'Time taken (ms)': 440.59, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 22, 'Content': ' faces', 'Token size': 1, 'Time taken (ms)': 440.59, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:29,466 - micro - MainProcess - INFO     {'Count': 23, 'Content': ' can', 'Token size': 1, 'Time taken (ms)': 202.79, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 23, 'Content': ' can', 'Token size': 1, 'Time taken (ms)': 202.79, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:29,495 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.45 seconds or 8446.44 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 8.45 seconds or 8446.44 milliseconds.\n",
      "2024-06-27 22:13:29,552 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:30,566 - micro - MainProcess - INFO     CPU usage: 19.6% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 19.6%\n",
      "2024-06-27 22:13:30,579 - micro - MainProcess - INFO     RAM usage: 86.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.8%\n",
      "2024-06-27 22:13:30,607 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:30,609 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:30.609616, (GMT): 2024-06-28 03:13:30.609616+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:30.609616, (GMT): 2024-06-28 03:13:30.609616+00:00\n",
      "2024-06-27 22:13:30,973 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 361.33, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 361.33, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:31,376 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 403.12, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 403.12, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:31,803 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 427.35, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 427.35, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:32,278 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 474.25, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 474.25, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:32,710 - micro - MainProcess - INFO     {'Count': 5, 'Content': ' its', 'Token size': 1, 'Time taken (ms)': 433.11, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': ' its', 'Token size': 1, 'Time taken (ms)': 433.11, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:33,101 - micro - MainProcess - INFO     {'Count': 6, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 390.57, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 390.57, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:33,491 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 389.97, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 389.97, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:33,965 - micro - MainProcess - INFO     {'Count': 8, 'Content': ' are', 'Token size': 1, 'Time taken (ms)': 473.68, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ' are', 'Token size': 1, 'Time taken (ms)': 473.68, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:34,436 - micro - MainProcess - INFO     {'Count': 9, 'Content': ':', 'Token size': 1, 'Time taken (ms)': 470.58, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': ':', 'Token size': 1, 'Time taken (ms)': 470.58, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:34,958 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' that', 'Token size': 1, 'Time taken (ms)': 522.65, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' that', 'Token size': 1, 'Time taken (ms)': 522.65, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:35,006 - micro - MainProcess - INFO     {'Count': 11, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 48.02, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 48.02, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:35,636 - micro - MainProcess - INFO     {'Count': 12, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 629.48, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 629.48, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:36,074 - micro - MainProcess - INFO     {'Count': 13, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 437.75, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 13, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 437.75, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:36,498 - micro - MainProcess - INFO     {'Count': 14, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 424.44, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 14, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 424.44, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:36,983 - micro - MainProcess - INFO     {'Count': 15, 'Content': ' are', 'Token size': 1, 'Time taken (ms)': 484.96, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 15, 'Content': ' are', 'Token size': 1, 'Time taken (ms)': 484.96, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:37,419 - micro - MainProcess - INFO     {'Count': 16, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 435.81, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 16, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 435.81, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:37,955 - micro - MainProcess - INFO     {'Count': 17, 'Content': ' over', 'Token size': 1, 'Time taken (ms)': 536.26, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 17, 'Content': ' over', 'Token size': 1, 'Time taken (ms)': 536.26, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:38,496 - micro - MainProcess - INFO     {'Count': 18, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 540.63, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 18, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 540.63, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:39,107 - micro - MainProcess - INFO     {'Count': 19, 'Content': ' outbreaks', 'Token size': 1, 'Time taken (ms)': 611.61, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 19, 'Content': ' outbreaks', 'Token size': 1, 'Time taken (ms)': 611.61, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:39,561 - micro - MainProcess - INFO     {'Count': 20, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 454.29, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 20, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 454.29, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:39,968 - micro - MainProcess - INFO     {'Count': 21, 'Content': 'ic', 'Token size': 1, 'Time taken (ms)': 406.24, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 21, 'Content': 'ic', 'Token size': 1, 'Time taken (ms)': 406.24, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:40,115 - micro - MainProcess - INFO     {'Count': 22, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 147.57, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 22, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 147.57, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:40,148 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.54 seconds or 9535.73 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 9.54 seconds or 9535.73 milliseconds.\n",
      "2024-06-27 22:13:40,257 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n",
      "2024-06-27 22:13:41,264 - micro - MainProcess - INFO     CPU usage: 12.5% (utils.py:log_system_info:233)\n",
      "INFO:micro:CPU usage: 12.5%\n",
      "2024-06-27 22:13:41,277 - micro - MainProcess - INFO     RAM usage: 86.8% (utils.py:log_system_info:235)\n",
      "INFO:micro:RAM usage: 86.8%\n",
      "2024-06-27 22:13:41,304 - micro - MainProcess - INFO     Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90. (utils.py:detect_model_encoding:81)\n",
      "INFO:micro:Fuzzy match found: 'gpt-4o-2024-05-13' matched to 'gpt-4' with a score of 90.\n",
      "2024-06-27 22:13:41,307 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:41.307750, (GMT): 2024-06-28 03:13:41.307750+00:00 (latencytest.py:make_call:722)\n",
      "INFO:micro:Starting call to model gpt-4o-2024-05-13 with max tokens 500 at (Local time): 2024-06-27 22:13:41.307750, (GMT): 2024-06-28 03:13:41.307750+00:00\n",
      "2024-06-27 22:13:41,673 - micro - MainProcess - INFO     {'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 363.75, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 363.75, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:42,212 - micro - MainProcess - INFO     {'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 538.71, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 2, 'Content': 'Machine', 'Token size': 1, 'Time taken (ms)': 538.71, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:42,769 - micro - MainProcess - INFO     {'Count': 3, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 557.01, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 3, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 557.01, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:43,351 - micro - MainProcess - INFO     {'Count': 4, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 582.38, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 4, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 582.38, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:43,871 - micro - MainProcess - INFO     {'Count': 5, 'Content': ' its', 'Token size': 1, 'Time taken (ms)': 519.65, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 5, 'Content': ' its', 'Token size': 1, 'Time taken (ms)': 519.65, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:45,497 - micro - MainProcess - INFO     {'Count': 6, 'Content': ' is', 'Token size': 1, 'Time taken (ms)': 1625.05, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 6, 'Content': ' is', 'Token size': 1, 'Time taken (ms)': 1625.05, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:46,098 - micro - MainProcess - INFO     {'Count': 7, 'Content': ' steps', 'Token size': 1, 'Time taken (ms)': 602.36, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 7, 'Content': ' steps', 'Token size': 1, 'Time taken (ms)': 602.36, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:46,146 - micro - MainProcess - INFO     {'Count': 8, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 47.98, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 8, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 47.98, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:46,656 - micro - MainProcess - INFO     {'Count': 9, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 509.07, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 9, 'Content': ' learning', 'Token size': 1, 'Time taken (ms)': 509.07, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:47,204 - micro - MainProcess - INFO     {'Count': 10, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 547.95, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 10, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 547.95, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:47,665 - micro - MainProcess - INFO     {'Count': 11, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 461.1, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 11, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 461.1, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:48,250 - micro - MainProcess - INFO     {'Count': 12, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 585.54, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 12, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 585.54, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:48,813 - micro - MainProcess - INFO     {'Count': 13, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 562.89, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 13, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 562.89, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:49,387 - micro - MainProcess - INFO     {'Count': 14, 'Content': ' trees', 'Token size': 1, 'Time taken (ms)': 574.39, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 14, 'Content': ' trees', 'Token size': 1, 'Time taken (ms)': 574.39, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:49,449 - micro - MainProcess - INFO     {'Count': 15, 'Content': ' During', 'Token size': 1, 'Time taken (ms)': 61.47, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 15, 'Content': ' During', 'Token size': 1, 'Time taken (ms)': 61.47, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:49,927 - micro - MainProcess - INFO     {'Count': 16, 'Content': ' patterns', 'Token size': 1, 'Time taken (ms)': 478.2, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 16, 'Content': ' patterns', 'Token size': 1, 'Time taken (ms)': 478.2, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:50,500 - micro - MainProcess - INFO     {'Count': 17, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 572.39, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 17, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 572.39, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:51,125 - micro - MainProcess - INFO     {'Count': 18, 'Content': ' dataset', 'Token size': 1, 'Time taken (ms)': 625.19, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 18, 'Content': ' dataset', 'Token size': 1, 'Time taken (ms)': 625.19, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:51,175 - micro - MainProcess - INFO     {'Count': 19, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 49.44, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 19, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 49.44, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:51,929 - micro - MainProcess - INFO     {'Count': 20, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 754.54, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 20, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 754.54, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:52,388 - micro - MainProcess - INFO     {'Count': 21, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 459.93, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 21, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 459.93, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:52,901 - micro - MainProcess - INFO     {'Count': 22, 'Content': ' categorized', 'Token size': 1, 'Time taken (ms)': 512.98, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 22, 'Content': ' categorized', 'Token size': 1, 'Time taken (ms)': 512.98, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:53,025 - micro - MainProcess - INFO     {'Count': 23, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 123.13, 'utilization': 'NA'} (latencytest.py:make_call:751)\n",
      "INFO:micro:{'Count': 23, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 123.13, 'utilization': 'NA'}\n",
      "2024-06-27 22:13:53,055 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.75 seconds or 11745.29 milliseconds. (latencytest.py:make_call:768)\n",
      "INFO:micro:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 11.75 seconds or 11745.29 milliseconds.\n",
      "2024-06-27 22:13:53,125 - micro - MainProcess - INFO     Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US (utils.py:get_local_time_in_azure_region:148)\n",
      "INFO:micro:Target region None not found, assuming local deployment. \n",
      "                    Machine location during test: Berwyn, US\n"
     ]
    }
   ],
   "source": [
    "await benchmark_streaming.run_latency_benchmark_bulk(deployment_names=[DEPLOYMENT_ID], max_tokens_list=[500,250], iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_100': {'ttlt_successful': [2.6457064],\n",
       "  'ttlt_unsuccessful': [],\n",
       "  'tbt': [336.87],\n",
       "  'ttft': [0.95],\n",
       "  'regions': [None],\n",
       "  'number_of_iterations': 1,\n",
       "  'completion_tokens': [6],\n",
       "  'prompt_tokens': [1008],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 2.6457064,\n",
       "   'completion_tokens': 6,\n",
       "   'prompt_tokens': 1008,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:12:01 '},\n",
       "  'worst_run': {'ttlt': 2.6457064,\n",
       "   'completion_tokens': 6,\n",
       "   'prompt_tokens': 1008,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:12:01 '}},\n",
       " 'gpt-4o-2024-05-13_250': {'ttlt_successful': [2.9828582000000097,\n",
       "   4.583761499999994,\n",
       "   4.387315100000009,\n",
       "   3.834885,\n",
       "   4.996095199999999],\n",
       "  'ttlt_unsuccessful': [],\n",
       "  'tbt': [229.94, 384.68, 337.66, 351.78, 457.21],\n",
       "  'ttft': [8.53, 6.38, 6.64, 5.75, 7.86],\n",
       "  'regions': [None, None, None, None, None],\n",
       "  'number_of_iterations': 5,\n",
       "  'completion_tokens': [12, 12, 13, 11, 11],\n",
       "  'prompt_tokens': [50, 50, 50, 50, 50],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 2.9828582000000097,\n",
       "   'completion_tokens': 12,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:02 '},\n",
       "  'worst_run': {'ttlt': 4.996095199999999,\n",
       "   'completion_tokens': 11,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:25 '}},\n",
       " 'gpt-4o-2024-05-13_500': {'ttlt_successful': [9.446672300000003,\n",
       "   9.403997600000011,\n",
       "   8.446443699999989,\n",
       "   9.535728200000008,\n",
       "   11.745287300000001],\n",
       "  'ttlt_unsuccessful': [],\n",
       "  'tbt': [371.25, 453.65, 368.2, 435.35, 515.97],\n",
       "  'ttft': [10.03, 6.01, 6.34, 7.23, 7.28],\n",
       "  'regions': [None, None, None, None, None],\n",
       "  'number_of_iterations': 5,\n",
       "  'completion_tokens': [25, 21, 23, 22, 23],\n",
       "  'prompt_tokens': [50, 50, 50, 50, 50],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 8.446443699999989,\n",
       "   'completion_tokens': 23,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:29 '},\n",
       "  'worst_run': {'ttlt': 11.745287300000001,\n",
       "   'completion_tokens': 23,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:53 '}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_streaming.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 22:15:06,079 - micro - MainProcess - INFO     Calculating statistics for data: [2.6457064] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [2.6457064]\n",
      "2024-06-27 22:15:06,088 - micro - MainProcess - INFO     Data converted to numpy array: [2.6457064] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [2.6457064]\n",
      "2024-06-27 22:15:06,095 - micro - MainProcess - INFO     Calculated median: 2.6457064 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 2.6457064\n",
      "2024-06-27 22:15:06,102 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 22:15:06,107 - micro - MainProcess - INFO     Calculated 95th percentile: 2.6457064 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 2.6457064\n",
      "2024-06-27 22:15:06,108 - micro - MainProcess - INFO     Calculated 99th percentile: 2.6457064 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 2.6457064\n",
      "2024-06-27 22:15:06,117 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 22:15:06,119 - micro - MainProcess - INFO     Result: (2.6457064, 0.0, 2.6457064, 2.6457064, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (2.6457064, 0.0, 2.6457064, 2.6457064, 0.0)\n",
      "2024-06-27 22:15:06,121 - micro - MainProcess - INFO     Calculating statistics for data: [6] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [6]\n",
      "2024-06-27 22:15:06,123 - micro - MainProcess - INFO     Data converted to numpy array: [6] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [6]\n",
      "2024-06-27 22:15:06,125 - micro - MainProcess - INFO     Calculated median: 6.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 6.0\n",
      "2024-06-27 22:15:06,129 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 22:15:06,132 - micro - MainProcess - INFO     Calculated 95th percentile: 6.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 6.0\n",
      "2024-06-27 22:15:06,133 - micro - MainProcess - INFO     Calculated 99th percentile: 6.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 6.0\n",
      "2024-06-27 22:15:06,136 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 22:15:06,137 - micro - MainProcess - INFO     Result: (6.0, 0.0, 6.0, 6.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (6.0, 0.0, 6.0, 6.0, 0.0)\n",
      "2024-06-27 22:15:06,139 - micro - MainProcess - INFO     Calculating statistics for data: [1008] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [1008]\n",
      "2024-06-27 22:15:06,142 - micro - MainProcess - INFO     Data converted to numpy array: [1008] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [1008]\n",
      "2024-06-27 22:15:06,144 - micro - MainProcess - INFO     Calculated median: 1008.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 1008.0\n",
      "2024-06-27 22:15:06,147 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 22:15:06,149 - micro - MainProcess - INFO     Calculated 95th percentile: 1008.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 1008.0\n",
      "2024-06-27 22:15:06,152 - micro - MainProcess - INFO     Calculated 99th percentile: 1008.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 1008.0\n",
      "2024-06-27 22:15:06,155 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 22:15:06,160 - micro - MainProcess - INFO     Result: (1008.0, 0.0, 1008.0, 1008.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (1008.0, 0.0, 1008.0, 1008.0, 0.0)\n",
      "2024-06-27 22:15:06,176 - micro - MainProcess - INFO     Calculating statistics for data: [336.87] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [336.87]\n",
      "2024-06-27 22:15:06,179 - micro - MainProcess - INFO     Data converted to numpy array: [336.87] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [336.87]\n",
      "2024-06-27 22:15:06,183 - micro - MainProcess - INFO     Calculated median: 336.87 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 336.87\n",
      "2024-06-27 22:15:06,187 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 22:15:06,190 - micro - MainProcess - INFO     Calculated 95th percentile: 336.87 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 336.87\n",
      "2024-06-27 22:15:06,196 - micro - MainProcess - INFO     Calculated 99th percentile: 336.87 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 336.87\n",
      "2024-06-27 22:15:06,200 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 22:15:06,204 - micro - MainProcess - INFO     Result: (336.87, 0.0, 336.87, 336.87, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (336.87, 0.0, 336.87, 336.87, 0.0)\n",
      "2024-06-27 22:15:06,206 - micro - MainProcess - INFO     Calculating statistics for data: [0.95] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.95]\n",
      "2024-06-27 22:15:06,208 - micro - MainProcess - INFO     Data converted to numpy array: [0.95] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.95]\n",
      "2024-06-27 22:15:06,212 - micro - MainProcess - INFO     Calculated median: 0.95 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.95\n",
      "2024-06-27 22:15:06,215 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 22:15:06,219 - micro - MainProcess - INFO     Calculated 95th percentile: 0.95 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.95\n",
      "2024-06-27 22:15:06,221 - micro - MainProcess - INFO     Calculated 99th percentile: 0.95 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.95\n",
      "2024-06-27 22:15:06,226 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 22:15:06,229 - micro - MainProcess - INFO     Result: (0.95, 0.0, 0.95, 0.95, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.95, 0.0, 0.95, 0.95, 0.0)\n",
      "2024-06-27 22:15:06,233 - micro - MainProcess - INFO     Calculating statistics for data: [2.9828582000000097, 4.583761499999994, 4.387315100000009, 3.834885, 4.996095199999999] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [2.9828582000000097, 4.583761499999994, 4.387315100000009, 3.834885, 4.996095199999999]\n",
      "2024-06-27 22:15:06,237 - micro - MainProcess - INFO     Data converted to numpy array: [2.9828582 4.5837615 4.3873151 3.834885  4.9960952] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [2.9828582 4.5837615 4.3873151 3.834885  4.9960952]\n",
      "2024-06-27 22:15:06,241 - micro - MainProcess - INFO     Calculated median: 4.387315100000009 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 4.387315100000009\n",
      "2024-06-27 22:15:06,245 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.7488764999999944 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.7488764999999944\n",
      "2024-06-27 22:15:06,249 - micro - MainProcess - INFO     Calculated 95th percentile: 4.913628459999998 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 4.913628459999998\n",
      "2024-06-27 22:15:06,251 - micro - MainProcess - INFO     Calculated 99th percentile: 4.979601851999999 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 4.979601851999999\n",
      "2024-06-27 22:15:06,254 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.16741315722934866 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.16741315722934866\n",
      "2024-06-27 22:15:06,256 - micro - MainProcess - INFO     Result: (4.387315100000009, 0.7488764999999944, 4.913628459999998, 4.979601851999999, 0.16741315722934866) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (4.387315100000009, 0.7488764999999944, 4.913628459999998, 4.979601851999999, 0.16741315722934866)\n",
      "2024-06-27 22:15:06,258 - micro - MainProcess - INFO     Calculating statistics for data: [12, 12, 13, 11, 11] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [12, 12, 13, 11, 11]\n",
      "2024-06-27 22:15:06,261 - micro - MainProcess - INFO     Data converted to numpy array: [12 12 13 11 11] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [12 12 13 11 11]\n",
      "2024-06-27 22:15:06,263 - micro - MainProcess - INFO     Calculated median: 12.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 12.0\n",
      "2024-06-27 22:15:06,267 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 1.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 1.0\n",
      "2024-06-27 22:15:06,270 - micro - MainProcess - INFO     Calculated 95th percentile: 12.8 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 12.8\n",
      "2024-06-27 22:15:06,273 - micro - MainProcess - INFO     Calculated 99th percentile: 12.96 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 12.96\n",
      "2024-06-27 22:15:06,278 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.06341792180972781 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.06341792180972781\n",
      "2024-06-27 22:15:06,280 - micro - MainProcess - INFO     Result: (12.0, 1.0, 12.8, 12.96, 0.06341792180972781) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (12.0, 1.0, 12.8, 12.96, 0.06341792180972781)\n",
      "2024-06-27 22:15:06,283 - micro - MainProcess - INFO     Calculating statistics for data: [50, 50, 50, 50, 50] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [50, 50, 50, 50, 50]\n",
      "2024-06-27 22:15:06,287 - micro - MainProcess - INFO     Data converted to numpy array: [50 50 50 50 50] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [50 50 50 50 50]\n",
      "2024-06-27 22:15:06,291 - micro - MainProcess - INFO     Calculated median: 50.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 50.0\n",
      "2024-06-27 22:15:06,295 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 22:15:06,300 - micro - MainProcess - INFO     Calculated 95th percentile: 50.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 50.0\n",
      "2024-06-27 22:15:06,303 - micro - MainProcess - INFO     Calculated 99th percentile: 50.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 50.0\n",
      "2024-06-27 22:15:06,307 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 22:15:06,310 - micro - MainProcess - INFO     Result: (50.0, 0.0, 50.0, 50.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (50.0, 0.0, 50.0, 50.0, 0.0)\n",
      "2024-06-27 22:15:06,313 - micro - MainProcess - INFO     Calculating statistics for data: [229.94, 384.68, 337.66, 351.78, 457.21] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [229.94, 384.68, 337.66, 351.78, 457.21]\n",
      "2024-06-27 22:15:06,316 - micro - MainProcess - INFO     Data converted to numpy array: [229.94 384.68 337.66 351.78 457.21] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [229.94 384.68 337.66 351.78 457.21]\n",
      "2024-06-27 22:15:06,322 - micro - MainProcess - INFO     Calculated median: 351.78 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 351.78\n",
      "2024-06-27 22:15:06,326 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 47.01999999999998 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 47.01999999999998\n",
      "2024-06-27 22:15:06,330 - micro - MainProcess - INFO     Calculated 95th percentile: 442.70399999999995 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 442.70399999999995\n",
      "2024-06-27 22:15:06,333 - micro - MainProcess - INFO     Calculated 99th percentile: 454.30879999999996 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 454.30879999999996\n",
      "2024-06-27 22:15:06,339 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.20954226591739528 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.20954226591739528\n",
      "2024-06-27 22:15:06,341 - micro - MainProcess - INFO     Result: (351.78, 47.01999999999998, 442.70399999999995, 454.30879999999996, 0.20954226591739528) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (351.78, 47.01999999999998, 442.70399999999995, 454.30879999999996, 0.20954226591739528)\n",
      "2024-06-27 22:15:06,346 - micro - MainProcess - INFO     Calculating statistics for data: [8.53, 6.38, 6.64, 5.75, 7.86] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [8.53, 6.38, 6.64, 5.75, 7.86]\n",
      "2024-06-27 22:15:06,350 - micro - MainProcess - INFO     Data converted to numpy array: [8.53 6.38 6.64 5.75 7.86] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [8.53 6.38 6.64 5.75 7.86]\n",
      "2024-06-27 22:15:06,353 - micro - MainProcess - INFO     Calculated median: 6.64 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 6.64\n",
      "2024-06-27 22:15:06,357 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 1.4800000000000004 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 1.4800000000000004\n",
      "2024-06-27 22:15:06,360 - micro - MainProcess - INFO     Calculated 95th percentile: 8.395999999999999 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 8.395999999999999\n",
      "2024-06-27 22:15:06,363 - micro - MainProcess - INFO     Calculated 99th percentile: 8.5032 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 8.5032\n",
      "2024-06-27 22:15:06,368 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.14435073684741606 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.14435073684741606\n",
      "2024-06-27 22:15:06,371 - micro - MainProcess - INFO     Result: (6.64, 1.4800000000000004, 8.395999999999999, 8.5032, 0.14435073684741606) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (6.64, 1.4800000000000004, 8.395999999999999, 8.5032, 0.14435073684741606)\n",
      "2024-06-27 22:15:06,379 - micro - MainProcess - INFO     Calculating statistics for data: [9.446672300000003, 9.403997600000011, 8.446443699999989, 9.535728200000008, 11.745287300000001] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [9.446672300000003, 9.403997600000011, 8.446443699999989, 9.535728200000008, 11.745287300000001]\n",
      "2024-06-27 22:15:06,383 - micro - MainProcess - INFO     Data converted to numpy array: [ 9.4466723  9.4039976  8.4464437  9.5357282 11.7452873] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [ 9.4466723  9.4039976  8.4464437  9.5357282 11.7452873]\n",
      "2024-06-27 22:15:06,387 - micro - MainProcess - INFO     Calculated median: 9.446672300000003 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 9.446672300000003\n",
      "2024-06-27 22:15:06,392 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.13173059999999737 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.13173059999999737\n",
      "2024-06-27 22:15:06,395 - micro - MainProcess - INFO     Calculated 95th percentile: 11.303375480000001 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 11.303375480000001\n",
      "2024-06-27 22:15:06,401 - micro - MainProcess - INFO     Calculated 99th percentile: 11.656904936000002 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 11.656904936000002\n",
      "2024-06-27 22:15:06,406 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.11211162708448552 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.11211162708448552\n",
      "2024-06-27 22:15:06,409 - micro - MainProcess - INFO     Result: (9.446672300000003, 0.13173059999999737, 11.303375480000001, 11.656904936000002, 0.11211162708448552) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (9.446672300000003, 0.13173059999999737, 11.303375480000001, 11.656904936000002, 0.11211162708448552)\n",
      "2024-06-27 22:15:06,412 - micro - MainProcess - INFO     Calculating statistics for data: [25, 21, 23, 22, 23] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [25, 21, 23, 22, 23]\n",
      "2024-06-27 22:15:06,415 - micro - MainProcess - INFO     Data converted to numpy array: [25 21 23 22 23] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [25 21 23 22 23]\n",
      "2024-06-27 22:15:06,418 - micro - MainProcess - INFO     Calculated median: 23.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 23.0\n",
      "2024-06-27 22:15:06,422 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 1.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 1.0\n",
      "2024-06-27 22:15:06,425 - micro - MainProcess - INFO     Calculated 95th percentile: 24.6 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 24.6\n",
      "2024-06-27 22:15:06,430 - micro - MainProcess - INFO     Calculated 99th percentile: 24.92 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 24.92\n",
      "2024-06-27 22:15:06,434 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.05818639983079649 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.05818639983079649\n",
      "2024-06-27 22:15:06,437 - micro - MainProcess - INFO     Result: (23.0, 1.0, 24.6, 24.92, 0.05818639983079649) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (23.0, 1.0, 24.6, 24.92, 0.05818639983079649)\n",
      "2024-06-27 22:15:06,441 - micro - MainProcess - INFO     Calculating statistics for data: [50, 50, 50, 50, 50] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [50, 50, 50, 50, 50]\n",
      "2024-06-27 22:15:06,444 - micro - MainProcess - INFO     Data converted to numpy array: [50 50 50 50 50] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [50 50 50 50 50]\n",
      "2024-06-27 22:15:06,449 - micro - MainProcess - INFO     Calculated median: 50.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 50.0\n",
      "2024-06-27 22:15:06,453 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 22:15:06,459 - micro - MainProcess - INFO     Calculated 95th percentile: 50.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 50.0\n",
      "2024-06-27 22:15:06,463 - micro - MainProcess - INFO     Calculated 99th percentile: 50.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 50.0\n",
      "2024-06-27 22:15:06,468 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 22:15:06,471 - micro - MainProcess - INFO     Result: (50.0, 0.0, 50.0, 50.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (50.0, 0.0, 50.0, 50.0, 0.0)\n",
      "2024-06-27 22:15:06,474 - micro - MainProcess - INFO     Calculating statistics for data: [371.25, 453.65, 368.2, 435.35, 515.97] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [371.25, 453.65, 368.2, 435.35, 515.97]\n",
      "2024-06-27 22:15:06,478 - micro - MainProcess - INFO     Data converted to numpy array: [371.25 453.65 368.2  435.35 515.97] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [371.25 453.65 368.2  435.35 515.97]\n",
      "2024-06-27 22:15:06,482 - micro - MainProcess - INFO     Calculated median: 435.35 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 435.35\n",
      "2024-06-27 22:15:06,488 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 82.39999999999998 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 82.39999999999998\n",
      "2024-06-27 22:15:06,492 - micro - MainProcess - INFO     Calculated 95th percentile: 503.50600000000003 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 503.50600000000003\n",
      "2024-06-27 22:15:06,495 - micro - MainProcess - INFO     Calculated 99th percentile: 513.4772 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 513.4772\n",
      "2024-06-27 22:15:06,499 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.12874059805977855 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.12874059805977855\n",
      "2024-06-27 22:15:06,502 - micro - MainProcess - INFO     Result: (435.35, 82.39999999999998, 503.50600000000003, 513.4772, 0.12874059805977855) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (435.35, 82.39999999999998, 503.50600000000003, 513.4772, 0.12874059805977855)\n",
      "2024-06-27 22:15:06,505 - micro - MainProcess - INFO     Calculating statistics for data: [10.03, 6.01, 6.34, 7.23, 7.28] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [10.03, 6.01, 6.34, 7.23, 7.28]\n",
      "2024-06-27 22:15:06,508 - micro - MainProcess - INFO     Data converted to numpy array: [10.03  6.01  6.34  7.23  7.28] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [10.03  6.01  6.34  7.23  7.28]\n",
      "2024-06-27 22:15:06,511 - micro - MainProcess - INFO     Calculated median: 7.23 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 7.23\n",
      "2024-06-27 22:15:06,516 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.9400000000000004 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.9400000000000004\n",
      "2024-06-27 22:15:06,526 - micro - MainProcess - INFO     Calculated 95th percentile: 9.479999999999999 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 9.479999999999999\n",
      "2024-06-27 22:15:06,530 - micro - MainProcess - INFO     Calculated 99th percentile: 9.92 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 9.92\n",
      "2024-06-27 22:15:06,562 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.1918089484018454 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.1918089484018454\n",
      "2024-06-27 22:15:06,568 - micro - MainProcess - INFO     Result: (7.23, 0.9400000000000004, 9.479999999999999, 9.92, 0.1918089484018454) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (7.23, 0.9400000000000004, 9.479999999999999, 9.92, 0.1918089484018454)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------------+---------+-------------------+-------------------+---------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+-------------------+---------------------+---------------------+-------------------+-------------+--------------------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|    Model_MaxTokens    | Iterations | Regions |   Average TTLT    |    Median TTLT    |      IQR TTLT       | 95th Percentile TTLT | 99th Percentile TTLT |       CV TTLT       | Median Prompt Tokens | IQR Prompt Tokens | Median Completion Tokens | IQR Completion Tokens | 95th Percentile Completion Tokens | 99th Percentile Completion Tokens | CV Completion Tokens | Average TBT | Median TBT |      IQR TBT      | 95th Percentile TBT | 99th Percentile TBT |   Average TTFT    | Median TTFT |      IQR TTFT      | 95th Percentile TTFT | 99th Percentile TTFT | Error Rate | Error Types | Successful Runs | Unsuccessful Runs | Throttle Count | Throttle Rate |                                                                        Best Run                                                                        |                                                                       Worst Run                                                                        |\n",
      "+-----------------------+------------+---------+-------------------+-------------------+---------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+-------------------+---------------------+---------------------+-------------------+-------------+--------------------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| gpt-4o-2024-05-13_100 |     1      |   N/A   |     2.6457064     |     2.6457064     |         0.0         |      2.6457064       |      2.6457064       |         0.0         |        1008.0        |        0.0        |           6.0            |          0.0          |                6.0                |                6.0                |         0.0          |   336.87    |   336.87   |        0.0        |       336.87        |       336.87        |       0.95        |    0.95     |        0.0         |         0.95         |         0.95         |    0.0     |     []      |        1        |         0         |       0        |      0.0      |     {\"ttlt\": 2.6457064, \"completion_tokens\": 6, \"prompt_tokens\": 1008, \"region\": null, \"utilization\": \"N/A\", \"local_time\": \"2024-06-27 22:12:01 \"}     |     {\"ttlt\": 2.6457064, \"completion_tokens\": 6, \"prompt_tokens\": 1008, \"region\": null, \"utilization\": \"N/A\", \"local_time\": \"2024-06-27 22:12:01 \"}     |\n",
      "| gpt-4o-2024-05-13_250 |     5      |   N/A   | 4.156983000000002 | 4.387315100000009 | 0.7488764999999944  |  4.913628459999998   |  4.979601851999999   | 0.16741315722934866 |         50.0         |        0.0        |           12.0           |          1.0          |               12.8                |               12.96               | 0.06341792180972781  |   352.254   |   351.78   | 47.01999999999998 | 442.70399999999995  | 454.30879999999996  | 7.032000000000001 |    6.64     | 1.4800000000000004 |  8.395999999999999   |        8.5032        |    0.0     |     []      |        5        |         0         |       0        |      0.0      | {\"ttlt\": 2.9828582000000097, \"completion_tokens\": 12, \"prompt_tokens\": 50, \"region\": null, \"utilization\": \"N/A\", \"local_time\": \"2024-06-27 22:13:02 \"} | {\"ttlt\": 4.996095199999999, \"completion_tokens\": 11, \"prompt_tokens\": 50, \"region\": null, \"utilization\": \"N/A\", \"local_time\": \"2024-06-27 22:13:25 \"}  |\n",
      "| gpt-4o-2024-05-13_500 |     5      |   N/A   | 9.715625820000003 | 9.446672300000003 | 0.13173059999999737 |  11.303375480000001  |  11.656904936000002  | 0.11211162708448552 |         50.0         |        0.0        |           23.0           |          1.0          |               24.6                |               24.92               | 0.05818639983079649  |   428.884   |   435.35   | 82.39999999999998 | 503.50600000000003  |      513.4772       |       7.378       |    7.23     | 0.9400000000000004 |  9.479999999999999   |         9.92         |    0.0     |     []      |        5        |         0         |       0        |      0.0      | {\"ttlt\": 8.446443699999989, \"completion_tokens\": 23, \"prompt_tokens\": 50, \"region\": null, \"utilization\": \"N/A\", \"local_time\": \"2024-06-27 22:13:29 \"}  | {\"ttlt\": 11.745287300000001, \"completion_tokens\": 23, \"prompt_tokens\": 50, \"region\": null, \"utilization\": \"N/A\", \"local_time\": \"2024-06-27 22:13:53 \"} |\n",
      "+-----------------------+------------+---------+-------------------+-------------------+---------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+-------------+------------+-------------------+---------------------+---------------------+-------------------+-------------+--------------------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_100': {'median_ttlt': 2.6457064,\n",
       "  'regions': [None],\n",
       "  'iqr_ttlt': 0.0,\n",
       "  'percentile_95_ttlt': 2.6457064,\n",
       "  'percentile_99_ttlt': 2.6457064,\n",
       "  'cv_ttlt': 0.0,\n",
       "  'median_completion_tokens': 6.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 6.0,\n",
       "  'percentile_99_completion_tokens': 6.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 1008.0,\n",
       "  'iqr_prompt_tokens': 0.0,\n",
       "  'percentile_95_prompt_tokens': 1008.0,\n",
       "  'percentile_99_prompt_tokens': 1008.0,\n",
       "  'cv_prompt_tokens': 0.0,\n",
       "  'average_ttlt': 2.6457064,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 1,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 1,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 336.87,\n",
       "  'iqr_tbt': 0.0,\n",
       "  'percentile_95_tbt': 336.87,\n",
       "  'percentile_99_tbt': 336.87,\n",
       "  'cv_tbt': 0.0,\n",
       "  'average_tbt': 336.87,\n",
       "  'median_ttft': 0.95,\n",
       "  'iqr_ttft': 0.0,\n",
       "  'percentile_95_ttft': 0.95,\n",
       "  'percentile_99_ttft': 0.95,\n",
       "  'cv_ttft': 0.0,\n",
       "  'average_ttft': 0.95,\n",
       "  'best_run': {'ttlt': 2.6457064,\n",
       "   'completion_tokens': 6,\n",
       "   'prompt_tokens': 1008,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:12:01 '},\n",
       "  'worst_run': {'ttlt': 2.6457064,\n",
       "   'completion_tokens': 6,\n",
       "   'prompt_tokens': 1008,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:12:01 '}},\n",
       " 'gpt-4o-2024-05-13_250': {'median_ttlt': 4.387315100000009,\n",
       "  'regions': [None],\n",
       "  'iqr_ttlt': 0.7488764999999944,\n",
       "  'percentile_95_ttlt': 4.913628459999998,\n",
       "  'percentile_99_ttlt': 4.979601851999999,\n",
       "  'cv_ttlt': 0.16741315722934866,\n",
       "  'median_completion_tokens': 12.0,\n",
       "  'iqr_completion_tokens': 1.0,\n",
       "  'percentile_95_completion_tokens': 12.8,\n",
       "  'percentile_99_completion_tokens': 12.96,\n",
       "  'cv_completion_tokens': 0.06341792180972781,\n",
       "  'median_prompt_tokens': 50.0,\n",
       "  'iqr_prompt_tokens': 0.0,\n",
       "  'percentile_95_prompt_tokens': 50.0,\n",
       "  'percentile_99_prompt_tokens': 50.0,\n",
       "  'cv_prompt_tokens': 0.0,\n",
       "  'average_ttlt': 4.156983000000002,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 5,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 5,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 351.78,\n",
       "  'iqr_tbt': 47.01999999999998,\n",
       "  'percentile_95_tbt': 442.70399999999995,\n",
       "  'percentile_99_tbt': 454.30879999999996,\n",
       "  'cv_tbt': 0.20954226591739528,\n",
       "  'average_tbt': 352.254,\n",
       "  'median_ttft': 6.64,\n",
       "  'iqr_ttft': 1.4800000000000004,\n",
       "  'percentile_95_ttft': 8.395999999999999,\n",
       "  'percentile_99_ttft': 8.5032,\n",
       "  'cv_ttft': 0.14435073684741606,\n",
       "  'average_ttft': 7.032000000000001,\n",
       "  'best_run': {'ttlt': 2.9828582000000097,\n",
       "   'completion_tokens': 12,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:02 '},\n",
       "  'worst_run': {'ttlt': 4.996095199999999,\n",
       "   'completion_tokens': 11,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:25 '}},\n",
       " 'gpt-4o-2024-05-13_500': {'median_ttlt': 9.446672300000003,\n",
       "  'regions': [None],\n",
       "  'iqr_ttlt': 0.13173059999999737,\n",
       "  'percentile_95_ttlt': 11.303375480000001,\n",
       "  'percentile_99_ttlt': 11.656904936000002,\n",
       "  'cv_ttlt': 0.11211162708448552,\n",
       "  'median_completion_tokens': 23.0,\n",
       "  'iqr_completion_tokens': 1.0,\n",
       "  'percentile_95_completion_tokens': 24.6,\n",
       "  'percentile_99_completion_tokens': 24.92,\n",
       "  'cv_completion_tokens': 0.05818639983079649,\n",
       "  'median_prompt_tokens': 50.0,\n",
       "  'iqr_prompt_tokens': 0.0,\n",
       "  'percentile_95_prompt_tokens': 50.0,\n",
       "  'percentile_99_prompt_tokens': 50.0,\n",
       "  'cv_prompt_tokens': 0.0,\n",
       "  'average_ttlt': 9.715625820000003,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 5,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 5,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 435.35,\n",
       "  'iqr_tbt': 82.39999999999998,\n",
       "  'percentile_95_tbt': 503.50600000000003,\n",
       "  'percentile_99_tbt': 513.4772,\n",
       "  'cv_tbt': 0.12874059805977855,\n",
       "  'average_tbt': 428.884,\n",
       "  'median_ttft': 7.23,\n",
       "  'iqr_ttft': 0.9400000000000004,\n",
       "  'percentile_95_ttft': 9.479999999999999,\n",
       "  'percentile_99_ttft': 9.92,\n",
       "  'cv_ttft': 0.1918089484018454,\n",
       "  'average_ttft': 7.378,\n",
       "  'best_run': {'ttlt': 8.446443699999989,\n",
       "   'completion_tokens': 23,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:29 '},\n",
       "  'worst_run': {'ttlt': 11.745287300000001,\n",
       "   'completion_tokens': 23,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': None,\n",
       "   'utilization': 'N/A',\n",
       "   'local_time': '2024-06-27 22:13:53 '}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_streaming.calculate_and_show_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_nonstreaming = AzureOpenAIBenchmarkNonStreaming(api_key=OPENAI_API_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=DEPLOYMENT_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 11:44:43,273 - micro - MainProcess - INFO     As no context was provided, 1000 tokens were added as average workloads. (latencytest.py:make_call:602)\n",
      "INFO:micro:As no context was provided, 1000 tokens were added as average workloads.\n",
      "2024-06-27 11:44:43,384 - micro - MainProcess - INFO     Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 1000 (latencytest.py:make_call:625)\n",
      "INFO:micro:Initiating call for Model: gpt-4o-2024-05-13, Max Tokens: 1000\n",
      "2024-06-27 11:45:14,868 - micro - MainProcess - INFO     Succesful Run - Time taken: 31.48 seconds. (latencytest.py:make_call:648)\n",
      "INFO:micro:Succesful Run - Time taken: 31.48 seconds.\n"
     ]
    }
   ],
   "source": [
    "await benchmark_nonstreaming.make_call(deployment_name=DEPLOYMENT_ID, max_tokens=1000)\n",
    "await benchmark_nonstreaming.run_latency_benchmark_bulk(deployment_names=[DEPLOYMENT_ID], max_tokens_list=[1000,500,250], iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_1000': {'ttlt_successful': [31.47952219999999,\n",
       "   18.452650199999994,\n",
       "   23.416592199999968,\n",
       "   45.44973810000005,\n",
       "   14.786188600000003,\n",
       "   26.359097200000008],\n",
       "  'ttlt_unsuccessful': [],\n",
       "  'tbt': [0.03147952219999999,\n",
       "   0.018452650199999993,\n",
       "   0.023416592199999968,\n",
       "   0.045449738100000046,\n",
       "   0.014786188600000003,\n",
       "   0.026359097200000008],\n",
       "  'ttft': [None, None, None, None, None, None],\n",
       "  'regions': ['East US 2',\n",
       "   'East US 2',\n",
       "   'East US 2',\n",
       "   'East US 2',\n",
       "   'East US 2',\n",
       "   'East US 2'],\n",
       "  'number_of_iterations': 6,\n",
       "  'completion_tokens': [1000, 1000, 1000, 1000, 1000, 1000],\n",
       "  'prompt_tokens': [986, 52, 50, 52, 50, 52],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 14.786188600000003,\n",
       "   'completion_tokens': 1000,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:48 EDT'},\n",
       "  'worst_run': {'ttlt': 45.44973810000005,\n",
       "   'completion_tokens': 1000,\n",
       "   'prompt_tokens': 52,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:32 EDT'}},\n",
       " 'gpt-4o-2024-05-13_250': {'ttlt_successful': [6.5350243999999975,\n",
       "   7.10248039999999,\n",
       "   8.431264599999963,\n",
       "   2.9964409000000387,\n",
       "   7.201789399999996],\n",
       "  'ttlt_unsuccessful': [],\n",
       "  'tbt': [0.02614009759999999,\n",
       "   0.02840992159999996,\n",
       "   0.033725058399999855,\n",
       "   0.011985763600000155,\n",
       "   0.028807157599999984],\n",
       "  'ttft': [None, None, None, None, None],\n",
       "  'regions': ['East US 2', 'East US 2', 'East US 2', 'East US 2', 'East US 2'],\n",
       "  'number_of_iterations': 5,\n",
       "  'completion_tokens': [250, 250, 250, 250, 250],\n",
       "  'prompt_tokens': [51, 51, 49, 49, 51],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 2.9964409000000387,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 49,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:46:31 EDT'},\n",
       "  'worst_run': {'ttlt': 8.431264599999963,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 49,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:46:27 EDT'}},\n",
       " 'gpt-4o-2024-05-13_500': {'ttlt_successful': [13.453411500000016,\n",
       "   10.463891999999987,\n",
       "   17.72546410000001,\n",
       "   20.02827719999999,\n",
       "   7.849451299999998],\n",
       "  'ttlt_unsuccessful': [],\n",
       "  'tbt': [0.02690682300000003,\n",
       "   0.020927783999999974,\n",
       "   0.03545092820000002,\n",
       "   0.04005655439999998,\n",
       "   0.0156989026],\n",
       "  'ttft': [None, None, None, None, None],\n",
       "  'regions': ['East US 2', 'East US 2', 'East US 2', 'East US 2', 'East US 2'],\n",
       "  'number_of_iterations': 5,\n",
       "  'completion_tokens': [500, 500, 500, 500, 500],\n",
       "  'prompt_tokens': [49, 51, 51, 51, 51],\n",
       "  'errors': {'count': 0, 'codes': []},\n",
       "  'best_run': {'ttlt': 7.849451299999998,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 51,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:16 EDT'},\n",
       "  'worst_run': {'ttlt': 20.02827719999999,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 51,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:07 EDT'}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_nonstreaming.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 11:48:53,157 - micro - MainProcess - INFO     Calculating statistics for data: [31.47952219999999, 18.452650199999994, 23.416592199999968, 45.44973810000005, 14.786188600000003, 26.359097200000008] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [31.47952219999999, 18.452650199999994, 23.416592199999968, 45.44973810000005, 14.786188600000003, 26.359097200000008]\n",
      "2024-06-27 11:48:53,164 - micro - MainProcess - INFO     Data converted to numpy array: [31.4795222 18.4526502 23.4165922 45.4497381 14.7861886 26.3590972] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [31.4795222 18.4526502 23.4165922 45.4497381 14.7861886 26.3590972]\n",
      "2024-06-27 11:48:53,167 - micro - MainProcess - INFO     Calculated median: 24.887844699999988 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 24.887844699999988\n",
      "2024-06-27 11:48:53,172 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 10.505780250000008 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 10.505780250000008\n",
      "2024-06-27 11:48:53,175 - micro - MainProcess - INFO     Calculated 95th percentile: 41.95718412500003 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 41.95718412500003\n",
      "2024-06-27 11:48:53,177 - micro - MainProcess - INFO     Calculated 99th percentile: 44.75122730500005 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 44.75122730500005\n",
      "2024-06-27 11:48:53,179 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.37364087930274653 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.37364087930274653\n",
      "2024-06-27 11:48:53,182 - micro - MainProcess - INFO     Result: (24.887844699999988, 10.505780250000008, 41.95718412500003, 44.75122730500005, 0.37364087930274653) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (24.887844699999988, 10.505780250000008, 41.95718412500003, 44.75122730500005, 0.37364087930274653)\n",
      "2024-06-27 11:48:53,184 - micro - MainProcess - INFO     Calculating statistics for data: [1000, 1000, 1000, 1000, 1000, 1000] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [1000, 1000, 1000, 1000, 1000, 1000]\n",
      "2024-06-27 11:48:53,186 - micro - MainProcess - INFO     Data converted to numpy array: [1000 1000 1000 1000 1000 1000] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [1000 1000 1000 1000 1000 1000]\n",
      "2024-06-27 11:48:53,188 - micro - MainProcess - INFO     Calculated median: 1000.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 1000.0\n",
      "2024-06-27 11:48:53,191 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 11:48:53,193 - micro - MainProcess - INFO     Calculated 95th percentile: 1000.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 1000.0\n",
      "2024-06-27 11:48:53,195 - micro - MainProcess - INFO     Calculated 99th percentile: 1000.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 1000.0\n",
      "2024-06-27 11:48:53,198 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 11:48:53,200 - micro - MainProcess - INFO     Result: (1000.0, 0.0, 1000.0, 1000.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (1000.0, 0.0, 1000.0, 1000.0, 0.0)\n",
      "2024-06-27 11:48:53,204 - micro - MainProcess - INFO     Calculating statistics for data: [986, 52, 50, 52, 50, 52] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [986, 52, 50, 52, 50, 52]\n",
      "2024-06-27 11:48:53,207 - micro - MainProcess - INFO     Data converted to numpy array: [986  52  50  52  50  52] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [986  52  50  52  50  52]\n",
      "2024-06-27 11:48:53,209 - micro - MainProcess - INFO     Calculated median: 52.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 52.0\n",
      "2024-06-27 11:48:53,212 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 1.5 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 1.5\n",
      "2024-06-27 11:48:53,215 - micro - MainProcess - INFO     Calculated 95th percentile: 752.5 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 752.5\n",
      "2024-06-27 11:48:53,218 - micro - MainProcess - INFO     Calculated 99th percentile: 939.3000000000002 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 939.3000000000002\n",
      "2024-06-27 11:48:53,222 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 1.6829977732662775 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 1.6829977732662775\n",
      "2024-06-27 11:48:53,223 - micro - MainProcess - INFO     Result: (52.0, 1.5, 752.5, 939.3000000000002, 1.6829977732662775) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (52.0, 1.5, 752.5, 939.3000000000002, 1.6829977732662775)\n",
      "2024-06-27 11:48:53,226 - micro - MainProcess - INFO     Calculating statistics for data: [0.03147952219999999, 0.018452650199999993, 0.023416592199999968, 0.045449738100000046, 0.014786188600000003, 0.026359097200000008] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.03147952219999999, 0.018452650199999993, 0.023416592199999968, 0.045449738100000046, 0.014786188600000003, 0.026359097200000008]\n",
      "2024-06-27 11:48:53,228 - micro - MainProcess - INFO     Data converted to numpy array: [0.03147952 0.01845265 0.02341659 0.04544974 0.01478619 0.0263591 ] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.03147952 0.01845265 0.02341659 0.04544974 0.01478619 0.0263591 ]\n",
      "2024-06-27 11:48:53,232 - micro - MainProcess - INFO     Calculated median: 0.024887844699999988 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.024887844699999988\n",
      "2024-06-27 11:48:53,236 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.01050578025000001 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.01050578025000001\n",
      "2024-06-27 11:48:53,241 - micro - MainProcess - INFO     Calculated 95th percentile: 0.04195718412500003 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.04195718412500003\n",
      "2024-06-27 11:48:53,244 - micro - MainProcess - INFO     Calculated 99th percentile: 0.044751227305000044 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.044751227305000044\n",
      "2024-06-27 11:48:53,251 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.3736408793027465 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.3736408793027465\n",
      "2024-06-27 11:48:53,252 - micro - MainProcess - INFO     Result: (0.024887844699999988, 0.01050578025000001, 0.04195718412500003, 0.044751227305000044, 0.3736408793027465) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.024887844699999988, 0.01050578025000001, 0.04195718412500003, 0.044751227305000044, 0.3736408793027465)\n",
      "2024-06-27 11:48:53,255 - micro - MainProcess - INFO     Calculating statistics for data: [6.5350243999999975, 7.10248039999999, 8.431264599999963, 2.9964409000000387, 7.201789399999996] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [6.5350243999999975, 7.10248039999999, 8.431264599999963, 2.9964409000000387, 7.201789399999996]\n",
      "2024-06-27 11:48:53,258 - micro - MainProcess - INFO     Data converted to numpy array: [6.5350244 7.1024804 8.4312646 2.9964409 7.2017894] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [6.5350244 7.1024804 8.4312646 2.9964409 7.2017894]\n",
      "2024-06-27 11:48:53,261 - micro - MainProcess - INFO     Calculated median: 7.10248039999999 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 7.10248039999999\n",
      "2024-06-27 11:48:53,265 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.666764999999998 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.666764999999998\n",
      "2024-06-27 11:48:53,269 - micro - MainProcess - INFO     Calculated 95th percentile: 8.18536955999997 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 8.18536955999997\n",
      "2024-06-27 11:48:53,272 - micro - MainProcess - INFO     Calculated 99th percentile: 8.382085591999964 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 8.382085591999964\n",
      "2024-06-27 11:48:53,277 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.2844681870071126 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.2844681870071126\n",
      "2024-06-27 11:48:53,279 - micro - MainProcess - INFO     Result: (7.10248039999999, 0.666764999999998, 8.18536955999997, 8.382085591999964, 0.2844681870071126) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (7.10248039999999, 0.666764999999998, 8.18536955999997, 8.382085591999964, 0.2844681870071126)\n",
      "2024-06-27 11:48:53,281 - micro - MainProcess - INFO     Calculating statistics for data: [250, 250, 250, 250, 250] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [250, 250, 250, 250, 250]\n",
      "2024-06-27 11:48:53,284 - micro - MainProcess - INFO     Data converted to numpy array: [250 250 250 250 250] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [250 250 250 250 250]\n",
      "2024-06-27 11:48:53,286 - micro - MainProcess - INFO     Calculated median: 250.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 250.0\n",
      "2024-06-27 11:48:53,288 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 11:48:53,294 - micro - MainProcess - INFO     Calculated 95th percentile: 250.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 250.0\n",
      "2024-06-27 11:48:53,298 - micro - MainProcess - INFO     Calculated 99th percentile: 250.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 250.0\n",
      "2024-06-27 11:48:53,301 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 11:48:53,304 - micro - MainProcess - INFO     Result: (250.0, 0.0, 250.0, 250.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (250.0, 0.0, 250.0, 250.0, 0.0)\n",
      "2024-06-27 11:48:53,305 - micro - MainProcess - INFO     Calculating statistics for data: [51, 51, 49, 49, 51] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [51, 51, 49, 49, 51]\n",
      "2024-06-27 11:48:53,309 - micro - MainProcess - INFO     Data converted to numpy array: [51 51 49 49 51] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [51 51 49 49 51]\n",
      "2024-06-27 11:48:53,315 - micro - MainProcess - INFO     Calculated median: 51.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 51.0\n",
      "2024-06-27 11:48:53,318 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 2.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 2.0\n",
      "2024-06-27 11:48:53,321 - micro - MainProcess - INFO     Calculated 95th percentile: 51.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 51.0\n",
      "2024-06-27 11:48:53,324 - micro - MainProcess - INFO     Calculated 99th percentile: 51.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 51.0\n",
      "2024-06-27 11:48:53,328 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.019517846556041257 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.019517846556041257\n",
      "2024-06-27 11:48:53,330 - micro - MainProcess - INFO     Result: (51.0, 2.0, 51.0, 51.0, 0.019517846556041257) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (51.0, 2.0, 51.0, 51.0, 0.019517846556041257)\n",
      "2024-06-27 11:48:53,333 - micro - MainProcess - INFO     Calculating statistics for data: [0.02614009759999999, 0.02840992159999996, 0.033725058399999855, 0.011985763600000155, 0.028807157599999984] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.02614009759999999, 0.02840992159999996, 0.033725058399999855, 0.011985763600000155, 0.028807157599999984]\n",
      "2024-06-27 11:48:53,335 - micro - MainProcess - INFO     Data converted to numpy array: [0.0261401  0.02840992 0.03372506 0.01198576 0.02880716] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.0261401  0.02840992 0.03372506 0.01198576 0.02880716]\n",
      "2024-06-27 11:48:53,338 - micro - MainProcess - INFO     Calculated median: 0.02840992159999996 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.02840992159999996\n",
      "2024-06-27 11:48:53,342 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.002667059999999992 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.002667059999999992\n",
      "2024-06-27 11:48:53,346 - micro - MainProcess - INFO     Calculated 95th percentile: 0.03274147823999988 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.03274147823999988\n",
      "2024-06-27 11:48:53,349 - micro - MainProcess - INFO     Calculated 99th percentile: 0.03352834236799986 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.03352834236799986\n",
      "2024-06-27 11:48:53,352 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.28446818700711257 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.28446818700711257\n",
      "2024-06-27 11:48:53,355 - micro - MainProcess - INFO     Result: (0.02840992159999996, 0.002667059999999992, 0.03274147823999988, 0.03352834236799986, 0.28446818700711257) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.02840992159999996, 0.002667059999999992, 0.03274147823999988, 0.03352834236799986, 0.28446818700711257)\n",
      "2024-06-27 11:48:53,360 - micro - MainProcess - INFO     Calculating statistics for data: [13.453411500000016, 10.463891999999987, 17.72546410000001, 20.02827719999999, 7.849451299999998] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [13.453411500000016, 10.463891999999987, 17.72546410000001, 20.02827719999999, 7.849451299999998]\n",
      "2024-06-27 11:48:53,363 - micro - MainProcess - INFO     Data converted to numpy array: [13.4534115 10.463892  17.7254641 20.0282772  7.8494513] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [13.4534115 10.463892  17.7254641 20.0282772  7.8494513]\n",
      "2024-06-27 11:48:53,368 - micro - MainProcess - INFO     Calculated median: 13.453411500000016 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 13.453411500000016\n",
      "2024-06-27 11:48:53,372 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 7.2615721000000235 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 7.2615721000000235\n",
      "2024-06-27 11:48:53,376 - micro - MainProcess - INFO     Calculated 95th percentile: 19.567714579999993 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 19.567714579999993\n",
      "2024-06-27 11:48:53,379 - micro - MainProcess - INFO     Calculated 99th percentile: 19.93616467599999 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 19.93616467599999\n",
      "2024-06-27 11:48:53,383 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.3229340250559107 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.3229340250559107\n",
      "2024-06-27 11:48:53,387 - micro - MainProcess - INFO     Result: (13.453411500000016, 7.2615721000000235, 19.567714579999993, 19.93616467599999, 0.3229340250559107) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (13.453411500000016, 7.2615721000000235, 19.567714579999993, 19.93616467599999, 0.3229340250559107)\n",
      "2024-06-27 11:48:53,390 - micro - MainProcess - INFO     Calculating statistics for data: [500, 500, 500, 500, 500] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [500, 500, 500, 500, 500]\n",
      "2024-06-27 11:48:53,410 - micro - MainProcess - INFO     Data converted to numpy array: [500 500 500 500 500] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [500 500 500 500 500]\n",
      "2024-06-27 11:48:53,412 - micro - MainProcess - INFO     Calculated median: 500.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 500.0\n",
      "2024-06-27 11:48:53,445 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 11:48:53,472 - micro - MainProcess - INFO     Calculated 95th percentile: 500.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 500.0\n",
      "2024-06-27 11:48:53,476 - micro - MainProcess - INFO     Calculated 99th percentile: 500.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 500.0\n",
      "2024-06-27 11:48:53,481 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.0 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.0\n",
      "2024-06-27 11:48:53,485 - micro - MainProcess - INFO     Result: (500.0, 0.0, 500.0, 500.0, 0.0) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (500.0, 0.0, 500.0, 500.0, 0.0)\n",
      "2024-06-27 11:48:53,489 - micro - MainProcess - INFO     Calculating statistics for data: [49, 51, 51, 51, 51] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [49, 51, 51, 51, 51]\n",
      "2024-06-27 11:48:53,492 - micro - MainProcess - INFO     Data converted to numpy array: [49 51 51 51 51] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [49 51 51 51 51]\n",
      "2024-06-27 11:48:53,496 - micro - MainProcess - INFO     Calculated median: 51.0 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 51.0\n",
      "2024-06-27 11:48:53,500 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.0 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.0\n",
      "2024-06-27 11:48:53,503 - micro - MainProcess - INFO     Calculated 95th percentile: 51.0 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 51.0\n",
      "2024-06-27 11:48:53,508 - micro - MainProcess - INFO     Calculated 99th percentile: 51.0 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 51.0\n",
      "2024-06-27 11:48:53,513 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.015810276679841896 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.015810276679841896\n",
      "2024-06-27 11:48:53,517 - micro - MainProcess - INFO     Result: (51.0, 0.0, 51.0, 51.0, 0.015810276679841896) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (51.0, 0.0, 51.0, 51.0, 0.015810276679841896)\n",
      "2024-06-27 11:48:53,524 - micro - MainProcess - INFO     Calculating statistics for data: [0.02690682300000003, 0.020927783999999974, 0.03545092820000002, 0.04005655439999998, 0.0156989026] (utils.py:calculate_statistics:177)\n",
      "INFO:micro:Calculating statistics for data: [0.02690682300000003, 0.020927783999999974, 0.03545092820000002, 0.04005655439999998, 0.0156989026]\n",
      "2024-06-27 11:48:53,529 - micro - MainProcess - INFO     Data converted to numpy array: [0.02690682 0.02092778 0.03545093 0.04005655 0.0156989 ] (utils.py:calculate_statistics:185)\n",
      "INFO:micro:Data converted to numpy array: [0.02690682 0.02092778 0.03545093 0.04005655 0.0156989 ]\n",
      "2024-06-27 11:48:53,533 - micro - MainProcess - INFO     Calculated median: 0.02690682300000003 (utils.py:calculate_statistics:189)\n",
      "INFO:micro:Calculated median: 0.02690682300000003\n",
      "2024-06-27 11:48:53,539 - micro - MainProcess - INFO     Calculated interquartile range (IQR): 0.01452314420000005 (utils.py:calculate_statistics:193)\n",
      "INFO:micro:Calculated interquartile range (IQR): 0.01452314420000005\n",
      "2024-06-27 11:48:53,545 - micro - MainProcess - INFO     Calculated 95th percentile: 0.039135429159999985 (utils.py:calculate_statistics:197)\n",
      "INFO:micro:Calculated 95th percentile: 0.039135429159999985\n",
      "2024-06-27 11:48:53,548 - micro - MainProcess - INFO     Calculated 99th percentile: 0.03987232935199998 (utils.py:calculate_statistics:201)\n",
      "INFO:micro:Calculated 99th percentile: 0.03987232935199998\n",
      "2024-06-27 11:48:53,552 - micro - MainProcess - INFO     Calculated coefficient of variation (CV): 0.3229340250559106 (utils.py:calculate_statistics:205)\n",
      "INFO:micro:Calculated coefficient of variation (CV): 0.3229340250559106\n",
      "2024-06-27 11:48:53,556 - micro - MainProcess - INFO     Result: (0.02690682300000003, 0.01452314420000005, 0.039135429159999985, 0.03987232935199998, 0.3229340250559106) (utils.py:calculate_statistics:208)\n",
      "INFO:micro:Result: (0.02690682300000003, 0.01452314420000005, 0.039135429159999985, 0.03987232935199998, 0.3229340250559106)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------+-----------+--------------------+--------------------+--------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|    Model_MaxTokens     | Iterations |  Regions  |    Average TTLT    |    Median TTLT     |      IQR TTLT      | 95th Percentile TTLT | 99th Percentile TTLT |       CV TTLT       | Median Prompt Tokens | IQR Prompt Tokens | Median Completion Tokens | IQR Completion Tokens | 95th Percentile Completion Tokens | 99th Percentile Completion Tokens | CV Completion Tokens |     Average TBT      |      Median TBT      |       IQR TBT        | 95th Percentile TBT  | 99th Percentile TBT  | Average TTFT | Median TTFT | IQR TTFT | 95th Percentile TTFT | 99th Percentile TTFT | Error Rate | Error Types | Successful Runs | Unsuccessful Runs | Throttle Count | Throttle Rate |                                                                             Best Run                                                                              |                                                                            Worst Run                                                                             |\n",
      "+------------------------+------------+-----------+--------------------+--------------------+--------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| gpt-4o-2024-05-13_250  |     5      | East US 2 | 6.453399939999997  |  7.10248039999999  | 0.666764999999998  |   8.18536955999997   |  8.382085591999964   | 0.2844681870071126  |         51.0         |        2.0        |          250.0           |          0.0          |               250.0               |               250.0               |         0.0          | 0.02581359975999999  | 0.02840992159999996  | 0.002667059999999992 | 0.03274147823999988  | 0.03352834236799986  |              |             |          |                      |                      |    0.0     |     []      |        5        |         0         |       0        |      0.0      | {\"ttlt\": 2.9964409000000387, \"completion_tokens\": 250, \"prompt_tokens\": 49, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-27 12:46:31 EDT\"}  | {\"ttlt\": 8.431264599999963, \"completion_tokens\": 250, \"prompt_tokens\": 49, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-27 12:46:27 EDT\"}  |\n",
      "| gpt-4o-2024-05-13_500  |     5      | East US 2 |    13.90409922     | 13.453411500000016 | 7.2615721000000235 |  19.567714579999993  |  19.93616467599999   | 0.3229340250559107  |         51.0         |        0.0        |          500.0           |          0.0          |               500.0               |               500.0               |         0.0          | 0.027808198440000004 | 0.02690682300000003  | 0.01452314420000005  | 0.039135429159999985 | 0.03987232935199998  |              |             |          |                      |                      |    0.0     |     []      |        5        |         0         |       0        |      0.0      |  {\"ttlt\": 7.849451299999998, \"completion_tokens\": 500, \"prompt_tokens\": 51, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-27 12:47:16 EDT\"}  | {\"ttlt\": 20.02827719999999, \"completion_tokens\": 500, \"prompt_tokens\": 51, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-27 12:47:07 EDT\"}  |\n",
      "| gpt-4o-2024-05-13_1000 |     6      | East US 2 | 26.657298083333334 | 24.887844699999988 | 10.505780250000008 |  41.95718412500003   |  44.75122730500005   | 0.37364087930274653 |         52.0         |        1.5        |          1000.0          |          0.0          |              1000.0               |              1000.0               |         0.0          | 0.026657298083333336 | 0.024887844699999988 | 0.01050578025000001  | 0.04195718412500003  | 0.044751227305000044 |              |             |          |                      |                      |    0.0     |     []      |        6        |         0         |       0        |      0.0      | {\"ttlt\": 14.786188600000003, \"completion_tokens\": 1000, \"prompt_tokens\": 50, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-27 12:47:48 EDT\"} | {\"ttlt\": 45.44973810000005, \"completion_tokens\": 1000, \"prompt_tokens\": 52, \"region\": \"East US 2\", \"utilization\": \"NA\", \"local_time\": \"2024-06-27 12:47:32 EDT\"} |\n",
      "+------------------------+------------+-----------+--------------------+--------------------+--------------------+----------------------+----------------------+---------------------+----------------------+-------------------+--------------------------+-----------------------+-----------------------------------+-----------------------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+--------------+-------------+----------+----------------------+----------------------+------------+-------------+-----------------+-------------------+----------------+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-05-13_1000': {'median_ttlt': 24.887844699999988,\n",
       "  'regions': ['East US 2'],\n",
       "  'iqr_ttlt': 10.505780250000008,\n",
       "  'percentile_95_ttlt': 41.95718412500003,\n",
       "  'percentile_99_ttlt': 44.75122730500005,\n",
       "  'cv_ttlt': 0.37364087930274653,\n",
       "  'median_completion_tokens': 1000.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 1000.0,\n",
       "  'percentile_99_completion_tokens': 1000.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 52.0,\n",
       "  'iqr_prompt_tokens': 1.5,\n",
       "  'percentile_95_prompt_tokens': 752.5,\n",
       "  'percentile_99_prompt_tokens': 939.3000000000002,\n",
       "  'cv_prompt_tokens': 1.6829977732662775,\n",
       "  'average_ttlt': 26.657298083333334,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 6,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 6,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 0.024887844699999988,\n",
       "  'iqr_tbt': 0.01050578025000001,\n",
       "  'percentile_95_tbt': 0.04195718412500003,\n",
       "  'percentile_99_tbt': 0.044751227305000044,\n",
       "  'cv_tbt': 0.3736408793027465,\n",
       "  'average_tbt': 0.026657298083333336,\n",
       "  'median_ttft': None,\n",
       "  'iqr_ttft': None,\n",
       "  'percentile_95_ttft': None,\n",
       "  'percentile_99_ttft': None,\n",
       "  'cv_ttft': None,\n",
       "  'average_ttft': None,\n",
       "  'best_run': {'ttlt': 14.786188600000003,\n",
       "   'completion_tokens': 1000,\n",
       "   'prompt_tokens': 50,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:48 EDT'},\n",
       "  'worst_run': {'ttlt': 45.44973810000005,\n",
       "   'completion_tokens': 1000,\n",
       "   'prompt_tokens': 52,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:32 EDT'}},\n",
       " 'gpt-4o-2024-05-13_250': {'median_ttlt': 7.10248039999999,\n",
       "  'regions': ['East US 2'],\n",
       "  'iqr_ttlt': 0.666764999999998,\n",
       "  'percentile_95_ttlt': 8.18536955999997,\n",
       "  'percentile_99_ttlt': 8.382085591999964,\n",
       "  'cv_ttlt': 0.2844681870071126,\n",
       "  'median_completion_tokens': 250.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 250.0,\n",
       "  'percentile_99_completion_tokens': 250.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 51.0,\n",
       "  'iqr_prompt_tokens': 2.0,\n",
       "  'percentile_95_prompt_tokens': 51.0,\n",
       "  'percentile_99_prompt_tokens': 51.0,\n",
       "  'cv_prompt_tokens': 0.019517846556041257,\n",
       "  'average_ttlt': 6.453399939999997,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 5,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 5,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 0.02840992159999996,\n",
       "  'iqr_tbt': 0.002667059999999992,\n",
       "  'percentile_95_tbt': 0.03274147823999988,\n",
       "  'percentile_99_tbt': 0.03352834236799986,\n",
       "  'cv_tbt': 0.28446818700711257,\n",
       "  'average_tbt': 0.02581359975999999,\n",
       "  'median_ttft': None,\n",
       "  'iqr_ttft': None,\n",
       "  'percentile_95_ttft': None,\n",
       "  'percentile_99_ttft': None,\n",
       "  'cv_ttft': None,\n",
       "  'average_ttft': None,\n",
       "  'best_run': {'ttlt': 2.9964409000000387,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 49,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:46:31 EDT'},\n",
       "  'worst_run': {'ttlt': 8.431264599999963,\n",
       "   'completion_tokens': 250,\n",
       "   'prompt_tokens': 49,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:46:27 EDT'}},\n",
       " 'gpt-4o-2024-05-13_500': {'median_ttlt': 13.453411500000016,\n",
       "  'regions': ['East US 2'],\n",
       "  'iqr_ttlt': 7.2615721000000235,\n",
       "  'percentile_95_ttlt': 19.567714579999993,\n",
       "  'percentile_99_ttlt': 19.93616467599999,\n",
       "  'cv_ttlt': 0.3229340250559107,\n",
       "  'median_completion_tokens': 500.0,\n",
       "  'iqr_completion_tokens': 0.0,\n",
       "  'percentile_95_completion_tokens': 500.0,\n",
       "  'percentile_99_completion_tokens': 500.0,\n",
       "  'cv_completion_tokens': 0.0,\n",
       "  'median_prompt_tokens': 51.0,\n",
       "  'iqr_prompt_tokens': 0.0,\n",
       "  'percentile_95_prompt_tokens': 51.0,\n",
       "  'percentile_99_prompt_tokens': 51.0,\n",
       "  'cv_prompt_tokens': 0.015810276679841896,\n",
       "  'average_ttlt': 13.90409922,\n",
       "  'error_rate': 0.0,\n",
       "  'number_of_iterations': 5,\n",
       "  'throttle_count': 0,\n",
       "  'throttle_rate': 0.0,\n",
       "  'errors_types': [],\n",
       "  'successful_runs': 5,\n",
       "  'unsuccessful_runs': 0,\n",
       "  'median_tbt': 0.02690682300000003,\n",
       "  'iqr_tbt': 0.01452314420000005,\n",
       "  'percentile_95_tbt': 0.039135429159999985,\n",
       "  'percentile_99_tbt': 0.03987232935199998,\n",
       "  'cv_tbt': 0.3229340250559106,\n",
       "  'average_tbt': 0.027808198440000004,\n",
       "  'median_ttft': None,\n",
       "  'iqr_ttft': None,\n",
       "  'percentile_95_ttft': None,\n",
       "  'percentile_99_ttft': None,\n",
       "  'cv_ttft': None,\n",
       "  'average_ttft': None,\n",
       "  'best_run': {'ttlt': 7.849451299999998,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 51,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:16 EDT'},\n",
       "  'worst_run': {'ttlt': 20.02827719999999,\n",
       "   'completion_tokens': 500,\n",
       "   'prompt_tokens': 51,\n",
       "   'region': 'East US 2',\n",
       "   'utilization': 'NA',\n",
       "   'local_time': '2024-06-27 12:47:07 EDT'}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_nonstreaming.calculate_and_show_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = AzureOpenAIBenchmarkStreaming(api_key=OPENAI_API_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=DEPLOYMENT_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 23:36:50,322 - micro - MainProcess - INFO     Starting call to model gpt-4o-2024-05-13 with max tokens 100 at (Local time): 2024-06-26 23:36:50.322042, (GMT): 2024-06-27 04:36:50.322042+00:00 (latencytest.py:make_call:529)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 971.27}\n",
      "{'Count': 2, 'Content': 'The', 'Token size': 1, 'Time taken (ms)': 787.63}\n",
      "{'Count': 3, 'Content': ' some', 'Token size': 1, 'Time taken (ms)': 1068.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 23:36:54,501 - micro - MainProcess - INFO     Finished call to model gpt-4o-2024-05-13. Time taken for chat: 4.18 seconds or 4178.88 milliseconds. (latencytest.py:make_call:581)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Count': 4, 'Content': ' by', 'Token size': 1, 'Time taken (ms)': 1264.66}\n",
      "{'Count': 5, 'Content': 'qu', 'Token size': 1, 'Time taken (ms)': 54.4}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m benchmark\u001b[38;5;241m.\u001b[39mmake_call(deployment_name\u001b[38;5;241m=\u001b[39mDEPLOYMENT_ID, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\upgrade-llm\\lib\\site-packages\\backoff\\_async.py:151\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m details \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: target,\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m: args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melapsed\u001b[39m\u001b[38;5;124m\"\u001b[39m: elapsed,\n\u001b[0;32m    148\u001b[0m }\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    153\u001b[0m     giveup_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m giveup(e)\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\Desktop\\gbb-ai-upgrade-llm\\src\\performance\\latencytest.py:595\u001b[0m, in \u001b[0;36mAzureOpenAIBenchmarkStreaming.make_call\u001b[1;34m(self, deployment_name, max_tokens, timeout)\u001b[0m\n\u001b[0;32m    589\u001b[0m     TTFT \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(first_token_time \u001b[38;5;241m/\u001b[39m context_tokens_size, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m context_tokens_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    590\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    591\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTBT\u001b[39m\u001b[38;5;124m\"\u001b[39m: TBT,\n\u001b[0;32m    592\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTFT\u001b[39m\u001b[38;5;124m\"\u001b[39m: TTFT,\n\u001b[0;32m    593\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTLT\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mround\u001b[39m(total_time_taken \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    594\u001b[0m     }\n\u001b[1;32m--> 595\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_time_taken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_results(deployment_name, max_tokens, headers, total_time_taken)\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\Desktop\\gbb-ai-upgrade-llm\\src\\performance\\latencytest.py:299\u001b[0m, in \u001b[0;36mAzureOpenAIBenchmarkLatency._store_results\u001b[1;34m(self, deployment_name, max_tokens, headers, time_taken, metrics)\u001b[0m\n\u001b[0;32m    297\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeployment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults:\n\u001b[1;32m--> 299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimes_succesful\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimes_unsucessfull\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregions\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber_of_iterations\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodes\u001b[39m\u001b[38;5;124m\"\u001b[39m: []},\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_run\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    308\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    309\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    310\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    311\u001b[0m         },\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworst_run\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    313\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    314\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    315\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    316\u001b[0m         },\n\u001b[0;32m    317\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTBT\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTFT\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTLT\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    320\u001b[0m     }\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time_taken \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults[key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber_of_iterations\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "await benchmark.make_call(deployment_name=DEPLOYMENT_ID, max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import logging\n",
    "import aiohttp\n",
    "import backoff\n",
    "from datetime import datetime, timezone\n",
    "from tabulate import tabulate\n",
    "import tiktoken\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def _terminal_http_code(e):\n",
    "    return 400 <= e.status < 500\n",
    "\n",
    "MAX_RETRY_ATTEMPTS = 3\n",
    "MAX_TIMEOUT_SECONDS = 60\n",
    "\n",
    "class AzureOpenAIBenchmarkStreaming(AzureOpenAIBenchmarkLatency):\n",
    "    def __init__(self, api_key, azure_endpoint, api_version=\"2024-02-15-preview\"):\n",
    "        \"\"\"\n",
    "        Initialize the AzureOpenAILatencyBenchmark with the API key, API version, and endpoint.\n",
    "        \"\"\"\n",
    "        super().__init__(api_key, azure_endpoint, api_version)\n",
    "        self.api_key = api_key\n",
    "        self.azure_endpoint = azure_endpoint\n",
    "        self.api_version = api_version\n",
    "        self.results = []\n",
    "\n",
    "    @backoff.on_exception(\n",
    "        backoff.expo,\n",
    "        aiohttp.ClientError,\n",
    "        jitter=backoff.full_jitter,\n",
    "        max_tries=MAX_RETRY_ATTEMPTS,\n",
    "        giveup=_terminal_http_code,\n",
    "    )\n",
    "    async def make_call(self, deployment_name, max_tokens, timeout=60):\n",
    "        \"\"\"\n",
    "        Make a chat completion call and print the time taken for the call.\n",
    "        \"\"\"\n",
    "        base_url = self.azure_endpoint\n",
    "        url = f\"{base_url}/openai/deployments/{deployment_name}/chat/completions?api-version={self.api_version}\"\n",
    "        start_phrase = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Give me history of New York\"}\n",
    "        ]\n",
    "        payload = {\n",
    "            \"messages\": start_phrase,\n",
    "            \"stream\": True,\n",
    "            \"max_tokens\": max_tokens\n",
    "        }\n",
    "        headers = {\n",
    "            \"api-key\": self.api_key,\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        logger.info(\n",
    "            f\"Starting call to model {deployment_name} with max tokens {max_tokens} at (Local time): {datetime.now()}, (GMT): {datetime.now(timezone.utc)}\"\n",
    "        )\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            try:\n",
    "                async with session.post(url, headers=headers, json=payload, timeout=timeout) as response:\n",
    "                    response.raise_for_status()\n",
    "                    prev_end_time = start_time  # Initialize prev_end_time to store the previous end_time\n",
    "                    count = 0  # Initialize a counter for chunks\n",
    "                    token_times = []  # List to store times for each token\n",
    "                    first_token_time = None\n",
    "\n",
    "                    async for chunk in response.content.iter_any():\n",
    "                        if chunk:  # filter out keep-alive new lines\n",
    "                            try:\n",
    "                                response_chunk = json.loads(chunk)\n",
    "                            except json.JSONDecodeError:\n",
    "                                # Extract content from the chunk string\n",
    "                                content_match = re.search(r'\"content\":\"(.*?)\"', chunk.decode('utf-8'))\n",
    "                                if content_match:\n",
    "                                    count += 1  # Increment the counter\n",
    "                                    content = content_match.group(1)\n",
    "\n",
    "                                    token_size = num_tokens_from_string(content, \"cl100k_base\")\n",
    "\n",
    "                                    end_time = time.perf_counter()\n",
    "                                    time_taken = (end_time - prev_end_time) * 1000  # Subtract prev_end_time from start_time\n",
    "                                    time_taken = max(time_taken, 1)  # Set a minimum value of 1 ms for time_taken\n",
    "                                    time_taken = round(time_taken, 2)  # Round time_taken to 2 decimal places\n",
    "\n",
    "                                    result = {\"Count\": count, \"Content\": content, \"Token size\": token_size, \"Time taken (ms)\": time_taken}\n",
    "                                    self.results.append(result)\n",
    "\n",
    "                                    # Print the result as it is added to the list\n",
    "                                    print(result)\n",
    "                                    \n",
    "                                    # Record the time for each token\n",
    "                                    token_times.append(time_taken)\n",
    "                                    if first_token_time is None:\n",
    "                                        first_token_time = time_taken\n",
    "\n",
    "                                    prev_end_time = end_time  # Update prev_end_time for the next iteration\n",
    "\n",
    "            except aiohttp.ClientError as e:\n",
    "                logger.error(f\"Error during API call: {str(e)}\")\n",
    "                raise\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        total_time_taken = end_time - start_time\n",
    "\n",
    "        logger.info(\n",
    "            f\"Finished call to model {deployment_name}. Time taken for chat: {round(total_time_taken, 2)} seconds or {round(total_time_taken * 1000, 2)} milliseconds.\"\n",
    "        )\n",
    "\n",
    "        # Calculate TBT and TTFT\n",
    "        if token_times:\n",
    "            TBT = round(sum(token_times[1:]) / (len(token_times) - 1), 2) if len(token_times) > 1 else 0\n",
    "            context_tokens_size = num_tokens_from_string(\"Give me history of New York\", \"cl100k_base\")\n",
    "            TTFT = round(first_token_time / context_tokens_size, 2) if context_tokens_size > 0 else 0\n",
    "            self.results.append({\"Count\": \"TBT\", \"Content\": \"\", \"Token size\": \"\", \"Time taken (ms)\": TBT})\n",
    "            self.results.append({\"Count\": \"TTFT\", \"Content\": \"\", \"Token size\": \"\", \"Time taken (ms)\": TTFT})\n",
    "\n",
    "        # Calculate the cumulative time\n",
    "        cumulative_time = sum(result[\"Time taken (ms)\"] for result in self.results if isinstance(result[\"Time taken (ms)\"], (int, float)))\n",
    "        cumulative_time = round(cumulative_time, 2)  # Round cumulative_time to 2 decimal places\n",
    "\n",
    "        # Add the cumulative time to the results list as an extra row\n",
    "        self.results.append({\"Count\": \"TTLT\", \"Content\": \"\", \"Token size\": \"\", \"Time taken (ms)\": cumulative_time})\n",
    "\n",
    "        # Display results in tabular form\n",
    "        print(\"\\nResults Table:\")\n",
    "        print(tabulate([result.values() for result in self.results], headers=self.results[0].keys(), tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the environment variables using os.getenv\n",
    "OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_API_ENDPOINT\")\n",
    "DEPLOYMENT_ID = os.getenv(\"AZURE_AOAI_CHAT_MODEL_NAME_DEPLOYMENT_ID\")\n",
    "DEPLOYMENT_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:  \n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"  \n",
    "    encoding = tiktoken.get_encoding(encoding_name)  \n",
    "    num_tokens = len(encoding.encode(string))  \n",
    "    return num_tokens  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin:openai.ChatCompletion.create\n",
      "END:openai.ChatCompletion.create\n",
      "Time taken: 3.7182253000000856 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "url = AZURE_OPENAI_ENDPOINT + \"/openai/deployments/\" + DEPLOYMENT_ID + \"/chat/completions?api-version=2023-05-15\"\n",
    "start_phrase = [{\"role\":\"system\",\"content\":\"You are an AI assistant that helps people find information.\"},\n",
    "                {\"role\":\"user\",\"content\":\"Write 5000 word essay on soccer\"}]\n",
    "payload = {        \n",
    "    \"messages\":start_phrase,\n",
    "    #\"stream\":True,\n",
    "    \"max_tokens\":200\n",
    "    }\n",
    "\n",
    "headers = {  \n",
    "    \"api-key\": OPENAI_API_KEY,  \n",
    "    \"Content-Type\": \"application/json\"  \n",
    "} \n",
    "print(\"Begin:openai.ChatCompletion.create\")\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "try:  \n",
    "    r = requests.post(url,  \n",
    "                      headers=headers,  \n",
    "                      json=payload,  \n",
    "                      timeout=10  \n",
    "                      )  \n",
    "except requests.exceptions.Timeout:  \n",
    "    print(\"The request has timed out. Please try again.\")  \n",
    "    \n",
    "print(\"END:openai.ChatCompletion.create\")\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin:openai.ChatCompletion.create\n",
      "{'Count': 1, 'Content': 'Sure', 'Token size': 1, 'Time taken (ms)': 709.08}\n",
      "{'Count': 2, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1.58}\n",
      "{'Count': 3, 'Content': ' here', 'Token size': 1, 'Time taken (ms)': 1.95}\n",
      "{'Count': 4, 'Content': ' is', 'Token size': 1, 'Time taken (ms)': 1.21}\n",
      "{'Count': 5, 'Content': ' an', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 6, 'Content': ' essay', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 7, 'Content': ' on', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 8, 'Content': ' soccer', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 9, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 10, 'Content': ' Due', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 11, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 12, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 13, 'Content': ' platform', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 14, 'Content': \"'s\", 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 15, 'Content': ' constraints', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 16, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 17, 'Content': ' I', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 18, 'Content': \" can't\", 'Token size': 2, 'Time taken (ms)': 1}\n",
      "{'Count': 19, 'Content': ' provide', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 20, 'Content': ' a', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 21, 'Content': ' full', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 22, 'Content': ' ', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 23, 'Content': '500', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 24, 'Content': '0', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 25, 'Content': ' words', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 26, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 27, 'Content': ' one', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 28, 'Content': ' go', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 29, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 30, 'Content': ' but', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 31, 'Content': \" I'll\", 'Token size': 2, 'Time taken (ms)': 1.0}\n",
      "{'Count': 32, 'Content': ' give', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 33, 'Content': ' you', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 34, 'Content': ' a', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 35, 'Content': ' sizeable', 'Token size': 2, 'Time taken (ms)': 3.0}\n",
      "{'Count': 36, 'Content': ' portion', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 37, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 640.83}\n",
      "{'Count': 38, 'Content': ' get', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 39, 'Content': ' started', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 40, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 41, 'Content': ' \\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 1}\n",
      "{'Count': 42, 'Content': '---\\\\n\\\\n', 'Token size': 4, 'Time taken (ms)': 6.95}\n",
      "{'Count': 43, 'Content': '###', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 44, 'Content': ' The', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 45, 'Content': ' Global', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 46, 'Content': ' Phen', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 47, 'Content': 'omen', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 48, 'Content': 'on', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 49, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 50, 'Content': ' Soccer', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 51, 'Content': '\\\\n\\\\n', 'Token size': 2, 'Time taken (ms)': 1.02}\n",
      "{'Count': 52, 'Content': '####', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 53, 'Content': ' Introduction', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 54, 'Content': '\\\\n\\\\n', 'Token size': 2, 'Time taken (ms)': 1}\n",
      "{'Count': 55, 'Content': 'Soc', 'Token size': 2, 'Time taken (ms)': 1}\n",
      "{'Count': 56, 'Content': 'cer', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 57, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1.57}\n",
      "{'Count': 58, 'Content': ' known', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 59, 'Content': ' as', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 60, 'Content': ' football', 'Token size': 1, 'Time taken (ms)': 1.07}\n",
      "{'Count': 61, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 62, 'Content': ' most', 'Token size': 1, 'Time taken (ms)': 1.08}\n",
      "{'Count': 63, 'Content': ' countries', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 64, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 65, 'Content': ' stands', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 66, 'Content': ' as', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 67, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 68, 'Content': ' world', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 69, 'Content': '’s', 'Token size': 1, 'Time taken (ms)': 1.07}\n",
      "{'Count': 70, 'Content': ' most', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 71, 'Content': ' popular', 'Token size': 1, 'Time taken (ms)': 472.87}\n",
      "{'Count': 72, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 73, 'Content': ' beloved', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 74, 'Content': ' sport', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 75, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 76, 'Content': ' Its', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 77, 'Content': ' simplicity', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 78, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 79, 'Content': ' accessibility', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 80, 'Content': ' have', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 81, 'Content': ' allowed', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 82, 'Content': ' it', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 83, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 84, 'Content': ' transcend', 'Token size': 1, 'Time taken (ms)': 2.0}\n",
      "{'Count': 85, 'Content': ' cultural', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 86, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 87, 'Content': ' economic', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 88, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 89, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 90, 'Content': ' geographical', 'Token size': 1, 'Time taken (ms)': 1.51}\n",
      "{'Count': 91, 'Content': ' barriers', 'Token size': 1, 'Time taken (ms)': 1.02}\n",
      "{'Count': 92, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 1.01}\n",
      "{'Count': 93, 'Content': ' Whether', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 94, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 95, 'Content': ' urban', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 96, 'Content': ' meg', 'Token size': 1, 'Time taken (ms)': 986.48}\n",
      "{'Count': 97, 'Content': 'ac', 'Token size': 1, 'Time taken (ms)': 1.01}\n",
      "{'Count': 98, 'Content': 'ities', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 99, 'Content': ' or', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 100, 'Content': ' rural', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 101, 'Content': ' communities', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 102, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 103, 'Content': ' soccer', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 104, 'Content': ' has', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 105, 'Content': ' established', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 106, 'Content': ' itself', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 107, 'Content': ' as', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 108, 'Content': ' not', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 109, 'Content': ' merely', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 110, 'Content': ' a', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 111, 'Content': ' sport', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 112, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 113, 'Content': ' but', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 114, 'Content': ' a', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 115, 'Content': ' significant', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 116, 'Content': ' cultural', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 117, 'Content': ' force', 'Token size': 1, 'Time taken (ms)': 1.03}\n",
      "{'Count': 118, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 119, 'Content': ' This', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 120, 'Content': ' essay', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 121, 'Content': ' del', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 122, 'Content': 'ves', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 123, 'Content': ' into', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 124, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 125, 'Content': ' intric', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 126, 'Content': 'acies', 'Token size': 1, 'Time taken (ms)': 618.69}\n",
      "{'Count': 127, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 128, 'Content': ' soccer', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 129, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 130, 'Content': ' its', 'Token size': 1, 'Time taken (ms)': 1.0}\n",
      "{'Count': 131, 'Content': ' history', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 132, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 133, 'Content': ' global', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 134, 'Content': ' influence', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 135, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 136, 'Content': ' economic', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 137, 'Content': ' impact', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 138, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 139, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 140, 'Content': ' social', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 141, 'Content': ' significance', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 142, 'Content': '.\\\\n\\\\n', 'Token size': 3, 'Time taken (ms)': 1}\n",
      "{'Count': 143, 'Content': '####', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 144, 'Content': ' History', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 145, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 146, 'Content': ' Soccer', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 147, 'Content': '\\\\n\\\\n', 'Token size': 2, 'Time taken (ms)': 1}\n",
      "{'Count': 148, 'Content': 'The', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 149, 'Content': ' origins', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 150, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 151, 'Content': ' soccer', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 152, 'Content': ' can', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 153, 'Content': ' be', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 154, 'Content': ' traced', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 155, 'Content': ' back', 'Token size': 1, 'Time taken (ms)': 612.13}\n",
      "{'Count': 156, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 1.4}\n",
      "{'Count': 157, 'Content': ' ancient', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 158, 'Content': ' civilizations', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 159, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 160, 'Content': ' with', 'Token size': 1, 'Time taken (ms)': 1.11}\n",
      "{'Count': 161, 'Content': ' early', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 162, 'Content': ' forms', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 163, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 164, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 165, 'Content': ' game', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 166, 'Content': ' appearing', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 167, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 168, 'Content': ' China', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 169, 'Content': ' during', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 170, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 171, 'Content': ' Han', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 172, 'Content': ' Dynasty', 'Token size': 1, 'Time taken (ms)': 8.96}\n",
      "{'Count': 173, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 174, 'Content': ' Greece', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 175, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1.02}\n",
      "{'Count': 176, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 177, 'Content': ' Rome', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 178, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 179, 'Content': ' However', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 180, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 181, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 182, 'Content': ' modern', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 183, 'Content': ' version', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 184, 'Content': ' of', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 185, 'Content': ' soccer', 'Token size': 1, 'Time taken (ms)': 324.38}\n",
      "{'Count': 186, 'Content': ' began', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 187, 'Content': ' to', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 188, 'Content': ' take', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 189, 'Content': ' shape', 'Token size': 1, 'Time taken (ms)': 1.51}\n",
      "{'Count': 190, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 191, 'Content': ' England', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 192, 'Content': ' in', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 193, 'Content': ' the', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 194, 'Content': ' ', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 195, 'Content': '19', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 196, 'Content': 'th', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 197, 'Content': ' century', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 198, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 199, 'Content': ' Initially', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "{'Count': 200, 'Content': ',', 'Token size': 1, 'Time taken (ms)': 1}\n",
      "END:openai.ChatCompletion.create\n",
      "Total time taken 4.79 seconds to complete.\n",
      "\n",
      "Results Table:\n",
      "+------------+---------------+------------+-----------------+\n",
      "|   Count    |    Content    | Token size | Time taken (ms) |\n",
      "+------------+---------------+------------+-----------------+\n",
      "|     1      |     Sure      |     1      |     709.08      |\n",
      "|     2      |       ,       |     1      |      1.58       |\n",
      "|     3      |     here      |     1      |      1.95       |\n",
      "|     4      |      is       |     1      |      1.21       |\n",
      "|     5      |      an       |     1      |        1        |\n",
      "|     6      |     essay     |     1      |        1        |\n",
      "|     7      |      on       |     1      |        1        |\n",
      "|     8      |    soccer     |     1      |        1        |\n",
      "|     9      |       .       |     1      |       1.0       |\n",
      "|     10     |      Due      |     1      |        1        |\n",
      "|     11     |      to       |     1      |       1.0       |\n",
      "|     12     |      the      |     1      |        1        |\n",
      "|     13     |   platform    |     1      |       1.0       |\n",
      "|     14     |      's       |     1      |        1        |\n",
      "|     15     |  constraints  |     1      |        1        |\n",
      "|     16     |       ,       |     1      |        1        |\n",
      "|     17     |       I       |     1      |        1        |\n",
      "|     18     |     can't     |     2      |        1        |\n",
      "|     19     |    provide    |     1      |       1.0       |\n",
      "|     20     |       a       |     1      |        1        |\n",
      "|     21     |     full      |     1      |        1        |\n",
      "|     22     |               |     1      |        1        |\n",
      "|     23     |      500      |     1      |        1        |\n",
      "|     24     |       0       |     1      |        1        |\n",
      "|     25     |     words     |     1      |        1        |\n",
      "|     26     |      in       |     1      |        1        |\n",
      "|     27     |      one      |     1      |        1        |\n",
      "|     28     |      go       |     1      |        1        |\n",
      "|     29     |       ,       |     1      |        1        |\n",
      "|     30     |      but      |     1      |        1        |\n",
      "|     31     |     I'll      |     2      |       1.0       |\n",
      "|     32     |     give      |     1      |        1        |\n",
      "|     33     |      you      |     1      |        1        |\n",
      "|     34     |       a       |     1      |        1        |\n",
      "|     35     |   sizeable    |     2      |       3.0       |\n",
      "|     36     |    portion    |     1      |        1        |\n",
      "|     37     |      to       |     1      |     640.83      |\n",
      "|     38     |      get      |     1      |        1        |\n",
      "|     39     |    started    |     1      |        1        |\n",
      "|     40     |       .       |     1      |        1        |\n",
      "|     41     |     \\n\\n      |     3      |        1        |\n",
      "|     42     |    ---\\n\\n    |     4      |      6.95       |\n",
      "|     43     |      ###      |     1      |        1        |\n",
      "|     44     |      The      |     1      |       1.0       |\n",
      "|     45     |    Global     |     1      |        1        |\n",
      "|     46     |     Phen      |     1      |        1        |\n",
      "|     47     |     omen      |     1      |        1        |\n",
      "|     48     |      on       |     1      |        1        |\n",
      "|     49     |      of       |     1      |        1        |\n",
      "|     50     |    Soccer     |     1      |        1        |\n",
      "|     51     |     \\n\\n      |     2      |      1.02       |\n",
      "|     52     |     ####      |     1      |        1        |\n",
      "|     53     | Introduction  |     1      |        1        |\n",
      "|     54     |     \\n\\n      |     2      |        1        |\n",
      "|     55     |      Soc      |     2      |        1        |\n",
      "|     56     |      cer      |     1      |        1        |\n",
      "|     57     |       ,       |     1      |      1.57       |\n",
      "|     58     |     known     |     1      |        1        |\n",
      "|     59     |      as       |     1      |        1        |\n",
      "|     60     |   football    |     1      |      1.07       |\n",
      "|     61     |      in       |     1      |        1        |\n",
      "|     62     |     most      |     1      |      1.08       |\n",
      "|     63     |   countries   |     1      |        1        |\n",
      "|     64     |       ,       |     1      |        1        |\n",
      "|     65     |    stands     |     1      |        1        |\n",
      "|     66     |      as       |     1      |        1        |\n",
      "|     67     |      the      |     1      |        1        |\n",
      "|     68     |     world     |     1      |        1        |\n",
      "|     69     |      ’s       |     1      |      1.07       |\n",
      "|     70     |     most      |     1      |        1        |\n",
      "|     71     |    popular    |     1      |     472.87      |\n",
      "|     72     |      and      |     1      |        1        |\n",
      "|     73     |    beloved    |     1      |       1.0       |\n",
      "|     74     |     sport     |     1      |        1        |\n",
      "|     75     |       .       |     1      |        1        |\n",
      "|     76     |      Its      |     1      |        1        |\n",
      "|     77     |  simplicity   |     1      |        1        |\n",
      "|     78     |      and      |     1      |        1        |\n",
      "|     79     | accessibility |     1      |        1        |\n",
      "|     80     |     have      |     1      |        1        |\n",
      "|     81     |    allowed    |     1      |        1        |\n",
      "|     82     |      it       |     1      |        1        |\n",
      "|     83     |      to       |     1      |        1        |\n",
      "|     84     |   transcend   |     1      |       2.0       |\n",
      "|     85     |   cultural    |     1      |        1        |\n",
      "|     86     |       ,       |     1      |        1        |\n",
      "|     87     |   economic    |     1      |        1        |\n",
      "|     88     |       ,       |     1      |        1        |\n",
      "|     89     |      and      |     1      |        1        |\n",
      "|     90     | geographical  |     1      |      1.51       |\n",
      "|     91     |   barriers    |     1      |      1.02       |\n",
      "|     92     |       .       |     1      |      1.01       |\n",
      "|     93     |    Whether    |     1      |        1        |\n",
      "|     94     |      in       |     1      |        1        |\n",
      "|     95     |     urban     |     1      |        1        |\n",
      "|     96     |      meg      |     1      |     986.48      |\n",
      "|     97     |      ac       |     1      |      1.01       |\n",
      "|     98     |     ities     |     1      |        1        |\n",
      "|     99     |      or       |     1      |        1        |\n",
      "|    100     |     rural     |     1      |        1        |\n",
      "|    101     |  communities  |     1      |        1        |\n",
      "|    102     |       ,       |     1      |        1        |\n",
      "|    103     |    soccer     |     1      |        1        |\n",
      "|    104     |      has      |     1      |        1        |\n",
      "|    105     |  established  |     1      |        1        |\n",
      "|    106     |    itself     |     1      |        1        |\n",
      "|    107     |      as       |     1      |        1        |\n",
      "|    108     |      not      |     1      |        1        |\n",
      "|    109     |    merely     |     1      |        1        |\n",
      "|    110     |       a       |     1      |        1        |\n",
      "|    111     |     sport     |     1      |        1        |\n",
      "|    112     |       ,       |     1      |        1        |\n",
      "|    113     |      but      |     1      |        1        |\n",
      "|    114     |       a       |     1      |        1        |\n",
      "|    115     |  significant  |     1      |        1        |\n",
      "|    116     |   cultural    |     1      |        1        |\n",
      "|    117     |     force     |     1      |      1.03       |\n",
      "|    118     |       .       |     1      |        1        |\n",
      "|    119     |     This      |     1      |        1        |\n",
      "|    120     |     essay     |     1      |        1        |\n",
      "|    121     |      del      |     1      |        1        |\n",
      "|    122     |      ves      |     1      |        1        |\n",
      "|    123     |     into      |     1      |        1        |\n",
      "|    124     |      the      |     1      |        1        |\n",
      "|    125     |    intric     |     1      |        1        |\n",
      "|    126     |     acies     |     1      |     618.69      |\n",
      "|    127     |      of       |     1      |        1        |\n",
      "|    128     |    soccer     |     1      |       1.0       |\n",
      "|    129     |       ,       |     1      |        1        |\n",
      "|    130     |      its      |     1      |       1.0       |\n",
      "|    131     |    history    |     1      |        1        |\n",
      "|    132     |       ,       |     1      |        1        |\n",
      "|    133     |    global     |     1      |        1        |\n",
      "|    134     |   influence   |     1      |        1        |\n",
      "|    135     |       ,       |     1      |        1        |\n",
      "|    136     |   economic    |     1      |        1        |\n",
      "|    137     |    impact     |     1      |        1        |\n",
      "|    138     |       ,       |     1      |        1        |\n",
      "|    139     |      and      |     1      |        1        |\n",
      "|    140     |    social     |     1      |        1        |\n",
      "|    141     | significance  |     1      |        1        |\n",
      "|    142     |     .\\n\\n     |     3      |        1        |\n",
      "|    143     |     ####      |     1      |        1        |\n",
      "|    144     |    History    |     1      |        1        |\n",
      "|    145     |      of       |     1      |        1        |\n",
      "|    146     |    Soccer     |     1      |        1        |\n",
      "|    147     |     \\n\\n      |     2      |        1        |\n",
      "|    148     |      The      |     1      |        1        |\n",
      "|    149     |    origins    |     1      |        1        |\n",
      "|    150     |      of       |     1      |        1        |\n",
      "|    151     |    soccer     |     1      |        1        |\n",
      "|    152     |      can      |     1      |        1        |\n",
      "|    153     |      be       |     1      |        1        |\n",
      "|    154     |    traced     |     1      |        1        |\n",
      "|    155     |     back      |     1      |     612.13      |\n",
      "|    156     |      to       |     1      |       1.4       |\n",
      "|    157     |    ancient    |     1      |        1        |\n",
      "|    158     | civilizations |     1      |        1        |\n",
      "|    159     |       ,       |     1      |        1        |\n",
      "|    160     |     with      |     1      |      1.11       |\n",
      "|    161     |     early     |     1      |        1        |\n",
      "|    162     |     forms     |     1      |        1        |\n",
      "|    163     |      of       |     1      |        1        |\n",
      "|    164     |      the      |     1      |        1        |\n",
      "|    165     |     game      |     1      |        1        |\n",
      "|    166     |   appearing   |     1      |        1        |\n",
      "|    167     |      in       |     1      |        1        |\n",
      "|    168     |     China     |     1      |        1        |\n",
      "|    169     |    during     |     1      |        1        |\n",
      "|    170     |      the      |     1      |        1        |\n",
      "|    171     |      Han      |     1      |        1        |\n",
      "|    172     |    Dynasty    |     1      |      8.96       |\n",
      "|    173     |       ,       |     1      |        1        |\n",
      "|    174     |    Greece     |     1      |        1        |\n",
      "|    175     |       ,       |     1      |      1.02       |\n",
      "|    176     |      and      |     1      |        1        |\n",
      "|    177     |     Rome      |     1      |        1        |\n",
      "|    178     |       .       |     1      |        1        |\n",
      "|    179     |    However    |     1      |        1        |\n",
      "|    180     |       ,       |     1      |        1        |\n",
      "|    181     |      the      |     1      |        1        |\n",
      "|    182     |    modern     |     1      |        1        |\n",
      "|    183     |    version    |     1      |        1        |\n",
      "|    184     |      of       |     1      |        1        |\n",
      "|    185     |    soccer     |     1      |     324.38      |\n",
      "|    186     |     began     |     1      |        1        |\n",
      "|    187     |      to       |     1      |        1        |\n",
      "|    188     |     take      |     1      |        1        |\n",
      "|    189     |     shape     |     1      |      1.51       |\n",
      "|    190     |      in       |     1      |        1        |\n",
      "|    191     |    England    |     1      |        1        |\n",
      "|    192     |      in       |     1      |        1        |\n",
      "|    193     |      the      |     1      |        1        |\n",
      "|    194     |               |     1      |        1        |\n",
      "|    195     |      19       |     1      |        1        |\n",
      "|    196     |      th       |     1      |        1        |\n",
      "|    197     |    century    |     1      |        1        |\n",
      "|    198     |       .       |     1      |        1        |\n",
      "|    199     |   Initially   |     1      |        1        |\n",
      "|    200     |       ,       |     1      |        1        |\n",
      "| Cumulative |               |            |     4578.54     |\n",
      "+------------+---------------+------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import regex as re\n",
    "from tabulate import tabulate  \n",
    "\n",
    "payload = {        \n",
    "    \"messages\":start_phrase,\n",
    "    \"stream\":True,\n",
    "    \"max_tokens\":200\n",
    "    }\n",
    "\n",
    "results = []  \n",
    "\n",
    "try: \n",
    "    print(\"Begin:openai.ChatCompletion.create\")  \n",
    "    start_time_api_call = time.perf_counter()  # Initialize start_time before the loop  \n",
    "    with requests.post(url, headers=headers, json=payload, timeout=10, stream=True) as r:  \n",
    "        start_time = time.time()  # Initialize start_time before the loop  \n",
    "        prev_end_time = start_time  # Initialize prev_end_time to store the previous end_time  \n",
    "        count = 0  # Initialize a counter for chunks  \n",
    "        for chunk in r.iter_lines():  \n",
    "            if chunk:  # filter out keep-alive new lines  \n",
    "                try:  \n",
    "                    response_chunk = json.loads(chunk)  \n",
    "                except json.JSONDecodeError:  \n",
    "                    # Extract content from the chunk string  \n",
    "                    content_match = re.search(r'\"content\":\"(.*?)\"', chunk.decode('utf-8'))  \n",
    "                    if content_match:  \n",
    "                        count += 1  # Increment the counter  \n",
    "                        content = content_match.group(1)  \n",
    "  \n",
    "                        token_size = num_tokens_from_string(content, \"cl100k_base\")  \n",
    "  \n",
    "                        end_time = time.time()  \n",
    "                        time_taken = (end_time - prev_end_time) * 1000  # Subtract prev_end_time from start_time  \n",
    "                        time_taken = max(time_taken, 1)  # Set a minimum value of 0.01 ms for time_taken  \n",
    "                        time_taken = round(time_taken, 2)  # Round time_taken to 2 decimal places  \n",
    "  \n",
    "                        result = {\"Count\": count, \"Content\": content, \"Token size\": token_size, \"Time taken (ms)\": time_taken}  \n",
    "                        results.append(result)  \n",
    "  \n",
    "                        # Print the result as it is added to the list  \n",
    "                        print(result)  \n",
    "                        prev_end_time = end_time  # Update prev_end_time for the next iteration  \n",
    "  \n",
    "                    continue  \n",
    "  \n",
    "except requests.exceptions.Timeout:  \n",
    "    print(\"The request has timed out. Please try again.\")  \n",
    "\n",
    "print(\"END:openai.ChatCompletion.create\")  \n",
    "end_time_api_call = time.perf_counter() \n",
    "  \n",
    "# Calculate the time taken and print the result  \n",
    "time_taken = end_time_api_call - start_time_api_call  \n",
    "print(f'Total time taken {time_taken:.2f} seconds to complete.')  \n",
    "\n",
    "# Calculate the cumulative time  \n",
    "cumulative_time = sum(result[\"Time taken (ms)\"] for result in results)  \n",
    "cumulative_time = round(cumulative_time, 2)  # Round cumulative_time to 2 decimal places  \n",
    "  \n",
    "# Add the cumulative time to the results list as an extra row  \n",
    "results.append({\"Count\": \"Cumulative\", \"Content\": \"\", \"Token size\": \"\", \"Time taken (ms)\": cumulative_time})  \n",
    "  \n",
    "# Display results in tabular form  \n",
    "print(\"\\nResults Table:\")  \n",
    "print(tabulate([result.values() for result in results], headers=results[0].keys(), tablefmt=\"pretty\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The content for this response was already consumed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\upgrade-llm\\lib\\site-packages\\requests\\models.py:974\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\upgrade-llm\\lib\\site-packages\\requests\\models.py:926\u001b[0m, in \u001b[0;36mResponse.text\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    923\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    924\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding\n\u001b[1;32m--> 926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m:\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;66;03m# Fallback to auto-detected encoding.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\upgrade-llm\\lib\\site-packages\\requests\\models.py:897\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;66;03m# Read the contents.\u001b[39;00m\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed:\n\u001b[1;32m--> 897\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe content for this response was already consumed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The content for this response was already consumed"
     ]
    }
   ],
   "source": [
    "response = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import sys  \n",
    "\n",
    "\n",
    "\n",
    "base_url = \"https://myopenAI.openai.azure.com/\"\n",
    "deployment_name  = \"mydep\"\n",
    "api_key  =\"******\" \n",
    "\n",
    "\n",
    "url = base_url + \"/openai/deployments/\" + deployment_name + \"/chat/completions?api-version=2023-05-15\"\n",
    "start_phrase = [{\"role\":\"system\",\"content\":\"You are an AI assistant that helps people find information.\"},\n",
    "                {\"role\":\"user\",\"content\":\"Write 5000 word essay on soccer\"}]\n",
    "payload = {        \n",
    "    \"messages\":start_phrase,\n",
    "    \"stream\":True,\n",
    "    \"max_tokens\":200\n",
    "    }\n",
    "\n",
    "headers = {  \n",
    "    \"api-key\": api_key,  \n",
    "    \"Content-Type\": \"application/json\"  \n",
    "} \n",
    "print(\"Begin:openai.ChatCompletion.create\")\n",
    "start_time_api_call = time.time()\n",
    "\n",
    "  \n",
    "try:  \n",
    "    with requests.post(url, headers=headers, json=payload, timeout=1, stream=True) as r:  \n",
    "        start_time = time.time()  \n",
    "        for chunk in r.iter_content(chunk_size=None, decode_unicode=True):  \n",
    "            end_time = time.time()  \n",
    "            time_taken = (end_time - start_time) * 1000  # Convert to milliseconds  \n",
    "            chunk_size = sys.getsizeof(chunk)  \n",
    "  \n",
    "            print(f\"Time taken for this chunk: {time_taken:.2f} ms\")  \n",
    "            print(f\"Size of this chunk: {chunk_size} bytes\")  \n",
    "            start_time = end_time  \n",
    "  \n",
    "except requests.exceptions.Timeout:  \n",
    "    print(\"The request has timed out. Please try again.\")  \n",
    "        \n",
    "print(\"END:openai.ChatCompletion.create\")\n",
    "end_time_api_call  = time.time()\n",
    "# Calculate the time taken and print the result\n",
    "time_taken = end_time_api_call - start_time_api_call\n",
    "print(f'Total time taken {time_taken:.2f} seconds to complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['usage']['completion_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = AzureOpenAIBenchmarkStreaming(api_key=OPENAI_API_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=DEPLOYMENT_VERSION)\n",
    "await benchmark.make_call(deployment_name=DEPLOYMENT_ID, max_tokens=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting call to model gpt-4o-2024-05-13 with max tokens 100 at (Local time): 2024-06-26 23:18:31.243877, (GMT): 2024-06-27 04:18:31.243877+00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 471.37}\n",
      "{'Count': 2, 'Content': 'Certainly', 'Token size': 1, 'Time taken (ms)': 936.2}\n",
      "{'Count': 3, 'Content': '.', 'Token size': 1, 'Time taken (ms)': 50.16}\n",
      "{'Count': 4, 'Content': ' before', 'Token size': 1, 'Time taken (ms)': 954.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Finished call to model gpt-4o-2024-05-13. Time taken for chat: 3.29 seconds or 3293.49 milliseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Count': 5, 'Content': 'on', 'Token size': 1, 'Time taken (ms)': 798.28}\n",
      "{'Count': 6, 'Content': ' and', 'Token size': 1, 'Time taken (ms)': 53.11}\n",
      "\n",
      "Results Table:\n",
      "+-------+-----------+------------+-----------------+\n",
      "| Count |  Content  | Token size | Time taken (ms) |\n",
      "+-------+-----------+------------+-----------------+\n",
      "|   1   |           |     0      |     471.37      |\n",
      "|   2   | Certainly |     1      |      936.2      |\n",
      "|   3   |     .     |     1      |      50.16      |\n",
      "|   4   |  before   |     1      |     954.29      |\n",
      "|   5   |    on     |     1      |     798.28      |\n",
      "|   6   |    and    |     1      |      53.11      |\n",
      "|  TBT  |           |            |     558.41      |\n",
      "| TTFT  |           |            |      78.56      |\n",
      "| TTLT  |           |            |     3900.38     |\n",
      "+-------+-----------+------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "await benchmark.make_call(deployment_name=DEPLOYMENT_ID, max_tokens=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await benchmark.make_call(deployment_name=DEPLOYMENT_ID, max_tokens=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Count': 1, 'Content': '', 'Token size': 0, 'Time taken (ms)': 506.69},\n",
       " {'Count': 2, 'Content': 'The', 'Token size': 1, 'Time taken (ms)': 1280.25},\n",
       " {'Count': 3, 'Content': '###', 'Token size': 1, 'Time taken (ms)': 47.56},\n",
       " {'Count': 4, 'Content': ' Period', 'Token size': 1, 'Time taken (ms)': 804.1},\n",
       " {'Count': 5, 'Content': ' as', 'Token size': 1, 'Time taken (ms)': 47.9},\n",
       " {'Count': 6, 'Content': 'ro', 'Token size': 1, 'Time taken (ms)': 1098.75},\n",
       " {'Count': 7, 'Content': 'acy', 'Token size': 1, 'Time taken (ms)': 47.63},\n",
       " {'Count': 'TBT', 'Content': '', 'Token size': '', 'Time taken (ms)': 554.37},\n",
       " {'Count': 'TTFT', 'Content': '', 'Token size': '', 'Time taken (ms)': 84.45},\n",
       " {'Count': 'Cumulative',\n",
       "  'Content': '',\n",
       "  'Token size': '',\n",
       "  'Time taken (ms)': 4471.7}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "upgrade-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
